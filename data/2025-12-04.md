<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments](https://arxiv.org/abs/2512.03166)
*Aya Taourirte,Md Sohag Mia*

Main category: cs.RO

TL;DR: 本文提出一个统一的多智能体强化学习框架，通过分层强化学习和平均场理论解决动态对抗环境中的实时决策、复杂协作和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 在机器人足球等动态对抗环境中部署多智能体系统需要实时决策、复杂协作和可扩展算法以避免维度灾难。现有强化学习方法在处理多粒度任务（长期策略vs即时动作）和大规模智能体交互复杂性方面存在困难。

Method: 1. 基于客户端-服务器架构使用PPO建立实时动作调度基线；2. 引入基于选项框架的分层强化学习结构，将问题分解为高层轨迹规划层（建模为半马尔可夫决策过程）和低层动作执行层；3. 将平均场理论集成到HRL框架中，将多智能体交互简化为单个智能体与群体平均的交互。

Result: PPO基线表现优异（平均4.32个进球，82.9%控球率）；HRL结构提高了全局策略（平均进球增至5.26）；平均场演员-评论家方法实现显著性能提升（平均5.93个进球，89.1%控球率，92.3%传球准确率）和训练稳定性增强。

Conclusion: 在Webots环境中进行的4v4比赛广泛仿真验证了该方法，证明了其在复杂多智能体领域中实现鲁棒、可扩展和协作行为的潜力。

Abstract: The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.

</details>


### [2] [KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.03256)
*Albert H. Li,Ivan Dario Jimenez Rodriguez,Joel W. Burdick,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: KALIKO方法通过卡尔曼滤波隐式学习嵌入表示，实现长时域动力学预测，在波浪扰动补偿控制任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 长时域动力学预测在机器人学和控制领域至关重要，但许多系统由于非线性、混沌和高维特性难以建模。Koopman理论通过线性算子建模状态嵌入的演化，但显式计算合适的基函数很困难，且选择不当会导致预测不准确或过拟合。

Method: 提出KALIKO（Kalman-Implicit Koopman Operator Learning）方法，利用卡尔曼滤波隐式学习与潜在动力学对应的嵌入表示，无需显式编码器。该方法产生可解释的表示，保持全局线性潜在动力学。

Result: 在高维PDE生成的波浪数据上评估，KALIKO在开环预测和闭环控制任务中均超越多个基线方法。特别在稳定欠驱动机械臂载荷的任务中，能够有效预测和补偿强波浪扰动。

Conclusion: KALIKO通过隐式学习嵌入表示，成功解决了Koopman算子学习中的基函数选择问题，在复杂动力学系统的预测和控制任务中表现出色，为处理非线性、高维系统的长时域预测提供了有效方法。

Abstract: Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.

</details>


### [3] [GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation](https://arxiv.org/abs/2512.03347)
*William van den Bogert,Gregory Linkowski,Nima Fazeli*

Main category: cs.RO

TL;DR: GOMP是一种交互式模仿学习方法，通过将非刚性抓取物体约束到低维流形来减少累积误差，提高精确装配任务的轨迹精度。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在工业装配等重复性操作任务中具有潜力，但通常因累积误差导致轨迹精度不足而受限。需要一种方法来缓解这些误差，特别是在精确装配任务中。

Method: 提出Grasped Object Manifold Projection (GOMP)方法，将非刚性抓取物体约束到低维流形。所有增强都从训练基础模仿学习策略的同一专家数据集中学习，并通过n臂老虎机交互组件进行调整。

Result: 在四个精确装配任务上使用触觉反馈展示了该框架的有效性，并指出该方法保持模态无关性。提供了理论分析，证明GOMP改进了模仿学习文献中已知的累积误差界限。

Conclusion: GOMP通过流形投影和交互式调整有效减少了模仿学习中的累积误差，提高了精确装配任务的性能，为工业应用提供了有前景的解决方案。

Abstract: Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at williamvdb.github.io/GOMPsite.

</details>


### [4] [Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing](https://arxiv.org/abs/2512.03397)
*Seungwon Choi,Dong-Gyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: Surfel-LIO提出了一种基于层次体素结构和预计算面元表示的激光雷达惯性里程计方法，通过O(1)对应关系检索和Z-order曲线编码，在保持精度的同时显著提升了处理速度。


<details>
  <summary>Details</summary>
Motivation: 现有LIO系统存在两个主要问题：1）最近邻搜索需要检查多个空间单元以获取足够的点进行平面拟合；2）尽管地图几何未变，但平面参数通常在每个迭代中重新计算。这些因素限制了系统的效率。

Method: 提出Surfel-LIO方法，采用层次体素结构（hVox）和预计算的面元表示。该设计实现了O(1)时间复杂度的对应关系检索，无需运行时邻居枚举或平面拟合，并结合Z-order曲线编码实现缓存友好的空间索引。

Result: 在M3DGR数据集上的实验结果表明，该方法相比最近的最先进方法实现了显著更快的处理速度，同时保持了可比较的状态估计精度。

Conclusion: Surfel-LIO通过创新的层次体素结构和预计算面元表示，有效解决了现有LIO系统的效率瓶颈，在保持精度的同时大幅提升了处理速度，为实时状态估计提供了更高效的解决方案。

Abstract: LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at https://github.com/93won/lidar_inertial_odometry.

</details>


### [5] [What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models](https://arxiv.org/abs/2512.03422)
*Tianchen Deng,Yue Pan,Shenghai Yuan,Dong Li,Chen Wang,Mingrui Li,Long Chen,Lihua Xie,Danwei Wang,Jingchuan Wang,Javier Civera,Hesheng Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 这篇论文对机器人学中的场景表示方法进行了全面综述，涵盖传统方法（点云、体素、SDF、场景图）和神经表示（NeRF、3DGS、基础模型），分析它们在机器人五大模块（感知、建图、定位、导航、操作）中的应用，并探讨3D基础模型作为未来统一解决方案的发展趋势。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM和定位系统主要依赖稀疏表示（如点云和体素），但密集场景表示在下游任务（如导航和避障）中至关重要。神经表示方法（如NeRF、3DGS和基础模型）能够整合高级语义特征和语言先验，实现更全面的3D场景理解和具身智能。本文旨在为研究者和从业者提供关于3D场景表示在机器人中应用的全面资源。

Method: 将机器人核心模块分为五个部分（感知、建图、定位、导航、操作），系统性地呈现不同场景表示方法的标准公式化，并比较各模块中不同表示方法的优缺点。通过开源项目持续收集和更新相关工作和技术。

Result: 提供了机器人场景表示方法的全面分类和比较框架，识别了不同表示方法在不同机器人任务中的适用性和局限性。特别强调了3D基础模型作为未来统一解决方案的潜力，并指出了实现这一目标所面临的挑战。

Conclusion: 3D基础模型有望成为未来机器人应用的统一场景表示解决方案，能够整合语义特征和语言先验，实现更全面的场景理解和智能行为。然而，完全实现这一模型仍面临诸多挑战。本文为研究社区提供了有价值的参考资源，并通过开源项目促进该领域的持续发展。

Abstract: In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.

</details>


### [6] [MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization](https://arxiv.org/abs/2512.03522)
*Gihyeon Lee,Jungwoo Lee,Juwon Kim,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: 提出基于多标签似然的语义图匹配框架，用于解决机器人全局定位中的语义模糊性问题，通过多标签图表示和上下文感知似然传播来提升语义对应关系


<details>
  <summary>Details</summary>
Motivation: 在未知物体类别和语义模糊的环境中，机器人进行全局定位时，高语义模糊性会加剧物体误分类和错误关联，导致姿态估计出现显著误差

Method: 提出多标签似然语义图匹配框架，使用多标签图表示而非单标签表示来捕捉和利用物体观测的固有语义上下文，通过上下文感知似然传播结合节点似然与其邻居的最大似然来增强图间的语义对应关系

Result: 在闭集和开集检测配置下评估了数据关联和姿态估计性能，并在真实室内场景和合成环境中展示了方法对大词汇量物体类别的可扩展性

Conclusion: 提出的多标签图匹配框架能有效处理语义模糊性，提升机器人全局定位的准确性和鲁棒性，特别是在未知物体类别和语义模糊的环境中

Abstract: Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.

</details>


### [7] [AdaPower: Specializing World Foundation Models for Predictive Manipulation](https://arxiv.org/abs/2512.03538)
*Yuhang Huang,Shilong Zou,Jiazhao Zhang,Xinwang Liu,Ruizhen Hu,Kai Xu*

Main category: cs.RO

TL;DR: AdaPower框架通过轻量级适配将通用世界基础模型转化为专业世界模型，显著提升预训练视觉语言动作策略的机器人控制性能，在LIBERO基准上任务成功率提升超过41%


<details>
  <summary>Details</summary>
Motivation: 世界基础模型（WFMs）具有强大的视觉动态模拟能力，但将其应用于精确机器人控制时存在生成真实性与控制导向精度之间的差距。现有方法将WFMs用作合成数据生成器，但计算成本高且未充分利用预训练的VLA策略

Method: 提出AdaPower框架，包含两个核心组件：1）时空测试时训练（TS-TTT）用于推理时适配；2）记忆持久性（MP）用于长期一致性保持。该框架集成在模型预测控制框架内，将通用WFMs转化为专业世界模型

Result: 在LIBERO基准测试中，任务成功率提升超过41%，无需策略重新训练，同时保持计算效率和通用能力

Conclusion: AdaPower提供了一种轻量级适配方法，有效弥合了世界基础模型的生成能力与机器人控制需求之间的差距，显著提升了预训练视觉语言动作策略的性能

Abstract: World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

</details>


### [8] [A Learning-based Control Methodology for Transitioning VTOL UAVs](https://arxiv.org/abs/2512.03548)
*Zexin Lin,Yebin Zhong,Hanwen Wan,Jiu Cheng,Zhenglong Sun,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: 提出基于强化学习的耦合过渡控制方法ST3M，将巡航模式视为悬停特例，有效减少VTOL无人机过渡过程中的振动并提升轨迹跟踪性能


<details>
  <summary>Details</summary>
Motivation: VTOL无人机在过渡过程中由于倾斜转子机制导致重心和推力方向变化，现有解耦控制方法会产生显著振动，且限制了交互考虑和适应性

Method: 提出基于强化学习的耦合过渡控制方法ST3M，将巡航模式视为悬停的特殊情况，采用新的控制视角

Result: 在仿真和真实环境中验证了方法的可行性，实现了高效控制器开发和迁移，精确控制无人机位置和姿态，表现出优秀的轨迹跟踪能力和减少的过渡振动

Conclusion: ST3M方法为VTOL无人机过渡控制提供了新视角，通过强化学习驱动的耦合控制有效解决了传统方法的振动问题，提升了过渡过程的稳定性和适应性

Abstract: Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.

</details>


### [9] [Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations](https://arxiv.org/abs/2512.03630)
*Shifa Sulaiman,Amarnath H,Simon Bogh,Naresh Marturi*

Main category: cs.RO

TL;DR: 本文基于雅可比方法实现了3种运动规划方案，用于冗余机械臂与耦合手指夹爪的轨迹跟踪，比较了雅可比转置、伪逆和阻尼最小二乘三种逆解方法在轨迹平滑性、误差等方面的性能。


<details>
  <summary>Details</summary>
Motivation: 为冗余机械臂与耦合手指夹爪系统寻找高效的运动规划方案，通过比较不同雅可比逆解方法来确定适合特定任务的逆解技术。

Method: 使用RRT*算法进行轨迹规划，基于螺旋理论求解正向运动学方程，分别采用雅可比转置(JT)、伪逆(PI)和阻尼最小平方(DLS)三种方法计算逆解，并通过螺旋理论公式获得空间雅可比和可操作性度量。

Result: 分析了生成轨迹的平滑性和RMSE误差，以及关节运动的连续性、加速度分布、急动度和冲击值，通过仿真研究比较了三种运动规划方案的优缺点。

Conclusion: 确定了适合特定任务的最优逆解技术，为冗余机械臂与耦合夹爪系统提供了有效的运动规划方案选择依据。

Abstract: Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.

</details>


### [10] [Context-Triggered Contingency Games for Strategic Multi-Agent Interaction](https://arxiv.org/abs/2512.03639)
*Kilian Schweppe,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 提出了一种上下文触发应急博弈框架，将基于时序逻辑规范的战略博弈与实时动态应急博弈相结合，用于自主多智能体系统的可靠高效交互。


<details>
  <summary>Details</summary>
Motivation: 解决自主多智能体系统中长期战略目标与短期动态适应之间的平衡问题，确保在不确定、交互式环境中的安全性和进展性。

Method: 采用两层架构：1) 基于时序逻辑规范生成战略博弈的策略模板，保证高层目标满足；2) 基于因子图的新求解器实现可扩展的实时模型预测控制，处理动态交互。

Result: 通过自动驾驶和机器人导航的仿真和硬件实验验证，证明了该框架能够实现高效、可靠、自适应的多智能体交互。

Conclusion: 上下文触发应急博弈框架成功整合了战略规划与实时控制，为不确定交互环境中的多智能体系统提供了既安全又具进展性的解决方案。

Abstract: We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.

</details>


### [11] [A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection](https://arxiv.org/abs/2512.03684)
*Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 本文提出了一种自主番茄采摘系统，采用结合六个软负泊松比手指与刚性外骨骼的混合夹爪，通过视觉感知和闭环力控实现轻柔采摘，平均采摘周期24.34秒，成功率约80%。


<details>
  <summary>Details</summary>
Motivation: 开发能够在杂乱环境中可靠采摘番茄的自主系统，需要解决轻柔抓取、果实分离、果梗切割等挑战，同时应对遮挡和光照变化等视觉难题。

Method: 1. 混合夹爪设计：六个软负泊松比手指+刚性外骨骼+乳胶篮筐，形成笼式抓取；2. 视觉系统：RGB-D相机+Detectron2进行语义分割（成熟/未成熟番茄）和关键点定位（果梗和果实中心）；3. 力控：基于虚拟功原理建立伺服扭矩与抓取力关系模型，使用带力敏电阻反馈的PID控制器进行闭环力调节；4. 轨迹规划：基于粒子群优化算法的5自由度机械臂轨迹规划。

Result: 系统完成完整采摘周期（接近、分离、切割、抓取、运输、释放），平均周期时间24.34秒，总体成功率约80%，抓取力保持在0.20-0.50N的低水平，验证了混合夹爪和集成视觉控制管道在杂乱环境中的可靠性。

Conclusion: 提出的混合夹爪设计和集成视觉控制管道能够实现番茄的可靠、轻柔采摘，在杂乱环境中表现出良好的性能，为农业自动化提供了有效的解决方案。

Abstract: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

</details>


### [12] [ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration](https://arxiv.org/abs/2512.03707)
*Sundas Rafat Mulkana,Ronyu Yu,Tanaya Guha,Emma Li*

Main category: cs.RO

TL;DR: ContactRL是一个基于强化学习的框架，通过力反馈将接触安全直接纳入奖励函数，使机器人学习自适应运动策略以最小化人机接触力，同时保持任务效率。


<details>
  <summary>Details</summary>
Motivation: 在协作人机任务中，安全不仅需要避免碰撞，还需要确保安全、有意的物理接触。当前方法在接触安全方面存在不足，需要一种能够直接处理接触安全的框架。

Method: 提出ContactRL框架，通过力反馈将接触安全直接纳入强化学习的奖励函数，使机器人学习自适应运动策略。为确保部署安全，还使用基于动能的控制屏障函数(eCBF)屏蔽来增强学习策略。

Result: 在仿真中，ContactRL实现了0.2%的低安全违规率和87.7%的高任务成功率，优于最先进的约束RL基准。在UR3e机器人平台上进行的360次小物体从人手交接的真实世界实验中，测量的法向力始终低于10N，证实了安全接触。

Conclusion: ContactRL实现了安全高效的物理协作，推动了协作机器人在接触丰富任务中的部署，为人机协作提供了新的安全框架。

Abstract: In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\% with a high task success rate of 87.7\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.

</details>


### [13] [Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing](https://arxiv.org/abs/2512.03729)
*Samantha Chapin,Kenneth Stewart,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: APIARY实验首次在太空零重力环境中使用强化学习控制自由飞行机器人，通过NASA Astrobee在国际空间站上验证了RL在太空机器人控制中的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在太空零重力环境下控制自由飞行机器人的潜力，为太空探索、物流和实时任务需求开发快速部署的自主行为。

Method: 使用基于演员-评论家PPO算法的6自由度控制策略，在NVIDIA Isaac Lab仿真环境中训练，通过随机化目标位姿和质量分布增强鲁棒性，然后进行地面测试和太空飞行验证。

Result: 2025年5月27日成功在国际空间站上使用NASA Astrobee机器人实现了首次太空中的RL控制自由飞行器验证，证明了RL在太空环境中的可行性。

Conclusion: 这项在轨演示验证了强化学习在提高机器人自主性方面的变革潜力，能够为太空探索、物流和实时任务需求快速开发和部署定制化行为。

Abstract: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

</details>


### [14] [Cross-embodied Co-design for Dexterous Hands](https://arxiv.org/abs/2512.03743)
*Kehlani Fay,Darin Anthony Djapri,Anya Zorin,James Clinton,Ali El Lahib,Hao Su,Michael T. Tolley,Sha Yi,Xiaolong Wang*

Main category: cs.RO

TL;DR: 提出一个机器人手形态与控制策略的协同设计框架，能够在24小时内完成从设计、训练、制造到部署的全流程


<details>
  <summary>Details</summary>
Motivation: 灵巧操作受限于控制和设计，缺乏关于什么使机械手最适合执行灵巧任务的共识，需要解决如何设计和控制针对灵巧性优化的机器人机械手这一根本挑战

Method: 提出一个协同设计框架，学习任务特定的手形态和互补的灵巧控制策略，支持：1）包括关节、手指和手掌生成的广泛形态搜索空间；2）通过形态条件跨实体控制实现广泛设计空间的可扩展评估；3）使用可访问组件进行真实世界制造

Result: 在多个灵巧任务上评估该方法，包括模拟和真实部署中的手内旋转任务，框架实现了端到端流程，能够在24小时内设计、训练、制造和部署新的机器人手

Conclusion: 该框架解决了机器人手形态与控制协同设计的挑战，实现了快速迭代和部署，完整框架将开源并在网站上提供

Abstract: Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.

</details>


### [15] [Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models](https://arxiv.org/abs/2512.03756)
*Marlon Steiner,Royden Wagner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 该论文研究了如何将导航信息集成到基于注意力的运动预测模型中，以弥合多智能体运动预测与基于目标的运动规划之间的差距，在nuPlan数据集上评估了多种导航集成策略。


<details>
  <summary>Details</summary>
Motivation: 结合运动预测和运动规划为增强自动驾驶车辆与其他交通参与者之间的交互提供了有前景的框架，但这带来了两个挑战：如何基于导航目标进行预测，以及如何确保稳定且运动学可行的轨迹。本文主要解决第一个挑战，即如何将导航信息集成到运动预测模型中。

Method: 本文研究了将导航信息扩展到基于注意力的运动预测模型中的方法。通过将自车的预期路线和目标姿态集成到模型架构中，提出了多种架构导航集成策略，并在nuPlan数据集上对这些策略进行了评估。

Result: 研究结果表明，预测驱动的运动规划具有潜力，导航信息可以同时增强预测和规划任务。作者在GitHub上公开了实现代码。

Conclusion: 通过将导航信息集成到运动预测模型中，可以有效地弥合多智能体运动预测与基于目标的运动规划之间的差距，为预测驱动的运动规划提供了可行的解决方案。

Abstract: Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.

</details>


### [16] [Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control](https://arxiv.org/abs/2512.03772)
*Gabriele Fadini,Deepak Ingole,Tong Duy Son,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 提出基于贝叶斯优化的扭矩非线性模型预测控制自动调参框架，使用数字孪生优化MPC参数，在UR10e机械臂上实现末端轨迹精确跟踪


<details>
  <summary>Details</summary>
Motivation: 传统手动调参MPC参数耗时且难以达到最优性能，需要自动化方法来优化高维参数空间，提高机器人末端轨迹跟踪精度

Method: 采用稀疏轴对齐子空间贝叶斯优化(SAASBO)结合数字孪生，优化MPC成本函数权重和底层控制器增益，通过仿真模型安全探索高维参数空间

Result: 仿真结果显示跟踪性能提升41.9%，求解时间减少2.5%；实际机器人实验验证跟踪性能提升25.8%，证明方法的有效性

Conclusion: 数字孪生支持的自动参数优化对机器人操作至关重要，贝叶斯优化框架能显著提升非线性模型预测控制的性能

Abstract: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

</details>


### [17] [Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving](https://arxiv.org/abs/2512.03774)
*Johannes Fischer,Marlon Steiner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 将安全强化学习（SRL）与模型预测控制（MPC）结合，通过强化学习为MPC提供新的安全参考轨迹，突破传统凸近似限制，寻找全局最优解。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在自动驾驶运动规划中采用凸近似方法，虽然能实现实时性，但将解限制在子空间中，可能无法找到全局最优解。

Method: 提出SRL-MPC框架：1）使用约束强化学习（CRL）确保安全性；2）采用手工设计的基于能量函数的安全指数作为约束目标；3）学习状态相关的拉格朗日乘子与安全策略；4）将学习到的安全轨迹作为MPC的参考轨迹。

Result: 在高速公路场景实验中，该方法在安全性和性能指标上均优于单独的MPC和SRL方法。

Conclusion: 结合SRL和MPC能够突破传统凸近似的限制，在保证安全性的同时探索更优的全局解，提升自动驾驶运动规划的性能。

Abstract: Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

</details>


### [18] [MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving](https://arxiv.org/abs/2512.03795)
*Jia Hu,Zhexi Lian,Xuerun Yan,Ruiang Bi,Dou Shen,Yu Ruan,Haoran Wang*

Main category: cs.RO

TL;DR: MPCFormer：一种结合物理先验与数据驱动的可解释社交感知自动驾驶方法，通过Transformer学习多车社交交互动力学，在MPC框架下生成类人驾驶行为，显著提升交互能力和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在高度动态和交互性强的交通场景中难以表现出类人行为，主要问题在于缺乏对社交交互底层机制的理解，导致与周围车辆的交互能力有限。

Method: 提出MPCFormer方法：1）将社交交互动力学建模为离散状态空间表示，嵌入物理先验增强可解释性；2）通过Transformer编码器-解码器架构从自然驾驶数据中学习动力学系数；3）在MPC框架下利用学习到的社交交互动力学进行规划。

Result: 在NGSIM数据集上的开环评估显示，MPCFormer具有最优的社交交互感知能力，5秒长时预测的ADE低至0.86米。闭环实验中，在高强度交互场景（连续变道驶出匝道）中，规划成功率94.67%，驾驶效率提升15.75%，碰撞率从21.25%降至0.5%，优于前沿的强化学习规划器。

Conclusion: MPCFormer是首个显式建模多车社交交互动力学的方法，通过结合物理先验和数据驱动学习，在MPC框架下实现了可解释、安全且类人的自动驾驶行为，显著提升了自动驾驶在复杂交互场景中的性能。

Abstract: Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.

</details>


### [19] [IM HERE: Interaction Model for Human Effort Based Robot Engagement](https://arxiv.org/abs/2512.03828)
*Dominykas Strazdas,Magnus Jung,Jan Marquenie,Ingo Siegert,Ayoub Al-Hamadi*

Main category: cs.RO

TL;DR: 提出IM HERE框架，通过基于努力的描述建模人-人、人-机、机-机交互中的参与度，实现社会行为的自动化分析和自主系统的社会规范遵从


<details>
  <summary>Details</summary>
Motivation: 现有参与度定义和模型要么过于模糊，要么缺乏跨情境的泛化能力，难以支持有意义的人机交互。需要能够准确建模认知参与动态过程的框架，以实现自主系统的社会整合

Method: 引入IM HERE框架，采用基于努力的描述方法分析实体间的双边关系，将关系模式简化为焦点放置和四个关键状态。该框架能捕捉相互关系、群体行为和社会规范遵从，整合主观感知和客观状态

Result: 框架能准确分解关系模式，识别和描述沟通误解，为自主系统提供具体的行为指令。实现了社会行为的自动化分析、建模和描述

Conclusion: IM HERE框架能有效建模不同情境下的参与度，使自主系统既能遵从社会规范实现完全社会整合，又能追求自身的社会目标，为人机交互提供了理论基础

Abstract: The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.

</details>


### [20] [OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance](https://arxiv.org/abs/2512.03874)
*Lei Zhang,Diwen Zheng,Kaixin Bai,Zhenshan Bing,Zoltan-Csaba Marton,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: OmniDexVLG是一个多模态语义感知的灵巧抓取生成框架，通过联合语言和视觉指导生成结构多样且语义连贯的灵巧抓取姿势。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧抓取生成难以实现语义可控，主要挑战在于缺乏对抓取分类学、接触语义和功能可供性等多个语义维度的统一建模。

Method: 1) OmniDexDataGen：语义丰富的灵巧抓取数据集生成流水线，包含抓取分类学引导的配置采样、功能可供性接触点采样、分类学感知的微分力闭合抓取采样、基于物理的优化验证；2) OmniDexReasoner：多模态抓取类型语义推理模块，利用多智能体协作、检索增强生成和思维链推理；3) 统一的视觉语言抓取生成模型，显式结合抓取分类学、接触结构和功能可供性语义。

Result: 在仿真和真实世界物体抓取实验中，该方法在抓取多样性、接触语义多样性、功能可供性多样性和语义一致性方面显著优于现有最先进方法。

Conclusion: OmniDexVLG通过统一建模多个语义维度，实现了从自然语言指令进行细粒度控制的语义感知灵巧抓取生成，为任务需求对齐和人类可解释的抓取语义提供了有效解决方案。

Abstract: Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

</details>


### [21] [A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments](https://arxiv.org/abs/2512.03886)
*Brais Fontan-Costas,M. Diaz-Cacho,Ruben Fernandez-Boullon,Manuel Alonso-Carracedo,Javier Perez-Robles*

Main category: cs.RO

TL;DR: 提出了一种用于封闭赛道车辆的自主系统架构，包含计算机视觉、定位与建图、路径规划和控制系统，采用模块化设计和流水线架构实现实时自主导航。


<details>
  <summary>Details</summary>
Motivation: 为在封闭赛道环境中实现车辆的自主导航，需要开发一个能够执行精确任务的系统架构，包括环境感知、精确定位、轨迹规划和车辆控制等功能。

Method: 采用模块化设计，各子系统独立运行但通过流水线架构连接数据。系统包含计算机视觉用于环境感知、定位与建图用于精确定位、路径规划用于最优轨迹生成、控制模块用于精确车辆执行。

Result: 实现了一个结合最先进技术的自主系统，能够在受控环境中进行实时自主导航，各子系统协同工作完成精确任务。

Conclusion: 提出的自主系统架构通过模块化设计和流水线数据连接，成功实现了在封闭赛道环境中的车辆自主导航，为受控环境下的自主驾驶提供了有效解决方案。

Abstract: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

</details>


### [22] [Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning](https://arxiv.org/abs/2512.03891)
*Ying-Kuan Tsai,Yi-Ping Chen,Vispi Karkaria,Wei Chen*

Main category: cs.RO

TL;DR: 提出基于数字孪生的控制协同设计框架，结合深度强化学习和多代设计概念，优化整车主动悬架系统，实现个性化适应不同驾驶行为和环境不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统主动悬架系统受限于固定硬件设计和控制策略，无法适应不确定和动态的运行条件。数字孪生和深度强化学习为实时数据驱动优化提供了新机会，但将这些技术集成到统一框架中仍存在挑战。

Method: 提出数字孪生控制协同设计框架，将自动微分集成到深度强化学习中，联合优化物理悬架组件和控制策略。采用多代设计概念，通过分位数学习进行模型更新以捕捉数据不确定性，处理部分可观测性问题。

Result: 在温和和激进两种驾驶设置下，优化系统实现了更平滑的轨迹，控制努力分别减少约43%和52%，同时保持乘坐舒适性和稳定性。

Conclusion: 开发了集成深度强化学习和不确定性感知模型更新的数字孪生控制协同设计框架，引入多代设计策略实现自改进系统，展示了针对不同驾驶类型的主动悬架系统个性化优化。

Abstract: Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.

</details>


### [23] [Hierarchical Vision Language Action Model Using Success and Failure Demonstrations](https://arxiv.org/abs/2512.03913)
*Jeongeun Park,Jihwan Yoon,Byungwoo Jeon,Juhan Park,Jinwoo Shin,Namhoon Cho,Kyungjae Lee,Sangdoo Yun,Sungjoon Choi*

Main category: cs.RO

TL;DR: VINE模型利用混合质量数据集（成功与失败演示）进行训练，通过分层架构将高层推理与底层控制分离，利用失败数据作为结构化学习信号来提升机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型通常只使用成功的遥操作演示数据，忽略了大量自然收集过程中的失败尝试。这些失败数据包含了策略脆弱性的重要信息，可用于提升模型鲁棒性。

Method: 提出VINE分层模型：System 2进行高层推理，在2D场景图抽象上执行可行性引导的树搜索，提出子目标转换，从成功和失败中预测成功概率，并在执行前修剪脆弱分支；System 1执行底层动作而不修改核心技能。完全基于离线遥操作数据训练，将负面经验直接整合到决策循环中。

Result: 在具有挑战性的操作任务中，该方法持续提高了成功率和鲁棒性，证明失败数据是将VLA模型的广泛能力转化为鲁棒执行的重要资源。

Conclusion: 失败数据是提升视觉-语言-动作模型鲁棒性的关键资源，通过分层架构将失败作为结构化学习信号而非噪声监督，能够有效提高机器人操作的可靠性和成功率。

Abstract: Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.

</details>


### [24] [Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response](https://arxiv.org/abs/2512.03936)
*Aron Distelzweig,Yiwei Wang,Faris Janjoš,Marcel Hallgarten,Mihai Dobre,Alexander Langmann,Joschka Boedecker,Johannes Betz*

Main category: cs.RO

TL;DR: BIBeR框架将运动预测与博弈论规划统一为交互感知过程，通过迭代最优响应循环实现双向适应，在交互场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶规划系统在常规场景表现良好，但在密集城市交通中仍面临挑战。现有方法要么简单丢弃不安全计划，要么采用端到端单向集成，缺乏对联合预测与规划不确定性的建模。博弈论方法虽有理论优势但应用有限。

Method: 提出贝叶斯迭代最优响应（BIBeR）框架，将先进预测器集成到迭代最优响应循环中，通过重复优化自车和周围车辆策略来近似纳什均衡。引入贝叶斯置信度估计量化预测可靠性，根据置信度调节更新强度。

Result: 在高度交互的interPlan变道场景中，BIBeR比最先进规划器提升11%性能，同时在标准nuPlan基准测试中也优于现有方法。

Conclusion: BIBeR成功统一了运动预测和博弈论规划，结合了结构化规划的透明性和学习模型的灵活性，为自动驾驶在密集交互场景中的决策提供了有效解决方案。

Abstract: Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.

</details>


### [25] [MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation](https://arxiv.org/abs/2512.03958)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: MDE-AgriVLN方法通过单目深度估计增强农业机器人的空间感知能力，在农业视觉语言导航任务中显著提升了导航成功率并降低了导航误差。


<details>
  <summary>Details</summary>
Motivation: 当前农业机器人主要依赖人工操作或轨道系统移动，且通常只配备单目摄像头，导致空间感知能力有限。农业视觉语言导航（AgriVLN）虽然将VLN扩展到农业领域，但单目视觉限制了机器人的导航性能。

Method: 提出MDE-AgriVLN方法，引入单目深度估计（MDE）模块，从RGB图像生成深度特征，辅助决策模块进行空间推理，从而增强农业机器人的导航能力。

Result: 在A2A基准测试中，MDE-AgriVLN将成功率从0.23提升到0.32，导航误差从4.43米降低到4.08米，实现了农业VLN领域的最先进性能。

Conclusion: 单目深度估计能有效增强农业机器人的空间感知能力，显著提升农业视觉语言导航的性能，为农业自主导航提供了新的技术方案。

Abstract: Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.

</details>


### [26] [Artificial Microsaccade Compensation: Stable Vision for an Ornithopter](https://arxiv.org/abs/2512.03995)
*Levi Burner,Guido de Croon,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 提出"人工微扫视补偿"方法，通过SO(3)表示优化3D旋转来稳定视频，特别适用于12-20Hz抖动的无尾扑翼机拍摄，实现实时无失真稳定效果，优于Adobe Premiere Pro的变形稳定器。


<details>
  <summary>Details</summary>
Motivation: 受人类等动物微扫视现象的启发，解决无尾扑翼机因12-20Hz抖动而无法使用相机传感的问题，开发实时视频稳定方法。

Method: 通过优化SO(3)表示的3D旋转来最小化图像强度变化，实现视频稳定；采用递归更新提高效率，并可调整为固定视角方向。

Result: 方法能实时生成无失真的稳定视频，显著减少帧间运动；与Adobe Premiere Pro变形稳定器相比，质量更高且实时运行。

Conclusion: 人工微扫视补偿方法成功解决了扑翼机视频稳定问题，提供高质量实时稳定效果，在视频稳定领域具有应用价值。

Abstract: Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for "Artificial Microsaccade Compensation". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.

</details>
