<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Design and Biomechanical Evaluation of a Lightweight Low-Complexity Soft Bilateral Ankle Exoskeleton](https://arxiv.org/abs/2602.18569)
*Josée Mallah,Zakii Javed,Zafer Azak,Thomas Stone,Luigi G. Occhipinti*

Main category: cs.RO

TL;DR: 开发了一款轻量、低复杂度、柔软的双侧踝关节外骨骼，用于跖屈辅助，可安装在任意鞋上，不影响健康步态


<details>
  <summary>Details</summary>
Motivation: 许多人（无论是医疗还是非医疗目的）都能从步态外骨骼辅助中受益，但传统外骨骼存在重量大、结构复杂的问题，需要补偿这些缺点

Method: 设计了轻量、低复杂度的柔软双侧踝关节外骨骼，采用鞋面附着设计，可安装在任意鞋上；开发了控制系统，并在零扭矩模式下进行实验测试

Result: 实验测试显示，在零扭矩模式下穿戴外骨骼与不穿戴外骨骼相比，下肢运动学和动力学没有显著差异，证明设备不阻碍健康步态，是顺应性良好且舒适的设备

Conclusion: 该外骨骼设备具有提供有效辅助的潜力，控制系统已开发完成，正在进行进一步的测试

Abstract: Many people could benefit from exoskeleton assistance during gait, for either medical or nonmedical purposes. But exoskeletons bring added mass and structure, which in turn require compensating for. In this work, we present a lightweight, low-complexity, soft bilateral ankle exoskeleton for plantarflexion assistance, with a shoe attachment design that can be mounted on top of any pair of shoes. Experimental tests show no significant difference in lower limb kinematics and kinetics when wearing the exoskeleton in zero-torque mode relative to not wearing an exoskeleton, showing that our device does not obstruct healthy gait, and proving it as a compliant and comfortable device, promising to provide effective assistance. Hence, a control system was developed, and additional tests are underway.

</details>


### [2] [Enhancing Goal Inference via Correction Timing](https://arxiv.org/abs/2602.18603)
*Anjiabei Wang,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: 研究探索机器人从人类纠正反馈中学习的新方法，重点关注纠正时机作为学习信号的价值


<details>
  <summary>Details</summary>
Motivation: 现有研究将纠正视为新演示或偏好，但忽略了人类决定干预机器人行为的时机这一关键信号，该时机受多种因素影响

Method: 研究纠正时机作为学习信号，探索其在三个潜在应用中的价值：识别触发纠正的机器人运动特征、快速推断纠正目标、学习更精确的任务约束

Result: 纠正时机在前两个应用中（识别触发特征和快速推断目标）显著改善了学习效果

Conclusion: 纠正时机作为机器人学习信号具有重要价值，为机器人从人类反馈中学习提供了新视角

Abstract: Corrections offer a natural modality for people to provide feedback to a robot, by (i) intervening in the robot's behavior when they believe the robot is failing (or will fail) the task objectives and (ii) modifying the robot's behavior to successfully fulfill the task. Each correction offers information on what the robot should and should not do, where the corrected behavior is more aligned with task objectives than the original behavior. Most prior work on learning from corrections involves interpreting a correction as a new demonstration (consisting of the modified robot behavior), or a preference (for the modified trajectory compared to the robot's original behavior). However, this overlooks one essential element of the correction feedback, which is the human's decision to intervene in the robot's behavior in the first place. This decision can be influenced by multiple factors including the robot's task progress, alignment with human expectations, dynamics, motion legibility, and optimality. In this work, we investigate whether the timing of this decision can offer a useful signal for inferring these task-relevant influences. In particular, we investigate three potential applications for this learning signal: (1) identifying features of a robot's motion that may prompt people to correct it, (2) quickly inferring the final goal of a human's correction based on the timing and initial direction of their correction motion, and (3) learning more precise constraints for task objectives. Our results indicate that correction timing results in improved learning for the first two of these applications. Overall, our work provides new insights on the value of correction timing as a signal for robot learning.

</details>


### [3] [OVerSeeC: Open-Vocabulary Costmap Generation from Satellite Images and Natural Language](https://arxiv.org/abs/2602.18606)
*Rwik Rana,Jesse Quattrociocchi,Dongmyeong Lee,Christian Ellis,Amanda Adkins,Adam Uccello,Garrett Warnell,Joydeep Biswas*

Main category: cs.RO

TL;DR: OVerSeeC是一个零样本模块化框架，通过分解为解释-定位-合成三个步骤，直接从卫星图像生成用于长距离规划的全局成本图，能够处理自然语言表达的实体和任务特定穿越规则。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖固定本体和静态成本映射，无法适应任务需求变化、部署时未知地形实体以及用户提示中编码的组合穿越逻辑。虽然基础模型在语言理解和开放词汇感知方面表现出色，但没有单一模型能同时解析细微的任务指令、在大规模图像中定位任意实体，并将它们合成为规划器可执行的成本函数。

Method: 提出OVerSeeC框架，将问题分解为三个模块：1) LLM提取实体和排序偏好；2) 开放词汇分割管道从高分辨率图像中识别这些实体；3) LLM使用用户的自然语言偏好和掩码合成可执行的成本图代码。

Result: 实验表明，OVerSeeC能够处理新颖实体、尊重排序和组合偏好，并在不同区域产生与人工绘制轨迹一致的路径，展示了对分布偏移的鲁棒性。

Conclusion: 基础模型的模块化组合能够实现开放词汇、偏好对齐的成本图生成，为可扩展、任务自适应的全局规划提供了有效解决方案。

Abstract: Aerial imagery provides essential global context for autonomous navigation, enabling route planning at scales inaccessible to onboard sensing. We address the problem of generating global costmaps for long-range planning directly from satellite imagery when entities and mission-specific traversal rules are expressed in natural language at test time. This setting is challenging since mission requirements vary, terrain entities may be unknown at deployment, and user prompts often encode compositional traversal logic. Existing approaches relying on fixed ontologies and static cost mappings cannot accommodate such flexibility. While foundation models excel at language interpretation and open-vocabulary perception, no single model can simultaneously parse nuanced mission directives, locate arbitrary entities in large-scale imagery, and synthesize them into an executable cost function for planners. We therefore propose OVerSeeC, a zero-shot modular framework that decomposes the problem into Interpret-Locate-Synthesize: (i) an LLM extracts entities and ranked preferences, (ii) an open-vocabulary segmentation pipeline identifies these entities from high-resolution imagery, and (iii) the LLM uses the user's natural language preferences and masks to synthesize executable costmap code. Empirically, OVerSeeC handles novel entities, respects ranked and compositional preferences, and produces routes consistent with human-drawn trajectories across diverse regions, demonstrating robustness to distribution shifts. This shows that modular composition of foundation models enables open-vocabulary, preference-aligned costmap generation for scalable, mission-adaptive global planning.

</details>


### [4] [FORMICA: Decision-Focused Learning for Communication-Free Multi-Robot Task Allocation](https://arxiv.org/abs/2602.18622)
*Antonio Lopez,Jack Muirhead,Carlo Pinciroli*

Main category: cs.RO

TL;DR: FORMICA：一种无需机器人间通信的学习型多机器人任务分配框架，通过预测队友出价实现隐式协调，在有限带宽环境下显著提升系统性能


<details>
  <summary>Details</summary>
Motivation: 现有多机器人任务分配方法依赖通信解决冲突，但在带宽受限、基础设施退化或对抗干扰环境下性能急剧下降，需要无需通信的协调方案

Method: 提出FORMICA框架，通过预测队友出价分布实现隐式协调，采用端到端训练最小化任务分配遗憾而非预测误差，使用均值场近似将复杂度从O(NT)降至O(T)

Result: 在16机器人64任务场景中提升系统奖励17%，接近最优MILP解；在256机器人4096任务场景中提升7%，训练仅需21秒，展现良好泛化能力

Conclusion: FORMICA在无需通信条件下实现了高质量任务分配，通过预测出价分布纠正分析均值场近似的系统性误差，适应任务聚类和空间异质性，具有实际部署价值

Abstract: Most multi-robot task allocation methods rely on communication to resolve conflicts and reach consistent assignments. In environments with limited bandwidth, degraded infrastructure, or adversarial interference, existing approaches degrade sharply. We introduce a learning-based framework that achieves high-quality task allocation without any robot-to-robot communication. The key idea is that robots coordinate implicitly by predicting teammates' bids: if each robot can anticipate competition for a task, it can adjust its choices accordingly. Our method predicts bid distributions to correct systematic errors in analytical mean-field approximations. While analytical predictions assume idealized conditions (uniform distributions, known bid functions), our learned approach adapts to task clustering and spatial heterogeneity. Inspired by Smart Predict-then-Optimize (SPO), we train predictors end-to-end to minimize Task Allocation Regret rather than prediction error. To scale to large swarms, we develop a mean-field approximation where each robot predicts the distribution of competing bids rather than individual bids, reducing complexity from $O(NT)$ to $O(T)$. We call our approach FORMICA: Field-Oriented Regret-Minimizing Implicit Coordination Algorithm. Experiments show FORMICA substantially outperforms a natural analytical baseline. In scenarios with 16 robots and 64 tasks, our approach improves system reward by 17% and approaches the optimal MILP solution. When deployed on larger scenarios (256 robots, 4096 tasks), the same model improves performance by 7%, demonstrating strong generalization. Training requires only 21 seconds on a laptop, enabling rapid adaptation to new environments.

</details>


### [5] [Soft Surfaced Vision-Based Tactile Sensing for Bipedal Robot Applications](https://arxiv.org/abs/2602.18638)
*Jaeeun Kim,Junhee Lim,Yu She*

Main category: cs.RO

TL;DR: 该论文提出了一种用于双足机器人的软表面视觉触觉脚传感器，通过光学捕捉接触变形，将足地交互转化为丰富的触觉信号，从而提升机器人的平衡控制和地形感知能力。


<details>
  <summary>Details</summary>
Motivation: 腿式运动受益于具身感知，其中感知源于身体与环境之间的物理交互。现有机器人主要依赖本体感知，缺乏对足地接触的丰富触觉反馈，限制了平衡控制和地形适应能力。

Method: 开发了软表面视觉触觉脚传感器，在双足机器人脚部安装皮肤状可变形层，通过光学捕捉接触变形。从接触图像流中估计接触姿态（位置和方向）、可视化剪切力、计算压力中心、分类地形并检测接触斑块的几何特征。

Result: 在倾斜平台和视觉遮挡条件下验证了传感器能力，显示足部触觉反馈相比仅依赖本体感知能显著改善平衡控制和地形感知。触觉感知提高了机器人的稳定性、适应性和环境意识。

Conclusion: 将触觉感知集成到腿式机器人脚部可以改善稳定性、适应性和环境意识，为实现更柔顺和智能的运动系统提供了有前景的方向。

Abstract: Legged locomotion benefits from embodied sensing, where perception emerges from the physical interaction between body and environment. We present a soft-surfaced, vision-based tactile foot sensor that endows a bipedal robot with a skin-like deformable layer that captures contact deformations optically, turning foot-ground interactions into rich haptic signals. From a contact image stream, our method estimates contact pose (position and orientation), visualizes shear, computes center of pressure (CoP), classifies terrain, and detects geometric features of the contact patch. We validate these capabilities on a tilting platform and in visually obscured conditions, showing that foot-borne tactile feedback improves balance control and terrain awareness beyond proprioception alone. These findings suggest that integrating tactile perception into legged robot feet improves stability, adaptability, and environmental awareness, offering a promising direction toward more compliant and intelligent locomotion systems. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw

</details>


### [6] [Robotic Fruits with Tunable Stiffness and Sensing: Towards a Methodology for Developing Realistic Physical Twins of Fruits](https://arxiv.org/abs/2602.18661)
*Saitarun Nadipineni,Keshav Pandiyan,Kaspar Althoefer,Shinichi Hirai,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: 开发可调谐的软物理孪生体来模拟不同成熟度水果的刚度特性，为机器人抓取器提供可持续、可控的测试平台


<details>
  <summary>Details</summary>
Motivation: 农业食品行业面临劳动力短缺、供应链中断等问题，机器人采摘成为有前景的替代方案。然而，由于天然水果机械特性高度可变，评估和训练软抓取器对易损水果的抓取非常困难。现有测试方法依赖大量真实水果，导致效率低下、成本高昂和浪费。

Method: 开发可调谐的软物理孪生体，模拟真实水果在不同成熟度下的刚度特性。设计并制造了猕猴桃的纤维增强气动物理孪生体，能够复制不同成熟度水平的刚度。

Result: 物理孪生体的刚度可以在多次试验中精确调谐（97.35-99.43%准确度）。使用商业机器人抓取器进行的抓取任务显示，物理孪生体的传感器反馈能够反映施加的抓取力。经过50次循环的应力测试显示，所需刚度能够可靠维持（0.56-1.10%误差）。

Conclusion: 机器人物理孪生体能够调整其刚度以模拟真实水果，为机器人抓取器的基准测试和训练提供了可持续、可控的平台，有望解决农业机器人领域的关键挑战。

Abstract: The global agri-food sector faces increasing challenges from labour shortages, high consumer demand, and supply-chain disruptions, resulting in substantial losses of unharvested produce. Robotic harvesting has emerged as a promising alternative; however, evaluating and training soft grippers for delicate fruits remains difficult due to the highly variable mechanical properties of natural produce. This makes it difficult to establish reliable benchmarks or data-driven control strategies. Existing testing practices rely on large quantities of real fruit to capture this variability, leading to inefficiency, higher costs, and waste. The methodology presented in this work aims to address these limitations by developing tunable soft physical twins that emulate the stiffness characteristics of real fruits at different ripeness levels. A fiber-reinforced pneumatic physical twin of a kiwi fruit was designed and fabricated to replicate the stiffness at different ripeness levels. Experimental results show that the stiffness of the physical twin can be tuned accurately over multiple trials (97.35 - 99.43% accuracy). Gripping tasks with a commercial robotic gripper showed that sensor feedback from the physical twin can reflect the applied gripping forces. Finally, a stress test was performed over 50 cycles showed reliable maintenance of desired stiffness (0.56 - 1.10% error). This work shows promise that robotic physical twins could adjust their stiffness to resemble that of real fruits. This can provide a sustainable, controllable platform for benchmarking and training robotic grippers.

</details>


### [7] [Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL)](https://arxiv.org/abs/2602.18663)
*Harry Robertshaw,Nikola Fischer,Lennart Karstensen,Benjamin Jackson,Xingyu Chen,S. M. Hadi Sadati,Christos Bergeles,Alejandro Granados,Thomas C Booth*

Main category: cs.RO

TL;DR: 本文提出了一种分层模块化多智能体强化学习框架，用于自主双设备血管内导航，在体外实验中实现了从股动脉到颈内动脉的自主导航，展示了在机械取栓应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 机械取栓是治疗大血管闭塞性急性缺血性脑卒中的最佳方法，但受地理和后勤障碍限制，可及性有限。强化学习在自主血管内导航中显示出潜力，但在"长"导航任务中的泛化能力仍然具有挑战性。

Method: 提出分层模块化多智能体强化学习框架，将复杂的双设备导航任务分解为专门的子任务，每个子任务使用Soft Actor-Critic强化学习进行训练。框架在体外和计算机模拟测试平台上进行验证。

Result: 计算机模拟中，单一血管模型在个体解剖结构上达到92-100%成功率，多血管模型在多个患者解剖结构上达到56-80%成功率。体外实验中，两种HM-MARL模型从股动脉到右颈总动脉的成功率为100%，到右颈内动脉为80%，但在左侧血管的超人挑战中失败。

Conclusion: 该研究首次展示了机械取栓血管内体外自主导航。虽然HM-MARL能够实现跨解剖结构的泛化，但模拟到现实的转换带来了挑战。未来工作将使用世界模型改进强化学习策略，并在未见过的体外数据上验证性能，推动自主机械取栓向临床转化。

Abstract: Mechanical thrombectomy (MT) is typically the optimal treatment for acute ischemic stroke involving large vessel occlusions, but access is limited due to geographic and logistical barriers. Reinforcement learning (RL) shows promise in autonomous endovascular navigation, but generalization across 'long' navigation tasks remains challenging. We propose a Hierarchical Modular Multi-Agent Reinforcement Learning (HM-MARL) framework for autonomous two-device navigation in vitro, enabling efficient and generalizable navigation. HM-MARL was developed to autonomously navigate a guide catheter and guidewire from the femoral artery to the internal carotid artery (ICA). A modular multi-agent approach was used to decompose the complex navigation task into specialized subtasks, each trained using Soft Actor-Critic RL. The framework was validated in both in silico and in vitro testbeds to assess generalization and real-world feasibility. In silico, a single-vasculature model achieved 92-100% success rates on individual anatomies, while a multi-vasculature model achieved 56-80% across multiple patient anatomies. In vitro, both HM-MARL models successfully navigated 100% of trials from the femoral artery to the right common carotid artery and 80% to the right ICA but failed on the left-side vessel superhuman challenge due to the anatomy and catheter type used in navigation. This study presents the first demonstration of in vitro autonomous navigation in MT vasculature. While HM-MARL enables generalization across anatomies, the simulation-to-real transition introduces challenges. Future work will refine RL strategies using world models and validate performance on unseen in vitro data, advancing autonomous MT towards clinical translation.

</details>


### [8] [Scout-Rover cooperation: online terrain strength mapping and traversal risk estimation for planetary-analog explorations](https://arxiv.org/abs/2602.18688)
*Shipeng Liu,J. Diego Caporale,Yifeng Zhang,Xingjue Liao,William Hoganson,Wilson Hu,Shivangi Misra,Neha Peddinti,Rachel Holladay,Ethan Fulcher,Akshay Ram Panyam,Andrik Puentes,Jordan M. Bretzfelder,Michael Zanetti,Uland Wong,Daniel E. Koditschek,Mark Yim,Douglas Jerolmack,Cynthia Sung,Feifei Qian*

Main category: cs.RO

TL;DR: 提出了一种腿式侦察机器人与轮式漫游车协同框架，通过腿式机器人的本体感知腿-地形交互在线估计松软土壤强度，构建地形图并评估轮式漫游车通行风险，实现危险变形地形下的安全导航。


<details>
  <summary>Details</summary>
Motivation: 行星表面科学探测需要进入松散、可变形表土区域（如火星沙丘、月球陨石坑），但这些地形对传统轮式漫游车存在高风险。现有方法缺乏对地形力学特性的实时感知能力，限制了科学探测范围。

Method: 采用腿式机器人作为移动侦察员，利用其腿-地形交互的本体感知数据在线估计表土强度；构建空间分辨率地形图；结合漫游车运动模型评估通行风险；进行风险感知路径规划。

Result: 在NASA艾姆斯月球模拟试验场和白沙沙丘场的模拟任务验证中，成功实现了：(1) 腿式运动在线地形强度测绘；(2) 漫游车特定通行风险评估；(3) 风险感知路径规划避免危险区域。侦察生成的地形图能可靠捕捉空间变异并预测移动故障模式。

Conclusion: 通过将具身地形感知与异构漫游车协同相结合，该框架增强了操作鲁棒性，扩展了可变形行星环境中可到达的科学工作空间，为危险地形探测提供了安全有效的解决方案。

Abstract: Robot-aided exploration of planetary surfaces is essential for understanding geologic processes, yet many scientifically valuable regions, such as Martian dunes and lunar craters, remain hazardous due to loose, deformable regolith. We present a scout-rover cooperation framework that expands safe access to such terrain using a hybrid team of legged and wheeled robots. In our approach, a high-mobility legged robot serves as a mobile scout, using proprioceptive leg-terrain interactions to estimate regolith strength during locomotion and construct spatially resolved terrain maps. These maps are integrated with rover locomotion models to estimate traversal risk and inform path planning.
  We validate the framework through analogue missions at the NASA Ames Lunar Simulant Testbed and the White Sands Dune Field. Experiments demonstrate (1) online terrain strength mapping from legged locomotion and (2) rover-specific traversal-risk estimation enabling safe navigation to scientific targets. Results show that scout-generated terrain maps reliably capture spatial variability and predict mobility failure modes, allowing risk-aware path planning that avoids hazardous regions. By combining embodied terrain sensing with heterogeneous rover cooperation, this framework enhances operational robustness and expands the reachable science workspace in deformable planetary environments.

</details>


### [9] [CLASH: Collision Learning via Augmented Sim-to-real Hybridization to Bridge the Reality Gap](https://arxiv.org/abs/2602.18707)
*Haotian He,Ning Guo,Siqi Shi,Qipeng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: CLASH框架通过少量真实数据学习碰撞模型，创建高保真混合仿真器，显著缩小sim-to-real差距，提升策略迁移成功率


<details>
  <summary>Details</summary>
Motivation: 传统物理引擎在模拟接触丰富的动力学（如碰撞）时，往往为了计算速度而牺牲准确性，导致仿真与现实之间存在差距，阻碍了仿真训练策略的直接部署

Method: 提出CLASH框架：首先从不完美的仿真器（MuJoCo）中蒸馏出基础模型以获取物理先验知识，然后用极少量的真实世界交互数据（仅需10个样本）进行微调，纠正仿真器的固有误差，从而创建高保真混合仿真器

Result: 混合仿真器不仅预测准确性更高，还将碰撞计算时间减少了近50%；使用该仿真器训练的策略在现实世界中迁移更稳健，在顺序推动任务中强化学习的成功率翻倍，基于模型控制的任务性能也显著提升

Conclusion: CLASH框架通过数据高效的方式学习碰撞模型，有效缩小sim-to-real差距，为机器人策略从仿真到现实的稳健迁移提供了可行方案

Abstract: The sim-to-real gap, particularly in the inaccurate modeling of contact-rich dynamics like collisions, remains a primary obstacle to deploying robot policies trained in simulation. Conventional physics engines often trade accuracy for computational speed, leading to discrepancies that prevent direct policy transfer. To address this, we introduce Collision Learning via Augmented Sim-to-real Hybridization (CLASH), a data-efficient framework that creates a high-fidelity hybrid simulator by learning a surrogate collision model from a minimal set of real-world data. In CLASH, a base model is first distilled from an imperfect simulator (MuJoCo) to capture general physical priors; this model is then fine-tuned with a remarkably small number of real-world interactions (as few as 10 samples) to correct for the simulator's inherent inaccuracies. The resulting hybrid simulator not only achieves higher predictive accuracy but also reduces collision computation time by nearly 50\%. We demonstrate that policies obtained with our hybrid simulator transfer more robustly to the real world, doubling the success rate in sequential pushing tasks with reinforecement learning and significantly increase the task performance with model-based control.

</details>


### [10] [Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation](https://arxiv.org/abs/2602.18716)
*Hoseong Jung,Sungil Son,Daesol Cho,Jonghae Park,Changhyun Choi,H. Jin Kim*

Main category: cs.RO

TL;DR: TART是一个用于战术资源控制和后续机动生成的时序动作表示学习框架，通过对比学习和互信息目标捕捉资源-机动交互的时序依赖关系，在迷宫导航和空战模拟中优于现有混合动作基线。


<details>
  <summary>Details</summary>
Motivation: 自主机器人系统在有限能量预算或受限感知条件下需要推理资源控制及其对后续机动的影响。现有的混合动作空间方法未能充分捕捉资源使用与机动之间的因果依赖关系，也忽视了战术决策的多模态特性，而这些在快速演变的场景中至关重要。

Method: 提出TART框架，利用基于互信息目标的对比学习来捕捉资源-机动交互中的固有时序依赖关系。学习到的表示被量化为离散码本条目，用于条件化策略，从而捕捉重复出现的战术模式并实现多模态和时序一致的行为。

Result: 在两个关键领域进行评估：(1)迷宫导航任务，其中有限的离散动作预算提供增强的移动能力；(2)高保真空战模拟器，F-16智能体协调使用武器和防御系统与飞行机动。在两个领域中，TART始终优于混合动作基线方法。

Conclusion: TART框架能够有效利用有限资源并产生上下文感知的后续机动，在需要战术资源控制的自主机器人系统中表现出优越性能，特别是在快速演变的动态环境中。

Abstract: Autonomous robotic systems should reason about resource control and its impact on subsequent maneuvers, especially when operating with limited energy budgets or restricted sensing. Learning-based control is effective in handling complex dynamics and represents the problem as a hybrid action space unifying discrete resource usage and continuous maneuvers. However, prior works on hybrid action space have not sufficiently captured the causal dependencies between resource usage and maneuvers. They have also overlooked the multi-modal nature of tactical decisions, both of which are critical in fast-evolving scenarios. In this paper, we propose TART, a Temporal Action Representation learning framework for Tactical resource control and subsequent maneuver generation. TART leverages contrastive learning based on a mutual information objective, designed to capture inherent temporal dependencies in resource-maneuver interactions. These learned representations are quantized into discrete codebook entries that condition the policy, capturing recurring tactical patterns and enabling multi-modal and temporally coherent behaviors. We evaluate TART in two domains where resource deployment is critical: (i) a maze navigation task where a limited budget of discrete actions provides enhanced mobility, and (ii) a high-fidelity air combat simulator in which an F-16 agent operates weapons and defensive systems in coordination with flight maneuvers. Across both domains, TART consistently outperforms hybrid-action baselines, demonstrating its effectiveness in leveraging limited resources and producing context-aware subsequent maneuvers.

</details>


### [11] [RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning](https://arxiv.org/abs/2602.18742)
*Seungku Kim,Suhyeok Jang,Byungjun Yoon,Dongyoung Kim,John Won,Jinwoo Shin*

Main category: cs.RO

TL;DR: RoboCurate是一个机器人合成数据生成框架，通过模拟重放验证生成视频中的动作质量，并利用图像编辑和视频转换增强数据多样性，显著提升机器人学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型生成的合成数据存在动作质量不一致的问题，而视觉语言模型在验证视频质量时无法准确评估物理准确性和动作本身的质量。

Method: 提出RoboCurate框架：1）在模拟器中重放预测动作，通过比较模拟轨迹与生成视频的运动一致性来评估动作质量；2）使用图像到图像编辑解锁超出可用数据集的观察多样性；3）应用动作保持的视频到视频转换来增强外观。

Result: 相比仅使用真实数据，RoboCurate生成的数据在多个任务上取得显著改进：GR-1 Tabletop（300演示）+70.1%，DexMimicGen预训练设置+16.1%，ALLEX人形机器人灵巧操作+179.9%。

Conclusion: RoboCurate通过模拟重放验证动作质量并结合数据增强技术，有效解决了合成机器人数据质量不一致的问题，显著提升了机器人学习性能。

Abstract: Synthetic data generated by video generative models has shown promise for robot learning as a scalable pipeline, but it often suffers from inconsistent action quality due to imperfectly generated videos. Recently, vision-language models (VLMs) have been leveraged to validate video quality, but they have limitations in distinguishing physically accurate videos and, even then, cannot directly evaluate the generated actions themselves. To tackle this issue, we introduce RoboCurate, a novel synthetic robot data generation framework that evaluates and filters the quality of annotated actions by comparing them with simulation replay. Specifically, RoboCurate replays the predicted actions in a simulator and assesses action quality by measuring the consistency of motion between the simulator rollout and the generated video. In addition, we unlock observation diversity beyond the available dataset via image-to-image editing and apply action-preserving video-to-video transfer to further augment appearance. We observe RoboCurate's generated data yield substantial relative improvements in success rates compared to using real data only, achieving +70.1% on GR-1 Tabletop (300 demos), +16.1% on DexMimicGen in the pre-training setup, and +179.9% in the challenging real-world ALLEX humanoid dexterous manipulation setting.

</details>


### [12] [Learning to Localize Reference Trajectories in Image-Space for Visual Navigation](https://arxiv.org/abs/2602.18803)
*Finn Lukas Busch,Matti Vahs,Quantao Yang,Jesús Gerardo Ortega Peimbert,Yixi Cai,Jana Tumova,Olov Andersson*

Main category: cs.RO

TL;DR: LoTIS是一个机器人无关的视觉导航模型，通过将参考RGB轨迹定位到机器人当前视图中，提供图像空间引导，无需相机标定、位姿或机器人特定训练。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航方法通常与特定机器人绑定，需要相机标定、位姿信息或机器人特定训练，限制了方法的通用性和部署便利性。

Method: 预测参考轨迹在机器人当前视图中的图像空间坐标，而非特定机器人的动作，实现感知与动作的解耦。采用跨轨迹训练策略增强对视角和相机变化的鲁棒性。

Result: 在传统前向导航中比最先进方法提升20-50个百分点，在模拟和真实环境中达到94-98%的成功率。在反向遍历等挑战性任务上实现5倍以上改进。

Conclusion: LoTIS提供了一种简单有效的机器人无关视觉导航方案，仅需手机视频即可让不同机器人沿轨迹导航，实现了零样本跨机器人部署。

Abstract: We present LoTIS, a model for visual navigation that provides robot-agnostic image-space guidance by localizing a reference RGB trajectory in the robot's current view, without requiring camera calibration, poses, or robot-specific training. Instead of predicting actions tied to specific robots, we predict the image-space coordinates of the reference trajectory as they would appear in the robot's current view. This creates robot-agnostic visual guidance that easily integrates with local planning. Consequently, our model's predictions provide guidance zero-shot across diverse embodiments. By decoupling perception from action and learning to localize trajectory points rather than imitate behavioral priors, we enable a cross-trajectory training strategy for robustness to viewpoint and camera changes. We outperform state-of-the-art methods by 20-50 percentage points in success rate on conventional forward navigation, achieving 94-98% success rate across diverse sim and real environments. Furthermore, we achieve over 5x improvements on challenging tasks where baselines fail, such as backward traversal. The system is straightforward to use: we show how even a video from a phone camera directly enables different robots to navigate to any point on the trajectory. Videos, demo, and code are available at https://finnbusch.com/lotis.

</details>


### [13] [Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model](https://arxiv.org/abs/2602.18813)
*Tommoro Robotics,:,Jesoon Kang,Taegeon Park,Jisu An,Soo Min Kimm,Jaejoon Kim,Jinu Pahk,Byungju Kim,Junseok Lee,Namheon Baek,Sungwan Ha,Hojun Baek,Eduardo Ayerve Cruz,Wontae Kim,Junghyeon Choi,Yousuk Lee,Joonmo Han,Sunghyun Cho,Sunghyun Kwon,Soyoung Lee,Jun Ki Lee,Seung-Joon Yi,Byoung-Tak Zhang,Theo Taeyeong Kim*

Main category: cs.RO

TL;DR: Habilis-β是一个用于真实世界部署的快速运动、长时运行的设备端视觉-语言-动作模型，通过生产力-可靠性平面评估框架，在连续运行测试中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前VLA评估主要局限于单次试验成功率，无法捕捉实际应用中所需的快速运动和长时运行能力，需要新的评估框架来反映真实部署需求。

Method: 整合无语言预训练获取交互先验，后训练捕捉状态漂移；采用ESPADA进行相位自适应运动整形加速自由空间移动，使用整流流蒸馏实现边缘设备高频控制，部署时通过CFG动态平衡指令遵循和交互先验。

Result: 在1小时连续运行评估中，Habilis-β在模拟环境中达到572.6 TPH和39.2秒MTBI，真实世界物流工作流中达到124 TPH和137.4秒MTBI，显著优于π0.5基线，并在RoboTwin 2.0排行榜上取得最高性能。

Conclusion: Habilis-β通过创新的评估框架PRP和系统设计，在快速运动和长时运行能力上表现出色，为真实世界VLA部署提供了有效解决方案。

Abstract: We introduce Habilis-$β$, a fast-motion and long-lasting on-device vision-language-action (VLA) model designed for real-world deployment. Current VLA evaluation remains largely confined to single-trial success rates under curated resets, which fails to capture the fast-motion and long-lasting capabilities essential for practical operation. To address this, we introduce the Productivity-Reliability Plane (PRP), which evaluates performance through Tasks per Hour (TPH) and Mean Time Between Intervention (MTBI) under a continuous-run protocol that demands both high-speed execution and sustained robustness. Habilis-$β$ achieves high performance by integrating language-free pre-training on large-scale play data for robust interaction priors with post-training on cyclic task demonstrations that capture state drift across consecutive task iterations. The system further employs ESPADA for phase-adaptive motion shaping to accelerate free-space transit, utilizes rectified-flow distillation to enable high-frequency control on edge devices, and incorporates classifier-free guidance (CFG) as a deployment-time knob to dynamically balance instruction adherence and learned interaction priors. In 1-hour continuous-run evaluations, Habilis-$β$ achieves strong performance under the PRP metrics, compared to $π_{0.5}$ in both simulation and real-world environments. In simulation, Habilis-$β$ achieves 572.6 TPH and 39.2 s MTBI (vs. 120.5 TPH and 30.5 s for $π_{0.5}$), while in a real-world humanoid logistics workflow it achieves 124 TPH and 137.4 s MTBI (vs. 19 TPH and 46.1 s for $π_{0.5}$). Finally, Habilis-$β$ achieves the highest reported performance on the standard RoboTwin 2.0 leaderboard across representative tasks, validating its effectiveness in complex manipulation scenarios.

</details>


### [14] [RotorSuite: A MATLAB/Simulink Toolbox for Tilt Multi-Rotor UAV Modeling](https://arxiv.org/abs/2602.18814)
*Nicola Cigarini,Giulia Michieletto,Angelo Cenedese*

Main category: cs.RO

TL;DR: 开发了一个名为RotorSuite的MATLAB/Simulink工具箱，用于建模和模拟各类多旋翼平台的动力学特性


<details>
  <summary>Details</summary>
Motivation: 随着空中平台从被动飞行传感器发展为接触感知机器人系统，平台设计快速进步，但准确建模这些新兴平台的过程耗时、依赖用户且容易出错

Method: 提出了一个MATLAB/Simulink工具箱，通过解析和基于物理的方法来建模和模拟各类多旋翼平台的动力学特性

Result: 开发了名为RotorSuite的工具箱，提供全面的文档和示例用例，适用于教学、研究和工业开发

Conclusion: RotorSuite工具箱为多旋翼平台的建模和仿真提供了一个有价值的工具，简化了分析、控制和验证过程

Abstract: In recent years, aerial platforms have evolved from passive flying sensors into versatile, contact-aware robotic systems, leading to rapid advances in platform design. Standard coplanar and collinear quadrotors have been complemented by modern tilted and tilting multi-rotor platforms with enhanced maneuverability. To properly analyze, control, and validate the performance of these emerging platforms, an accurate modeling step is required; however, this can be time-consuming, user-dependent and error-prone. To address this issue, we propose a MATLAB/Simulink toolbox for modeling and simulating the dynamics of a broad class of multi-rotor platforms through both an analytical and physics-based approaches. The toolbox, named RotorSuite, is provided with comprehensive documentation and example use cases, representing a valuable tool for didactic, research, and industrial development purposes.

</details>


### [15] [GRAB: A Systematic Real-World Grasping Benchmark for Robotic Food Waste Sorting](https://arxiv.org/abs/2602.18835)
*Moniesha Thilakarathna,Xing Wang,Min Wang,David Hinwood,Shuangzhe Liu,Damith Herath*

Main category: cs.RO

TL;DR: GRAB框架通过整合多样化变形物体、先进视觉抓取姿态估计和抓取前条件，为食品废物分类中的机器人抓取提供了全面的基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 食品废物管理对可持续发展至关重要，但无机污染物阻碍了回收潜力。机器人自动化通过自动污染物去除加速分类过程，但污染物的多样性和不可预测性给机器人抓取带来重大挑战。现有基准测试框架依赖有限的模拟数据集，优先考虑简单的成功率指标，忽视了关键的物体和环境相关的抓取前条件。

Method: 提出了GRAB（Grasping Real-World Article Benchmarking）框架，整合了多样化变形物体、先进的抓取姿态估计视觉系统，以及关键的抓取前条件。通过四个高保真场景中的1,750次食品污染物抓取尝试，系统比较了工业抓取模式。

Result: 大规模评估揭示了不同抓取器的优势和局限性。在杂乱环境中，物体质量成为主导性能因素，而视觉质量和杂乱程度起中等作用。物体质量对抓取性能的影响比视觉质量或杂乱程度更大。

Conclusion: 研究结果强调了关键的设计考虑因素，并强调了开发能够实现稳健跨类别性能的多模态抓取器技术的必要性，以实现有效的机器人食品废物分类。

Abstract: Food waste management is critical for sustainability, yet inorganic contaminants hinder recycling potential. Robotic automation presents a compelling approach to this challenge by accelerating the sorting process through automated contaminant removal. Still, the diverse and unpredictable nature of contaminants creates major challenges for robotic grasping. Benchmarking frameworks are critical for evaluating challenges from various perspectives. However, existing protocols rely on limited simulation datasets, prioritise simple metrics such as success rate, and overlook key object and environment-related pre-grasp conditions. This paper introduces GRAB, a comprehensive Grasping Real-World Article Benchmarking framework that addresses this gap by integrating diverse deformable objects, advanced grasp-pose-estimation vision, and, importantly, pre-grasp conditions, establishing a set of critical graspability metrics. It systematically compares industrial grasping modalities through an in-depth experimental evaluation involving 1,750 food contaminant grasp attempts across four high-fidelity scenes. This large-scale evaluation provides an extensive assessment of grasp performance for food waste sorting, offering a level of depth that has rarely been explored in previous studies. The results reveal distinct gripper strengths and limitations, with object quality emerging as the dominant performance factor in cluttered environments, while vision quality and clutter levels play moderate roles. These findings highlight essential design considerations and reinforce the necessity of developing multimodal gripper technologies capable of robust cross-category performance for effective robotic food waste sorting.

</details>


### [16] [When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor](https://arxiv.org/abs/2602.18850)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 该研究比较了四种人机协作意图沟通系统：两种意图预测模型（基于力预测和增强速度预测）和两种显式沟通方法（按钮界面和语音命令），在移动社交机器人IVO上进行物体搬运协作任务测试。结果显示，当系统达到足够性能后，人类不再注意到技术改进；人们更喜欢更自然的系统（即使故障率更高）；最佳方案是预测与显式沟通的结合。


<details>
  <summary>Details</summary>
Motivation: 由于人类行为的随机性导致意图预测模型存在不确定性，一些研究者开始倡导使用显式沟通系统来明确获取人类意图。本研究旨在比较意图预测系统和显式沟通系统在人机协作物体搬运任务中的表现，探索哪种沟通方式更有效。

Method: 研究使用IVO移动社交机器人（配备力传感器和LiDAR），在5-7米距离的障碍环境中进行物体搬运协作任务。比较四种系统：1）基于力预测的意图预测器；2）增强速度预测算法；3）按钮界面；4）语音命令识别系统。75名志愿者完成255次实验，分为三组：第一轮测试推理系统，第二轮测试沟通系统，第三轮测试组合策略。

Result: 实验结果发现：1）一旦系统达到足够性能，人类不再注意到技术改进并给予积极评价；2）人类更喜欢更自然的系统（如语音命令），即使这些系统的故障率更高；3）最受青睐的方案是预测系统与显式沟通系统的恰当组合。

Conclusion: 在人机协作意图沟通中，单纯的技术改进在达到一定阈值后不再被用户感知。用户偏好更自然的交互方式，即使这意味着更高的故障率。最优的人机协作沟通策略应该是预测性系统与显式沟通系统的智能结合，既能利用预测提高效率，又能通过显式沟通确保意图的准确传达。

Abstract: Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one based on force prediction and another with an enhanced velocity prediction algorithm) and two explicit communication methods (a button interface and a voice-command recognition system). These systems were integrated into IVO, a custom mobile social robot equipped with force sensor to detect the force exchange between both agents and LiDAR to detect the environment. The collaborative task required transporting an object over a 5-7 meter distance with obstacles in the middle, demanding rapid decisions and precise physical coordination. 75 volunteers perform a total of 255 executions divided into three groups, testing inference systems in the first round, communication systems in the second, and the combined strategies in the third. The results show that, 1) once sufficient performance is achieved, the human no longer notices and positively assesses technical improvements; 2) the human prefers systems that are more natural to them even though they have higher failure rates; and 3) the preferred option is the right combination of both systems.

</details>


### [17] [Gait Asymmetry from Unilateral Weakness and Improvement With Ankle Assistance: a Reinforcement Learning based Simulation Study](https://arxiv.org/abs/2602.18862)
*Yifei Yuan,Ghaith Androwis,Xianlian Zhou*

Main category: cs.RO

TL;DR: 使用强化学习模拟框架研究单侧肌肉无力对步态对称性的影响，并评估踝关节外骨骼辅助的改善效果


<details>
  <summary>Details</summary>
Motivation: 单侧肌肉无力会导致不对称步态，破坏肢体间协调和站立时间。本研究旨在量化渐进性单侧肌肉无力对步态对称性的影响，并评估踝关节外骨骼辅助在受损条件下的改善效果，为患者实验前的早期控制器开发建立仿真和学习工作流程

Method: 采用基于强化学习的肌肉骨骼仿真框架，通过将右腿肌肉力量减少到基线水平的75%、50%和25%来诱导不对称步态。使用离地时间、峰值接触力和关节级对称性指标量化步态不对称性，并评估踝关节外骨骼辅助的效果

Result: 随着肌肉无力的增加，时间和运动学不对称性逐渐增大，踝关节最为明显。踝关节活动范围对称性从100%力量时的接近对称（SI=+6.4%，r=0.974）恶化到25%力量时的严重不对称（SI=-47.1%，r=0.889），同时负荷向未受损肢体转移。在50%力量时，踝关节外骨骼辅助改善了运动学对称性，将踝关节SI从25.8%降低到18.5%，相关性从r=0.948提高到0.966，尽管峰值负荷仍偏向未受损侧

Conclusion: 该框架支持对损伤严重程度和辅助策略的受控评估，为未来在人体实验中的验证提供了基础，展示了强化学习仿真在步态康复研究中的应用潜力

Abstract: Unilateral muscle weakness often leads to asymmetric gait, disrupting interlimb coordination and stance timing. This study presents a reinforcement learning (RL) based musculoskeletal simulation framework to (1) quantify how progressive unilateral muscle weakness affects gait symmetry and (2) evaluate whether ankle exoskeleton assistance can improve gait symmetry under impaired conditions. The overarching goal is to establish a simulation- and learning-based workflow that supports early controller development prior to patient experiments. Asymmetric gait was induced by reducing right-leg muscle strength to 75%, 50%, and 25% of baseline. Gait asymmetry was quantified using toe-off timing, peak contact forces, and joint-level symmetry metrics. Increasing weakness produced progressively larger temporal and kinematic asymmetry, most pronounced at the ankle. Ankle range of motion symmetry degraded from near-symmetric behavior at 100% strength (symmetry index, SI = +6.4%; correlation r=0.974) to severe asymmetry at 25% strength (SI = -47.1%, r=0.889), accompanied by a load shift toward the unimpaired limb. At 50% strength, ankle exoskeleton assistance improved kinematic symmetry relative to the unassisted impaired condition, reducing the magnitude of ankle SI from 25.8% to 18.5% and increasing ankle correlation from r=0.948 to 0.966, although peak loading remained biased toward the unimpaired side. Overall, this framework supports controlled evaluation of impairment severity and assistive strategies, and provides a basis for future validation in human experiments.

</details>


### [18] [Equivalence and Divergence of Bayesian Log-Odds and Dempster's Combination Rule for 2D Occupancy Grids](https://arxiv.org/abs/2602.18872)
*Tatiana Berlenko,Kirill Krinkin*

Main category: cs.RO

TL;DR: 本文提出了一种基于pignistic变换的方法论，用于公平比较贝叶斯对数几率与Dempster组合规则在占据栅格地图构建中的表现，通过匹配每个观测的决策概率来隔离融合规则与传感器参数化的影响。


<details>
  <summary>Details</summary>
Motivation: 需要一种公平的方法来比较贝叶斯融合和Dempster组合规则在占据栅格地图构建中的性能，避免传感器参数化对比较结果的影响。

Method: 采用基于pignistic变换的方法论，通过匹配每个观测的决策概率来隔离融合规则与传感器参数化的影响。在BetP匹配和归一化似真性匹配两种条件下进行测试。

Result: 在BetP匹配条件下，贝叶斯融合在模拟、两个真实激光雷达数据集以及下游路径规划任务中均表现更优（15/15方向一致性，p = 3.1e-5），绝对差异较小（0.001-0.022）。在归一化似真性匹配条件下，结果方向反转，表明结果依赖于匹配准则的选择。

Conclusion: 该方法论为未来任何贝叶斯/信念函数比较提供了可重复使用的框架，同时表明比较结果高度依赖于所选择的匹配准则。

Abstract: We introduce a pignistic-transform-based methodology for fair comparison of Bayesian log-odds and Dempster's combination rule in occupancy grid mapping, matching per-observation decision probabilities to isolate the fusion rule from sensor parameterization. Under BetP matching across simulation, two real lidar datasets, and downstream path planning, Bayesian fusion is consistently favored (15/15 directional consistency, p = 3.1e-5) with small absolute differences (0.001-0.022). Under normalized plausibility matching, the direction reverses, confirming the result is matching-criterion-specific. The methodology is reusable for any future Bayesian/belief function comparison.

</details>


### [19] [Temporal-Logic-Aware Frontier-Based Exploration](https://arxiv.org/abs/2602.18951)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 提出一种基于承诺状态的未知环境下机器人时态逻辑运动规划方法，用于处理标签位置未知的scLTL规范任务


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在未知环境中执行时态逻辑任务的问题，当期望标签的确切位置事先未知时，需要设计能够有效探索并完成任务的方法

Method: 引入承诺状态概念，捕捉不可逆动作带来的中间任务进展；提出基于前沿的探索算法，在向任务进展的同时保留所有可能的满足方式

Result: 提出的方法是可靠且完备的，能够战略性地引导机器人向任务进展，同时保持所有可能的任务满足路径

Conclusion: 通过承诺状态和前沿探索算法，有效解决了未知环境下时态逻辑运动规划问题，仿真验证了方法的有效性

Abstract: This paper addresses the problem of temporal logic motion planning for an autonomous robot operating in an unknown environment. The objective is to enable the robot to satisfy a syntactically co-safe Linear Temporal Logic (scLTL) specification when the exact locations of the desired labels are not known a priori. We introduce a new type of automaton state, referred to as commit states. These states capture intermediate task progress resulting from actions whose consequences are irreversible. In other words, certain future paths to satisfaction become not feasible after taking those actions that lead to the commit states. By leveraging commit states, we propose a sound and complete frontier-based exploration algorithm that strategically guides the robot to make progress toward the task while preserving all possible ways of satisfying it. The efficacy of the proposed method is validated through simulations.

</details>


### [20] [TactEx: An Explainable Multimodal Robotic Interaction Framework for Human-Like Touch and Hardness Estimation](https://arxiv.org/abs/2602.18967)
*Felix Verstraete,Lan Wei,Wen Fan,Dandan Zhang*

Main category: cs.RO

TL;DR: TactEx是一个可解释的多模态机器人交互框架，融合视觉、触觉和语言进行类人硬度估计和交互指导，在水果成熟度评估任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确感知物体硬度对于安全和灵巧的接触密集型机器人操作至关重要，需要结合触觉感知和上下文理解。

Method: 系统融合GelSight-Mini触觉流、RGB观察和语言提示，使用ResNet50+LSTM模型从序列触觉数据估计硬度，跨模态对齐模块结合视觉线索和大语言模型指导，比较YOLO和Grounded-SAM进行接触点选择。

Result: 系统能够显著区分不同成熟度水平（所有水果对的p<0.01），在简单用户查询上达到90%任务成功率，并能泛化到新任务而无需大规模调优。

Conclusion: 结合预训练的视觉和触觉模型与语言基础化，有望推进机器人中可解释的、类人的触觉感知和决策制定。

Abstract: Accurate perception of object hardness is essential for safe and dexterous contact-rich robotic manipulation. Here, we present TactEx, an explainable multimodal robotic interaction framework that unifies vision, touch, and language for human-like hardness estimation and interactive guidance. We evaluate TactEx on fruit-ripeness assessment, a representative task that requires both tactile sensing and contextual understanding. The system fuses GelSight-Mini tactile streams with RGB observations and language prompts. A ResNet50+LSTM model estimates hardness from sequential tactile data, while a cross-modal alignment module combines visual cues with guidance from a large language model (LLM). This explainable multimodal interface allows users to distinguish ripeness levels with statistically significant class separation (p < 0.01 for all fruit pairs). For touch placement, we compare YOLO with Grounded-SAM (GSAM) and find GSAM to be more robust for fine-grained segmentation and contact-site selection. A lightweight LLM parses user instructions and produces grounded natural-language explanations linked to the tactile outputs. In end-to-end evaluations, TactEx attains 90% task success on simple user queries and generalises to novel tasks without large-scale tuning. These results highlight the promise of combining pretrained visual and tactile models with language grounding to advance explainable, human-like touch perception and decision-making in robotics.

</details>


### [21] [Bumper Drone: Elastic Morphology Design for Aerial Physical Interaction](https://arxiv.org/abs/2602.18976)
*Pongporn Supa,Alex Dunnett,Feng Xiao,Rui Wu,Mirko Kovac,Basaran Bahadir Kocer*

Main category: cs.RO

TL;DR: 无人机平台配备弹性触角，通过"触碰即走"机动实现被动环境交互导航，无需主动避障控制


<details>
  <summary>Details</summary>
Motivation: 空中机器人需要从避免障碍物发展到利用环境接触交互进行导航、探索和操作。关键挑战在于处理未知目标上的不确定接触力，这通常需要精确传感和主动控制。

Method: 提出配备弹性触角的无人机平台，实现"触碰即走"机动。利用环境交互作为体现控制形式，通过无人机-障碍物系统的被动动态响应（类似质量-弹簧-阻尼系统）实现低级稳定和近障碍物导航。

Result: 实验显示弹性触角能吸收冲击能量并保持飞行器稳定性，与刚性触角配置相比减少38%的俯仰振荡。下部触角布置进一步减少约54%的俯仰振荡。平台还能与静态物体保持稳定持续接触，仅依赖标准姿态PID控制器。

Conclusion: 弹性触角设计使无人机能够通过被动动态响应实现环境交互导航，减少对主动避障控制的依赖，为空中物理交互提供新方法。

Abstract: Aerial robots are evolving from avoiding obstacles to exploiting the environmental contact interactions for navigation, exploration and manipulation. A key challenge in such aerial physical interactions lies in handling uncertain contact forces on unknown targets, which typically demand accurate sensing and active control. We present a drone platform with elastic horns that enables touch-and-go manoeuvres - a self-regulated, consecutive bumping motion that allows the drone to maintain proximity to a wall without relying on active obstacle avoidance. It leverages environmental interaction as a form of embodied control, where low-level stabilisation and near-obstacle navigation emerge from the passive dynamic responses of the drone-obstacle system that resembles a mass-spring-damper system. Experiments show that the elastic horn can absorb impact energy while maintaining vehicle stability, reducing pitch oscillations by 38% compared to the rigid horn configuration. The lower horn arrangement was found to reduce pitch oscillations by approximately 54%. In addition to intermittent contact, the platform equipped with elastic horns also demonstrates stable, sustained contact with static objects, relying on a standard attitude PID controller.

</details>


### [22] [FruitTouch: A Perceptive Gripper for Gentle and Scalable Fruit Harvesting](https://arxiv.org/abs/2602.18991)
*Ruohan Zhang,Mohammad Amin Mirzaee,Wenzhen Yuan*

Main category: cs.RO

TL;DR: FruitTouch是一种紧凑型夹爪，集成了高分辨率视觉触觉传感，用于水果自动采摘，能够稳定抓取多种水果并实时监测力、滑动和软度。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺推动水果采摘自动化需求，需要紧凑、能稳定抓取多种水果并提供可靠反馈的传感器化夹爪。

Method: 提出FruitTouch紧凑夹爪，通过优化的光学设计集成高分辨率视觉触觉传感，嵌入式摄像头捕捉触觉图像。

Result: 触觉图像提供丰富信息用于实时力估计、滑动检测和软度预测，在真实水果采摘实验中验证了稳定的抓取和有效的损伤预防。

Conclusion: FruitTouch解决了水果采摘自动化的关键需求，展示了紧凑设计下稳定抓取和实时监测的能力。

Abstract: The automation of fruit harvesting has gained increasing significance in response to rising labor shortages. A sensorized gripper is a key component of this process, which must be compact enough for confined spaces, able to stably grasp diverse fruits, and provide reliable feedback on fruit conditions for efficient harvesting. To address this need, we propose FruitTouch, a compact gripper that integrates high-resolution, vision-based tactile sensing through an optimized optical design. This configuration accommodates a wide range of fruit sizes while maintaining low cost and mechanical simplicity. Tactile images captured by an embedded camera provide rich information for real-time force estimation, slip detection, and softness prediction. We validate the gripper in real-world fruit harvesting experiments, demonstrating robust grasp stability and effective damage prevention.

</details>


### [23] [A Checklist for Deploying Robots in Public: Articulating Tacit Knowledge in the HRI Community](https://arxiv.org/abs/2602.19038)
*Claire Liang,Franziska Babel,Hannah Pelikan,Sydney Thompson,Xiang Zhi Tan*

Main category: cs.RO

TL;DR: 本文提出了一个用于公共机器人部署的检查清单指南，通过模块化卡片形式帮助研究人员避免常见错误，并作为开源社区资源持续演进。


<details>
  <summary>Details</summary>
Motivation: 公共机器人部署中存在许多未记录的挑战和常见陷阱，导致进入门槛高且重复犯错。为了分享人机交互社区的隐性知识，需要提供系统化的指导工具。

Method: 基于研究团队自身公共机器人部署经验收集关键主题，构建模块化翻转卡片的分层表格结构，按部署阶段和重要领域组织。采访六位跨学科专家完善清单，并在真实公共研究中验证。

Result: 开发出实用的检查清单工具，包含社区输入的精炼内容，在实际公共研究中得到验证。提供开源、可定制的社区资源，支持列表、卡片和交互式网页工具多种使用形式。

Conclusion: 该检查清单成功收集并系统化了公共HRI研究的集体专业知识，降低了部署门槛，避免了重复错误，并作为可演进的社区资源支持持续改进。

Abstract: Many of the challenges encountered in in-the-wild public deployments of robots remain undocumented despite sharing many common pitfalls. This creates a high barrier of entry and results in repetition of avoidable mistakes. To articulate the tacit knowledge in the HRI community, this paper presents a guideline in the form of a checklist to support researchers in preparing for robot deployments in public. Drawing on their own experience with public robot deployments, the research team collected essential topics to consider in public HRI research. These topics are represented as modular flip cards in a hierarchical table, structured into deployment phases and important domains. We interviewed six interdisciplinary researchers with expertise in public HRI and show how including community input refines the checklist. We further show the checklist in action in context of real public studies. Finally, we contribute the checklist as an open-source, customizable community resource that both collects joint expertise for continual evolution and is usable as a list, set of cards, and an interactive web tool.

</details>


### [24] [Path planning for unmanned surface vehicle based on predictive artificial potential field. International Journal of Advanced Robotic Systems](https://arxiv.org/abs/2602.19062)
*Jia Song,Ce Hao,Jiangcheng Su*

Main category: cs.RO

TL;DR: 本文提出了一种结合时间信息和预测势能的新型预测人工势场方法，用于高速无人水面艇的路径规划，旨在减少航行时间和节约能源。


<details>
  <summary>Details</summary>
Motivation: 高速无人水面艇的路径规划需要更复杂的解决方案来减少航行时间和节约能源。传统人工势场方法在全局和局部路径规划中存在局限性，特别是在处理车辆动力学和局部最小值可达性方面。

Method: 研究首先分析了最先进的传统人工势场及其缺点，然后提出了预测人工势场的三个改进：角度限制、速度调整和预测势能。这些改进考虑了车辆动力学和局部最小值可达性，以增强生成路径的可行性和平滑性。

Result: 与传统人工势场相比，预测人工势场成功限制了最大转弯角度，缩短了航行时间，并能智能避障。仿真结果进一步验证了该方法能够解决凹形局部最小值问题，在特殊场景中提高了可达性。

Conclusion: 预测人工势场方法为高速无人水面艇生成更高效的路径，减少了航行时间并节约了能源，解决了传统方法在复杂场景中的局限性。

Abstract: Path planning for high-speed unmanned surface vehicles requires more complex solutions to reduce sailing time and save energy. This article proposes a new predictive artificial potential field that incorporates time information and predictive potential to plan smoother paths. It explores the principles of the artificial potential field, considering vehicle dynamics and local minimum reachability. The study first analyzes the most advanced traditional artificial potential field and its drawbacks in global and local path planning. It then introduces three modifications to the predictive artificial potential field-angle limit, velocity adjustment, and predictive potential to enhance the feasibility and flatness of the generated path. A comparison between the traditional and predictive artificial potential fields demonstrates that the latter successfully restricts the maximum turning angle, shortens sailing time, and intelligently avoids obstacles. Simulation results further verify that the predictive artificial potential field addresses the concave local minimum problem and improves reachability in special scenarios, ultimately generating a more efficient path that reduces sailing time and conserves energy for unmanned surface vehicles.

</details>


### [25] [Design, Locomotion, and Control of Amphibious Robots: Recent Advances](https://arxiv.org/abs/2602.19077)
*Yi Jin,Chang Liu,Roger D. Quinn,Robert J. Wood,C. Chase Cao*

Main category: cs.RO

TL;DR: 这篇综述论文回顾了两栖机器人的最新进展，重点关注运动机制、驱动技术和传感控制集成，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 两栖机器人能够在陆地和水域无缝操作，在环境保护、灾害响应和国防等领域具有重要应用价值。然而，其性能受到运动机制、驱动技术和传感控制集成等因素的限制，需要系统性的综述来指导未来研究。

Method: 采用文献综述方法，系统分析两栖机器人在运动策略、材料基驱动器、控制系统等方面的最新进展，并整合现有研究成果。

Result: 总结了当前两栖机器人在运动机制、驱动技术和控制集成方面的主要进展，识别了关键的技术挑战和研究空白。

Conclusion: 两栖机器人研究需要朝着更高效、更具韧性和多功能的方向发展，本文为未来研究提供了明确的技术挑战和发展机遇指导。

Abstract: Amphibious robots, operating seamlessly across land and water, are advancing applications in conservation, disaster response, and defense. Their performance depends on locomotion mechanisms, actuation technologies, and sensor-control integration. This review highlights recent progress in these areas, examining movement strategies, material-based actuators, and control systems for autonomy and adaptability. Challenges and opportunities are outlined to guide future research toward more efficient, resilient, and multifunctional amphibious robots.

</details>


### [26] [A User-driven Design Framework for Robotaxi](https://arxiv.org/abs/2602.19107)
*Yue Deng,Changyang He*

Main category: cs.RO

TL;DR: 研究通过实地访谈和体验发现，用户选择无人驾驶出租车主要因为低成本、社交推荐和好奇心，看重自主性增强和驾驶行为一致性，但面临灵活性不足、透明度不够、管理困难、边缘情况鲁棒性差和紧急处理等问题，隐私、安全、伦理和信任是核心影响因素。


<details>
  <summary>Details</summary>
Motivation: 现有研究过于关注无人驾驶出租车的技术驾驶性能，而忽视了乘客在无人类司机情况下的实际体验和评价。先前研究多依赖模拟或假设场景，缺乏对真实世界使用情况的理解。

Method: 采用18次半结构化访谈和自民族志乘车体验，调查真实世界的无人驾驶出租车使用情况。

Result: 用户被低成本、社交推荐和好奇心吸引；看重自主性增强、驾驶行为一致性和标准化乘车体验；但面临灵活性有限、透明度不足、管理困难、边缘情况鲁棒性问题和紧急处理担忧；隐私、安全、伦理和信任是核心影响因素。

Conclusion: 提出了一个用户驱动的设计框架，涵盖端到端旅程：预乘车配置（叫车）、情境感知接客（接客）、行程中可解释性（行驶）和可追溯的乘车后反馈（下车），以指导无人驾驶出租车的交互和服务设计。

Abstract: Robotaxis are emerging as a promising form of urban mobility, yet research has largely emphasized technical driving performance while leaving open how passengers experience and evaluate rides without a human driver. To address the limitations of prior work that often relies on simulated or hypothetical settings, we investigate real-world robotaxi use through 18 semi-structured interviews and autoethnographic ride experiences. We found that users were drawn to robotaxis by low cost, social recommendation, and curiosity. They valued a distinctive set of benefits, such as an increased sense of agency, and consistent driving behavioral consistency and standardized ride experiences. However, they encountered persistent challenges around limited flexibility, insufficient transparency, management difficulty, robustness concerns in edge cases, and emergency handling concerns. Robotaxi experiences were shaped by privacy, safety, ethics, and trust. Users were often privacy-indifferent yet sensitive to opaque access and leakage risks; safety perceptions were polarized; and ethical considerations surfaced round issues such as accountability, feedback responsibility and absence of human-like social norms. Based on these findings, we propose a user-driven design framework spanning the end-to-end journey, such as pre-ride configuration (hailing), context-aware pickup facilitation (pick-up) in-ride explainability (traveling), and accountable post-ride feedback (drop-off) to guide robotaxi interaction and service design.

</details>


### [27] [Understanding Fire Through Thermal Radiation Fields for Mobile Robots](https://arxiv.org/abs/2602.19108)
*Anton R. Wagner,Madhan Balaji Rao,Xuesu Xiao,Sören Pirk*

Main category: cs.RO

TL;DR: 提出了一种为移动机器人构建实时热辐射场的方法，使机器人能够在火灾环境中安全导航，避免热危险区域。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应中，自主移动机器人需要安全穿越火灾环境的能力。当前缺乏能够实时感知和理解火灾热辐射的机器人导航方法。

Method: 通过配准深度和热成像图像获得带有温度值的3D点云，识别火源，利用斯特藩-玻尔兹曼定律估算空域热辐射，构建连续热辐射场，并将热约束嵌入到代价地图中计算安全路径。

Result: 在波士顿动力Spot机器人上进行了受控实验验证，机器人能够避开危险区域并成功到达导航目标。

Conclusion: 该方法为自主部署在火灾环境中的移动机器人铺平了道路，在搜救、消防和危险品响应中具有潜在应用价值。

Abstract: Safely moving through environments affected by fire is a critical capability for autonomous mobile robots deployed in disaster response. In this work, we present a novel approach for mobile robots to understand fire through building real-time thermal radiation fields. We register depth and thermal images to obtain a 3D point cloud annotated with temperature values. From these data, we identify fires and use the Stefan-Boltzmann law to approximate the thermal radiation in empty spaces. This enables the construction of a continuous thermal radiation field over the environment. We show that this representation can be used for robot navigation, where we embed thermal constraints into the cost map to compute collision-free and thermally safe paths. We validate our approach on a Boston Dynamics Spot robot in controlled experimental settings. Our experiments demonstrate the robot's ability to avoid hazardous regions while still reaching navigation goals. Our approach paves the way toward mobile robots that can be autonomously deployed in fire-affected environments, with potential applications in search-and-rescue, firefighting, and hazardous material response.

</details>


### [28] [Distributed and Consistent Multi-Robot Visual-Inertial-Ranging Odometry on Lie Groups](https://arxiv.org/abs/2602.19173)
*Ziwei Kang,Yizhi Zhou*

Main category: cs.RO

TL;DR: 提出DC-VIRO框架，通过紧密融合多机器人的视觉-惯性里程计和UWB测距数据，解决GPS拒止环境下的定位漂移问题，同时实现锚点自校准。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境中，多机器人系统需要可靠的定位。视觉惯性里程计虽然轻量准确但存在累积漂移，而UWB测距提供全局观测但现有方法多为单机器人设计且依赖预校准锚点，实际应用中鲁棒性有限。

Method: 提出分布式协作视觉-惯性-测距里程计框架，将VIO和UWB测量紧密融合；将锚点位置明确纳入系统状态以解决校准不确定性；通过机器人间通信共享锚点观测提供额外几何约束；采用李群上的右不变误差公式化，保持标准VIO的可观测性。

Result: 多机器人仿真结果表明，DC-VIRO显著提高了定位精度和鲁棒性，同时在分布式设置中实现了锚点自校准。

Conclusion: DC-VIRO框架通过紧密融合多机器人的VIO和UWB测量，有效解决了GPS拒止环境下的定位漂移问题，提高了系统鲁棒性，并实现了锚点自校准，为多机器人系统提供了可靠的分布式定位解决方案。

Abstract: Reliable localization is a fundamental requirement for multi-robot systems operating in GPS-denied environments. Visual-inertial odometry (VIO) provides lightweight and accurate motion estimation but suffers from cumulative drift in the absence of global references. Ultra-wideband (UWB) ranging offers complementary global observations, yet most existing UWB-aided VIO methods are designed for single-robot scenarios and rely on pre-calibrated anchors, which limits their robustness in practice. This paper proposes a distributed collaborative visual-inertial-ranging odometry (DC-VIRO) framework that tightly fuses VIO and UWB measurements across multiple robots. Anchor positions are explicitly included in the system state to address calibration uncertainty, while shared anchor observations are exploited through inter-robot communication to provide additional geometric constraints. By leveraging a right-invariant error formulation on Lie groups, the proposed approach preserves the observability properties of standard VIO, ensuring estimator consistency. Simulation results with multiple robots demonstrate that DC-VIRO significantly improves localization accuracy and robustness, while simultaneously enabling anchor self-calibration in distributed settings.

</details>


### [29] [Visual Prompt Guided Unified Pushing Policy](https://arxiv.org/abs/2602.19193)
*Hieu Bui,Ziyan Gao,Yuya Hosoda,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 提出了一种统一的推动策略，通过轻量级提示机制指导生成反应式、多模态的推动动作，可作为VLM引导规划框架中的低级原语


<details>
  <summary>Details</summary>
Motivation: 现有推动方法通常依赖由有限应用范围预定义推动原语组成的多步推动计划，这限制了它们在不同场景下的效率和通用性

Method: 将轻量级提示机制整合到流匹配策略中，形成统一的推动策略，视觉提示可由高级规划器指定，使推动策略能在各种规划问题中重复使用

Result: 实验结果表明，提出的统一推动策略不仅优于现有基线方法，还能有效作为VLM引导规划框架中的低级原语，高效解决桌面清洁任务

Conclusion: 通过整合提示机制的流匹配策略实现了高效、通用的推动策略，为机器人操作提供了更灵活和可重用的解决方案

Abstract: As one of the simplest non-prehensile manipulation skills, pushing has been widely studied as an effective means to rearrange objects. Existing approaches, however, typically rely on multi-step push plans composed of pre-defined pushing primitives with limited application scopes, which restrict their efficiency and versatility across different scenarios. In this work, we propose a unified pushing policy that incorporates a lightweight prompting mechanism into a flow matching policy to guide the generation of reactive, multimodal pushing actions. The visual prompt can be specified by a high-level planner, enabling the reuse of the pushing policy across a wide range of planning problems. Experimental results demonstrate that the proposed unified pushing policy not only outperforms existing baselines but also effectively serves as a low-level primitive within a VLM-guided planning framework to solve table-cleaning tasks efficiently.

</details>


### [30] [The Price Is Not Right: Neuro-Symbolic Methods Outperform VLAs on Structured Long-Horizon Manipulation Tasks with Significantly Lower Energy Consumption](https://arxiv.org/abs/2602.19260)
*Timothy Duggan,Pierrick Lorang,Hong Lu,Matthias Scheutz*

Main category: cs.RO

TL;DR: 该研究对比了视觉-语言-动作模型与神经符号架构在结构化长时程机器人操作任务上的表现，发现神经符号方法在成功率、泛化能力和能源效率方面显著优于VLA模型。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉-语言-动作模型被提出作为通用机器人策略的途径，但其在结构化、长时程操作任务上的有效性和效率尚不明确，需要与传统的神经符号架构进行实证比较。

Method: 研究采用头对头实证比较方法：一方面使用微调的开源权重VLA模型π0，另一方面采用结合PDDL符号规划与学习低级控制的神经符号架构。在模拟环境中评估两种方法在结构化汉诺塔操作任务上的表现，同时测量训练和执行过程中的任务性能和能源消耗。

Result: 在3块汉诺塔任务中，神经符号模型达到95%成功率，而最佳VLA模型仅34%。神经符号模型还能泛化到未见过的4块变体（78%成功率），而两种VLA模型均无法完成任务。在训练过程中，VLA微调消耗的能源比神经符号方法高出近两个数量级。

Conclusion: 研究结果突显了端到端基础模型方法与结构化推理架构在长时程机器人操作中的重要权衡，强调了显式符号结构在提高可靠性、数据效率和能源效率方面的关键作用。

Abstract: Vision-Language-Action (VLA) models have recently been proposed as a pathway toward generalist robotic policies capable of interpreting natural language and visual inputs to generate manipulation actions. However, their effectiveness and efficiency on structured, long-horizon manipulation tasks remain unclear. In this work, we present a head-to-head empirical comparison between a fine-tuned open-weight VLA model π0 and a neuro-symbolic architecture that combines PDDL-based symbolic planning with learned low-level control. We evaluate both approaches on structured variants of the Towers of Hanoi manipulation task in simulation while measuring both task performance and energy consumption during training and execution. On the 3-block task, the neuro-symbolic model achieves 95% success compared to 34% for the best-performing VLA. The neuro-symbolic model also generalizes to an unseen 4-block variant (78% success), whereas both VLAs fail to complete the task. During training, VLA fine-tuning consumes nearly two orders of magnitude more energy than the neuro-symbolic approach. These results highlight important trade-offs between end-to-end foundation-model approaches and structured reasoning architectures for long-horizon robotic manipulation, emphasizing the role of explicit symbolic structure in improving reliability, data efficiency, and energy efficiency. Code and models are available at https://price-is-not-right.github.io

</details>


### [31] [3D Shape Control of Extensible Multi-Section Soft Continuum Robots via Visual Servoing](https://arxiv.org/abs/2602.19273)
*Abhinav Gandhi,Shou-Shan Chiang,Cagdas D. Onal,Berk Calli*

Main category: cs.RO

TL;DR: 提出基于视觉的软体连续机械臂全身形状控制算法，无需本体感知传感器，利用外部摄像头实现全局稳定的形状控制


<details>
  <summary>Details</summary>
Motivation: 现有视觉控制算法主要调节机器人末端执行器位姿，无法充分利用软体连续机械臂的运动学冗余性；现有方法存在局部极小值问题，且依赖本体感知传感器

Method: 提出基于模型的2.5D形状视觉伺服控制算法，利用外部摄像头获取机器人全身形状图像，通过逆运动学求解器生成参考特征，无需参考姿态图像

Result: 在多段连续机械臂上验证了控制器能精确调节全身形状，末端定位误差小于1毫米，实现了堆叠、倾倒、拉动等概念验证任务

Conclusion: 该视觉控制算法能有效调节软体连续机械臂的全身形状，无需本体感知传感器，具有全局稳定性和高精度，适用于无传感器能力的连续机械臂

Abstract: In this paper, we propose a novel vision-based control algorithm for regulating the whole body shape of extensible multisection soft continuum manipulators. Contrary to existing vision-based control algorithms in the literature that regulate the robot's end effector pose, our proposed control algorithm regulates the robot's whole body configuration, enabling us to leverage its kinematic redundancy. Additionally, our model-based 2.5D shape visual servoing provides globally stable asymptotic convergence in the robot's 3D workspace compared to the closest works in the literature that report local minima. Unlike existing visual servoing algorithms in the literature, our approach does not require information from proprioceptive sensors, making it suitable for continuum manipulators without such capabilities. Instead, robot state is estimated from images acquired by an external camera that observes the robot's whole body shape and is also utilized to close the shape control loop. Traditionally, visual servoing schemes require an image of the robot at its reference pose to generate the reference features. In this work, we utilize an inverse kinematics solver to generate reference features for the desired robot configuration and do not require images of the robot at the reference. Experiments are performed on a multisection continuum manipulator demonstrating the controller's capability to regulate the robot's whole body shape while precisely positioning the robot's end effector. Results validate our controller's ability to regulate the shape of continuum robots while demonstrating a smooth transient response and a steady-state error within 1 mm. Proof-of-concept object manipulation experiments including stacking, pouring, and pulling tasks are performed to demonstrate our controller's applicability.

</details>


### [32] [Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation](https://arxiv.org/abs/2602.19304)
*Haojun Shi,Suyu Ye,Katherine M. Guerrerio,Jianzhi Shen,Yifan Yin,Daniel Khashabi,Chien-Ming Huang,Tianmin Shu*

Main category: cs.RO

TL;DR: CaPE：基于代码编辑的多模态路径规划方法，通过语言通信实现安全可解释的机器人协作


<details>
  <summary>Details</summary>
Motivation: 在去中心化智能体协作中，当智能体无法准确预测彼此意图时，语言通信对确保安全至关重要。特别是在路径级协作场景中，智能体需要根据环境和其他智能体的语言通信调整路径以避免碰撞或完成物理协作任务。

Method: 提出CaPE（Code as Path Editor）方法，利用视觉语言模型（VLM）合成路径编辑程序，并通过基于模型的规划器进行验证。该方法将语言通信安全地、可解释地映射到路径计划更新中。

Result: 在模拟和真实世界的多种场景中进行了评估，包括自动驾驶、家庭环境和联合搬运任务中的多机器人及人机协作。CaPE可以作为即插即用模块集成到不同机器人系统中，显著提升机器人根据语言通信调整计划的能力。

Conclusion: CaPE结合了VLM的路径编辑程序合成和基于模型规划的安全性，使机器人能够在保持安全性和可解释性的同时实现开放式协作。

Abstract: Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.

</details>


### [33] [WildOS: Open-Vocabulary Object Search in the Wild](https://arxiv.org/abs/2602.19308)
*Hardik Shah,Erica Tevere,Deegan Atha,Marcel Kaufmann,Shehryar Khattak,Manthan Patel,Marco Hutter,Jonas Frey,Patrick Spieler*

Main category: cs.RO

TL;DR: WildOS是一个用于长距离开放词汇物体搜索的统一系统，结合安全几何探索与语义视觉推理，在复杂户外环境中实现鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 在复杂无结构的户外环境中，机器人需要长距离运行且没有先验地图和有限的深度感知。仅依赖几何边界进行探索往往不足，需要语义推理能力来确定安全可通行的路径和方向。

Method: WildOS构建稀疏导航图维护空间记忆，利用基于基础模型的视觉模块ExploRFM对图的边界节点进行评分。ExploRFM同时预测可通行性、视觉边界和图像空间中的物体相似性。此外，引入基于粒子滤波的方法对开放词汇目标查询进行粗略定位，估计超出机器人深度视野的候选目标位置。

Result: 在多种越野和城市地形中的广泛闭环现场实验表明，WildOS实现了鲁棒导航，在效率和自主性方面显著优于纯几何和纯视觉的基线方法。

Conclusion: 研究结果突显了视觉基础模型在驱动开放世界机器人行为方面的潜力，这些行为既具有语义信息又基于几何基础，为复杂户外环境中的自主导航提供了有效解决方案。

Abstract: Autonomous navigation in complex, unstructured outdoor environments requires robots to operate over long ranges without prior maps and limited depth sensing. In such settings, relying solely on geometric frontiers for exploration is often insufficient. In such settings, the ability to reason semantically about where to go and what is safe to traverse is crucial for robust, efficient exploration. This work presents WildOS, a unified system for long-range, open-vocabulary object search that combines safe geometric exploration with semantic visual reasoning. WildOS builds a sparse navigation graph to maintain spatial memory, while utilizing a foundation-model-based vision module, ExploRFM, to score frontier nodes of the graph. ExploRFM simultaneously predicts traversability, visual frontiers, and object similarity in image space, enabling real-time, onboard semantic navigation tasks. The resulting vision-scored graph enables the robot to explore semantically meaningful directions while ensuring geometric safety. Furthermore, we introduce a particle-filter-based method for coarse localization of the open-vocabulary target query, that estimates candidate goal positions beyond the robot's immediate depth horizon, enabling effective planning toward distant goals. Extensive closed-loop field experiments across diverse off-road and urban terrains demonstrate that WildOS enables robust navigation, significantly outperforming purely geometric and purely vision-based baselines in both efficiency and autonomy. Our results highlight the potential of vision foundation models to drive open-world robotic behaviors that are both semantically informed and geometrically grounded. Project Page: https://leggedrobotics.github.io/wildos/

</details>


### [34] [TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics](https://arxiv.org/abs/2602.19313)
*Shirui Chen,Cole Harrison,Ying-Chun Lee,Angela Jin Yang,Zhongzheng Ren,Lillian J. Ratliff,Jiafei Duan,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: TOPReward是一种基于概率的时间价值函数，利用预训练视频视觉语言模型的潜在世界知识来估计机器人任务进度，显著提高了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在强化学习中面临样本效率低和真实世界奖励稀疏的问题，现有时间价值函数难以泛化到训练域之外，需要开发通用的过程奖励模型来提供细粒度反馈。

Method: 提出TOPReward方法，直接从预训练视频视觉语言模型的内部token对数概率中提取任务进度，而不是像先前方法那样提示模型直接输出进度值，避免了数值表示错误。

Result: 在130多个真实世界任务和多个机器人平台上进行零样本评估，TOPReward在Qwen3-VL上达到0.947的平均价值顺序相关性，显著优于接近零相关性的最先进GVL基线。

Conclusion: TOPReward作为一种多功能工具，可用于下游应用如成功检测和奖励对齐的行为克隆，为解决视觉-语言-动作模型在强化学习中的泛化问题提供了有效方案。

Abstract: While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.

</details>


### [35] [Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders](https://arxiv.org/abs/2602.19315)
*Victor-Alexandru Darvariu,Charlotte Z. Reed,Jan Stratmann,Bruno Lacerda,Benjamin Allsup,Stephen Woodward,Elizabeth Siddle,Trishna Saeharaseelan,Owain Jones,Dan Jones,Tobias Ferreira,Chloe Baker,Kevin Chaplin,James Kirk,Ashley Morris,Ryan Patmore,Jeff Polton,Charlotte Williams,Alexandra Kokkinaki,Alvaro Lorenzo Lopez,Justin J. H. Buck,Nick Hawes*

Main category: cs.RO

TL;DR: 本文提出了一种基于蒙特卡洛树搜索的在线规划方法，用于水下滑翔机导航，并通过物理信息模拟器处理控制不确定性和洋流预测，实现了北海上为期3个月、1000公里的自主部署验证。


<details>
  <summary>Details</summary>
Motivation: 水下滑翔机已成为海洋采样的重要工具，但大型机队自主长期部署的成功案例很少，缺乏合适的方法论和系统。利益相关者需要管理日益庞大的滑翔机机队的工具。

Method: 将滑翔机导航规划建模为随机最短路径马尔可夫决策过程，提出基于蒙特卡洛树搜索的样本在线规划器。使用物理信息模拟器生成样本，该模拟器能捕捉控制执行不确定性和洋流预测，同时保持计算可行性。模拟器参数通过历史滑翔机数据拟合。将这些方法集成到Slocum滑翔机的自主指挥控制系统中，实现每次上浮时的闭环重新规划。

Result: 系统在北海上进行了两次现场部署，总计约3个月和1000公里的自主操作。结果显示，与直线导航相比，效率有所提高，证明了基于样本的规划在长期海洋自主性中的实用性。

Conclusion: 提出的基于蒙特卡洛树搜索的样本在线规划方法能够有效处理水下滑翔机导航中的不确定性问题，通过物理信息模拟器和历史数据拟合，实现了长期自主部署，为海洋自主系统提供了实用的解决方案。

Abstract: Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.

</details>


### [36] [Design and Control of Modular Magnetic Millirobots for Multimodal Locomotion and Shape Reconfiguration](https://arxiv.org/abs/2602.19346)
*Erik Garcia Oyono,Jialin Lin,Dandan Zhang*

Main category: cs.RO

TL;DR: 提出了一种模块化磁性毫米机器人平台，包含三种功能模块，通过二维磁场控制实现运动、重构和货物操作，在受限环境中展现出多模态适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有模块化磁性机器人平台依赖工作空间碰撞进行重构，使用笨重的三维电磁系统，缺乏稳健的单模块控制，限制了在生物医学环境中的应用。

Method: 设计了三类立方体模块（自由模块、固定模块、夹持模块），通过编程组合的时变二维均匀和梯度磁场输入驱动运动和重构，结合实时视觉反馈和A*路径规划实现闭环导航。

Result: 实现了稳健的单模块控制、自组装、多模态变换和低场强下的拆卸。链到夹持器变换成功率90%，链到方形变换一致性较低，表明模块几何形状影响重构可靠性。

Conclusion: 建立了一个多功能模块化机器人平台，具备多模态行为和稳健控制能力，为受限环境中可扩展和自适应任务执行提供了有前景的途径。

Abstract: Modular small-scale robots offer the potential for on-demand assembly and disassembly, enabling task-specific adaptation in dynamic and constrained environments. However, existing modular magnetic platforms often depend on workspace collisions for reconfiguration, employ bulky three-dimensional electromagnetic systems, and lack robust single-module control, which limits their applicability in biomedical settings. In this work, we present a modular magnetic millirobotic platform comprising three cube-shaped modules with embedded permanent magnets, each designed for a distinct functional role: a free module that supports self-assembly and reconfiguration, a fixed module that enables flip-and-walk locomotion, and a gripper module for cargo manipulation. Locomotion and reconfiguration are actuated by programmable combinations of time-varying two-dimensional uniform and gradient magnetic field inputs. Experiments demonstrate closed-loop navigation using real-time vision feedback and A* path planning, establishing robust single-module control capabilities. Beyond locomotion, the system achieves self-assembly, multimodal transformations, and disassembly at low field strengths. Chain-to-gripper transformations succeeded in 90% of trials, while chain-to-square transformations were less consistent, underscoring the role of module geometry in reconfiguration reliability. These results establish a versatile modular robotic platform capable of multimodal behavior and robust control, suggesting a promising pathway toward scalable and adaptive task execution in confined environments.

</details>


### [37] [Vid2Sid: Videos Can Help Close the Sim2Real Gap](https://arxiv.org/abs/2602.19359)
*Kevin Qiu,Yu Zhang,Marek Cygan,Josie Hughes*

Main category: cs.RO

TL;DR: Vid2Sid是一个视频驱动的系统识别管道，结合基础模型感知和VLM-in-the-loop优化器，通过分析仿真-真实配对视频来诊断物理参数不匹配，提供可解释的校准过程。


<details>
  <summary>Details</summary>
Motivation: 传统机器人仿真器物理参数校准通常手动完成或使用黑盒优化器，这些方法虽然能减少误差但无法解释哪些物理差异导致了误差。在仅使用外部相机感知的情况下，问题进一步复杂化，因为存在感知噪声且缺乏直接的力或状态测量。

Method: 提出Vid2Sid系统识别管道，结合基础模型感知和VLM-in-the-loop优化器。系统分析配对仿真-真实视频，诊断具体不匹配，并通过自然语言推理提出物理参数更新。在MuJoCo中的肌腱驱动手指（刚体动力学）和PyElastica中的可变形连续体触手（软体动力学）上进行评估。

Result: 在训练期间未见过的sim2real保持控制测试中，Vid2Sid在所有设置中达到最佳平均排名，匹配或超越黑盒优化器，同时独特地在每次迭代中提供可解释的推理。Sim2sim验证确认Vid2Sid最准确地恢复地面真实参数（平均相对误差低于13% vs. 28-98%）。消融分析揭示了三种校准机制。

Conclusion: 当感知清晰且仿真器表达能力足够时，VLM引导的优化表现出色，而模型类别限制在更具挑战性的设置中限制了性能。Vid2Sid提供了一种可解释的物理参数校准方法，超越了传统黑盒优化器。

Abstract: Calibrating a robot simulator's physics parameters (friction, damping, material stiffness) to match real hardware is often done by hand or with black-box optimizers that reduce error but cannot explain which physical discrepancies drive the error. When sensing is limited to external cameras, the problem is further compounded by perception noise and the absence of direct force or state measurements. We present Vid2Sid, a video-driven system identification pipeline that couples foundation-model perception with a VLM-in-the-loop optimizer that analyzes paired sim-real videos, diagnoses concrete mismatches, and proposes physics parameter updates with natural language rationales. We evaluate our approach on a tendon-actuated finger (rigid-body dynamics in MuJoCo) and a deformable continuum tentacle (soft-body dynamics in PyElastica). On sim2real holdout controls unseen during training, Vid2Sid achieves the best average rank across all settings, matching or exceeding black-box optimizers while uniquely providing interpretable reasoning at each iteration. Sim2sim validation confirms that Vid2Sid recovers ground-truth parameters most accurately (mean relative error under 13\% vs. 28--98\%), and ablation analysis reveals three calibration regimes. VLM-guided optimization excels when perception is clean and the simulator is expressive, while model-class limitations bound performance in more challenging settings.

</details>


### [38] [Seeing Farther and Smarter: Value-Guided Multi-Path Reflection for VLM Policy Optimization](https://arxiv.org/abs/2602.19372)
*Yanting Yang,Shenyuan Gao,Qingwen Bu,Li Chen,Dimitris N. Metaxas*

Main category: cs.RO

TL;DR: 提出了一种新的测试时计算框架，将状态评估与动作生成解耦，通过显式建模动作计划的优势值，使用可扩展的评论家估计，并结合波束搜索探索多个未来路径，显著提升了机器人操作任务的成功率和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的反射规划方法存在三个主要问题：1）依赖从噪声预测中隐式学习状态价值，效率低且不准确；2）只评估单一贪婪未来；3）推理延迟大。需要更直接、细粒度的监督信号来支持鲁棒决策。

Method: 提出测试时计算框架，将状态评估与动作生成解耦。显式建模动作计划的优势（目标距离减少量），使用可扩展评论家估计。采用波束搜索探索多个未来路径，在解码时聚合以建模期望长期回报。引入轻量级置信度触发器，在直接预测可靠时提前退出，仅在必要时调用反射。

Result: 在多样未见的多阶段机器人操作任务上，相比最先进基线方法，成功率提升24.6%，推理时间减少56.5%。

Conclusion: 通过解耦状态评估与动作生成、显式建模动作优势、多路径探索和自适应反射触发，实现了更高效、鲁棒的机器人操作规划，显著提升了视觉语言模型在复杂长时域任务中的性能。

Abstract: Solving complex, long-horizon robotic manipulation tasks requires a deep understanding of physical interactions, reasoning about their long-term consequences, and precise high-level planning. Vision-Language Models (VLMs) offer a general perceive-reason-act framework for this goal. However, previous approaches using reflective planning to guide VLMs in correcting actions encounter significant limitations. These methods rely on inefficient and often inaccurate implicit learning of state-values from noisy foresight predictions, evaluate only a single greedy future, and suffer from substantial inference latency. To address these limitations, we propose a novel test-time computation framework that decouples state evaluation from action generation. This provides a more direct and fine-grained supervisory signal for robust decision-making. Our method explicitly models the advantage of an action plan, quantified by its reduction in distance to the goal, and uses a scalable critic to estimate. To address the stochastic nature of single-trajectory evaluation, we employ beam search to explore multiple future paths and aggregate them during decoding to model their expected long-term returns, leading to more robust action generation. Additionally, we introduce a lightweight, confidence-based trigger that allows for early exit when direct predictions are reliable, invoking reflection only when necessary. Extensive experiments on diverse, unseen multi-stage robotic manipulation tasks demonstrate a 24.6% improvement in success rate over state-of-the-art baselines, while significantly reducing inference time by 56.5%.

</details>


### [39] [Hilbert-Augmented Reinforcement Learning for Scalable Multi-Robot Coverage and Exploration](https://arxiv.org/abs/2602.19400)
*Tamil Selvan Gurunathan,Aryya Gangopadhyay*

Main category: cs.RO

TL;DR: 将希尔伯特空间填充先验集成到去中心化多机器人学习与执行中的覆盖框架，通过希尔伯特空间索引增强DQN和PPO算法，提高稀疏奖励环境下的探索效率和收敛速度，并在波士顿动力Spot机器人上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 在多机器人覆盖任务中，传统强化学习方法在稀疏奖励环境下存在探索效率低、冗余度高的问题。需要一种能够结构化探索、减少冗余的框架来提高覆盖效率和收敛速度。

Method: 提出一个覆盖框架，将希尔伯特空间填充先验集成到去中心化多机器人学习系统中。通过希尔伯特空间索引增强DQN和PPO算法，结构化探索过程。开发航点接口，将希尔伯特排序转换为曲率有界、时间参数化的SE(2)轨迹，确保在资源受限机器人上的可行性。

Result: 实验显示，在多机器人网格覆盖任务中，该方法在覆盖效率、冗余度和收敛速度方面优于DQN/PPO基线。在波士顿动力Spot腿式机器人上的验证表明，该方法能够在室内环境中可靠执行生成的轨迹，实现低冗余覆盖。

Conclusion: 几何先验（特别是希尔伯特空间填充）能够显著提高群机器人和腿式机器人的自主性和可扩展性，为稀疏奖励环境下的多机器人覆盖任务提供了有效的解决方案。

Abstract: We present a coverage framework that integrates Hilbert space-filling priors into decentralized multi-robot learning and execution. We augment DQN and PPO with Hilbert-based spatial indices to structure exploration and reduce redundancy in sparse-reward environments, and we evaluate scalability in multi-robot grid coverage. We further describe a waypoint interface that converts Hilbert orderings into curvature-bounded, time-parameterized SE(2) trajectories (planar (x, y, θ)), enabling onboard feasibility on resource-constrained robots. Experiments show improvements in coverage efficiency, redundancy, and convergence speed over DQN/PPO baselines. In addition, we validate the approach on a Boston Dynamics Spot legged robot, executing the generated trajectories in indoor environments and observing reliable coverage with low redundancy. These results indicate that geometric priors improve autonomy and scalability for swarm and legged robotics.

</details>


### [40] [Anticipate, Adapt, Act: A Hybrid Framework for Task Planning](https://arxiv.org/abs/2602.19518)
*Nabanita Dash,Ayush Kaura,Shivam Singh,Ramandeep Singh,Snehasis Banerjee,Mohan Sridharan,K. Madhava Krishna*

Main category: cs.RO

TL;DR: 论文提出了一种混合框架，将LLM的通用预测能力与RDDL的概率序列决策能力相结合，使机器人能够预测和适应人机协作中的潜在失败。


<details>
  <summary>Details</summary>
Motivation: 尽管现有AI规划系统和大型语言模型性能出色，但在复杂领域与人类协作时，机器人预测和适应失败的能力仍然面临挑战，主要原因是任务及其结果的不确定性。

Method: 开发了一个混合框架，整合了大型语言模型的通用预测能力和关系动态影响图语言的概率序列决策能力。机器人能够推理任务和人类能力，预测由于人类能力不足或领域对象缺失导致的潜在失败，并执行预防或恢复行动。

Result: 在VirtualHome 3D仿真环境中的实验评估显示，相比最先进的基线方法，该框架在性能上有显著提升。

Conclusion: 提出的混合框架有效提升了机器人在人机协作中预测和适应失败的能力，为解决复杂领域中的不确定性挑战提供了有前景的解决方案。

Abstract: Anticipating and adapting to failures is a key capability robots need to collaborate effectively with humans in complex domains. This continues to be a challenge despite the impressive performance of state of the art AI planning systems and Large Language Models (LLMs) because of the uncertainty associated with the tasks and their outcomes. Toward addressing this challenge, we present a hybrid framework that integrates the generic prediction capabilities of an LLM with the probabilistic sequential decision-making capability of Relational Dynamic Influence Diagram Language. For any given task, the robot reasons about the task and the capabilities of the human attempting to complete it; predicts potential failures due to lack of ability (in the human) or lack of relevant domain objects; and executes actions to prevent such failures or recover from them. Experimental evaluation in the VirtualHome 3D simulation environment demonstrates substantial improvement in performance compared with state of the art baselines.

</details>


### [41] [Cost-Aware Diffusion Active Search](https://arxiv.org/abs/2602.19538)
*Arundhati Banerjee,Jeff Schneider*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩散模型的主动搜索方法，通过采样前瞻动作序列来平衡探索与利用，避免了传统树搜索的高计算成本，并在单智能体和多智能体团队中实现了高效的成本感知决策。


<details>
  <summary>Details</summary>
Motivation: 主动搜索需要在未知环境中进行在线自适应决策，传统方法存在局限性：基于信息增益和Thompson采样的近视贪婪方法效果有限；有限视野前瞻算法虽然性能更好，但依赖计算昂贵的搜索树构建。需要一种既能实现有效前瞻决策又避免高计算成本的方法。

Method: 利用扩散模型的序列建模能力，采样前瞻动作序列来平衡主动搜索中的探索-利用权衡，无需构建详尽的搜索树。针对扩散强化学习方法在主动搜索中存在的乐观偏差问题，提出了缓解方案，支持单智能体和多智能体团队的高效成本感知决策。

Result: 提出的算法在离线强化学习中优于标准基线方法，实现了更高的完全恢复率。在成本感知主动决策方面，比树搜索方法计算效率更高。

Conclusion: 扩散模型为主动搜索提供了一种有效的前瞻决策方法，既能平衡探索-利用权衡，又避免了传统树搜索的高计算成本，在单智能体和多智能体场景中都表现出优越性能。

Abstract: Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also shown that agents capable of lookahead over a finite horizon outperform myopic policies for active search. Unfortunately, lookahead algorithms typically rely on building a computationally expensive search tree that is simulated and updated based on the agent's observations and a model of the environment dynamics. Instead, in this work, we leverage the sequence modeling abilities of diffusion models to sample lookahead action sequences that balance the exploration-exploitation trade-off for active search without building an exhaustive search tree. We identify the optimism bias in prior diffusion based reinforcement learning approaches when applied to the active search setting and propose mitigating solutions for efficient cost-aware decision making with both single and multi-agent teams. Our proposed algorithm outperforms standard baselines in offline reinforcement learning in terms of full recovery rate and is computationally more efficient than tree search in cost-aware active decision making.

</details>


### [42] [Chasing Ghosts: A Simulation-to-Real Olfactory Navigation Stack with Optional Vision Augmentation](https://arxiv.org/abs/2602.19577)
*Kordel K. France,Ovidiu Daescu,Latifur Khan,Rohith Peddi*

Main category: cs.RO

TL;DR: 本文提出了一种开源无人机系统，使用最小传感器套件进行在线气味源定位，无需外部基础设施或预定义覆盖模式，通过仿真训练的导航策略实现直接导航至气味源。


<details>
  <summary>Details</summary>
Motivation: 自主气味源定位对空中机器人仍具挑战性，现有无人机嗅觉系统依赖预定义覆盖模式、外部基础设施或大量传感协调，需要更简单有效的解决方案。

Method: 开发了完整的开源无人机系统，集成定制嗅觉硬件、机载传感和基于仿真的学习导航策略，可选视觉模态加速导航，无需构建显式气体分布图或外部定位系统。

Result: 在大型室内环境中使用乙醇源进行真实飞行实验验证，在现实气流条件下展示了一致的源寻找行为，系统具备可重复性。

Conclusion: 主要贡献是提供了在最小传感假设下基于无人机的嗅觉导航和源寻找的可复制系统和方法框架，开源了硬件设计、固件、仿真代码、数据集和电路板。

Abstract: Autonomous odor source localization remains a challenging problem for aerial robots due to turbulent airflow, sparse and delayed sensory signals, and strict payload and compute constraints. While prior unmanned aerial vehicle (UAV)-based olfaction systems have demonstrated gas distribution mapping or reactive plume tracing, they rely on predefined coverage patterns, external infrastructure, or extensive sensing and coordination. In this work, we present a complete, open-source UAV system for online odor source localization using a minimal sensor suite. The system integrates custom olfaction hardware, onboard sensing, and a learning-based navigation policy trained in simulation and deployed on a real quadrotor. Through our minimal framework, the UAV is able to navigate directly toward an odor source without constructing an explicit gas distribution map or relying on external positioning systems. Vision is incorporated as an optional complementary modality to accelerate navigation under certain conditions. We validate the proposed system through real-world flight experiments in a large indoor environment using an ethanol source, demonstrating consistent source-finding behavior under realistic airflow conditions. The primary contribution of this work is a reproducible system and methodological framework for UAV-based olfactory navigation and source finding under minimal sensing assumptions. We elaborate on our hardware design and open source our UAV firmware, simulation code, olfaction-vision dataset, and circuit board to the community. Code, data, and designs will be made available at https://github.com/KordelFranceTech/ChasingGhosts.

</details>


### [43] [Denoising Particle Filters: Learning State Estimation with Single-Step Objectives](https://arxiv.org/abs/2602.19651)
*Lennart Röstel,Berthold Bäuml*

Main category: cs.RO

TL;DR: 提出一种基于粒子滤波的新型状态估计算法，通过独立训练状态转移模型，利用机器人系统的马尔可夫性质，避免端到端序列训练的高成本


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的状态估计方法通常将问题视为序列建模，虽然端到端性能可能较好，但模型难以解释且训练成本高（需要展开时间序列预测）。需要一种既能保持良好性能又具有可解释性和训练效率的替代方案。

Method: 提出基于粒子滤波的算法，从单个状态转移训练模型，充分利用机器人系统的马尔可夫性质。通过最小化去噪分数匹配目标隐式学习测量模型，在推理时结合学习的去噪器和（学习的）动态模型，在每个时间步近似求解贝叶斯滤波方程，引导预测状态向测量数据流形靠拢。

Result: 在仿真中的挑战性机器人状态估计任务上评估该方法，展示了与调优的端到端训练基线相比具有竞争力的性能。

Conclusion: 该方法提供了经典滤波算法的理想可组合性，允许在不重新训练的情况下整合先验信息和外部传感器模型，同时保持了学习方法的性能优势。

Abstract: Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.

</details>


### [44] [Scalable Low-Density Distributed Manipulation Using an Interconnected Actuator Array](https://arxiv.org/abs/2602.19653)
*Bailey Dacre,Rodrigo Moreno,Jørn Lambertsen,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 提出一种由模块化3自由度机器人瓦片和柔性表面层组成的分布式操纵系统，通过柔性层允许更大的执行器间距，降低执行器密度，同时保持对小物体的鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 传统分布式操纵系统需要密集的执行器阵列来有效操纵小物体，这增加了系统复杂性和成本。需要一种能够减少执行器密度同时保持操纵能力的方法。

Method: 使用模块化3自由度机器人瓦片通过柔性表面层互连，形成连续可控的操纵表面。分析阵列的耦合工作空间，开发能够将物体移动到N×N阵列内任意位置的操纵策略。

Result: 使用最小2×2原型进行实验验证，成功操纵了不同形状和大小的物体，证明柔性层允许增加执行器间距而不影响操纵能力。

Conclusion: 柔性表面层使分布式操纵系统能够显著降低执行器密度，同时保持对小物体的鲁棒控制，为构建更经济高效的分布式操纵系统提供了可行方案。

Abstract: Distributed Manipulator Systems, composed of arrays of robotic actuators necessitate dense actuator arrays to effectively manipulate small objects. This paper presents a system composed of modular 3-DoF robotic tiles interconnected by a compliant surface layer, forming a continuous, controllable manipulation surface. The compliant layer permits increased actuator spacing without compromising object manipulation capabilities, significantly reducing actuator density while maintaining robust control, even for smaller objects. We characterize the coupled workspace of the array and develop a manipulation strategy capable of translating objects to arbitrary positions within an N X N array. The approach is validated experimentally using a minimal 2 X 2 prototype, demonstrating the successful manipulation of objects with varied shapes and sizes.

</details>


### [45] [CACTO-BIC: Scalable Actor-Critic Learning via Biased Sampling and GPU-Accelerated Trajectory Optimization](https://arxiv.org/abs/2602.19699)
*Elisa Alboni,Pietro Noah Crestaz,Elias Fontanari,Andrea Del Prete*

Main category: cs.RO

TL;DR: CACTO-BIC通过改进初始状态采样策略和GPU加速，解决了轨迹优化与强化学习结合方法CACTO的扩展性问题，提高了数据效率和计算速度，适用于高维系统和实时应用。


<details>
  <summary>Details</summary>
Motivation: 轨迹优化（TO）和强化学习（RL）在解决最优控制问题中各具优势：TO能高效计算局部最优解但难以处理非凸问题，RL对非凸问题更鲁棒但计算成本高。CACTO结合了两者优势，但面临扩展性限制，系统复杂度增加会显著提高TO的计算成本。

Method: 提出CACTO-BIC方法：1）利用局部最优策略价值函数的特性改进初始状态采样策略，提高数据效率；2）利用GPU加速减少计算时间。该方法在AlienGO四足机器人等高维系统上进行实验验证。

Result: 实验评估显示：相比CACTO，CACTO-BIC提高了样本效率并加快了计算速度；与PPO相比，能在更短时间内获得相似质量的解决方案；在AlienGO四足机器人上的实验证明该方法能扩展到高维系统并适用于实时应用。

Conclusion: CACTO-BIC通过改进采样策略和GPU加速，有效解决了CACTO的扩展性限制，实现了更高的数据效率和计算速度，能够扩展到高维机器人系统并满足实时应用需求。

Abstract: Trajectory Optimization (TO) and Reinforcement Learning (RL) offer complementary strengths for solving optimal control problems. TO efficiently computes locally optimal solutions but can struggle with non-convexity, while RL is more robust to non-convexity at the cost of significantly higher computational demands. CACTO (Continuous Actor-Critic with Trajectory Optimization) was introduced to combine these advantages by learning a warm-start policy that guides the TO solver towards low-cost trajectories. However, scalability remains a key limitation, as increasing system complexity significantly raises the computational cost of TO. This work introduces CACTO-BIC to address these challenges. CACTO-BIC improves data efficiency by biasing initial-state sampling leveraging a property of the value function associated with locally optimal policies; moreover, it reduces computation time by exploiting GPU acceleration. Empirical evaluations show improved sample efficiency and faster computation compared to CACTO. Comparisons with PPO demonstrate that our approach can achieve similar solutions in less time. Finally, experiments on the AlienGO quadruped robot demonstrate that CACTO-BIC can scale to high-dimensional systems and is suitable for real-time applications.

</details>


### [46] [Towards Dexterous Embodied Manipulation via Deep Multi-Sensory Fusion and Sparse Expert Scaling](https://arxiv.org/abs/2602.19764)
*Yirui Sun,Guangyu Zhuge,Keliang Liu,Jie Gu,Zhihao xia,Qionglin Ren,Chunxu tian,Zhongxue Ga*

Main category: cs.RO

TL;DR: DeMUSE是一个深度多模态统一稀疏专家框架，使用扩散Transformer整合RGB、深度和6轴力传感器数据，通过自适应模态特定归一化平衡多模态特征，采用稀疏专家混合提升模型容量，在仿真和真实环境中实现高成功率。


<details>
  <summary>Details</summary>
Motivation: 当前以视觉为中心的范式往往忽略了复杂任务所需的关键力和几何反馈，需要深度整合异构多模态感官输入来实现灵巧的具身操作。

Method: 提出DeMUSE框架：1）使用扩散Transformer将RGB、深度和6轴力整合为统一序列化流；2）采用自适应模态特定归一化重新校准模态感知特征；3）使用稀疏专家混合架构提升模型容量；4）联合去噪目标同步合成环境演化和动作序列。

Result: 在仿真和真实世界试验中分别达到83.2%和72.5%的成功率，展示了最先进的性能，验证了深度多感官整合对复杂物理交互的必要性。

Conclusion: DeMUSE框架通过深度整合异构多模态感官输入，有效解决了当前视觉中心范式的局限性，为复杂物理交互任务提供了有效的解决方案。

Abstract: Realizing dexterous embodied manipulation necessitates the deep integration of heterogeneous multimodal sensory inputs. However, current vision-centric paradigms often overlook the critical force and geometric feedback essential for complex tasks. This paper presents DeMUSE, a Deep Multimodal Unified Sparse Experts framework leveraging a Diffusion Transformer to integrate RGB, depth, and 6-axis force into a unified serialized stream. Adaptive Modality-specific Normalization (AdaMN) is employed to recalibrate modality-aware features, mitigating representation imbalance and harmonizing the heterogeneous distributions of multi-sensory signals. To facilitate efficient scaling, the architecture utilizes a Sparse Mixture-of-Experts (MoE) with shared experts, increasing model capacity for physical priors while maintaining the low inference latency required for real-time control. A Joint denoising objective synchronously synthesizes environmental evolution and action sequences to ensure physical consistency. Achieving success rates of 83.2% and 72.5% in simulation and real-world trials, DeMUSE demonstrates state-of-the-art performance, validating the necessity of deep multi-sensory integration for complex physical interactions.

</details>


### [47] [TactiVerse: Generalizing Multi-Point Tactile Sensing in Soft Robotics Using Single-Point Data](https://arxiv.org/abs/2602.19850)
*Junhui Lee,Hyosung Kim,Saekwang Nam*

Main category: cs.RO

TL;DR: TactiVerse：基于U-Net的软体触觉传感器框架，通过空间热图预测实现接触几何估计，即使仅用单点压痕数据训练也能实现高精度单点感知，并能通过多点数据增强显著提升多点感知能力。


<details>
  <summary>Details</summary>
Motivation: 软体机器人中高度柔性材料的实时变形预测面临挑战。现有基于视觉的软体触觉传感器虽然能跟踪内部标记位移，但基于学习的3D接触估计模型严重依赖训练数据集，难以泛化到复杂场景（如多点感知）。

Method: 提出TactiVerse框架，基于U-Net架构，将接触几何估计建模为空间热图预测任务。即使仅使用有限的单点压痕数据集训练，也能实现高精度感知，并通过添加多点接触数据增强训练集来提升多点感知能力。

Result: 单点感知方面：平均绝对误差0.0589 mm，优于传统回归CNN基线的0.0612 mm。多点感知方面：通过数据增强，两点辨别的平均MAE从1.214 mm显著提升至0.383 mm。

Conclusion: 该方法能够从基本相互作用中成功推断复杂接触几何，实现了先进的多点和大面积形状感知，显著简化了基于标记的软体传感器开发，为现实世界触觉感知提供了高度可扩展的解决方案。

Abstract: Real-time prediction of deformation in highly compliant soft materials remains a significant challenge in soft robotics. While vision-based soft tactile sensors can track internal marker displacements, learning-based models for 3D contact estimation heavily depend on their training datasets, inherently limiting their ability to generalize to complex scenarios such as multi-point sensing. To address this limitation, we introduce TactiVerse, a U-Net-based framework that formulates contact geometry estimation as a spatial heatmap prediction task. Even when trained exclusively on a limited dataset of single-point indentations, our architecture achieves highly accurate single-point sensing, yielding a superior mean absolute error of 0.0589 mm compared to the 0.0612 mm of a conventional regression-based CNN baseline. Furthermore, we demonstrate that augmenting the training dataset with multi-point contact data substantially enhances the sensor's multi-point sensing capabilities, significantly improving the overall mean MAE for two-point discrimination from 1.214 mm to 0.383 mm. By successfully extrapolating complex contact geometries from fundamental interactions, this methodology unlocks advanced multi-point and large-area shape sensing. Ultimately, it significantly streamlines the development of marker-based soft sensors, offering a highly scalable solution for real-world tactile perception.

</details>


### [48] [Athena: An Autonomous Open-Hardware Tracked Rescue Robot Platform](https://arxiv.org/abs/2602.19898)
*Stefan Fabian,Aljoscha Schmidt,Jonas Süß,Dishant,Aum Oza,Oskar von Stryk*

Main category: cs.RO

TL;DR: 本文介绍了Athena，一个开源的救援地面机器人研究平台，具有四个独立可重构的履带臂和低成本远程急停解决方案，适用于灾害响应任务。


<details>
  <summary>Details</summary>
Motivation: 灾害响应和态势评估中，机器人能降低救援人员风险。由于任务环境和机器人能力需求差异大且难以预知，需要异构机器人编队。无人机能快速侦察但载荷能力有限，地面机器人能携带传感器和机械臂但需应对复杂地形。

Method: 开发了Athena开源救援地面机器人平台，具有四个独立可重构的履带臂，采用工业PU皮带和齿形插件的新型安装方案可更换测试不同履带轮廓，配备最大伸展1.54米的机械臂，并提供低成本远程急停解决方案。

Result: 成功开发了完整的救援机器人硬件平台，包括机械设计、电子系统和底层软件，所有CAD、PCB文件及底层软件均已开源发布。

Conclusion: Athena平台为救援机器人研究提供了灵活、可重构的开源解决方案，特别适合复杂地形导航和灾害响应任务，通过开源共享促进救援机器人技术发展。

Abstract: In disaster response and situation assessment, robots have great potential in reducing the risks to the safety and health of first responders. As the situations encountered and the required capabilities of the robots deployed in such missions differ wildly and are often not known in advance, heterogeneous fleets of robots are needed to cover a wide range of mission requirements. While UAVs can quickly survey the mission environment, their ability to carry heavy payloads such as sensors and manipulators is limited. UGVs can carry required payloads to assess and manipulate the mission environment, but need to be able to deal with difficult and unstructured terrain such as rubble and stairs. The ability of tracked platforms with articulated arms (flippers) to reconfigure their geometry makes them particularly effective for navigating challenging terrain. In this paper, we present Athena, an open-hardware rescue ground robot research platform with four individually reconfigurable flippers and a reliable low-cost remote emergency stop (E-Stop) solution. A novel mounting solution using an industrial PU belt and tooth inserts allows the replacement and testing of different track profiles. The manipulator with a maximum reach of 1.54m can be used to operate doors, valves, and other objects of interest. Full CAD & PCB files, as well as all low-level software, are released as open-source contributions.

</details>


### [49] [Scaling Law of Neural Koopman Operators](https://arxiv.org/abs/2602.19943)
*Abulikemu Abuduweili,Yuyang Pang,Feihan Li,Changliu Liu*

Main category: cs.RO

TL;DR: 本文为神经Koopman算子理论建立了严格的标度律框架，揭示了样本量、潜在空间维度与控制质量之间的关系，并提出了两种轻量级正则化器来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的神经Koopman算子理论已成为线性化和控制非线性机器人系统的强大工具，但其性能取决于样本量与模型维度之间的权衡关系，而这一关系的标度律一直不明确。

Method: 1. 推导Koopman近似误差的理论上界，将其分解为采样误差和投影误差；2. 基于理论结果引入两种轻量级正则化器：协方差损失（稳定学习到的潜在特征）和逆控制损失（确保模型与物理驱动对齐）；3. 在六个机器人环境中进行系统实验验证。

Result: 实验结果表明：1. 模型拟合误差遵循推导出的标度律；2. 正则化器提高了动态模型拟合的保真度；3. 增强了闭环控制性能。

Conclusion: 研究结果为学习Koopman动力学进行控制时，如何在数据收集和模型容量之间分配努力提供了简单指导方案。

Abstract: Data-driven neural Koopman operator theory has emerged as a powerful tool for linearizing and controlling nonlinear robotic systems. However, the performance of these data-driven models fundamentally depends on the trade-off between sample size and model dimensions, a relationship for which the scaling laws have remained unclear. This paper establishes a rigorous framework to address this challenge by deriving and empirically validating scaling laws that connect sample size, latent space dimension, and downstream control quality. We derive a theoretical upper bound on the Koopman approximation error, explicitly decomposing it into sampling error and projection error. We show that these terms decay at specific rates relative to dataset size and latent dimension, providing a rigorous basis for the scaling law. Based on the theoretical results, we introduce two lightweight regularizers for the neural Koopman operator: a covariance loss to help stabilize the learned latent features and an inverse control loss to ensure the model aligns with physical actuation. The results from systematic experiments across six robotic environments confirm that model fitting error follows the derived scaling laws, and the regularizers improve dynamic model fitting fidelity, with enhanced closed-loop control performance. Together, our results provide a simple recipe for allocating effort between data collection and model capacity when learning Koopman dynamics for control.

</details>


### [50] [Contextual Safety Reasoning and Grounding for Open-World Robots](https://arxiv.org/abs/2602.19983)
*Zachary Ravichadran,David Snyder,Alexander Robey,Hamed Hassani,Vijay Kumar,George J. Pappas*

Main category: cs.RO

TL;DR: CORE框架通过视觉语言模型实现机器人安全行为的在线上下文推理、环境落地和执行，无需先验环境知识


<details>
  <summary>Details</summary>
Motivation: 传统安全方法在固定约束和用户指定上下文中运行，无法处理开放世界环境中不断变化的上下文变异性

Method: 使用视觉语言模型从视觉观察中持续推理上下文相关的安全规则，将这些规则在物理环境中落地，并通过控制屏障函数执行空间定义的安全集

Result: CORE在未见环境中强制执行上下文适当的行为，显著优于缺乏在线上下文推理的先前语义安全方法，并提供考虑感知不确定性的概率安全保证

Conclusion: CORE框架通过在线上下文推理和空间落地，能够有效处理开放世界环境中的上下文变异性，为机器人安全提供了新方法

Abstract: Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.

</details>


### [51] [Hydrodynamic Performance Enhancement of Unmanned Underwater Gliders with Soft Robotic Morphing Wings for Agility Improvement](https://arxiv.org/abs/2602.20054)
*A. Giordano,G. De Meurichy,V. Telazzi,C. Mucignat,I. Lunati,D. A. L. M. Louchard,M. Iovieno,S. F. Armanini,M. Kovac*

Main category: cs.RO

TL;DR: 软变形翼UUV相比传统刚性翼UUV整体效率提升9.75%，证实了软体机器人技术在水下航行器性能提升方面的潜力


<details>
  <summary>Details</summary>
Motivation: 评估配备软变形翼的水下无人航行器（UUV）相比传统刚性翼的水动力效率。软变形翼能够按需改变气动特性，提高水动力效率可延长UUV的作业航程并可能决定任务可行性。

Method: 对软变形翼及其配备的UUV进行了结构和计算流体动力学（CFD）模拟，比较软变形翼与传统刚性翼的性能差异。

Result: 采用软变形翼的UUV相比配备传统刚性翼的同等航行器实现了9.75%的整体效率提升。

Conclusion: 研究结果证实了软体机器人技术在提升水下航行器性能方面的潜力，特别是在需要压力无关操作的应用中具有优势。

Abstract: This work assesses the hydrodynamic efficiency of Underwater Unmanned Vehicles (UUVs) equipped with soft morphing wings compared to conventional rigid wings. Unlike rigid wings, deformable counterparts can alter their aerodynamic properties on demand. Improvements in hydrodynamic efficiency extend a UUV's operational range and may determine mission feasibility. Structural and Computational Fluid Dynamics (CFD) simulations were conducted for both a soft morphing wing and a UUV incorporating it. The results show that a UUV employing soft wings achieves 9.75 percent higher overall efficiency than an equivalent vehicle with traditional rigid wings. These findings confirm the potential of soft robotics to enhance underwater vehicle performance, particularly in applications requiring pressure-agnostic operation.

</details>


### [52] [To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](https://arxiv.org/abs/2602.20055)
*Apoorva Vashisth,Manav Kulshrestha,Pranav Bakshi,Damon Conover,Guillaume Sartoretti,Aniket Bera*

Main category: cs.RO

TL;DR: 本文提出了一种终身交互式导航问题，让具备操作能力的移动机器人能够移动杂物来开辟路径，完成顺序物体放置任务。作者开发了一个基于LLM的约束规划框架，结合主动感知，在物理模拟器和真实硬件上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景（如家庭环境和仓库）中，杂物可能阻塞所有路径，而传统视觉导航假设至少存在一条无障碍路径。为了解决这种实际挑战，需要让机器人具备移动杂物开辟路径的能力来完成顺序物体放置任务。

Method: 提出了一个LLM驱动的、基于约束的规划框架，结合主动感知。LLM在结构化场景图上进行推理，决定移动哪个物体、放置到哪里、以及下一步观察哪里来发现任务相关信息。框架将推理与主动感知结合，使机器人能够探索预期有助于任务完成的区域，而不是详尽地映射整个环境。标准运动规划器执行相应的导航-拾取-放置或绕行序列。

Result: 在物理启用的ProcTHOR-10k模拟器中评估，该方法优于非学习和基于学习的基线方法。进一步在真实世界硬件上进行了定性演示，验证了方法的实际可行性。

Conclusion: 终身交互式导航问题是一个重要的现实挑战，提出的LLM驱动约束规划框架结合主动感知的方法能够有效解决这一问题，使机器人能够在杂物阻塞的环境中通过移动物体来开辟路径，完成顺序物体放置任务。

Abstract: Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving placing an given object (eg. Alarm clock, Pillow) onto a target object (eg. Dining table, Desk, Bed). To address this lifelong setting - where effects of environment changes accumulate and have long-term effects - we propose an LLM-driven, constraint-based planning framework with active perception. Our framework allows the LLM to reason over a structured scene graph of discovered objects and obstacles, deciding which object to move, where to place it, and where to look next to discover task-relevant information. This coupling of reasoning and active perception allows the agent to explore the regions expected to contribute to task completion rather than exhaustively mapping the environment. A standard motion planner then executes the corresponding navigate-pick-place, or detour sequence, ensuring reliable low-level control. Evaluated in physics-enabled ProcTHOR-10k simulator, our approach outperforms non-learning and learning-based baselines. We further demonstrate our approach qualitatively on real-world hardware.

</details>


### [53] [AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation](https://arxiv.org/abs/2602.20057)
*Ge Yuan,Qiyuan Qiao,Jing Zhang,Dong Xu*

Main category: cs.RO

TL;DR: AdaWorldPolicy是一个结合世界模型、扩散策略和在线自适应学习的统一框架，用于增强动态环境下的机器人操作能力，通过多模态注意力机制实现模块间深度特征交换，并利用力-力矩反馈缓解动态力偏移。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要能够预测物理结果并适应真实世界环境的策略。现有方法在动态条件下表现有限，需要大量人工干预。本研究旨在开发一个能够在动态环境中进行在线自适应学习、减少人工参与的机器人操作框架。

Method: 提出AdaWorldPolicy框架，包含三个基于Flow Matching Diffusion Transformers的模块：世界模型、动作专家和力预测器，通过多模态自注意力层相互连接。进一步提出在线自适应学习策略，动态切换动作生成模式和未来想象模式，驱动三个模块的实时更新。

Result: 在模拟和真实机器人基准测试中，AdaWorldPolicy实现了最先进的性能，对分布外场景具有动态自适应能力。

Conclusion: 世界模型为动态环境中的在线自适应学习提供了强大的监督信号，结合力-力矩反馈可以缓解动态力偏移。提出的统一框架通过闭环机制实现了对视觉和物理域偏移的自适应，在机器人操作任务中表现出色。

Abstract: Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a unified framework, World-Model-Driven Diffusion Policy with Online Adaptive Learning (AdaWorldPolicy) to enhance robotic manipulation under dynamic conditions with minimal human involvement. Our core insight is that world models provide strong supervision signals, enabling online adaptive learning in dynamic environments, which can be complemented by force-torque feedback to mitigate dynamic force shifts. Our AdaWorldPolicy integrates a world model, an action expert, and a force predictor-all implemented as interconnected Flow Matching Diffusion Transformers (DiT). They are interconnected via the multi-modal self-attention layers, enabling deep feature exchange for joint learning while preserving their distinct modularity characteristics. We further propose a novel Online Adaptive Learning (AdaOL) strategy that dynamically switches between an Action Generation mode and a Future Imagination mode to drive reactive updates across all three modules. This creates a powerful closed-loop mechanism that adapts to both visual and physical domain shifts with minimal overhead. Across a suite of simulated and real-robot benchmarks, our AdaWorldPolicy achieves state-of-the-art performance, with dynamical adaptive capacity to out-of-distribution scenarios.

</details>


### [54] [NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning](https://arxiv.org/abs/2602.20119)
*Jiahui Fu,Junyu Nan,Lingfeng Sun,Hongyu Li,Jianing Qian,Jennifer L. Barry,Kris Kitani,George Konidaris*

Main category: cs.RO

TL;DR: NovaPlan是一个分层框架，结合了视觉语言模型规划、视频生成和几何基础机器人执行，用于零样本长时程操作任务。


<details>
  <summary>Details</summary>
Motivation: 解决长时程任务需要机器人整合高层语义推理和低层物理交互。现有视觉语言模型和视频生成模型虽然能分解任务和想象结果，但缺乏真实世界执行所需的物理基础。

Method: 采用分层框架：高层使用VLM规划器闭环分解任务并监控执行，实现单步失败后的自主重规划；低层从生成视频中提取任务相关物体关键点和人手姿态作为运动学先验，通过切换机制选择更好的参考来生成机器人动作。

Result: 在三个长时程任务和功能操作基准测试中，NovaPlan能够执行复杂装配任务并展示灵巧的错误恢复行为，无需任何先验演示或训练。

Conclusion: NovaPlan通过统一闭环VLM视频规划和几何基础机器人执行，实现了零样本长时程操作，在复杂装配和错误恢复方面表现出色。

Abstract: Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation. At the high level, a VLM planner decomposes tasks into sub-goals and monitors robot execution in a closed loop, enabling the system to recover from single-step failures through autonomous re-planning. To compute low-level robot actions, we extract and utilize both task-relevant object keypoints and human hand poses as kinematic priors from the generated videos, and employ a switching mechanism to choose the better one as a reference for robot actions, maintaining stable execution even under heavy occlusion or depth inaccuracy. We demonstrate the effectiveness of NovaPlan on three long-horizon tasks and the Functional Manipulation Benchmark (FMB). Our results show that NovaPlan can perform complex assembly tasks and exhibit dexterous error recovery behaviors without any prior demonstrations or training. Project page: https://nova-plan.github.io/

</details>


### [55] [Simulation-Ready Cluttered Scene Estimation via Physics-aware Joint Shape and Pose Optimization](https://arxiv.org/abs/2602.20150)
*Wei-Cheng Huang,Jiaheng Han,Xiaohan Ye,Zherong Pan,Kris Hauser*

Main category: cs.RO

TL;DR: 提出了一种基于优化的真实到仿真场景估计方法，能够联合恢复多个刚性物体的形状和姿态，同时考虑物理约束，适用于杂乱环境。


<details>
  <summary>Details</summary>
Motivation: 现有方法在杂乱环境中存在计算成本高、鲁棒性差、扩展到多交互物体时通用性受限的问题，而准确估计仿真就绪场景对下游规划和策略学习任务至关重要。

Method: 采用统一的基于优化的真实到仿真场景估计框架，结合形状可微接触模型实现物体几何和姿态的联合优化，利用增广拉格朗日海森矩阵的结构稀疏性开发高效线性系统求解器，并构建端到端流程包括学习式物体初始化、物理约束的联合形状-姿态优化和可微纹理细化。

Result: 在包含最多5个物体和22个凸包的杂乱场景实验中，该方法能够鲁棒地重建物理有效、仿真就绪的物体形状和姿态。

Conclusion: 该方法通过统一的优化框架和关键技术创新，成功解决了杂乱环境中多物体场景估计的挑战，为下游任务提供了高质量的仿真就绪场景。

Abstract: Estimating simulation-ready scenes from real-world observations is crucial for downstream planning and policy learning tasks. Regretfully, existing methods struggle in cluttered environments, often exhibiting prohibitive computational cost, poor robustness, and restricted generality when scaling to multiple interacting objects. We propose a unified optimization-based formulation for real-to-sim scene estimation that jointly recovers the shapes and poses of multiple rigid objects under physical constraints. Our method is built on two key technical innovations. First, we leverage the recently introduced shape-differentiable contact model, whose global differentiability permits joint optimization over object geometry and pose while modeling inter-object contacts. Second, we exploit the structured sparsity of the augmented Lagrangian Hessian to derive an efficient linear system solver whose computational cost scales favorably with scene complexity. Building on this formulation, we develop an end-to-end real-to-sim scene estimation pipeline that integrates learning-based object initialization, physics-constrained joint shape-pose optimization, and differentiable texture refinement. Experiments on cluttered scenes with up to 5 objects and 22 convex hulls demonstrate that our approach robustly reconstructs physically valid, simulation-ready object shapes and poses.

</details>
