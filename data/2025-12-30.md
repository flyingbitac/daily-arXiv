<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs](https://arxiv.org/abs/2512.22342)
*Wensi Huang,Shaohao Zhu,Meng Wei,Jinming Xu,Xihui Liu,Hanqing Wang,Tai Wang,Feng Zhao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 论文提出了交互式实例对象导航（IION）任务和视觉语言-语言导航（VL-LN）基准，用于解决现实世界中模糊导航指令的问题，要求智能体通过主动对话来推断用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有具身导航任务中的指令通常是明确无歧义的，但现实世界的导航指令往往模糊不清，需要智能体通过主动对话来解析不确定性和推断用户意图。

Method: 提出IION任务，扩展实例对象导航（ION），允许智能体在导航过程中用自然语言自由咨询oracle。基于此任务构建VL-LN基准，包含大规模自动生成的数据集和综合评估协议。

Result: VL-LN包含超过41k个长视野对话增强轨迹用于训练，以及带有能够响应智能体查询的oracle的自动评估协议。训练出的具备对话能力的导航模型相比基线有显著提升。

Conclusion: VL-LN基准为对话使能的具身导航研究提供了有效的训练和评估框架，实验证明其有效性和可靠性，推动了该领域的发展。

Abstract: In most existing embodied navigation tasks, instructions are well-defined and unambiguous, such as instruction following and object searching. Under this idealized setting, agents are required solely to produce effective navigation outputs conditioned on vision and language inputs. However, real-world navigation instructions are often vague and ambiguous, requiring the agent to resolve uncertainty and infer user intent through active dialog. To address this gap, we propose Interactive Instance Object Navigation (IION), a task that requires agents not only to generate navigation actions but also to produce language outputs via active dialog, thereby aligning more closely with practical settings. IION extends Instance Object Navigation (ION) by allowing agents to freely consult an oracle in natural language while navigating. Building on this task, we present the Vision Language-Language Navigation (VL-LN) benchmark, which provides a large-scale, automatically generated dataset and a comprehensive evaluation protocol for training and assessing dialog-enabled navigation models. VL-LN comprises over 41k long-horizon dialog-augmented trajectories for training and an automatic evaluation protocol with an oracle capable of responding to agent queries. Using this benchmark, we train a navigation model equipped with dialog capabilities and show that it achieves significant improvements over the baselines. Extensive experiments and analyses further demonstrate the effectiveness and reliability of VL-LN for advancing research on dialog-enabled embodied navigation. Code and dataset: https://0309hws.github.io/VL-LN.github.io/

</details>


### [2] [A Unified AI, Embedded, Simulation, and Mechanical Design Approach to an Autonomous Delivery Robot](https://arxiv.org/abs/2512.22408)
*Amro Gamar,Ahmed Abduljalil,Alargam Mohammed,Ali Elhenidy,Abeer Tawakol*

Main category: cs.RO

TL;DR: 开发了一个集机械工程、嵌入式系统和人工智能于一体的全自主送货机器人平台，采用异构计算架构，实现了AI感知与实时控制的协同工作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在现实世界中部署的自主送货系统，解决资源受限平台上计算密集型AI算法的优化问题，以及ROS 2主机与嵌入式控制器之间低延迟可靠通信的技术挑战。

Method: 采用异构计算架构：RPi 5和ROS 2处理基于AI的感知和路径规划，ESP32运行FreeRTOS确保实时电机控制。通过精确的电机选择和材料工程优化机械设计，实现有效载荷能力和移动性。采用PID电机控制、严格的内存和任务管理，以及AWS IoT监控和固件级电机停机安全机制。

Result: 实现了确定性的PID电机控制，通过严格的内存和任务管理确保了系统可靠性。AWS IoT监控和固件级电机停机安全机制增强了系统可靠性。最终开发出了一个稳健且可操作的自主送货系统，具备现实世界部署能力。

Conclusion: 这项工作展示了一种统一的多学科方法论，成功开发出了一个能够在现实世界中部署的稳健自主送货系统，解决了资源受限平台上的技术挑战，实现了AI感知与实时控制的协同工作。

Abstract: This paper presents the development of a fully autonomous delivery robot integrating mechanical engineering, embedded systems, and artificial intelligence. The platform employs a heterogeneous computing architecture, with RPi 5 and ROS 2 handling AI-based perception and path planning, while ESP32 running FreeRTOS ensures real-time motor control. The mechanical design was optimized for payload capacity and mobility through precise motor selection and material engineering. Key technical challenges addressed include optimizing computationally intensive AI algorithms on a resource-constrained platform and implementing a low-latency, reliable communication link between the ROS 2 host and embedded controller. Results demonstrate deterministic, PID-based motor control through rigorous memory and task management, and enhanced system reliability via AWS IoT monitoring and a firmware-level motor shutdown failsafe. This work highlights a unified, multi-disciplinary methodology, resulting in a robust and operational autonomous delivery system capable of real-world deployment.

</details>


### [3] [Emergence of Human to Robot Transfer in Vision-Language-Action Models](https://arxiv.org/abs/2512.22414)
*Simar Kareer,Karl Pertsch,James Darpinian,Judy Hoffman,Danfei Xu,Sergey Levine,Chelsea Finn,Suraj Nair*

Main category: cs.RO

TL;DR: 该研究探索了利用人类视频数据训练视觉-语言-动作模型的可能性，发现当模型在足够多样化的场景、任务和体现形式上预训练时，能够实现从人类到机器人的技能迁移。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型需要大量多样化数据来实现开放世界的泛化能力。人类视频覆盖了丰富的真实世界场景且易于获取，但直接利用人类视频训练VLA模型面临人类-机器人映射的工程挑战。受大型语言模型从多样化监督中学习能力的启发，研究者探索VLA模型是否也能通过规模效应实现类似能力。

Method: 引入简单的协同训练方法，通过在不同场景、任务和体现形式上进行大规模预训练，使VLA模型能够学习到体现无关的表征。这种方法允许模型从人类视频数据中学习，并将其知识迁移到机器人控制任务中。

Result: 研究发现，当VLA模型在足够多样化的机器人预训练基础上，能够实现从人类到机器人的技能迁移。分析表明这种涌现能力源于多样化预训练产生了人类和机器人数据的体现无关表征。在仅有人类数据的泛化设置中，该方法能够将性能提升近一倍。

Conclusion: 通过足够多样化的预训练，VLA模型能够学习到体现无关的表征，从而实现从人类视频到机器人控制的技能迁移。这一发现为利用丰富的人类视频数据训练机器人系统提供了新的可能性，减少了手动工程映射的需求。

Abstract: Vision-language-action (VLA) models can enable broad open world generalization, but require large and diverse datasets. It is appealing to consider whether some of this data can come from human videos, which cover diverse real-world situations and are easy to obtain. However, it is difficult to train VLAs with human videos alone, and establishing a mapping between humans and robots requires manual engineering and presents a major research challenge. Drawing inspiration from advances in large language models, where the ability to learn from diverse supervision emerges with scale, we ask whether a similar phenomenon holds for VLAs that incorporate human video data. We introduce a simple co-training recipe, and find that human-to-robot transfer emerges once the VLA is pre-trained on sufficient scenes, tasks, and embodiments. Our analysis suggests that this emergent capability arises because diverse pretraining produces embodiment-agnostic representations for human and robot data. We validate these findings through a series of experiments probing human to robot skill transfer and find that with sufficiently diverse robot pre-training our method can nearly double the performance on generalization settings seen only in human data.

</details>


### [4] [Bugs with Features: Vision-Based Fault-Tolerant Collective Motion Inspired by Nature](https://arxiv.org/abs/2512.22448)
*Peleg Shefi,Amir Ayali,Gal A. Kaminka*

Main category: cs.RO

TL;DR: 论文提出两种机制提升视觉感知机器人集群运动的鲁棒性：结合水平和垂直尺寸的邻居距离估计方法，以及间歇性运动来检测和避免故障机器人


<details>
  <summary>Details</summary>
Motivation: 自然群体运动具有鲁棒性，但人工集群系统（特别是基于视觉感知的）通常很脆弱，主要由于视觉感知固有的模糊性和信息损失问题

Method: 1. 开发结合邻居水平和垂直尺寸的鲁棒距离估计方法；2. 引入间歇性运动机制，使机器人能可靠检测落后同伴并中断集群运动；3. 提出对故障机器人的鲁棒避免策略

Result: 通过大量基于物理的仿真实验，显示这些技术显著提高了集群的韧性，适用于基于距离的避让-吸引模型和对齐模型，在多种实验设置中都有效

Conclusion: 受蝗虫研究启发的机制能有效提升视觉感知机器人集群运动的鲁棒性，解决了人工集群系统在视觉感知下的脆弱性问题

Abstract: In collective motion, perceptually-limited individuals move in an ordered manner, without centralized control. The perception of each individual is highly localized, as is its ability to interact with others. While natural collective motion is robust, most artificial swarms are brittle. This particularly occurs when vision is used as the sensing modality, due to ambiguities and information-loss inherent in visual perception. This paper presents mechanisms for robust collective motion inspired by studies of locusts. First, we develop a robust distance estimation method that combines visually perceived horizontal and vertical sizes of neighbors. Second, we introduce intermittent locomotion as a mechanism that allows robots to reliably detect peers that fail to keep up, and disrupt the motion of the swarm. We show how such faulty robots can be avoided in a manner that is robust to errors in classifying them as faulty. Through extensive physics-based simulation experiments, we show dramatic improvements to swarm resilience when using these techniques. We show these are relevant to both distance-based Avoid-Attract models, as well as to models relying on Alignment, in a wide range of experiment settings.

</details>


### [5] [Asymmetric Friction in Geometric Locomotion](https://arxiv.org/abs/2512.22484)
*Ross L. Hatton,Yousef Salaman,Shai Revzen*

Main category: cs.RO

TL;DR: 该论文将几何力学中的运动性映射从黎曼度量推广到芬斯勒度量，考虑了各向异性且不对称的阻力，建立了子芬斯勒框架来分析机器人运动能力。


<details>
  <summary>Details</summary>
Motivation: 现有几何力学模型主要基于黎曼度量描述各向同性或各向异性阻力，但无法处理不对称阻力（如前进和后退阻力不同）。实际生物和机器人系统中常存在这种不对称性，需要更一般的理论框架。

Method: 将黎曼度量推广到芬斯勒度量来描述不对称阻力，将子黎曼构造方法扩展到子芬斯勒框架，建立系统运动性映射，并识别类似于子黎曼系统中约束曲率的系统特性。

Result: 成功建立了包含不对称阻力的子芬斯勒运动性映射理论框架，识别了表征系统运动能力的关键特性，扩展了几何力学模型的应用范围。

Conclusion: 该研究将几何力学中的运动性映射从对称阻力情况推广到不对称阻力情况，为分析更广泛的生物和机器人运动系统提供了更一般的数学框架，子芬斯勒方法能够更好地描述实际系统中的复杂阻力特性。

Abstract: Geometric mechanics models of locomotion have provided insight into how robots and animals use environmental interactions to convert internal shape changes into displacement through the world, encoding this relationship in a ``motility map''. A key class of such motility maps arises from (possibly anisotropic) linear drag acting on the system's individual body parts, formally described via Riemannian metrics on the motions of the system's individual body parts. The motility map can then be generated by invoking a sub-Riemannian constraint on the aggregate system motion under which the position velocity induced by a given shape velocity is that which minimizes the power dissipated via friction. The locomotion of such systems is ``geometric'' in the sense that the final position reached by the system depends only on the sequence of shapes that the system passes through, but not on the rate with which the shape changes are made.
  In this paper, we consider a far more general class of systems in which the drag may be not only anisotropic (with different coefficients for forward/backward and left/right motions), but also asymmetric (with different coefficients for forward and backward motions). Formally, including asymmetry in the friction replaces the Riemannian metrics on the body parts with Finsler metrics. We demonstrate that the sub-Riemannian approach to constructing the system motility map extends naturally to a sub-Finslerian approach and identify system properties analogous to the constraint curvature of sub-Riemannian systems that allow for the characterization of the system motion capabilities.

</details>


### [6] [Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces](https://arxiv.org/abs/2512.22502)
*Shen Changqing,Xu Bingzhou,Qi Bosong,Zhang Xiaojian,Yan Sijie,Ding Han*

Main category: cs.RO

TL;DR: 提出一种基于保形缝映射和拓扑保持网格变形的球头铣削路径规划方法，解决多连通自由曲面加工中的边界一致性和梯度奇异点问题。


<details>
  <summary>Details</summary>
Motivation: 在多连通自由曲面上进行球头铣削路径规划时，现有标量场优化方法难以同时保持边界一致性并消除导致等值线分支或终止的零梯度奇异点，这会破坏刀具路径的连续性。

Method: 采用保形缝映射构建无奇异点的初始标量场，将优化重新表述为边界同步更新控制的拓扑保持网格变形，实现全局优化的间距、残留高度均匀性和平滑轨迹过渡。

Result: 相比最先进的基于保形缝映射的方法，加工效率提高14.24%，残留高度均匀性改善5.70%，铣削冲击引起的振动降低超过10%。

Conclusion: 该方法能够生成连续、边界一致且无自相交的刀具路径，在高性能加工场景中具有广泛适用性。

Abstract: Ball-end milling path planning on multiply connected freeform surfaces is pivotal for high-quality and efficient machining of components in automotive and aerospace manufacturing. Although scalar-field-based optimization provides a unified framework for multi-objective toolpath generation, maintaining boundary conformity while eliminating zero-gradient singularities that cause iso-curve branching or termination and disrupt toolpath continuity remains challenging on multiply connected surfaces. We propose an efficient strategy to robustly enforce these constraints throughout optimization. Conformal slit mapping is employed to construct a feasible, singularity-free initial scalar field. The optimization is reformulated as a topology-preserving mesh deformation governed by boundary-synchronous updates, enabling globally optimized spacing, scallop-height uniformity, and smooth trajectory transitions. Consequently, the toolpaths are continuous, boundary-conforming, and free of self-intersections. Milling experiments demonstrate that, compared with a state-of-the-art conformal slit mapping-based method, the proposed approach increases machining efficiency by 14.24%, improves scallop-height uniformity by 5.70%, and reduces milling impact-induced vibrations by over 10%. The strategy offers broad applicability in high-performance machining scenarios.

</details>


### [7] [Clutter-Resistant Vision-Language-Action Models through Object-Centric and Geometry Grounding](https://arxiv.org/abs/2512.22519)
*Khoa Vo,Taisei Hanyu,Yuki Ikebe,Trong Thang Pham,Nhat Chung,Minh Nhat Vu,Duy Nguyen Ho Minh,Anh Nguyen,Anthony Gunderman,Chase Rainwater,Ngan Le*

Main category: cs.RO

TL;DR: OBEYED-VLA框架通过显式解耦感知与动作推理，在视觉-语言-动作模型中引入物体中心和几何感知的观察表示，显著提升了机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型将感知与控制耦合在单一管道中，主要针对动作预测进行优化，这会削弱语言条件的基础。在实际测试中，策略在目标缺失时过度抓取、被杂物干扰、并对背景外观过拟合。

Method: 提出OBEYED-VLA框架，包含两个阶段：1) 基于VLM的物体中心基础阶段，跨相机视角选择任务相关物体区域；2) 几何基础阶段，强调物体的3D结构而非外观。然后将基础后的视图输入预训练的VLA策略，仅使用无环境杂物和非目标物体的单物体演示进行微调。

Result: 在真实世界UR10e桌面设置中，OBEYED-VLA在四个挑战性场景中显著优于强VLA基线：干扰物体、目标缺失拒绝、背景外观变化、以及未见物体的杂乱操作。消融研究证实语义基础和几何感知基础都对性能提升至关重要。

Conclusion: 将感知作为显式的、物体中心的组件是增强和泛化基于VLA的机器人操作的有效方法。感知与动作推理的显式解耦能提高鲁棒性和泛化能力。

Abstract: Recent Vision-Language-Action (VLA) models have made impressive progress toward general-purpose robotic manipulation by post-training large Vision-Language Models (VLMs) for action prediction. Yet most VLAs entangle perception and control in a monolithic pipeline optimized purely for action, which can erode language-conditioned grounding. In our real-world tabletop tests, policies over-grasp when the target is absent, are distracted by clutter, and overfit to background appearance.
  To address these issues, we propose OBEYED-VLA (OBject-centric and gEometrY groundED VLA), a framework that explicitly disentangles perceptual grounding from action reasoning. Instead of operating directly on raw RGB, OBEYED-VLA augments VLAs with a perception module that grounds multi-view inputs into task-conditioned, object-centric, and geometry-aware observations. This module includes a VLM-based object-centric grounding stage that selects task-relevant object regions across camera views, along with a complementary geometric grounding stage that emphasizes the 3D structure of these objects over their appearance. The resulting grounded views are then fed to a pretrained VLA policy, which we fine-tune exclusively on single-object demonstrations collected without environmental clutter or non-target objects.
  On a real-world UR10e tabletop setup, OBEYED-VLA substantially improves robustness over strong VLA baselines across four challenging regimes and multiple difficulty levels: distractor objects, absent-target rejection, background appearance changes, and cluttered manipulation of unseen objects. Ablation studies confirm that both semantic grounding and geometry-aware grounding are critical to these gains. Overall, the results indicate that making perception an explicit, object-centric component is an effective way to strengthen and generalize VLA-based robotic manipulation.

</details>


### [8] [VLA-Arena: An Open-Source Framework for Benchmarking Vision-Language-Action Models](https://arxiv.org/abs/2512.22539)
*Borong Zhang,Jiahao Li,Jiachen Shen,Yishuai Cai,Yuhao Zhang,Yuanpei Chen,Juntao Dai,Jiaming Ji,Yaodong Yang*

Main category: cs.RO

TL;DR: VLA-Arena是一个用于系统评估视觉-语言-动作模型能力的综合基准，通过结构化任务设计框架从三个正交维度量化难度，揭示VLA模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型快速发展，但缺乏量化理解其限制和失败模式的系统方法。需要建立一个全面的基准来精确测量模型能力边界。

Method: 提出结构化任务设计框架，从三个正交维度量化难度：(1)任务结构（安全、干扰、外推、长视野），(2)语言指令，(3)视觉观察。设计了170个任务，每个任务有3个难度级别，并应用语言和视觉扰动进行解耦分析。

Result: 对最先进VLA模型的广泛评估揭示了多个关键限制：强记忆化而非泛化倾向、不对称鲁棒性、缺乏安全约束考虑、无法组合学习技能处理长视野任务。

Conclusion: VLA-Arena为系统评估VLA模型提供了全面基准，揭示了当前模型的局限性，并提供了完整框架、数据集和工具链以促进相关研究。

Abstract: While Vision-Language-Action models (VLAs) are rapidly advancing towards generalist robot policies, it remains difficult to quantitatively understand their limits and failure modes. To address this, we introduce a comprehensive benchmark called VLA-Arena. We propose a novel structured task design framework to quantify difficulty across three orthogonal axes: (1) Task Structure, (2) Language Command, and (3) Visual Observation. This allows us to systematically design tasks with fine-grained difficulty levels, enabling a precise measurement of model capability frontiers. For Task Structure, VLA-Arena's 170 tasks are grouped into four dimensions: Safety, Distractor, Extrapolation, and Long Horizon. Each task is designed with three difficulty levels (L0-L2), with fine-tuning performed exclusively on L0 to assess general capability. Orthogonal to this, language (W0-W4) and visual (V0-V4) perturbations can be applied to any task to enable a decoupled analysis of robustness. Our extensive evaluation of state-of-the-art VLAs reveals several critical limitations, including a strong tendency toward memorization over generalization, asymmetric robustness, a lack of consideration for safety constraints, and an inability to compose learned skills for long-horizon tasks. To foster research addressing these challenges and ensure reproducibility, we provide the complete VLA-Arena framework, including an end-to-end toolchain from task definition to automated evaluation and the VLA-Arena-S/M/L datasets for fine-tuning. Our benchmark, data, models, and leaderboard are available at https://vla-arena.github.io.

</details>


### [9] [Modeling of UAV Tether Aerodynamics for Real-Time Simulation](https://arxiv.org/abs/2512.22588)
*Max Beffert,Andreas Zell*

Main category: cs.RO

TL;DR: 提出了两种实时准静态系留建模方法：基于悬链线理论的解析方法（<1ms）和基于分段离散化的数值方法（5ms），用于解决移动基座或强风条件下的系留无人机力建模问题。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机受电池限制飞行时间短，通过系留从地面供电可实现连续作业。但在快速移动基座或强风条件下，需要考虑系留绳的力建模（包括空气动力学效应），现有方法难以满足实时性要求。

Method: 提出两种互补方法：1）基于悬链线理论和均匀阻力假设的解析方法，计算极快（<1ms）；2）将系留绳离散为分段和集中质量的数值方法，使用CasADi和IPOPT求解平衡方程，通过热启动和解析初始化实现实时性能（5ms）。

Result: 通过负载传感器进行真实世界测试验证。解析方法对大多数系留无人机应用具有足够精度且计算成本极低；数值方法在需要时提供更高灵活性和物理精度。两种方法均实现实时性能。

Conclusion: 两种方法构成了轻量级、可扩展的实时系留仿真框架，适用于离线优化和在线任务（仿真、控制和轨迹规划）。解析方法适合大多数应用，数值方法在需要更高精度时提供补充。

Abstract: One of the main limitations of multirotor UAVs is their short flight time due to battery constraints. A practical solution for continuous operation is to power the drone from the ground via a tether. While this approach has been demonstrated for stationary systems, scenarios with a fast-moving base vehicle or strong wind conditions require modeling the tether forces, including aerodynamic effects. In this work, we propose two complementary approaches for real-time quasi-static tether modeling with aerodynamics. The first is an analytical method based on catenary theory with a uniform drag assumption, achieving very fast solve times below 1ms. The second is a numerical method that discretizes the tether into segments and lumped masses, solving the equilibrium equations using CasADi and IPOPT. By leveraging initialization strategies, such as warm starting and analytical initialization, real-time performance was achieved with a solve time of 5ms, while allowing for flexible force formulations. Both approaches were validated in real-world tests using a load cell to measure the tether force. The results show that the analytical method provides sufficient accuracy for most tethered UAV applications with minimal computational cost, while the numerical method offers higher flexibility and physical accuracy when required. These approaches form a lightweight and extensible framework for real-time tether simulation, applicable to both offline optimization and online tasks such as simulation, control, and trajectory planning.

</details>


### [10] [Sistema de navegación de cobertura para vehículos no holonómicos en ambientes de exterior](https://arxiv.org/abs/2512.22734)
*Michelle Valenzuela,Francisco Leiva,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 本文提出了一种用于非完整机器人的覆盖导航系统，旨在实现特定区域的完全覆盖，适用于采矿等工业场景的自动化任务。


<details>
  <summary>Details</summary>
Motivation: 移动机器人覆盖导航对于清洁、采矿等工业自动化任务至关重要。采矿行业中的物料移动、清洁、尾矿坝建设等单元过程都需要覆盖导航，自动化这些过程对提高作业安全性具有重要意义。

Method: 开发了一个覆盖导航系统，包括为移动平台计算覆盖特定区域的路径，并集成了恢复行为机制。当遇到动态障碍物或未映射的障碍物（如其他机器或行人）时，系统能够执行规避机动和恢复后操作，确保区域完全覆盖。

Result: 系统在不同模拟和真实室外环境中进行了测试，大多数实验获得了接近90%的覆盖率。下一步计划将系统扩展到采矿机械/车辆上，并在真实环境中验证其操作。

Conclusion: 该覆盖导航系统为非完整机器人提供了有效的区域覆盖解决方案，证明了采矿等工业过程中自动化覆盖导航任务的可行性，为工业自动化应用提供了概念验证。

Abstract: In mobile robotics, coverage navigation refers to the deliberate movement of a robot with the purpose of covering a certain area or volume. Performing this task properly is fundamental for the execution of several activities, for instance, cleaning a facility with a robotic vacuum cleaner. In the mining industry, it is required to perform coverage in several unit processes related with material movement using industrial machinery, for example, in cleaning tasks, in dumps, and in the construction of tailings dam walls. The automation of these processes is fundamental to enhance the security associated with their execution. In this work, a coverage navigation system for a non-holonomic robot is presented. This work is intended to be a proof of concept for the potential automation of various unit processes that require coverage navigation like the ones mentioned before. The developed system includes the calculation of routes that allow a mobile platform to cover a specific area, and incorporates recovery behaviors in case that an unforeseen event occurs, such as the arising of dynamic or previously unmapped obstacles in the terrain to be covered, e.g., other machines or pedestrians passing through the area, being able to perform evasive maneuvers and post-recovery to ensure a complete coverage of the terrain. The system was tested in different simulated and real outdoor environments, obtaining results near 90% of coverage in the majority of experiments. The next step of development is to scale up the utilized robot to a mining machine/vehicle whose operation will be validated in a real environment. The result of one of the tests performed in the real world can be seen in the video available in https://youtu.be/gK7_3bK1P5g.

</details>


### [11] [Active Constraint Learning in High Dimensions from Demonstrations](https://arxiv.org/abs/2512.22757)
*Zheng Qiu,Chih-Yuan Chiu,Glen Chou*

Main category: cs.RO

TL;DR: 提出一种迭代式主动约束学习算法，通过智能地请求信息丰富的演示轨迹来推断演示者环境中的未知约束


<details>
  <summary>Details</summary>
Motivation: 在从演示学习（LfD）范式中，如何高效地从稀疏演示中推断未知约束是一个挑战。传统方法可能依赖随机采样，效率较低，需要更智能的方法来主动获取信息丰富的演示数据

Method: 使用迭代式主动约束学习算法：1）在可用演示数据集上训练高斯过程（GP）来表示未知约束；2）利用GP后验查询起始/目标状态；3）生成信息丰富的演示并添加到数据集中。该方法在高维非线性动力学和未知非线性约束条件下进行测试

Result: 在仿真和硬件实验中，该方法在从迭代生成的稀疏但信息丰富的演示集中准确执行约束推断方面，优于基于随机采样的基线方法

Conclusion: 提出的迭代主动约束学习算法能够有效地从稀疏演示中推断未知约束，通过智能地选择信息丰富的演示轨迹，提高了约束推断的准确性和效率

Abstract: We present an iterative active constraint learning (ACL) algorithm, within the learning from demonstrations (LfD) paradigm, which intelligently solicits informative demonstration trajectories for inferring an unknown constraint in the demonstrator's environment. Our approach iteratively trains a Gaussian process (GP) on the available demonstration dataset to represent the unknown constraints, uses the resulting GP posterior to query start/goal states, and generates informative demonstrations which are added to the dataset. Across simulation and hardware experiments using high-dimensional nonlinear dynamics and unknown nonlinear constraints, our method outperforms a baseline, random-sampling based method at accurately performing constraint inference from an iteratively generated set of sparse but informative demonstrations.

</details>


### [12] [Two-Robot Computational Landscape: A Complete Characterization of Model Power in Minimal Mobile Robot Systems](https://arxiv.org/abs/2512.22770)
*Naoki Kitamura,Yuichi Sudo,Koichi Wada*

Main category: cs.RO

TL;DR: 首次完整刻画了两个自主移动机器人在所有主要模型下的计算能力，揭示了与多机器人情况根本不同的计算格局，特别是在完全同步下FSTA和LUMI模型等价，表明完美同步可以替代记忆和通信。


<details>
  <summary>Details</summary>
Motivation: 虽然多机器人场景下的计算能力层次结构已基本建立，但两个机器人的精确计算结构一直未解决。本文旨在填补这一空白，全面分析两个机器人在所有主要模型下的计算能力。

Method: 采用无模拟方法，系统分析两个机器人在OBLOT、FSTA、FCOM和LUMI模型下，面对完整调度器谱系（FSYNCH、SSYNCH、ASYNCH及其原子变体）的计算能力。通过构造性证明建立等价和分离关系。

Result: 1. 证明了在完全同步下FSTA^F和LUMI^F模型等价，表明完美同步可以替代记忆和通信；2. 证明了FSTA和FCOM模型正交且不可比较；3. 建立了完整的两个机器人计算能力层次结构，与多机器人情况有根本差异。

Conclusion: 首次获得了两个自主移动机器人的完整精确计算格局，揭示了最小规模协调的内在挑战，为理解分布式机器人系统的计算能力提供了新的理论基础。

Abstract: The computational power of autonomous mobile robots under the Look-Compute-Move (LCM) model has been widely studied through an extensive hierarchy of robot models defined by the presence of memory, communication, and synchrony assumptions. While the general n-robot landscape has been largely established, the exact structure for two robots has remained unresolved. This paper presents the first complete characterization of the computational power of two autonomous robots across all major models, namely OBLOT, FSTA, FCOM, and LUMI, under the full spectrum of schedulers (FSYNCH, SSYNCH, ASYNCH, and their atomic variants). Our results reveal a landscape that fundamentally differs from the general case. Most notably, we prove that FSTA^F and LUMI^F coincide under full synchrony, a surprising collapse indicating that perfect synchrony can substitute both memory and communication when only two robots exist. We also show that FSTA and FCOM are orthogonal: there exists a problem solvable in the weakest communication model but impossible even in the strongest finite-state model, completing the bidirectional incomparability. All equivalence and separation results are derived through a novel simulation-free method, providing a unified and constructive view of the two-robot hierarchy. This yields the first complete and exact computational landscape for two robots, highlighting the intrinsic challenges of coordination at the minimal scale.

</details>


### [13] [The body is not there to compute: Comment on "Informational embodiment: Computational role of information structure in codes and robots" by Pitti et al](https://arxiv.org/abs/2512.22868)
*Matej Hoffmann*

Main category: cs.RO

TL;DR: 该评论文章认为身体的主要功能不是计算，反对将计算和信息处理作为理解生物体进化和机器人设计的核心框架。


<details>
  <summary>Details</summary>
Motivation: 作者旨在挑战目标文章中提出的观点，即计算和信息处理是理解动物身体进化和机器人身体设计优化的核心框架。作者认为这种计算主义的视角过于简化，未能捕捉身体的本质功能。

Method: 通过哲学评论的方式，对目标文章的计算主义框架进行批判性分析，提出身体的主要功能不是计算，而是执行其他更基本的生物和物理功能。

Result: 作者成功指出了计算主义框架在理解身体功能方面的局限性，强调身体的主要角色不是信息处理，而是其他更基本的生物功能。

Conclusion: 虽然计算和信息理论在理解神经系统和认知方面有价值，但将其应用于身体的理解和设计时存在局限性，身体的主要功能不是计算，需要更全面的理解框架。

Abstract: Applying the lens of computation and information has been instrumental in driving the technological progress of our civilization as well as in empowering our understanding of the world around us. The digital computer was and for many still is the leading metaphor for how our mind operates. Information theory (IT) has also been important in our understanding of how nervous systems encode and process information. The target article deploys information and computation to bodies: to understand why they have evolved in particular ways (animal bodies) and to design optimal bodies (robots). In this commentary, I argue that the main role of bodies is not to compute.

</details>


### [14] [P-FABRIK: A General Intuitive and Robust Inverse Kinematics Method for Parallel Mechanisms Using FABRIK Approach](https://arxiv.org/abs/2512.22927)
*Daqian Cao,Quan Yuan,Weibang Bai*

Main category: cs.RO

TL;DR: 提出P-FABRIK方法，基于FABRIK算法为多种并联机构提供通用、直观、鲁棒的逆运动学解决方案，能处理冗余并联机构和工作空间外目标问题。


<details>
  <summary>Details</summary>
Motivation: 传统几何逆运动学方法依赖特定空间几何约束，应用于冗余并联机构时面临约束复杂性增加的问题，且当目标位姿超出工作空间时无解，导致不可预测的控制问题。

Method: 提出P-FABRIK方法，基于FABRIK算法，通过新的拓扑分解策略将通用并联机构分解为多个串联子链，迭代修正各子链末端目标来计算逆运动学解。

Result: 通过平面、标准和冗余并联机构的多案例研究验证了该方法在多种并联机构中的通用性；数值仿真研究证实了其有效性、计算效率以及处理工作空间外目标的鲁棒性。

Conclusion: P-FABRIK方法为并联机构提供了一种通用、直观、鲁棒的逆运动学解决方案，能够有效处理传统方法难以解决的冗余机构和工作空间外目标问题。

Abstract: Traditional geometric inverse kinematics methods for parallel mechanisms rely on specific spatial geometry constraints. However, their application to redundant parallel mechanisms is challenged due to the increased constraint complexity. Moreover, it will output no solutions and cause unpredictable control problems when the target pose lies outside its workspace. To tackle these challenging issues, this work proposes P-FABRIK, a general, intuitive, and robust inverse kinematics method to find one feasible solution for diverse parallel mechanisms based on the FABRIK algorithm. By decomposing the general parallel mechanism into multiple serial sub-chains using a new topological decomposition strategy, the end targets of each sub-chain can be subsequently revised to calculate the inverse kinematics solutions iteratively. Multiple case studies involving planar, standard, and redundant parallel mechanisms demonstrated the proposed method's generality across diverse parallel mechanisms. Furthermore, numerical simulation studies verified its efficacy and computational efficiency, as well as its robustness ability to handle out-of-workspace targets.

</details>


### [15] [PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO](https://arxiv.org/abs/2512.22957)
*Mengyu Ji,Shiliang Guo,Zhengzhen Li,Jiahao Shen,Huazi Cao,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于变增益扩张状态观测器的规定性能运动控制框架PreGME，用于解决空中机械臂的动态耦合问题，实现高精度鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂（多旋翼基座+机械臂）存在显著动态耦合，实现精确鲁棒的运动控制具有挑战性但很重要。

Method: 提出PreGME框架：1）变增益扩张状态观测器实时估计动态耦合；2）规定性能飞行控制结合误差轨迹约束，预设误差轨迹引导系统演化。

Result: 实验验证（空中棍棒旋转、空中调酒、空中拉车）：即使在机械臂快速运动（末端速度1.02m/s，加速度5.10m/s²）引起的动态耦合下，仍能实现高跟踪性能。

Conclusion: 提出的PreGME方法能准确估计快速变化的动态耦合，通过规定性能确保跟踪误差在预设性能包络内，实现高精度控制，适用于需要机械臂激进运动的操作任务。

Abstract: An aerial manipulator, comprising a multirotor base and a robotic arm, is subject to significant dynamic coupling between these two components. Therefore, achieving precise and robust motion control is a challenging yet important objective. Here, we propose a novel prescribed performance motion control framework based on variable-gain extended state observers (ESOs), referred to as PreGME. The method includes variable-gain ESOs for real-time estimation of dynamic coupling and a prescribed performance flight control that incorporates error trajectory constraints. Compared with existing methods, the proposed approach exhibits the following two characteristics. First, the adopted variable-gain ESOs can accurately estimate rapidly varying dynamic coupling. This enables the proposed method to handle manipulation tasks that require aggressive motion of the robotic arm. Second, by prescribing the performance, a preset error trajectory is generated to guide the system evolution along this trajectory. This strategy allows the proposed method to ensure the tracking error remains within the prescribed performance envelope, thereby achieving high-precision control. Experiments on a real platform, including aerial staff twirling, aerial mixology, and aerial cart-pulling experiments, are conducted to validate the effectiveness of the proposed method.
  Experimental results demonstrate that even under the dynamic coupling caused by rapid robotic arm motion (end-effector velocity: 1.02 m/s, acceleration: 5.10 m/s$^2$), the proposed method achieves high tracking performance.

</details>


### [16] [Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives](https://arxiv.org/abs/2512.22983)
*Shuanghao Bai,Wenxuan Song,Jiayi Chen,Yuheng Ji,Zhide Zhong,Jin Yang,Han Zhao,Wanqi Zhou,Zhe Li,Pengxiang Ding,Cheng Chi,Chang Xu,Xiaolong Zheng,Donglin Wang,Haoang Li,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 这篇综述论文从算法角度审视机器人操作，将基于学习的方法组织到高层规划与底层控制的统一框架中，分析了现代机器人操作基础模型的设计空间。


<details>
  <summary>Details</summary>
Motivation: 随着视觉、语言和多模态学习的快速发展，机器人基础模型取得了显著进展，但机器人操作仍然是一个核心且具有挑战性的问题。需要从算法角度系统梳理和组织现有的基于学习的方法，为机器人操作基础模型提供清晰的设计框架。

Method: 论文采用分层分析方法：在高层规划层面，扩展了经典任务规划概念，纳入语言、代码、运动、功能性和3D表示等推理；在底层控制层面，提出了基于训练范式的分类法，从输入建模、潜在表示学习和策略学习三个维度组织现有方法。

Result: 建立了一个统一的机器人操作算法框架，将高层规划与底层控制有机结合，为理解现代机器人操作基础模型提供了系统化的分析视角，并识别了该领域的关键设计维度。

Conclusion: 论文明确了机器人操作基础模型的设计空间，指出了未来研究方向，包括可扩展性、数据效率、多模态物理交互和安全性等挑战，为后续研究提供了理论框架和指导方向。

Abstract: Recent advances in vision, language, and multimodal learning have substantially accelerated progress in robotic foundation models, with robot manipulation remaining a central and challenging problem. This survey examines robot manipulation from an algorithmic perspective and organizes recent learning-based approaches within a unified abstraction of high-level planning and low-level control. At the high level, we extend the classical notion of task planning to include reasoning over language, code, motion, affordances, and 3D representations, emphasizing their role in structured and long-horizon decision making. At the low level, we propose a training-paradigm-oriented taxonomy for learning-based control, organizing existing methods along input modeling, latent representation learning, and policy learning. Finally, we identify open challenges and prospective research directions related to scalability, data efficiency, multimodal physical interaction, and safety. Together, these analyses aim to clarify the design space of modern foundation models for robotic manipulation.

</details>


### [17] [Embodied Learning of Reward for Musculoskeletal Control with Vision Language Models](https://arxiv.org/abs/2512.23077)
*Saraswati Soedarmadji,Yunyue Wei,Chen Zhang,Yisong Yue,Yanan Sui*

Main category: cs.RO

TL;DR: MoVLR框架利用视觉语言模型将高级运动目标转化为可优化的奖励函数，用于高维肌肉骨骼系统的运动控制


<details>
  <summary>Details</summary>
Motivation: 高维肌肉骨骼系统的运动控制面临奖励函数设计的根本挑战。人类能用语言描述运动目标（如"直立向前行走"），但实现这些目标的控制策略是隐式的，难以直接从高级目标和自然语言描述设计奖励函数

Method: 提出Motion from Vision-Language Representation (MoVLR)框架，利用视觉语言模型在目标规范和运动控制之间架起桥梁。通过控制优化和VLM反馈的迭代交互探索奖励空间，将语言和视觉评估转化为结构化指导，用于具身学习

Result: MoVLR能够发现和优化高维肌肉骨骼系统的运动控制和操作的奖励函数，使控制策略与物理协调行为对齐

Conclusion: 视觉语言模型能够有效地将抽象运动描述建立在生理运动控制的隐式原则上，为解决高维肌肉骨骼系统控制中的奖励函数设计问题提供了新途径

Abstract: Discovering effective reward functions remains a fundamental challenge in motor control of high-dimensional musculoskeletal systems. While humans can describe movement goals explicitly such as "walking forward with an upright posture," the underlying control strategies that realize these goals are largely implicit, making it difficult to directly design rewards from high-level goals and natural language descriptions. We introduce Motion from Vision-Language Representation (MoVLR), a framework that leverages vision-language models (VLMs) to bridge the gap between goal specification and movement control. Rather than relying on handcrafted rewards, MoVLR iteratively explores the reward space through iterative interaction between control optimization and VLM feedback, aligning control policies with physically coordinated behaviors. Our approach transforms language and vision-based assessments into structured guidance for embodied learning, enabling the discovery and refinement of reward functions for high-dimensional musculoskeletal locomotion and manipulation. These results suggest that VLMs can effectively ground abstract motion descriptions in the implicit principles governing physiological motor control.

</details>


### [18] [APOLLO Blender: A Robotics Library for Visualization and Animation in Blender](https://arxiv.org/abs/2512.23103)
*Peter Messina,Daniel Rakita*

Main category: cs.RO

TL;DR: 开发了一个轻量级软件库，为机器人研究人员提供简单的Blender脚本接口，用于快速创建高质量的出版物可视化内容。


<details>
  <summary>Details</summary>
Motivation: Blender作为强大的免费3D图形平台，学习曲线陡峭且缺乏机器人专用集成，使得研究人员难以高效使用它来创建高质量的机器人研究可视化内容。

Method: 开发了一个轻量级软件库，提供三个主要功能：1) 直接从URDF等标准化描述导入机器人和环境；2) 基于Python的脚本工具，用于关键帧设置机器人状态和视觉属性；3) 方便的3D基本形状生成工具，用于示意图和动画制作。

Result: 该库使机器人研究人员能够快速创建出版物就绪的图像、动画和解释性示意图，无需深入的Blender专业知识，并通过一系列概念验证示例进行了演示。

Conclusion: 该软件库填补了机器人研究与Blender可视化之间的空白，显著降低了创建高质量可视化内容的门槛，同时讨论了当前局限性和未来扩展机会。

Abstract: High-quality visualizations are an essential part of robotics research, enabling clear communication of results through figures, animations, and demonstration videos. While Blender is a powerful and freely available 3D graphics platform, its steep learning curve and lack of robotics-focused integrations make it difficult and time-consuming for researchers to use effectively. In this work, we introduce a lightweight software library that bridges this gap by providing simple scripting interfaces for common robotics visualization tasks. The library offers three primary capabilities: (1) importing robots and environments directly from standardized descriptions such as URDF; (2) Python-based scripting tools for keyframing robot states and visual attributes; and (3) convenient generation of primitive 3D shapes for schematic figures and animations. Together, these features allow robotics researchers to rapidly create publication-ready images, animations, and explanatory schematics without needing extensive Blender expertise. We demonstrate the library through a series of proof-of-concept examples and conclude with a discussion of current limitations and opportunities for future extensions.

</details>


### [19] [Pole-centric Descriptors for Robust Robot Localization: Evaluation under Pole-at-Distance (PaD) Observations using the Small Pole Landmark (SPL) Dataset](https://arxiv.org/abs/2512.23141)
*Wuhao Xie,Kanji Tanaka*

Main category: cs.RO

TL;DR: 该论文针对远距离杆状结构识别可靠性下降的问题，从描述符设计转向系统研究描述符鲁棒性，建立了基于SPL数据集的评估框架，比较了对比学习和监督学习范式。


<details>
  <summary>Details</summary>
Motivation: 在大规模城市环境中，杆状结构作为机器人长期定位的稳定几何锚点，但在远距离观测时识别可靠性显著下降，需要系统研究描述符的鲁棒性问题。

Method: 1) 建立专门的评估框架，基于SPL数据集；2) 使用自动跟踪关联管道构建数据集，无需人工标注；3) 对比分析对比学习(CL)和监督学习(SL)两种范式。

Result: 对比学习在稀疏几何特征空间中诱导出更鲁棒的特征表示，在5-10米距离范围内表现出更优的检索性能。

Conclusion: 该工作为评估挑战性现实场景中的地标独特性提供了实证基础和可扩展方法学，表明对比学习范式更适合处理远距离杆状结构的识别问题。

Abstract: While pole-like structures are widely recognized as stable geometric anchors for long-term robot localization, their identification reliability degrades significantly under Pole-at-Distance (Pad) observations typical of large-scale urban environments. This paper shifts the focus from descriptor design to a systematic investigation of descriptor robustness. Our primary contribution is the establishment of a specialized evaluation framework centered on the Small Pole Landmark (SPL) dataset. This dataset is constructed via an automated tracking-based association pipeline that captures multi-view, multi-distance observations of the same physical landmarks without manual annotation. Using this framework, we present a comparative analysis of Contrastive Learning (CL) and Supervised Learning (SL) paradigms. Our findings reveal that CL induces a more robust feature space for sparse geometry, achieving superior retrieval performance particularly in the 5--10m range. This work provides an empirical foundation and a scalable methodology for evaluating landmark distinctiveness in challenging real-world scenarios.

</details>


### [20] [Towards the Automation in the Space Station: Feasibility Study and Ground Tests of a Multi-Limbed Intra-Vehicular Robot](https://arxiv.org/abs/2512.23153)
*Seiko Piotr Yamaguchi,Kentaro Uno,Yasumaru Fujii,Masazumi Imai,Kazuki Takada,Taku Okawara,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 研究多肢体舱内机器人在国际空间站自主执行物流任务的可行性，通过仿真和原型测试验证其运输能力


<details>
  <summary>Details</summary>
Motivation: 宇航员在国际空间站上花费大量时间处理物流任务（准备、收尾、货物收集和运输），减少了执行关键任务的时间。需要自主移动机械臂来支持这些操作，减少机组人员和地面操作员的工作量，实现实时任务执行。

Method: 进行可行性研究，包括仿真和原型测试。仿真中模拟机器人在3D空间中的运动规划，原型测试在2D平台上进行以模拟微重力环境，测试实际运动执行能力。

Result: 结果表明，机器人能够以最少的人工干预执行这些任务，为增强国际空间站操作效率提供了有前景的解决方案。

Conclusion: 自主多肢体舱内机器人在国际空间站执行物流任务是可行的，能够显著提高操作效率，减少宇航员的工作负担。

Abstract: This paper presents a feasibility study, including simulations and prototype tests, on the autonomous operation of a multi-limbed intra-vehicular robot (mobile manipulator), shortly MLIVR, designed to assist astronauts with logistical tasks on the International Space Station (ISS). Astronauts spend significant time on tasks such as preparation, close-out, and the collection and transportation of goods, reducing the time available for critical mission activities. Our study explores the potential for a mobile manipulator to support these operations, emphasizing the need for autonomous functionality to minimize crew and ground operator effort while enabling real-time task execution. We focused on the robot's transportation capabilities, simulating its motion planning in 3D space. The actual motion execution was tested with a prototype on a 2D table to mimic a microgravity environment. The results demonstrate the feasibility of performing these tasks with minimal human intervention, offering a promising solution to enhance operational efficiency on the ISS.

</details>


### [21] [A Sequential Hermaphrodite Coupling Mechanism for Lattice-based Modular Robots](https://arxiv.org/abs/2512.23154)
*Keigo Torii,Kentaro Uno,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出一种新型形状匹配机械耦合机制，满足单侧耦合/解耦、解耦时表面平整、能与被动接口耦合等复杂设计要求，适用于模块化机器人系统和机械臂工具更换器。


<details>
  <summary>Details</summary>
Motivation: 面向极端环境（如太空）大规模建造的晶格型模块化机器人系统，需要满足单侧耦合/解耦、解耦时表面平整、能与被动接口耦合等多重复杂设计要求的耦合机制。

Method: 提出形状匹配机械耦合机制，通过可控的顺序状态转换实现雄性和雌性状态切换。解耦时所有机制处于雌性状态；耦合过程中一侧切换为雄性状态实现单侧耦合；单侧解耦可通过强制将对方机制从雄性状态切换为雌性状态实现。

Result: 该机制成功满足了所有设计要求：单侧耦合和解耦、解耦时表面平整、能与被动耦合接口耦合以及耦合机制之间的耦合行为。

Conclusion: 提出的形状匹配机械耦合机制能够满足模块化机器人系统的复杂耦合需求，可应用于各种模块化机器人系统和机械臂工具更换器。

Abstract: Lattice-based modular robot systems are envisioned for large-scale construction in extreme environments, such as space. Coupling mechanisms for heterogeneous structural modules should meet all of the following requirements: single-sided coupling and decoupling, flat surfaces when uncoupled, and coupling to passive coupling interfaces as well as coupling behavior between coupling mechanisms. The design requirements for such a coupling mechanism are complex. We propose a novel shape-matching mechanical coupling mechanism that satisfies these design requirements. This mechanism enables controlled, sequential transitions between male and female states. When uncoupled, all mechanisms are in the female state. To enable single-sided coupling, one side of the mechanisms switches to the male state during the coupling process. Single-sided decoupling is possible not only from the male side but also from the female side by forcibly switching the opposite mechanism's male state to the female state. This coupling mechanism can be applied to various modular robot systems and robot arm tool changers.

</details>


### [22] [SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling](https://arxiv.org/abs/2512.23162)
*Yufan He,Pengfei Guo,Mengya Xu,Zhaoshuo Li,Andriy Myronenko,Dillan Imans,Bingjie Liu,Dongren Yang,Mingxue Gu,Yongnan Ji,Yueming Jin,Ren Zhao,Baiyong Shen,Daguang Xu*

Main category: cs.RO

TL;DR: 提出利用SurgWorld世界模型生成合成手术视频，通过逆动力学模型推断伪运动学数据，解决手术机器人数据稀缺问题，显著提升VLA策略性能


<details>
  <summary>Details</summary>
Motivation: 手术机器人面临数据稀缺问题，虽然有大量手术视频但缺乏对应的机器人运动学数据，限制了模仿学习和VLA训练的应用

Method: 1) 构建SATA数据集包含详细手术机器人动作描述；2) 基于先进物理AI世界模型和SATA构建SurgWorld生成多样化手术视频；3) 使用逆动力学模型从合成视频推断伪运动学数据；4) 用增强数据训练手术VLA策略

Result: 使用增强数据训练的手术VLA策略在真实手术机器人平台上显著优于仅使用真实演示数据训练的模型

Conclusion: 通过利用未标记手术视频和生成式世界建模，为自主手术技能获取提供了可扩展路径，开启了通用且数据高效的手术机器人策略的大门

Abstract: Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.

</details>


### [23] [A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict](https://arxiv.org/abs/2512.23220)
*Qin Wang,Shanmin Pang,Jianwu Fang,Shengye Dong,Fuhao Liu,Jianru Xue,Chen Lv*

Main category: cs.RO

TL;DR: 提出了一种面向人类的协同驾驶方法，通过意图感知轨迹规划和基于强化学习的控制权分配，减少人机冲突，提升驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 人车协同驾驶是实现完全自动驾驶的重要桥梁，但现有方法在人机交互自然性和有效性方面存在不足，需要减少人机冲突并提高驾驶员对自动驾驶技术的信任和接受度。

Method: 提出HOCD方法，包含两个层面：战术层面设计意图感知轨迹规划方法，使用意图一致性成本作为核心指标；操作层面开发基于强化学习的控制权分配策略，通过设计的奖励函数优化策略。

Result: 仿真和人在环实验结果表明，该方法在轨迹规划中能对齐驾驶员意图，确保合理的控制权分配，相比其他协同驾驶方法显著提升了驾驶性能并减轻了人机冲突。

Conclusion: HOCD方法通过优先考虑驾驶员意图和状态，实现了更自然有效的人车交互，为人机协同驾驶提供了有效解决方案，有助于推动自动驾驶技术的发展。

Abstract: Human-vehicle cooperative driving serves as a vital bridge to fully autonomous driving by improving driving flexibility and gradually building driver trust and acceptance of autonomous technology. To establish more natural and effective human-vehicle interaction, we propose a Human-Oriented Cooperative Driving (HOCD) approach that primarily minimizes human-machine conflict by prioritizing driver intention and state. In implementation, we take both tactical and operational levels into account to ensure seamless human-vehicle cooperation. At the tactical level, we design an intention-aware trajectory planning method, using intention consistency cost as the core metric to evaluate the trajectory and align it with driver intention. At the operational level, we develop a control authority allocation strategy based on reinforcement learning, optimizing the policy through a designed reward function to achieve consistency between driver state and authority allocation. The results of simulation and human-in-the-loop experiments demonstrate that our proposed approach not only aligns with driver intention in trajectory planning but also ensures a reasonable authority allocation. Compared to other cooperative driving approaches, the proposed HOCD approach significantly enhances driving performance and mitigates human-machine conflict.The code is available at https://github.com/i-Qin/HOCD.

</details>


### [24] [Beyond Coverage Path Planning: Can UAV Swarms Perfect Scattered Regions Inspections?](https://arxiv.org/abs/2512.23257)
*Socratis Gkelios,Savvas D. Apostolidis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos,Athanasios Ch. Kapoutsis*

Main category: cs.RO

TL;DR: 本文提出mUDAI方法解决无人机对分散区域快速巡检问题，通过优化图像采集位置和飞行轨迹，平衡数据分辨率与操作时间，减少冗余数据收集和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 无人机巡检虽然比传统方法更安全高效，但电池限制影响其有效性。现有覆盖路径规划方法在检查多个非连接感兴趣区域时效率低下，需要开发优化的飞行路径和数据采集技术。

Method: 提出多无人机分离区域巡检方法，实施双重优化程序：计算最佳图像采集位置和最有效的无人机轨迹，平衡数据分辨率和操作时间。

Result: 通过模拟评估和实际部署验证，该方法能提高操作效率同时保持高质量数据采集，在实际操作中表现出有效性。提供了开源Python实现、实验数据和在线交互平台。

Conclusion: mUDAI方法能够实现分散感兴趣区域的快速高效巡检，适用于安全基础设施评估、农业检查和应急现场评估等应用场景。

Abstract: Unmanned Aerial Vehicles (UAVs) have revolutionized inspection tasks by offering a safer, more efficient, and flexible alternative to traditional methods. However, battery limitations often constrain their effectiveness, necessitating the development of optimized flight paths and data collection techniques. While existing approaches like coverage path planning (CPP) ensure comprehensive data collection, they can be inefficient, especially when inspecting multiple non connected Regions of Interest (ROIs). This paper introduces the Fast Inspection of Scattered Regions (FISR) problem and proposes a novel solution, the multi UAV Disjoint Areas Inspection (mUDAI) method. The introduced approach implements a two fold optimization procedure, for calculating the best image capturing positions and the most efficient UAV trajectories, balancing data resolution and operational time, minimizing redundant data collection and resource consumption. The mUDAI method is designed to enable rapid, efficient inspections of scattered ROIs, making it ideal for applications such as security infrastructure assessments, agricultural inspections, and emergency site evaluations. A combination of simulated evaluations and real world deployments is used to validate and quantify the method's ability to improve operational efficiency while preserving high quality data capture, demonstrating its effectiveness in real world operations. An open source Python implementation of the mUDAI method can be found on GitHub (https://github.com/soc12/mUDAI) and the collected and processed data from the real world experiments are all hosted on Zenodo (https://zenodo.org/records/13866483). Finally, this online platform (https://sites.google.com/view/mudai-platform/) allows interested readers to interact with the mUDAI method and generate their own multi UAV FISR missions.

</details>


### [25] [PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering](https://arxiv.org/abs/2512.23318)
*Sheng-Kai Chen,Jie-Yu Chao,Jr-Yu Chang,Po-Lien Wu,Po-Chiang Lin*

Main category: cs.RO

TL;DR: PCR-ORB是一种增强的ORB-SLAM3框架，通过深度学习点云精炼和语义分割来减少动态物体对vSLAM系统的干扰，在KITTI数据集上取得了混合但部分序列显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的移动物体会严重影响视觉SLAM系统的跟踪精度和地图一致性，传统方法难以有效处理动态物体干扰，需要更智能的解决方案来提升系统鲁棒性。

Method: 基于ORB-SLAM3框架，集成深度学习点云精炼技术，使用YOLOv8进行语义分割，结合CUDA加速处理实现实时性能。采用多阶段过滤策略，包括地面平面估计、天空区域移除、边缘过滤和时间一致性验证。

Result: 在KITTI数据集（序列00-09）上的综合评估显示性能表现因场景而异。序列04取得了显著改进：ATE RMSE提升25.9%，ATE中值提升30.4%。但不同序列结果混合，表明效果具有场景依赖性。

Conclusion: PCR-ORB框架为动态物体过滤提供了有效解决方案，在特定场景下能显著提升SLAM性能，但效果受环境条件影响。该方法揭示了动态环境导航的挑战和机遇，为复杂环境下的鲁棒导航系统开发提供了见解。

Abstract: Visual Simultaneous Localization and Mapping (vSLAM) systems encounter substantial challenges in dynamic environments where moving objects compromise tracking accuracy and map consistency. This paper introduces PCR-ORB (Point Cloud Refinement ORB), an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to mitigate dynamic object interference. Our approach employs YOLOv8 for semantic segmentation combined with CUDA-accelerated processing to achieve real-time performance. The system implements a multi-stage filtering strategy encompassing ground plane estimation, sky region removal, edge filtering, and temporal consistency validation. Comprehensive evaluation on the KITTI dataset (sequences 00-09) demonstrates performance characteristics across different environmental conditions and scene types. Notable improvements are observed in specific sequences, with sequence 04 achieving 25.9% improvement in ATE RMSE and 30.4% improvement in ATE median. However, results show mixed performance across sequences, indicating scenario-dependent effectiveness. The implementation provides insights into dynamic object filtering challenges and opportunities for robust navigation in complex environments.

</details>


### [26] [Theory of Mind for Explainable Human-Robot Interaction](https://arxiv.org/abs/2512.23482)
*Marie Bauer,Julia Gachot,Matthias Kerzel,Cornelius Weber,Stefan Wermter*

Main category: cs.RO

TL;DR: 该论文提出将人机交互中的心理理论视为可解释人工智能的一种形式，通过VXAI框架评估，以解决当前心理理论应用缺乏对机器人实际内部推理验证的问题。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互中的心理理论方法很少评估解释与机器人实际内部推理的对应程度，存在重要研究空白。同时，可解释人工智能研究主要关注AI系统本身，缺乏用户中心的解释视角。

Method: 提出将心理理论整合到可解释人工智能框架中，特别是通过VXAI框架及其七个期望标准来评估心理理论。将心理理论原则嵌入可解释人工智能，实现从系统中心到用户中心的视角转变。

Result: 通过将心理理论视为可解释人工智能的一种形式，能够更好地评估机器人解释与其实际内部推理的一致性，同时使解释更加用户中心化，优先考虑用户的信息需求和视角。

Conclusion: 将心理理论整合到可解释人工智能框架中可以弥补当前人机交互研究的不足，促进更透明、可解释且用户中心的机器人系统发展，提升人机交互的效果和信任度。

Abstract: Within the context of human-robot interaction (HRI), Theory of Mind (ToM) is intended to serve as a user-friendly backend to the interface of robotic systems, enabling robots to infer and respond to human mental states. When integrated into robots, ToM allows them to adapt their internal models to users' behaviors, enhancing the interpretability and predictability of their actions. Similarly, Explainable Artificial Intelligence (XAI) aims to make AI systems transparent and interpretable, allowing humans to understand and interact with them effectively. Since ToM in HRI serves related purposes, we propose to consider ToM as a form of XAI and evaluate it through the eValuation XAI (VXAI) framework and its seven desiderata. This paper identifies a critical gap in the application of ToM within HRI, as existing methods rarely assess the extent to which explanations correspond to the robot's actual internal reasoning. To address this limitation, we propose to integrate ToM within XAI frameworks. By embedding ToM principles inside XAI, we argue for a shift in perspective, as current XAI research focuses predominantly on the AI system itself and often lacks user-centered explanations. Incorporating ToM would enable a change in focus, prioritizing the user's informational needs and perspective.

</details>


### [27] [Robust Deep Learning Control with Guaranteed Performance for Safe and Reliable Robotization in Heavy-Duty Machinery](https://arxiv.org/abs/2512.23505)
*Mehdi Heydari Shahna*

Main category: cs.RO

TL;DR: 该论文开发了一个控制框架，用于简化重型移动机械的电气化控制设计，并通过分层控制策略在保证安全的前提下部分集成AI技术。


<details>
  <summary>Details</summary>
Motivation: 重型移动机械面临两大转型：从柴油液压驱动转向清洁电力系统，以及从人工监督转向更高自主性。但完全电气化面临技术经济挑战，AI在重型机械中的应用受限于严格的安全要求。

Method: 开发了一个通用模块化控制框架，采用能源独立的通用鲁棒控制策略，定义分层控制策略，在保证安全性能的前提下部分集成AI，并通过三个案例研究验证框架有效性。

Result: 框架在三个案例研究中得到验证，涵盖不同类型执行器和工况的重型移动机器人和机械臂，成果发表在五篇同行评审论文和一篇未发表手稿中。

Conclusion: 该控制框架为重型移动机械的电气化和自主化转型提供了有效解决方案，推进了非线性控制和机器人技术发展，支持两大行业转型。

Abstract: Today's heavy-duty mobile machines (HDMMs) face two transitions: from diesel-hydraulic actuation to clean electric systems driven by climate goals, and from human supervision toward greater autonomy. Diesel-hydraulic systems have long dominated, so full electrification, via direct replacement or redesign, raises major technical and economic challenges. Although advanced artificial intelligence (AI) could enable higher autonomy, adoption in HDMMs is limited by strict safety requirements, and these machines still rely heavily on human supervision.
  This dissertation develops a control framework that (1) simplifies control design for electrified HDMMs through a generic modular approach that is energy-source independent and supports future modifications, and (2) defines hierarchical control policies that partially integrate AI while guaranteeing safety-defined performance and stability.
  Five research questions align with three lines of investigation: a generic robust control strategy for multi-body HDMMs with strong stability across actuation types and energy sources; control solutions that keep strict performance under uncertainty and faults while balancing robustness and responsiveness; and methods to interpret and trust black-box learning strategies so they can be integrated stably and verified against international safety standards.
  The framework is validated in three case studies spanning different actuators and conditions, covering heavy-duty mobile robots and robotic manipulators. Results appear in five peer-reviewed publications and one unpublished manuscript, advancing nonlinear control and robotics and supporting both transitions.

</details>


### [28] [Act2Goal: From World Model To General Goal-conditioned Policy](https://arxiv.org/abs/2512.23541)
*Pengfei Zhou,Liliang Chen,Shengcong Chen,Di Chen,Wenzhi Zhao,Rongjun Jin,Guanghui Ren,Jianlan Luo*

Main category: cs.RO

TL;DR: Act2Goal是一个目标条件操作策略，结合了目标条件视觉世界模型和多尺度时间控制，通过生成中间视觉状态序列和分解轨迹来实现长时程操作任务的鲁棒执行。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉目标的任务指定方法虽然紧凑明确，但现有目标条件策略在长时程操作任务上表现不佳，主要原因是依赖单步动作预测而缺乏对任务进度的显式建模。

Method: 提出Act2Goal框架：1) 目标条件视觉世界模型生成可信的中间视觉状态序列；2) 多尺度时间哈希(MSTH)将轨迹分解为密集近端帧（细粒度闭环控制）和稀疏远端帧（全局任务一致性）；3) 通过端到端交叉注意力将视觉表示与运动控制耦合。

Result: 实现了对新物体、空间布局和环境的强零样本泛化能力；通过后见目标重标记和LoRA微调实现无奖励在线适应；真实机器人实验显示，在挑战性分布外任务上，成功率从30%提升到90%，仅需几分钟的自主交互。

Conclusion: 具有多尺度时间控制的目标条件世界模型为鲁棒的长时程操作提供了必要的结构化指导，Act2Goal框架显著提升了操作任务的性能和适应性。

Abstract: Specifying robotic manipulation tasks in a manner that is both expressive and precise remains a central challenge. While visual goals provide a compact and unambiguous task specification, existing goal-conditioned policies often struggle with long-horizon manipulation due to their reliance on single-step action prediction without explicit modeling of task progress. We propose Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control. Given a current observation and a target visual goal, the world model generates a plausible sequence of intermediate visual states that captures long-horizon structure. To translate this visual plan into robust execution, we introduce Multi-Scale Temporal Hashing (MSTH), which decomposes the imagined trajectory into dense proximal frames for fine-grained closed-loop control and sparse distal frames that anchor global task consistency. The policy couples these representations with motor control through end-to-end cross-attention, enabling coherent long-horizon behavior while remaining reactive to local disturbances. Act2Goal achieves strong zero-shot generalization to novel objects, spatial layouts, and environments. We further enable reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision. Real-robot experiments demonstrate that Act2Goal improves success rates from 30% to 90% on challenging out-of-distribution tasks within minutes of autonomous interaction, validating that goal-conditioned world models with multi-scale temporal control provide structured guidance necessary for robust long-horizon manipulation. Project page: https://act2goal.github.io/

</details>


### [29] [Soft Robotic Technological Probe for Speculative Fashion Futures](https://arxiv.org/abs/2512.23570)
*Amy Ingold,Loong Yi Lee,Richard Suphapol Diteesawat,Ajmal Roshan,Yael Zekaria,Edith-Clare Hall,Enrico Werner,Nahian Rahman,Elaine Czech,Jonathan Rossiter*

Main category: cs.RO

TL;DR: Sumbrella是一款软体机器人服装，作为推测性时尚探针开发，结合了折纸启发的双稳态单元、织物气动驱动和计算机视觉，用于探索人们对软体机器人可穿戴设备的未来关系想象。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴机器人的发展，需要不仅关注功能，还要考虑社会意义的设计方法。研究旨在探索软体机器人服装如何影响人们对可穿戴技术的解读、互动和未来关系想象。

Method: 设计了Sumbrella软体机器人服装，包含折纸启发的双稳态单元、织物气动驱动室、线缆驱动形状变形机制、计算机视觉组件，以及集成电源和控制电子设备的帽子和夹克。通过12名创意技术专家的焦点小组，将其作为技术探针来探索人们对软体机器人可穿戴设备的解读和想象。

Result: 参与者围绕推测性未来和表达潜力进行了丰富讨论，但也提出了对剥削、监控以及生物传感技术嵌入公共生活的个人风险和社会伦理的担忧。研究为HRI领域提供了软体机器人服装设计的关键考虑因素和建议。

Conclusion: 推测性设计方法使HRI研究人员不仅能考虑功能性，还能探索可穿戴机器人如何影响公共场合中被认为可接受或理想的定义。研究强调了软体机器人服装在动态交流、社会动态影响和伦理指南方面的重要性。

Abstract: Emerging wearable robotics demand design approaches that address not only function, but also social meaning. In response, we present Sumbrella, a soft robotic garment developed as a speculative fashion probe. We first detail the design and fabrication of the Sumbrella, including sequenced origami-inspired bistable units, fabric pneumatic actuation chambers, cable driven shape morphing mechanisms, computer vision components, and an integrated wearable system comprising a hat and bolero jacket housing power and control electronics. Through a focus group with twelve creative technologists, we then used Sumbrella as a technological probe to explore how people interpreted, interacted, and imagined future relationships with soft robotic wearables. While Sumbrella allowed our participants to engage in rich discussion around speculative futures and expressive potential, it also surfaced concerns about exploitation, surveillance, and the personal risks and societal ethics of embedding biosensing technologies in public life. We contribute to the Human-Robot Interaction (HRI) field key considerations and recommendations for designing soft robotic garments, including the potential for kinesic communication, the impact of such technologies on social dynamics, and the importance of ethical guidelines. Finally, we provide a reflection on our application of speculative design; proposing that it allows HRI researchers to not only consider functionality, but also how wearable robots influence definitions of what is considered acceptable or desirable in public settings.

</details>


### [30] [A Kalman Filter-Based Disturbance Observer for Steer-by-Wire Systems](https://arxiv.org/abs/2512.23593)
*Nikolai Beving,Jonas Marxen,Steffen Mueller,Johannes Betz*

Main category: cs.RO

TL;DR: 提出基于卡尔曼滤波的扰动观测器，仅使用电机状态测量即可估计高频驾驶员扭矩，解决线控转向系统中驾驶员阻抗导致的性能下降问题，仿真显示延迟仅14ms。


<details>
  <summary>Details</summary>
Motivation: 线控转向系统取代机械连接带来诸多优势，但易受驾驶员无意扭矩产生的高频扰动（驾驶员阻抗）影响，降低转向性能。现有方法要么依赖昂贵的直接扭矩传感器，要么缺乏捕捉快速高频扰动的时域分辨率。

Method: 设计基于卡尔曼滤波的扰动观测器，使用PT1滞后近似将驾驶员被动扭矩建模为扩展状态，并集成到线性和非线性线控转向系统模型中。评估不同卡尔曼滤波变体，包括非线性扩展卡尔曼滤波器。

Result: 提出的扰动观测器能够准确重构驾驶员引起的扰动，延迟仅为14ms。非线性扩展卡尔曼滤波器在处理摩擦非线性方面优于线性版本，在静态到动态摩擦转换期间改善估计性能。

Conclusion: 该方法有效解决了线控转向系统中驾驶员阻抗的估计问题，但研究基于仿真验证，需要在真实驾驶条件下进一步研究观测器的鲁棒性。

Abstract: Steer-by-Wire systems replace mechanical linkages, which provide benefits like weight reduction, design flexibility, and compatibility with autonomous driving. However, they are susceptible to high-frequency disturbances from unintentional driver torque, known as driver impedance, which can degrade steering performance. Existing approaches either rely on direct torque sensors, which are costly and impractical, or lack the temporal resolution to capture rapid, high-frequency driver-induced disturbances. We address this limitation by designing a Kalman filter-based disturbance observer that estimates high-frequency driver torque using only motor state measurements. We model the drivers passive torque as an extended state using a PT1-lag approximation and integrate it into both linear and nonlinear Steer-by-Wire system models. In this paper, we present the design, implementation and simulation of this disturbance observer with an evaluation of different Kalman filter variants. Our findings indicate that the proposed disturbance observer accurately reconstructs driver-induced disturbances with only minimal delay 14ms. We show that a nonlinear extended Kalman Filter outperforms its linear counterpart in handling frictional nonlinearities, improving estimation during transitions from static to dynamic friction. Given the study's methodology, it was unavoidable to rely on simulation-based validation rather than real-world experimentation. Further studies are needed to investigate the robustness of the observers under real-world driving conditions.

</details>


### [31] [Interactive Robot Programming for Surface Finishing via Task-Centric Mixed Reality Interfaces](https://arxiv.org/abs/2512.23616)
*Christoph Willibald,Lugh Martensen,Thomas Eiband,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出了一种面向非专家的机器人编程方法，通过交互式任务导向工作流程简化表面处理任务的编程，降低机器人部署门槛


<details>
  <summary>Details</summary>
Motivation: 当前机器人编程需要专业知识，设置过程复杂，阻碍了机器人在高产品变异性、小批量生产场景（如小型手工艺制造）中的应用，特别是表面处理任务

Method: 开发了结合人工输入的新型表面分割算法，通过交互式任务导向工作流程让非专家直观编程，提供连续视觉反馈让用户迭代优化分割结果，基于分割表面模型生成机器人轨迹

Result: 通过两个综合用户研究评估多种交互设计，得出最优界面方案，显著降低用户工作量，提高可用性，使缺乏实践经验的用户也能有效完成任务编程

Conclusion: 提出的机器人编程方法成功降低了协作机器人在表面处理任务中的部署门槛，使非专家用户能够有效编程，有望促进机器人在小型制造和手工艺领域的应用

Abstract: Lengthy setup processes that require robotics expertise remain a major barrier to deploying robots for tasks involving high product variability and small batch sizes. As a result, collaborative robots, despite their advanced sensing and control capabilities, are rarely used for surface finishing in small-scale craft and manufacturing settings. To address this gap, we propose a novel robot programming approach that enables non-experts to intuitively program robots through interactive, task-focused workflows. For that, we developed a new surface segmentation algorithm that incorporates human input to identify and refine workpiece regions for processing. Throughout the programming process, users receive continuous visual feedback on the robot's learned model, enabling them to iteratively refine the segmentation result. Based on the segmented surface model, a robot trajectory is generated to cover the desired processing area. We evaluated multiple interaction designs across two comprehensive user studies to derive an optimal interface that significantly reduces user workload, improves usability and enables effective task programming even for users with limited practical experience.

</details>


### [32] [The N-5 Scaling Law: Topological Dimensionality Reduction in the Optimal Design of Fully-actuated Multirotors](https://arxiv.org/abs/2512.23619)
*Antonio Franchi*

Main category: cs.RO

TL;DR: 本文研究了N旋翼飞行器的几何设计，发现最优配置的拓扑结构由机架对称性决定，提出了N-5缩放定律，揭示了最优配置保持下的连续重构能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法将全驱动全向N旋翼飞行器的几何设计视为参数优化问题，寻找固定架构族中的单一最优方向集。本研究旨在探索优化景观本身的内在拓扑结构。

Method: 将设计问题表述在投影线乘积流形RP^2^N上，固定转子位置于多面体机架顶点，变化其作用线方向。通过最小化坐标不变的Log-Volume各向同性度量，分析全局最优解的拓扑结构。

Result: 发现最优解的拓扑严格由机架对称性决定：对于一般（不规则）顶点排列，解为离散孤立点集；当机架几何趋于规则时，解空间经历临界相变，塌缩到N维环面，随后简化为由仿射相位锁定驱动的连续1维曲线。提出了N-5缩放定律：对于所有检查的正则平面多边形和柏拉图立体（N≤10），最优配置空间由K=N-5个不相连的1维拓扑分支组成。

Conclusion: 这些锁定模式对应一系列可容许的星形多边形{N/q}，允许精确预测任意N的最优相位。这种拓扑揭示了设计冗余，使车辆能够沿这些分支连续重构，同时保持最优的各向同性控制能力。

Abstract: The geometric design of fully-actuated and omnidirectional N-rotor aerial vehicles is conventionally formulated as a parametric optimization problem, seeking a single optimal set of N orientations within a fixed architectural family. This work departs from that paradigm to investigate the intrinsic topological structure of the optimization landscape itself. We formulate the design problem on the product manifold of Projective Lines \RP^2^N, fixing the rotor positions to the vertices of polyhedral chassis while varying their lines of action. By minimizing a coordinate-invariant Log-Volume isotropy metric, we reveal that the topology of the global optima is governed strictly by the symmetry of the chassis. For generic (irregular) vertex arrangements, the solutions appear as a discrete set of isolated points. However, as the chassis geometry approaches regularity, the solution space undergoes a critical phase transition, collapsing onto an N-dimensional Torus of the lines tangent at the vertexes to the circumscribing sphere of the chassis, and subsequently reducing to continuous 1-dimensional curves driven by Affine Phase Locking. We synthesize these observations into the N-5 Scaling Law: an empirical relationship holding for all examined regular planar polygons and Platonic solids (N <= 10), where the space of optimal configurations consists of K=N-5 disconnected 1D topological branches. We demonstrate that these locking patterns correspond to a sequence of admissible Star Polygons {N/q}, allowing for the exact prediction of optimal phases for arbitrary N. Crucially, this topology reveals a design redundancy that enables optimality-preserving morphing: the vehicle can continuously reconfigure along these branches while preserving optimal isotropic control authority.

</details>


### [33] [RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion](https://arxiv.org/abs/2512.23649)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Tao Huang,Zhenguo Sun,Yibo Peng,Pengwei Wang,Zhongyuan Wang,Fangzhou Liu,Chang Xu,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboMirror是首个免重定向的视频到运动框架，通过视觉语言模型从第一人称/第三人称视频中提取视觉运动意图，直接指导扩散策略生成物理合理、语义对齐的运动，无需显式姿态重建或重定向。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动系统依赖精心策划的动作捕捉轨迹或稀疏文本指令，在视觉理解和控制之间存在关键差距。文本到运动方法存在语义稀疏性和流水线错误问题，而基于视频的方法只进行机械姿态模仿，缺乏真正的视觉理解。

Method: 提出RoboMirror框架，利用视觉语言模型从原始的第一人称/第三人称视频中提取视觉运动意图，这些意图直接条件化一个基于扩散的策略，生成物理合理、语义对齐的运动，无需显式姿态重建或重定向。

Result: 实验验证了RoboMirror的有效性：通过第一人称视频实现远程呈现，将第三人称控制延迟降低80%，任务成功率比基线方法提高3.7%。

Conclusion: 通过围绕视频理解重新构建人形机器人控制，RoboMirror弥合了视觉理解和行动之间的差距，实现了"先理解后模仿"的范式。

Abstract: Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying "understand before you imitate". Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.

</details>


### [34] [Do You Have Freestyle? Expressive Humanoid Locomotion via Audio Control](https://arxiv.org/abs/2512.23650)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Tao Huang,Zhenguo Sun,Yibo Peng,Pengwei Wang,Zhongyuan Wang,Fangzhou Liu,Chang Xu,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboPerform：首个统一的音频到运动框架，可直接从音频生成音乐驱动的舞蹈和语音驱动的伴随手势，无需显式运动重建，实现低延迟高保真


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人缺乏即兴表达能力，局限于预定义动作或稀疏指令。现有方法通过音频生成运动再重定向到机器人，存在级联误差、高延迟和声学-驱动映射不连贯的问题

Method: 基于"运动=内容+风格"核心原则，将音频作为隐式风格信号，无需显式运动重建。采用ResMoE教师策略适应多样化运动模式，结合扩散式学生策略进行音频风格注入

Result: 实验验证显示RoboPerform在物理合理性和音频对齐方面取得有希望的结果，成功将机器人转变为能够响应音频的表演者

Conclusion: RoboPerform通过免重定向设计实现了低延迟高保真的音频驱动运动生成，为机器人表演能力提供了创新解决方案

Abstract: Humans intuitively move to sound, but current humanoid robots lack expressive improvisational capabilities, confined to predefined motions or sparse commands. Generating motion from audio and then retargeting it to robots relies on explicit motion reconstruction, leading to cascaded errors, high latency, and disjointed acoustic-actuation mapping. We propose RoboPerform, the first unified audio-to-locomotion framework that can directly generate music-driven dance and speech-driven co-speech gestures from audio. Guided by the core principle of "motion = content + style", the framework treats audio as implicit style signals and eliminates the need for explicit motion reconstruction. RoboPerform integrates a ResMoE teacher policy for adapting to diverse motion patterns and a diffusion-based student policy for audio style injection. This retargeting-free design ensures low latency and high fidelity. Experimental validation shows that RoboPerform achieves promising results in physical plausibility and audio alignment, successfully transforming robots into responsive performers capable of reacting to audio.

</details>


### [35] [The Bulldozer Technique: Efficient Elimination of Local Minima Traps for APF-Based Robot Navigation](https://arxiv.org/abs/2512.23672)
*Mohammed Baziyad,Manal Al Shohna,Tamer Rabie*

Main category: cs.RO

TL;DR: 本文提出了一种名为"推土机"的新型路径规划技术，通过后填充机制和斜坡增强解决人工势场法的局部最小值陷阱问题，在保持APF优点的同时实现更快的执行速度和良好的路径质量。


<details>
  <summary>Details</summary>
Motivation: 人工势场法在自主移动机器人路径规划中因简单、实时响应和计算需求低而受欢迎，但传统APF方法存在局部最小值陷阱问题，机器人会卡在无法明确朝向目标的位置。

Method: 提出"推土机"技术，引入后填充机制系统识别并消除局部最小值区域（通过增加其势能值，类似推土机填平道路坑洼），并加入斜坡增强帮助机器人从局部最小值陷阱中逃脱。

Result: 通过物理移动机器人在不同复杂度地图上的实验验证，与标准APF、自适应APF以及A*、PRM、RRT等成熟规划算法比较，推土机技术有效解决局部最小值问题，实现更快的执行速度和具有竞争力的路径质量。运动学跟踪控制器评估确认规划路径的平滑性和可跟踪性，适合实际执行。

Conclusion: 推土机技术成功解决了人工势场法的局部最小值陷阱问题，同时保持了APF方法的优势，为自主移动机器人提供了有效的路径规划解决方案。

Abstract: Path planning is a fundamental component in autonomous mobile robotics, enabling a robot to navigate from its current location to a desired goal while avoiding obstacles. Among the various techniques, Artificial Potential Field (APF) methods have gained popularity due to their simplicity, real-time responsiveness, and low computational requirements. However, a major limitation of conventional APF approaches is the local minima trap problem, where the robot becomes stuck in a position with no clear direction toward the goal. This paper proposes a novel path planning technique, termed the Bulldozer, which addresses the local minima issue while preserving the inherent advantages of APF. The Bulldozer technique introduces a backfilling mechanism that systematically identifies and eliminates local minima regions by increasing their potential values, analogous to a bulldozer filling potholes in a road. Additionally, a ramp-based enhancement is incorporated to assist the robot in escaping trap areas when starting within a local minimum. The proposed technique is experimentally validated using a physical mobile robot across various maps with increasing complexity. Comparative analyses are conducted against standard APF, adaptive APF, and well-established planning algorithms such as A*, PRM, and RRT. Results demonstrate that the Bulldozer technique effectively resolves the local minima problem while achieving superior execution speed and competitive path quality. Furthermore, a kinematic tracking controller is employed to assess the smoothness and traceability of the planned paths, confirming their suitability for real-world execution.

</details>


### [36] [Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation](https://arxiv.org/abs/2512.23703)
*Huajie Tan,Sixiang Chen,Yijie Xu,Zixiao Wang,Yuheng Ji,Cheng Chi,Yaoxu Lyu,Zhongxia Zhao,Xiansheng Chen,Peterson Co,Shaoxuan Xie,Guocai Yao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: Dopamine-Reward提出了一种新颖的奖励建模方法，通过多视角输入学习通用、步骤感知的过程奖励模型，解决了传统强化学习在机器人应用中奖励函数设计的核心难题。


<details>
  <summary>Details</summary>
Motivation: 将强化学习应用于真实世界机器人的主要障碍是设计有效的奖励函数。现有的基于学习的过程奖励模型存在两个基本限制：奖励模型缺乏步骤感知理解且依赖单视角感知，导致对细粒度操作进展的评估不可靠；奖励塑造过程理论不严谨，常导致语义陷阱误导策略优化。

Method: 提出Dopamine-Reward方法，核心是通用奖励模型（GRM），在3400+小时数据集上训练，采用步骤奖励离散化实现结构化理解，多视角奖励融合克服感知限制。基于此提出Dopamine-RL框架，采用理论严谨的策略不变奖励塑造方法，使智能体能够利用密集奖励进行高效自我改进而不改变最优策略。

Result: GRM在奖励评估方面达到最先进准确度，基于GRM的Dopamine-RL显著提高策略学习效率。GRM通过单条专家轨迹一次性适应新任务后，Dopamine-RL仅需150次在线尝试（约1小时真实机器人交互）就能将策略从接近零成功率提升到95%，并在任务间保持强泛化能力。

Conclusion: Dopamine-Reward通过步骤感知和多视角融合的奖励建模，结合理论严谨的奖励塑造方法，有效解决了机器人强化学习中的奖励设计难题，实现了高效、通用的策略学习框架。

Abstract: The primary obstacle for applying reinforcement learning (RL) to real-world robotics is the design of effective reward functions. While recently learning-based Process Reward Models (PRMs) are a promising direction, they are often hindered by two fundamental limitations: their reward models lack step-aware understanding and rely on single-view perception, leading to unreliable assessments of fine-grained manipulation progress; and their reward shaping procedures are theoretically unsound, often inducing a semantic trap that misguides policy optimization. To address these, we introduce Dopamine-Reward, a novel reward modeling method for learning a general-purpose, step-aware process reward model from multi-view inputs. At its core is our General Reward Model (GRM), trained on a vast 3,400+ hour dataset, which leverages Step-wise Reward Discretization for structural understanding and Multi-Perspective Reward Fusion to overcome perceptual limitations. Building upon Dopamine-Reward, we propose Dopamine-RL, a robust policy learning framework that employs a theoretically-sound Policy-Invariant Reward Shaping method, which enables the agent to leverage dense rewards for efficient self-improvement without altering the optimal policy, thereby fundamentally avoiding the semantic trap. Extensive experiments across diverse simulated and real-world tasks validate our approach. GRM achieves state-of-the-art accuracy in reward assessment, and Dopamine-RL built on GRM significantly improves policy learning efficiency. For instance, after GRM is adapted to a new task in a one-shot manner from a single expert trajectory, the resulting reward model enables Dopamine-RL to improve the policy from near-zero to 95% success with only 150 online rollouts (approximately 1 hour of real robot interaction), while retaining strong generalization across tasks. Project website: https://robo-dopamine.github.io

</details>
