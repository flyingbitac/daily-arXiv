<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: CLOT：基于高频定位反馈的实时全身人形机器人遥操作系统，通过闭环全局运动跟踪实现长时间无漂移的人形模仿


<details>
  <summary>Details</summary>
Motivation: 解决长时程全身人形机器人遥操作中的全局姿态漂移问题。现有基于学习的跟踪方法通常在机器人局部坐标系中运行，忽略全局姿态反馈，导致长时间执行时产生漂移和不稳定性。

Method: 提出CLOT系统，通过高频定位反馈实现闭环全局运动跟踪。采用数据驱动的随机化策略，将观测轨迹与奖励评估解耦，实现平滑稳定的全局校正。使用对抗运动先验正则化策略以抑制不自然行为。收集20小时人类运动数据训练策略，设计基于Transformer的策略并训练超过1300GPU小时。

Result: 在31自由度全尺寸人形机器人上部署，仿真和真实世界实验验证了高动态运动、高精度跟踪以及在sim-to-real人形遥操作中的强鲁棒性。

Conclusion: CLOT系统通过闭环全局运动跟踪解决了长时程人形机器人遥操作的漂移问题，实现了无漂移的人对人形模仿，为实时全身人形遥操作提供了有效解决方案。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [2] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: 论文提出了Safe-SDL框架，通过定义操作设计域、控制屏障函数和事务安全协议来解决自主实验室中的安全问题，填补AI生成指令与物理安全之间的"语法到安全鸿沟"。


<details>
  <summary>Details</summary>
Motivation: 自主实验室(SDLs)虽然能加速科学发现，但引入了传统实验室或纯数字AI所没有的安全挑战。核心问题是"语法到安全鸿沟"——AI生成的语法正确指令与其物理安全影响之间的脱节。

Method: 提出Safe-SDL框架，包含三个协同组件：1) 形式化定义的操作设计域(ODDs)，将系统行为限制在数学验证的边界内；2) 控制屏障函数(CBFs)，通过连续状态空间监控提供实时安全保证；3) 新颖的事务安全协议(CRUTD)，确保数字规划与物理执行之间的原子一致性。

Result: 通过对UniLabOS和Osprey架构等现有实现的分析，展示了这些系统如何实例化关键安全原则。在LabSafety Bench上的评估显示，当前基础模型存在显著的安全失败，证明架构安全机制是必需而非可选的。

Conclusion: 该框架为自主科学系统的安全部署提供了理论基础和实践实施指导，为负责任地加速AI驱动发现奠定了基础。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [3] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 提出一个通用框架，通过三层架构预测人体躯干运动、规划最优质心轨迹来控制超数机器人肢体，以维持人机系统平衡


<details>
  <summary>Details</summary>
Motivation: 超数机器人肢体在广泛应用中潜力巨大，但其可用性受到安全性和控制灵活性的限制。特别是维持人机系统平衡这一关键问题，是实现安全舒适增强任务的前提条件

Method: 提出一个通用的三层分层架构：1)预测层估计人体躯干和质心动力学；2)规划层生成最优质心轨迹以抵消躯干运动，并计算相应的SL控制输入；3)控制层在SL硬件上执行这些输入

Result: 在10名参与者执行前后和侧向弯曲任务的评估中，结果显示站立不稳定性明显减少，证明了该框架在增强平衡方面的有效性

Conclusion: 这项工作为实现安全和多功能的人机交互铺平了道路，为解决超数机器人肢体平衡问题提供了通用框架

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [4] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 该论文提出了一个用于温室环境中移动机器人控制器评估的综合基准测试框架，包含三维环境模型、物理仿真器和分层控制架构，定义了三个基准类别和三种扰动场景，并引入了标准化性能指标。


<details>
  <summary>Details</summary>
Motivation: 农业环境中移动机器人面临不平坦地形、可变摩擦、载荷变化和坡度等挑战条件，显著影响控制性能和稳定性。尽管农业机器人平台应用日益增加，但缺乏标准化、可复现的基准测试阻碍了在真实操作条件下控制策略的公平比较和系统评估。

Method: 提出了一个综合基准测试框架，集成了精确的三维环境模型、基于物理的仿真器，以及包含低层、中层和高层控制层的分层控制架构。定义了三个基准类别（从执行器级控制到完全自主导航）和三种扰动场景（载荷变化、地形类型和坡度）。引入了标准化性能指标（SAE、SCI和复合性能指数），并采用基于重复试验的统计分析来减少传感器噪声和环境变异性的影响。框架采用插件式架构，便于用户自定义控制器和规划器的集成。

Result: 该基准测试框架提供了一个稳健且可扩展的工具，能够在真实条件下对经典、预测和基于规划的控制策略进行定量比较，弥合了基于仿真的分析与真实农业工业应用之间的差距。

Conclusion: 提出的基准测试框架为温室环境中移动机器人控制器的评估提供了系统、可复现的方法，有助于推动农业机器人控制策略的标准化比较和性能提升，促进仿真分析向实际农业应用的转化。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [5] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 提出可扩展的生成-精炼流程，用于合成大规模、多样化且物理可行的抓取，通过进化算法在仿真器中优化分析生成的抓取，并将结果蒸馏到扩散模型中


<details>
  <summary>Details</summary>
Motivation: 数据驱动的抓取预测依赖昂贵的数据集且通常局限于特定夹爪形态，而分析方法因简化假设常产生物理不可行的抓取，需要高保真仿真器过滤，这减少了抓取数量和多样性

Method: 提出可扩展的生成-精炼流程：1）用分析方法生成种子抓取集；2）在高保真仿真器（Isaac Sim）中使用异步、无梯度的进化算法优化这些抓取；3）将精炼后的抓取分布蒸馏到扩散模型中用于实际部署

Result: 在Handles数据集和DexGraspNet子集上，每个物体获得超过120个不同的稳定抓取（比未精炼的分析方法提高1.7-6倍），在独特抓取覆盖方面比基于扩散的方法提高46-60%

Conclusion: 该方法能够高效生成大规模、多样化且物理可行的抓取，通过将高保真仿真器用作优化阶段而非仅用于验证，显著提高了抓取质量和数量，同时多样性对训练和部署都很重要

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity.
  We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [6] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: OSCAR是一种受寄生蜂产卵器启发的自推进胶囊机器人，通过弹簧凸轮系统驱动12个周向滑块产生相移序列运动，利用摩擦各向异性在结肠中产生净向前推力。


<details>
  <summary>Details</summary>
Motivation: 传统结肠镜检查存在导管打结问题，导致患者不适。在结肠的湿滑、粘弹性环境中可靠移动是一个重大挑战，需要开发新的自推进机制。

Method: 采用寄生蜂产卵器的运动策略，通过弹簧加载的凸轮系统机械编码运动模式，驱动12个周向滑块进行协调的相移序列运动。通过调整运动轮廓使回缩阶段相对于前进阶段最大化，在界面处创建受控的摩擦各向异性以产生净向前推力。开发了包含Kelvin-Voigt公式的分析模型来捕捉滑块与组织之间的粘弹性粘滑相互作用。

Result: 离体猪结肠实验显示平均稳态牵引力为0.85N，与模型预测相符。推力生成与速度无关，且与相位不对称性呈线性比例关系。OSCAR平均速度为3.08mm/s，足以匹配传统结肠镜的盲肠插管时间。

Conclusion: 通过将相位编码的摩擦各向异性与预测模型相结合，OSCAR在低法向载荷下实现了可控的推力生成，为机器人胶囊结肠镜检查提供了更安全、更稳健的自推进运动。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [7] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: FABCO框架通过集成行为观察克隆与可行性估计，解决模仿学习中演示者与机器人物理特性差异导致的两个问题：演示数据缺乏机器人动作，以及演示动作对机器人不可行。


<details>
  <summary>Details</summary>
Motivation: 模仿学习通过手持演示接口从演示者动作学习机器人控制策略，但由于演示者与机器人物理特性差异，面临两个限制：演示数据不包含机器人动作，且演示动作可能对机器人不可行，这使得策略学习变得困难。

Method: FABCO整合了行为观察克隆（使用机器人动力学模型补充机器人动作）与可行性估计。可行性估计使用从机器人执行数据学习的动力学模型评估演示动作在机器人动力学下的可再现性。估计的可行性用于多模态反馈和可行性感知策略学习，以改进演示者动作并学习鲁棒策略。

Result: 通过15名参与者在两个任务上的实验，确认FABCO相比无可行性反馈的情况，将模仿学习性能提高了3.2倍以上。

Conclusion: FABCO通过整合可行性估计和多模态反馈，有效解决了模仿学习中演示者与机器人物理特性不匹配的问题，显著提高了模仿学习性能，使机器人能够学习并稳定执行可行的控制策略。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [8] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了多种机器人跟踪估计与预测技术的性能，包括误差大小、计算量和鲁棒性等指标


<details>
  <summary>Details</summary>
Motivation: 多机器人跟踪问题需要有效的估计和预测技术，但现有方法在误差、计算效率和鲁棒性方面的性能差异需要系统比较

Method: 比较了卡尔曼滤波器及其变体（扩展卡尔曼、无迹卡尔曼）与基于序列蒙特卡洛采样的方法（粒子滤波器、高斯混合Sigma点粒子滤波器）

Result: 对各种方法在估计误差、计算复杂度和非高斯噪声鲁棒性方面进行了性能评估和比较

Conclusion: 为多机器人跟踪问题提供了不同估计预测技术的性能对比，为实际应用中的方法选择提供参考依据

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [9] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种用于磁驱动手术机器人的控制框架，能够在低帧率、噪声大的荧光成像条件下保持准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 磁驱动手术机器人能够在复杂解剖路径中导航，减少组织创伤并提高手术精度。然而，临床部署受到荧光成像条件下控制的挑战，因为荧光成像提供低帧率和噪声大的位姿反馈。

Method: 提出一个控制框架，结合了：1）直接输出线圈电流的非线性模型预测控制（NMPC）；2）基于Zernike多项式的解析可微磁场模型；3）用于估计机器人状态的卡尔曼滤波器。

Result: 实验验证显示，当反馈降采样至3Hz并添加高斯噪声（σ=2mm）模拟临床荧光成像时，该方法仍保持高精度。在脊柱模型实验中，成功执行药物输送轨迹，均方根位置误差为1.18mm，同时保持与关键解剖边界的安全距离。

Conclusion: 该控制框架能够在临床荧光成像的挑战性条件下，为磁驱动手术机器人提供准确稳定的控制，有望促进这类系统在临床中的实际应用。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [10] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 本文针对VLA模型中的动作标记化问题，从优化角度提出了设计原则，开发了ActionCodec标记器，显著提升了训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型中的动作标记化设计主要关注重构保真度，忽视了其对VLA优化的直接影响，缺乏从优化角度出发的设计原则指导。

Method: 基于信息论洞察，提出了动作标记化的设计原则：最大化时间标记重叠、最小化词汇冗余、增强多模态互信息、确保标记独立性，并据此开发了ActionCodec标记器。

Result: ActionCodec显著提升了VLA模型的训练效率和性能。在LIBERO基准上，使用ActionCodec微调的SmolVLM2-2.2B达到95.5%成功率（无需机器人预训练），经架构优化后达到97.4%，创下无需机器人预训练的VLA模型新SOTA。

Conclusion: 本文为动作标记化设计提供了明确的优化原则和路线图，提出的ActionCodec标记器及设计原则将推动社区开发更有效的动作标记器。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [11] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 该论文提出了一种结合NASA F'飞行软件框架与ROS2中间件的混合架构，通过室内四旋翼飞行测试验证了实时视觉导航性能，展示了认证级确定性系统与灵活自主系统的有效集成。


<details>
  <summary>Details</summary>
Motivation: 自主航空航天系统需要平衡确定性实时控制与先进感知能力的架构，现有系统往往难以同时满足认证级确定性和灵活自主性的需求。

Method: 采用NASA F'飞行软件框架与ROS2中间件通过Protocol Buffers桥接的集成系统，在室内四旋翼飞行平台上进行32.25分钟的飞行测试，使用视觉导航系统评估架构性能。

Result: 视觉系统达到87.19 Hz位置估计频率，99.90%数据连续性，11.47 ms平均延迟；15个地面命令100%执行成功；系统资源利用率低（15.19% CPU，1244 MB RAM），无陈旧遥测消息。

Conclusion: 结果验证了混合飞行软件架构的可行性，能够将认证级确定性与灵活自主性结合，适用于自主飞行器系统。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [12] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 提出解耦设计，将低级空间状态估计与高级语义规划分离，引入交互式度量世界表示，结合反事实推理，在导航任务中实现零样本SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型的导航智能体采用紧耦合设计，严重限制了系统性能。需要分离空间感知与语义规划，同时克服现有方法依赖简化文本地图的局限性。

Method: 提出解耦设计框架：1) 分离低级空间状态估计与高级语义规划；2) 引入交互式度量世界表示，保持丰富一致的空间信息；3) 结合反事实推理激发MLLMs能力；4) 度量表示确保动作的物理有效性。

Result: 在R2R-CE和RxR-CE基准测试中分别达到48.8%和42.2%的成功率，建立新的零样本SOTA。实现零样本仿真到真实世界的迁移，在TurtleBot 4轮式机器人和定制无人机上验证了框架的鲁棒性和领域不变性。

Conclusion: 解耦设计框架作为鲁棒、领域不变的接口，有效支持具身视觉语言导航任务。度量世界表示和反事实推理的结合显著提升了导航智能体的性能。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [13] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 提出基于Lyapunov的PI类控制器设计方法，用于四轮独立驱动转向移动机器人的L₂稳定运动控制


<details>
  <summary>Details</summary>
Motivation: 为四轮独立驱动转向移动机器人开发具有严格稳定性保证的运动控制器，解决配置依赖效应问题，适合实时嵌入式实现

Method: 使用显式结构验证模型，基于Lyapunov函数构造控制器，获得显式边界和L₂稳定性结果，设计保持PI形式的控制律

Result: 控制器在真实四轮移动机器人平台上实验验证了有效性和鲁棒性，同时保持了标准嵌入式实现的适用性

Conclusion: 提出的Lyapunov-based PI类控制器为四轮移动机器人提供了具有严格稳定性保证的运动控制方案，兼具理论严谨性和工程实用性

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [14] [Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513)
*Ji Li,Jing Xia,Mingyi Li,Shiyan Hu*

Main category: cs.RO

TL;DR: 提出非参数记忆框架，显式分离情景记忆和语义记忆，用于具身探索和问答，通过检索优先、推理辅助范式提升性能


<details>
  <summary>Details</summary>
Motivation: 现有基于文本摘要的记忆方法会丢失丰富的视觉和空间细节，在非平稳环境中表现脆弱，需要更好的记忆机制来处理长时观察和有限上下文预算

Method: 提出非参数记忆框架，分离情景记忆和语义记忆；采用检索优先、推理辅助范式，通过语义相似性回忆情景经验并用视觉推理验证；引入程序式规则提取机制将经验转化为结构化、可重用的语义记忆

Result: 在具身问答和探索基准测试中达到最先进性能：A-EQA上LLM-Match提升7.3%，LLM MatchXSPL提升11.4%；GOAT-Bench上成功率提升7.7%，SPL提升6.8%

Conclusion: 情景记忆主要提升探索效率，语义记忆增强具身智能体的复杂推理能力；提出的框架能有效处理长时观察和有限上下文预算的挑战

Abstract: Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.

</details>


### [15] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: VLM-DEWM：一种用于动态制造环境中机器人操作的可验证认知架构，通过持久化外部世界模型解决VLM的状态跟踪和推理不透明问题


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在智能制造中显示出高级规划的潜力，但在动态工作单元部署面临两大挑战：1）无状态操作，无法持续跟踪视野外状态，导致世界状态漂移；2）推理不透明，故障难以诊断，导致昂贵的盲目重试

Method: 提出VLM-DEWM认知架构，通过持久化、可查询的动态外部世界模型将VLM推理与世界状态管理解耦。每个VLM决策被结构化为外部化推理轨迹，包含动作提议、世界信念和因果假设，在执行前与DEWM进行验证

Result: 在多站装配、大规模设施探索和真实机器人故障恢复任务中评估。相比基线记忆增强VLM系统，VLM-DEWM将状态跟踪准确率从56%提升到93%，恢复成功率从低于5%提升到95%，并通过结构化内存显著降低计算开销

Conclusion: VLM-DEWM为动态制造环境中的长时程机器人操作提供了一个可验证且具有弹性的解决方案，通过结构化推理和持久化世界状态管理解决了现有VLM部署的关键限制

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [16] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: CASF框架通过约束相关度量增强流式流策略，在运行时重塑学习的速度场，使机器人轨迹能够实时适应安全约束，同时保持多模态和反应性。


<details>
  <summary>Details</summary>
Motivation: 现有流式流策略缺乏训练后适应机制来强制执行安全和任务特定约束，需要一种能够在运行时调整轨迹以满足约束条件的框架。

Method: CASF将每个约束建模为可微距离函数，转换为局部度量并拉回到机器人控制空间，在约束边界附近平滑地衰减或重定向运动，从而变形底层流以保持安全性。

Result: 在模拟和真实世界操作任务中，CASF生成满足约束的轨迹，保持平滑、可行和动态一致性，优于标准后处理投影基线方法。

Conclusion: CASF成功增强了流式流策略的约束适应能力，实现了实时轨迹调整，同时保持了原始策略的多模态和反应特性。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [17] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 该论文提出了一种利用超声波润滑主动控制摩擦力的机器人运动方法，通过激发共振结构在超声频率下动态切换接触界面的"抓握"和"滑动"状态，实现了超过90%运动效率的双向运动。


<details>
  <summary>Details</summary>
Motivation: 摩擦力是地面运动的关键媒介，但在机器人系统中通常被视为由表面材料和条件决定的被动属性。研究者希望开发一种能够主动控制摩擦力的方法，以改善机器人运动系统的设计和效率。

Method: 开发了两种摩擦控制模块：圆柱形设计用于管状环境，平板设计用于外部表面。将这些模块集成到仿生系统中，模拟尺蠖和黄蜂产卵器的运动方式。通过激发共振结构在超声频率下动态切换接触界面的"抓握"和"滑动"状态。

Result: 两个系统都实现了双向运动，运动效率接近完美，超过90%。摩擦特性实验表明，在刚性、柔软、颗粒状和生物组织界面等各种表面上，在干燥和湿润条件下，以及在不同粗糙度的表面上，都能显著降低摩擦力。

Conclusion: 超声波润滑被确立为一种可行的主动摩擦控制机制，可用于机器人运动，具有降低设计复杂性和提高机器人运动系统效率的潜力。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [18] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: SpecFuse：一种用于无人机在振荡海洋平台上自主着陆的谱时融合预测控制框架，通过频率域波分解和时间域递归状态估计实现高精度6自由度运动预测，显著提升着陆精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 无人机在振荡海洋平台上的自主着陆受到波浪引起的多频振荡、风扰动和运动预测相位滞后的严重限制。现有方法要么将平台运动视为一般随机过程，要么缺乏对波浪谱特性的显式建模，导致在动态海况下性能不佳。

Method: 提出SpecFuse框架：1）集成频率域波分解与时间域递归状态估计，显式建模主导波谐波以减轻相位滞后；2）设计分层控制架构，包括用于非凸约束下动态轨迹规划的采样基HPO-RRT*算法；3）学习增强的预测控制器，融合数据驱动的扰动补偿与基于优化的执行。

Result: 经过2000次仿真和8次湖上实验验证：预测误差3.2厘米，着陆偏差4.46厘米，成功率仿真98.7%/实际87.5%，嵌入式硬件延迟82毫秒，在精度上比现有方法提升44%-48%。

Conclusion: SpecFuse框架通过谱时融合方法显著提高了无人机在振荡海洋平台上的自主着陆性能，对波风耦合扰动具有鲁棒性，支持搜救和环境监测等关键海上任务。所有代码、实验配置和数据集将开源发布以促进可重复性。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [19] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 提出了一种结合NURBS轨迹表示、CMA-ES全局优化和控制器引导空间反馈的闭环自主赛车线优化框架，通过卡尔曼滤波启发的空间更新利用跟踪误差作为局部赛道特征信号，在仿真中实现17.38%圈速提升，在实际硬件上获得7.60%圈速改进。


<details>
  <summary>Details</summary>
Motivation: 传统方法将跟踪误差视为瞬态扰动，而本文认为这些误差包含了局部赛道特性的重要信息。需要开发一种能够利用这些误差信号、适应空间变化的赛道和车辆行为、且对摩擦条件变化具有鲁棒性的自主赛车线优化方法。

Method: 采用NURBS（非均匀有理B样条）进行轨迹表示，结合CMA-ES（协方差矩阵自适应进化策略）进行全局轨迹优化。核心创新是通过卡尔曼滤波启发的空间更新机制，将跟踪误差转化为局部赛道特征信息，构建自适应加速度约束图，迭代优化轨迹。

Result: 在仿真环境中，相比使用最大静态加速度参数化的控制器，实现了17.38%的圈速减少。在实际硬件测试中，使用从高到低不同摩擦系数的轮胎配方，无需显式参数化摩擦系数，获得了7.60%的圈速改进，展示了在真实场景中对变化抓地力条件的鲁棒性。

Conclusion: 该闭环框架成功地将跟踪误差转化为有价值的赛道特征信息，通过自适应约束图实现了接近最优的性能。方法对摩擦条件变化具有鲁棒性，无需显式参数化摩擦系数，在仿真和实际硬件测试中都取得了显著的圈速提升，证明了其在真实世界自主赛车应用中的有效性。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [20] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 机器人辅助喂食系统需要适应社交用餐环境，通过参与式设计发现系统应具备白手套服务原则，支持多模态输入、情境敏感社交行为、扩展角色和适应餐桌关系。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助喂食系统主要在实验室或家庭环境中测试，缺乏对社交用餐环境（如餐厅）的探索。社交用餐环境具有动态性和非监督性，需要机器人能够适应和响应这些挑战。

Method: 通过参与式设计方法，结合半结构化访谈和基于AI的视觉故事板工具，与残障人士合作探索理想的社交用餐场景。

Result: 研究发现社交用餐机器人系统应体现白手套服务原则：1）支持多模态输入和不显眼的输出；2）具备情境敏感的社交行为并优先考虑用户；3）扩展喂食以外的角色；4）适应餐桌上的其他关系。

Conclusion: 这项研究为机器人辅助喂食在社交环境和群体情境中的应用提供了重要启示，强调了系统设计需要考虑社交互动和情境适应性。

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


### [21] [FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](https://arxiv.org/abs/2602.15813)
*Haochen Zhang,Nirav Savaliya,Faizan Siddiqui,Enna Sachdeva*

Main category: cs.RO

TL;DR: FAST-EQA是一个用于具身问答的框架，通过识别视觉目标、评分感兴趣区域来指导导航，并使用思维链推理视觉记忆来回答问题，同时保持有界的场景记忆和高效的探索策略。


<details>
  <summary>Details</summary>
Motivation: 具身问答需要在部分可观测环境下结合视觉场景理解、目标导向探索和时空推理。主要挑战是限制物理搜索到问题相关子空间，同时保持紧凑、可操作的观察记忆，并且需要快速推理时间。

Method: 1) 识别可能的视觉目标；2) 评分全局感兴趣区域来指导导航；3) 使用思维链推理视觉记忆来回答问题；4) 维护有界场景记忆，存储固定容量的区域-目标假设并在线更新；5) 全局探索策略将狭窄开口和门视为高价值前沿，以最小计算补充局部目标搜索。

Result: 在HMEQA和EXPRESS-Bench上达到最先进性能，在OpenEQA和MT-HM3D上表现有竞争力。显著快于先前方法，同时提高了场景覆盖率和答案可靠性。

Conclusion: FAST-EQA通过有界记忆管理、高效的探索策略和思维链推理，成功解决了具身问答中的搜索空间限制、记忆管理和推理速度等关键挑战，实现了高性能和快速推理的平衡。

Abstract: Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.

</details>


### [22] [Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827)
*Zhen Wu,Xiaoyu Huang,Lujie Yang,Yuanhang Zhang,Koushil Sreenath,Xi Chen,Pieter Abbeel,Rocky Duan,Angjoo Kanazawa,Carmelo Sferrazza,Guanya Shi,C. Karen Liu*

Main category: cs.RO

TL;DR: 提出Perceptive Humanoid Parkour (PHP)框架，使人形机器人能够通过视觉自主完成长时程、复杂的跑酷动作，包括跨越、攀爬、翻滚等多种技能。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人虽然能在不同地形稳定行走，但要实现人类般敏捷、动态的跑酷动作仍面临挑战。跑酷需要低层鲁棒性、人类动作表现力、长时程技能组合和感知驱动决策。

Method: 1. 使用运动匹配技术将人类技能重定向并组合成长时程运动轨迹；2. 训练运动跟踪强化学习专家策略；3. 通过DAgger和RL结合将这些策略蒸馏为单一基于深度的多技能学生策略；4. 利用感知和技能组合实现自主决策。

Result: 在Unitree G1人形机器人上验证，成功完成攀爬高达1.25米（机器人身高的96%）的障碍物，以及长时程多障碍物穿越，并能实时适应障碍物扰动。

Conclusion: PHP框架成功实现了人形机器人的自主跑酷能力，结合了人类动作的优雅流畅性和机器人的感知决策能力，为动态复杂环境中的机器人运动提供了有效解决方案。

Abstract: While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.

</details>


### [23] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个学习任务无关灵巧操作技能框架，通过仿真训练3D点轨迹条件策略，实现零样本迁移到真实世界任务


<details>
  <summary>Details</summary>
Motivation: 解决灵巧操作中通用策略学习的挑战：真实世界遥操作数据收集昂贵难扩展，仿真中设计多任务特定环境和奖励同样困难

Method: 提出Dex4D框架，在仿真中训练领域无关的3D点轨迹条件策略，覆盖数千个不同姿态配置的物体，学习"任意姿态到任意姿态"的操作能力

Result: 方法支持零样本迁移到真实机器人任务，无需微调，在仿真和真实实验中优于现有基线，展示了对新物体、场景布局、背景和轨迹的强泛化能力

Conclusion: Dex4D框架通过任务无关灵巧技能学习和零样本迁移，实现了鲁棒可扩展的灵巧操作，为通用机器人策略学习提供了有效解决方案

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>
