<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey](https://arxiv.org/abs/2601.22198)
*Judith Vilella-Cantos,Mónica Ballesta,David Valiente,María Flores,Luis Payá*

Main category: cs.RO

TL;DR: 本文是第一篇专注于农业环境中基于LiDAR定位的综述，系统回顾了深度学习在农业环境中的应用和LiDAR地点识别技术，分析了现有方法、数据集、评估指标以及该领域的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 精准农业是能够从自主机器人系统中获益最多的领域之一，但农业环境缺乏显著特征且结构非结构化，使得地点识别具有挑战性。目前LiDAR地点识别技术主要应用于城市环境，农业环境中的研究相对缺乏，需要专门的综述来推动该领域的发展。

Method: 本文采用系统性文献综述方法，全面回顾了农业环境中最新的深度学习应用和LiDAR地点识别技术。重点关注这些环境中出现的挑战，分析了现有方法、数据集和评估指标。

Result: 本文是第一篇专注于农业环境中基于LiDAR定位的综述，提供了对该领域的全面理解。分析了现有方法的局限性，并指出了未来研究方向，旨在促进这一专业领域的进一步研究。

Conclusion: 农业环境中的LiDAR定位面临独特挑战，需要专门的研究方法。本文填补了该领域综述的空白，为研究人员提供了系统性的参考框架，有望推动精准农业中自主机器人系统的发展。

Abstract: An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.

</details>


### [2] [ReloPush-BOSS: Optimization-guided Nonmonotone Rearrangement Planning for a Car-like Robot Pusher](https://arxiv.org/abs/2601.22289)
*Jeeho Ahn,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: 本文提出ReloPush-BOSS框架，用于在密集杂乱环境中使用类车机器人推动器进行多物体重排规划，通过优化预重定位来避免局部最小值，实现高效可行的重排序列。


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中使用类车机器人推动器进行多物体重排面临运动学、几何和物理约束的挑战，导致非单调问题实例，需要将操作动作分解为多个部分。现有方法通过规划预重定位来解决，但决定预重定位位置时容易陷入局部最小值，导致不可行或高成本路径。

Method: 提出ReloPush-BOSS框架：1）基于Dubins路径分类引导预重定位优化，避免局部最小值；2）将优化后的预重定位集成到编码运动学、几何和推动约束的对象可遍历图中；3）以深度优先方式搜索该图，生成高效可行的重排序列。

Result: 在最多包含13个物体的密集杂乱场景中，ReloPush-BOSS框架相比现有基线方法展现出最高的成功率和最短的推动路径。在1/10比例类车推动器上的硬件实验验证了方法的鲁棒性。

Conclusion: 通过优化预重定位并集成到约束编码图中进行搜索，ReloPush-BOSS框架能够有效解决密集杂乱环境中的多物体重排规划问题，在仿真和硬件实验中均表现出优越性能。

Abstract: We focus on multi-object rearrangement planning in densely cluttered environments using a car-like robot pusher. The combination of kinematic, geometric and physics constraints underlying this domain results in challenging nonmonotone problem instances which demand breaking each manipulation action into multiple parts to achieve a desired object rearrangement. Prior work tackles such instances by planning prerelocations, temporary object displacements that enable constraint satisfaction, but deciding where to prerelocate remains difficult due to local minima leading to infeasible or high-cost paths. Our key insight is that these minima can be avoided by steering a prerelocation optimization toward low-cost regions informed by Dubins path classification. These optimized prerelocations are integrated into an object traversability graph that encodes kinematic, geometric, and pushing constraints. Searching this graph in a depth-first fashion results in efficient, feasible rearrangement sequences. Across a series of densely cluttered scenarios with up to 13 objects, our framework, ReloPush-BOSS, exhibits consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate the robustness of our approach. Code and footage from our experiments can be found at: https://fluentrobotics.com/relopushboss.

</details>


### [3] [Lantern: A Minimalist Robotic Object Platform](https://arxiv.org/abs/2601.22381)
*Victor Nikhil Antony,Zhili Gong,Guanchen Li,Clara Jeon,Chien-Ming Huang*

Main category: cs.RO

TL;DR: Lantern是一个低成本、简约的机器人对象平台，旨在降低人机交互研究门槛，通过简单形式激发人类社交意义投射，支持多样化应用场景。


<details>
  <summary>Details</summary>
Motivation: 设计一个低成本、简约的机器人对象平台，降低人机交互研究门槛，利用人类对简单形式赋予社交意义的倾向，探索多样化的人机交互场景。

Method: 通过深入的机电架构设计和工程迭代，开发Lantern平台（成本约40美元）；通过五个探索性研究评估其HRI潜力：1)协同设计工作坊，2)感官室案例研究，3)外部HRI实验室分发，4)研究生HRI课程整合，5)老年人和儿童的公共展览。

Result: Lantern能有效激发参与度，支持从情绪调节到专注工作等多种应用，作为降低HRI领域门槛的可行平台。

Conclusion: Lantern作为一个低成本、开源的简约机器人对象平台，成功展示了其在促进人机交互研究、降低领域门槛方面的潜力，能够激发人类参与并支持多样化应用场景。

Abstract: Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.

</details>


### [4] [Plant-Inspired Robot Design Metaphors for Ambient HRI](https://arxiv.org/abs/2601.22387)
*Victor Nikhil Antony,Adithya R N,Sarah Derrick,Zhili Gong,Peter M. Donley,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 论文探索以植物为隐喻灵感设计人机交互，通过设计研究开发植物启发式机器人原型，探讨低需求、环境化的交互范式


<details>
  <summary>Details</summary>
Motivation: 当前人机交互主要基于拟人化和拟动物化范式，产生高需求、显性的交互形式。植物作为环境化、低需求的存在，通过时间节奏和微妙表达塑造氛围、日常和关系，为HRI提供了新的设计灵感

Method: 采用设计研究方法，进行迭代的构思、原型制作和反思循环。通过原型中心工作坊探索人们对植物启发式机器人的感知和想象

Result: 开发了一套推测性、开源的原型，探索植物启发的存在感、时间性、形态和手势。通过工作坊获得了人们对植物启发式机器人的设计洞察

Conclusion: 贡献包括：(1)植物启发式机器人原型集；(2)人们对植物启发式机器人感知的设计洞察；(3)使用植物隐喻重塑人机交互的设计考量

Abstract: Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.

</details>


### [5] [Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach](https://arxiv.org/abs/2601.22406)
*Shahar Dubiner,Peng Ren,Roberto Manduchi*

Main category: cs.RO

TL;DR: 提出一种融合GNSS、惯性数据和地图空间先验的粒子滤波行人导航方法，在GNSS性能受限的城市环境中提高定位精度，特别为视障用户提供精确的街道侧向识别。


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中GNSS性能下降导致的定位精度问题，这对依赖精确导航（如识别正确街道侧）的盲人或低视力用户尤为关键。传统基于摄像头的视觉定位方法不实用。

Method: 采用粒子滤波融合GNSS和惯性数据，并融入地图空间先验（如不可通行的建筑物和不太可能的步行区域），作为概率形式的地图匹配。惯性定位由RoNIN机器学习方法提供，通过与GNSS估计和不确定性的粒子加权实现融合。

Result: 在旧金山市中心6条具有挑战性的步行路线上评估，使用与行人道正确性和定位误差相关的三个指标。结果显示：融合方法（GNSS+RoNIN+PF）在大多数指标上显著优于仅使用GNSS的定位；仅使用惯性定位加粒子滤波在关键指标（如行人道分配和跨街道误差）上也优于仅使用GNSS。

Conclusion: 提出的融合GNSS、惯性数据和地图先验的粒子滤波方法能有效提高城市环境中的行人定位精度，特别有助于视障用户的精确导航需求，在GNSS受限情况下提供更可靠的定位性能。

Abstract: The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.

</details>


### [6] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: 该研究提出了一种针对5MP+高分辨率立体视觉系统的新型校准和立体匹配方法，旨在实现高精度和快速处理，并展示了高像素相机需要通过高精度校准才能生成高质量点云。


<details>
  <summary>Details</summary>
Motivation: 高分辨率（5MP+）立体视觉系统对于提升机器人能力至关重要，能够实现更远距离的操作并生成更密集、更准确的3D点云。然而，传统方法往往无法满足高角分辨率传感器所需的高校准精度和快速处理要求。

Method: 采用新颖的帧到帧校准和立体匹配方法处理5MP相机图像，同时引入新的实时性能评估方法，通过将实时视差图与计算密集型立体匹配算法生成的基准真值视差图进行比较。

Result: 研究表明，高像素相机只有通过实施高精度校准才能生成高质量的点云，验证了所提方法在实现高精度和快速处理方面的有效性。

Conclusion: 高分辨率立体视觉系统的潜力需要通过高精度校准和高效处理方法来充分实现，本研究提出的方法为解决这一关键差距提供了有效途径。

Abstract: High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.

</details>


### [7] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: CARE框架通过仅使用视频-文本对进行预训练，无需动作标注，学习连续潜在动作表示，然后在少量标注数据上微调动作头，实现机器人控制。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型依赖动作监督，限制了可扩展性和泛化能力。需要一种无需动作标注的弱监督方法来训练机器人控制模型。

Method: CARE框架仅使用视频-文本对进行预训练，通过新设计的多任务预训练目标学习连续潜在动作表示，然后在少量标注数据上微调动作头用于控制。

Result: 在多个仿真任务中，CARE表现出更高的成功率、更好的语义可解释性，并能避免捷径学习，证明了其在弱监督机器人控制中的有效性。

Conclusion: CARE框架通过消除对动作标注的依赖，实现了更好的可扩展性、可解释性和有效性，为弱监督机器人控制提供了有前景的解决方案。

Abstract: Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.

</details>


### [8] [RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing](https://arxiv.org/abs/2601.22517)
*Kangning Yin,Zhe Cao,Wentao Dong,Weishuai Zeng,Tianyi Zhang,Qiang Zhang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Weinan Zhang*

Main category: cs.RO

TL;DR: RoboStriker：一个三阶段分层框架，通过解耦高层战略推理与低层物理执行，实现全自主人形机器人拳击。该方法结合运动技能学习、潜在空间蒸馏和潜在空间神经虚拟自博弈，解决了人形机器人高维接触动力学和多智能体强化学习训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在接触丰富且高度动态的任务（如拳击）中实现人类水平的竞争智能和身体敏捷性仍面临重大挑战。多智能体强化学习虽然为战略交互提供了原则性框架，但直接应用于人形控制受到高维接触动力学和缺乏强物理运动先验的阻碍。

Method: 1. 通过单智能体运动跟踪器在人类动作捕捉数据上学习全面的拳击技能库；2. 将这些技能蒸馏到结构化潜在流形中，通过将高斯参数化分布投影到单位超球面上进行正则化；3. 提出潜在空间神经虚拟自博弈，让竞争智能体在潜在动作空间而非原始电机空间中进行交互，显著稳定多智能体训练。

Result: 实验结果表明，RoboStriker在仿真中实现了优越的竞争性能，并展现出仿真到现实的迁移能力。

Conclusion: RoboStriker通过分层框架成功解决了人形机器人拳击中的战略推理与物理执行耦合问题，为接触丰富动态任务中的人形机器人控制提供了有效解决方案。

Abstract: Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.

</details>


### [9] [Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios](https://arxiv.org/abs/2601.22545)
*Feng Tao,Luca Paparusso,Chenyi Gu,Robin Koehler,Chenxu Wu,Xinyu Huang,Christian Juette,David Paz,Ren Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的实时路径规划框架，专门用于解决停车场等受限环境中的路径规划问题，相比传统规划器在成功率和效率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统经典规划器在完美感知假设下有效，但对实际感知约束敏感，且在线搜索计算成本高，难以在复杂环境中实现实时部署。需要一种更实用、轻量级的解决方案。

Method: 采用深度强化学习框架，将路径规划任务建模为基于自行车模型的顺序决策问题，使智能体能够直接学习符合车辆运动学和环境约束的导航策略。开发了新的基准测试集支持训练和评估。

Result: 该方法在成功率和效率方面达到最先进水平，相比经典规划器基线，成功率提升+96%，效率提升+52%。开发的开源基准测试集已公开发布。

Conclusion: 提出的DRL框架能够实现实时路径规划，不需要理想化感知结构，避免了定位和跟踪等额外模块，简化了实际部署，为自主系统研究提供了有价值的开源资源。

Abstract: Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.

</details>


### [10] [Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation](https://arxiv.org/abs/2601.22550)
*Geonho Leem,Jaedong Lee,Jehee Lee,Seungmoon Song,Jungdam Won*

Main category: cs.RO

TL;DR: Exo-plore：结合神经力学模拟与深度强化学习的仿真框架，无需真人实验即可优化髋关节外骨骼辅助


<details>
  <summary>Details</summary>
Motivation: 当前外骨骼控制器优化需要大量人体实验，参与者需行走数小时，这对行动不便者尤其困难，形成了受益者无法参与实验的矛盾

Method: 结合神经力学模拟与深度强化学习，创建仿真框架优化髋关节外骨骼辅助，无需真实人体实验

Result: 1) 生成捕捉人类对辅助力适应的真实步态数据；2) 在步态随机性下仍能产生可靠优化结果；3) 可泛化到病理步态，病理严重程度与最优辅助呈强线性关系

Conclusion: Exo-plore框架为外骨骼辅助优化提供高效仿真方案，特别适用于行动不便者，解决了传统实验方法的可及性问题

Abstract: Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.

</details>


### [11] [Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies](https://arxiv.org/abs/2601.22672)
*Theodora Kastritsi,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种用于超数机器人身体的新型控制框架，通过虚拟夹具和在线姿态评估提供动觉反馈，防止用户采用非人体工学姿势，同时调整浮动基座位置以改善协调性。


<details>
  <summary>Details</summary>
Motivation: 超数机器人身体可以增强人类负载能力，但在与人类物理交互的任务中，用户仍可能采用非人体工学姿势，长期可能导致不适或伤害。需要一种方法来促进人体工学习惯的学习。

Method: 开发了虚拟夹具方法与连续在线人体工学姿态评估框架集成，当检测到非人体工学姿势时提供动觉反馈以阻止此类行为。同时调整浮动基座位置以改善操作者与机器人的协调性。

Result: 实验结果表明该人体工学驱动控制框架的功能和有效性，包括两个涉及14名受试者的实际移动操作任务的用户研究，与不考虑人体工学的基线控制框架相比表现更优。

Conclusion: 提出的控制框架能够有效促进超数机器人身体用户采用人体工学姿势，通过动觉反馈培养长期的人体工学习惯，改善人机协调性，减少物理交互中的伤害风险。

Abstract: Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.

</details>


### [12] [FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation](https://arxiv.org/abs/2601.22686)
*Biyu Ye,Na Fan,Zhengping Fan,Weiliang Deng,Hongming Chen,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 提出了一种用于空中机械臂的机载框架，通过视觉预抓取惯性估计和抓取后适应机制，实现实时惯性动力学估计与适应，解决了时变惯性参数带来的控制挑战。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂在自动化运输和紧急服务中具有优势，但实际部署面临时变惯性参数的复杂性挑战，这些参数对负载变化和机械臂配置高度敏感。

Method: 1) 视觉预抓取惯性估计模块；2) 抓取后适应机制；3) 基于增益调度的惯性感知自适应控制策略；4) 通过频域系统辨识评估鲁棒性。

Result: 提出了新的抓取后控制见解，并通过真实世界实验验证了所提框架的有效性和可行性。

Conclusion: 该研究为空中机械臂的鲁棒操控提供了创新解决方案，结合视觉估计和自适应控制，实现了对时变惯性参数的有效处理。

Abstract: Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.

</details>


### [13] [Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives](https://arxiv.org/abs/2601.22849)
*Christian Dietz,Sebastian Albrecht,Gianluca Frison,Moritz Diehl,Armin Nurkanović*

Main category: cs.RO

TL;DR: 该论文提出了一种基于可微物理仿真的高效装配运动规划方法，通过二阶导数信息减少仿真步数，并引入鲁棒优化确保仿真到现实的迁移成功率。


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配运动规划主要依赖强化学习和基于采样的方法，需要大量物理仿真步骤，效率较低。需要一种更高效的规划方法，减少仿真计算量。

Method: 构建可微物理仿真器，提供二阶解析导数给数值求解器；采用基于内点法的平滑技术使碰撞检测和接触解析可微；提出改进的基于优化的碰撞检测线性规划公式；设计多场景轨迹优化问题确保鲁棒性。

Result: 在真实世界实验中实现了超过99%的成功执行率；验证了接触动力学平滑近似和鲁棒建模对成功率的影响；在模拟中测试不同孔轴配合问题，证明使用精确Hessian矩阵优于常用近似方法。

Conclusion: 提出的基于可微物理仿真的鲁棒最优控制方法能够高效规划装配运动，显著减少仿真步数，同时保持高成功率，为机器人装配任务提供了有效的解决方案。

Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.

</details>


### [14] [Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs](https://arxiv.org/abs/2601.22927)
*Lars Ullrich,Michael Buchholz,Klaus Dietmayer,Knut Graichen*

Main category: cs.RO

TL;DR: 本文重新审视了完全自动驾驶，分析了AI在自动驾驶领域的挑战与机遇，识别了当前局限性和未来技术可能性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶向完全自主驾驶的过渡面临现实开放世界的挑战，而AI在自动驾驶研究中展现出超越传统方法、处理更高复杂性和实现新自主水平的能力，但同时AI也带来了安全和可迁移性等问题。

Method: 分析了当前自动驾驶技术现状，概述了局限性，识别了可预见的技术可能性，并在前瞻性发展背景下考察了各种挑战。

Result: 识别了AI在自动驾驶功能方面带来的挑战和机遇，重新审视了完全自动驾驶，并提出了相应的需求和由此产生的研究问题。

Conclusion: 本文通过分析AI领域的进展，重新思考了完全自动驾驶，并明确了相关需求和未来研究方向。

Abstract: Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.

</details>


### [15] [MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2601.22930)
*Xidong Li,Mingyu Guo,Chenchao Xu,Bailin Li,Wenjing Zhu,Yangang Zou,Rui Chen,Zehuan Wang*

Main category: cs.RO

TL;DR: MTDrive是一个多轮轨迹规划框架，通过MLLMs与RL结合，利用多轮迭代优化处理自动驾驶中的复杂场景，相比单轮方法有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs与RL结合的方法仅限于单轮推理，无法处理需要迭代优化的复杂自动驾驶场景，限制了在长尾场景中的表现。

Method: 提出MTDrive多轮框架，引入mtGRPO算法缓解奖励稀疏问题，通过跨轮次相对优势计算，并构建交互式轨迹理解数据集支持多轮训练。

Result: 在NAVSIM基准测试中表现优于现有方法，验证了多轮推理范式的有效性；通过系统级优化实现了2.5倍训练吞吐量提升。

Conclusion: MTDrive通过多轮迭代优化显著提升了自动驾驶轨迹规划在复杂场景中的性能，为MLLMs与RL的深度结合提供了新范式。

Abstract: Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing "long-tail" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.

</details>


### [16] [Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation](https://arxiv.org/abs/2601.22965)
*Runhua Zhang,Junyi Hou,Changxu Cheng,Qiyi Chen,Tao Wang,Wuyue Zhao*

Main category: cs.RO

TL;DR: SIDP提出了一种自模仿扩散策略框架，通过奖励引导的自模仿机制选择性模仿自身采样轨迹，减少对大量采样和后过滤的依赖，实现更高效的视觉导航。


<details>
  <summary>Details</summary>
Motivation: 传统扩散策略依赖模仿学习训练，继承了专家演示的次优性和冗余性，需要计算密集的"生成-过滤"流程和辅助选择器，导致推理效率低下。

Method: 提出自模仿扩散策略框架，包含奖励引导的自模仿机制，鼓励策略持续产生高质量轨迹；采用奖励驱动的课程学习范式缓解数据利用效率问题，以及目标无关的探索进行轨迹增强。

Result: 在综合仿真基准测试中显著优于先前方法，真实世界实验验证了其在多个机器人平台上的有效性；在Jetson Orin Nano上推理速度比基线NavDP快2.5倍（110ms vs 273ms）。

Conclusion: SIDP通过自模仿机制有效解决了传统扩散策略的次优性和冗余问题，实现了高效实时部署，为视觉导航提供了更优的解决方案。

Abstract: Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive "generate-then-filter" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.

</details>


### [17] [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.22988)
*Di Zhang,Weicheng Duan,Dasen Gu,Hongye Lu,Hai Zhang,Hang Yu,Junqiao Zhao,Guang Chen*

Main category: cs.RO

TL;DR: MethodName是一个统一的表示-策略学习框架，通过单视图3D预训练和多步蒸馏实现机器人操作的视图泛化，在RLBench任务上平均成功率提升12.7%，在视角变化下泛化能力显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人操作需要具备强大空间场景理解和跨多样化相机视角泛化能力的视觉运动策略。现有3D感知视觉表示方法存在三个关键局限：推理时依赖多视角观察（在单视图受限场景中不实用）、不完整的场景建模（无法捕捉精确操作所需的全貌和细粒度几何结构）、以及缺乏有效的策略训练策略来保留和利用获得的3D知识。

Method: MethodName是一个统一的表示-策略学习框架，包含：1）单视图3D预训练范式，利用点云重建和前馈高斯溅射在多视图监督下学习全貌几何表示；2）策略学习阶段，执行多步蒸馏以保留预训练的几何理解，并将其有效转移到操作技能中。

Result: 在12个RLBench任务上，MethodName比先前最先进方法的平均成功率高出12.7%。在6个代表性任务的零样本视图泛化评估中，在中等和大幅视角变化下，MethodName的成功率仅下降22.0%和29.7%，而最先进方法的下降幅度更大，分别为41.6%和51.5%。

Conclusion: MethodName通过统一的表示-策略学习框架，解决了现有3D感知方法在单视图场景、几何建模完整性和知识保留方面的局限性，实现了强大的视图泛化机器人操作能力。

Abstract: Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.

</details>


### [18] [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080)
*Yubiao Ma,Han Yu,Jiayin Xie,Changtai Lv,Qiang Luo,Chi Zhang,Yunpeng Yin,Boyang Xing,Xuemei Ren,Dongdong Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于动力学条件命令聚合框架的人形机器人全身控制器，通过因果时间编码器和多头交叉注意力机制处理参考运动中的噪声和不一致性，结合跌倒恢复课程提升鲁棒性，仅需3.5小时运动数据即可实现端到端训练


<details>
  <summary>Details</summary>
Motivation: 学习通用人形机器人全身控制器面临挑战：参考运动转移到机器人域后可能存在噪声和不一致性，闭环执行会放大局部缺陷，导致高动态和接触丰富行为中的漂移或失败

Method: 提出动力学条件命令聚合框架：1) 使用因果时间编码器总结近期本体感知；2) 多头交叉注意力命令编码器基于当前动力学选择性地聚合上下文窗口；3) 集成跌倒恢复课程，包含随机不稳定初始化和退火向上辅助力

Result: 该方法仅需约3.5小时运动数据，支持单阶段端到端训练无需蒸馏。在多样化参考输入和挑战性运动机制下评估，展示了零样本迁移到未见运动的能力，以及在物理人形机器人上实现鲁棒的仿真到现实迁移

Conclusion: 提出的动力学条件命令聚合框架能够有效处理参考运动中的噪声和不一致性，结合跌倒恢复课程显著提升了控制器的鲁棒性和抗干扰能力，实现了高效的数据利用和可靠的仿真到现实迁移

Abstract: Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.

</details>


### [19] [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087)
*Wu Songwei,Jiang Zhiduo,Xie Guanghu,Liu Yang,Liu Hong*

Main category: cs.RO

TL;DR: LG-Flow Policy是一种轨迹级模仿学习框架，通过在连续潜在动作空间进行流匹配，实现快速单步推理和稳定执行，解决了扩散模型推理延迟高和原始动作空间流匹配不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成策略在长时程机器人操作中存在挑战：扩散模型建模能力强但推理延迟高，流匹配可实现快速单步生成但在原始动作空间直接应用时执行不稳定。需要同时实现表达性行为建模、实时推理和稳定执行。

Method: 提出LG-Flow Policy框架：1）将动作序列编码为时间正则化的潜在轨迹；2）在连续潜在动作空间学习显式流匹配；3）引入几何感知点云条件；4）执行时多模态调制（以视觉线索为代表）。该方法将全局运动结构与低级控制噪声解耦。

Result: 在仿真和物理机器人平台上的实验表明：LG-Flow Policy实现接近单步推理，相比原始动作空间的流匹配基线显著提高轨迹平滑度和任务成功率，且比扩散策略效率更高。

Conclusion: LG-Flow Policy通过潜在空间流匹配有效解决了长时程机器人操作中的建模能力、推理速度和执行稳定性之间的权衡问题，为实际机器人应用提供了高效可靠的解决方案。

Abstract: Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.
  We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.
  LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.

</details>


### [20] [End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms](https://arxiv.org/abs/2601.23285)
*MH Farhadi,Ali Rabiee,Sima Ghafoori,Anna Cetera,Andrew Fisher,Reza Abiri*

Main category: cs.RO

TL;DR: BRACE框架通过端到端梯度流整合贝叶斯意图推断和上下文自适应辅助，在复杂、目标模糊场景中显著提升共享自主系统的性能


<details>
  <summary>Details</summary>
Motivation: 共享自主系统需要从用户意图推断到辅助水平确定的统一方法。现有方法依赖静态混合比例或将目标推断与辅助仲裁分离，导致在非结构化环境中性能不佳

Method: 提出BRACE框架，通过端到端梯度流架构微调贝叶斯意图推断和上下文自适应辅助，将协作控制策略基于环境上下文和完整目标概率分布

Result: 相比SOTA方法（IDA、DQN），在三个逐步分离的评估中：2D光标任务、机器人手臂非线性动力学、目标模糊和环境约束下的集成操作，成功率和路径效率分别提升6.3%和41%，相比无辅助控制提升36.3%和87%

Conclusion: 集成优化在复杂、目标模糊场景中最为有益，可推广到需要目标导向辅助的机器人领域，推进了自适应共享自主系统的技术前沿

Abstract: Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.

</details>
