<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [StepNav: Structured Trajectory Priors for Efficient and Multimodal Visual Navigation](https://arxiv.org/abs/2602.02590)
*Xubo Luo,Aodi Wu,Haodong Han,Xue Wan,Wei Zhang,Leizheng Shu,Ruisuo Wang*

Main category: cs.RO

TL;DR: StepNav：一种基于结构化多模态轨迹先验的视觉导航框架，通过变分原理生成更安全高效的轨迹


<details>
  <summary>Details</summary>
Motivation: 当前生成模型依赖非结构化噪声先验，导致轨迹不安全、效率低、单模态，无法满足实时需求。需要一种能够生成可靠轨迹的方法来解决杂乱不确定环境中的视觉导航问题。

Method: StepNav首先学习几何感知的成功概率场来识别所有可行导航通道，然后构建显式的多模态混合先验来初始化条件流匹配过程。该细化过程被表述为具有显式平滑性和安全性正则化的最优控制问题。

Result: 在仿真和真实世界基准测试中，StepNav在鲁棒性、效率和安全性方面均优于最先进的生成规划器，用更少的步骤生成更安全高效的规划。

Conclusion: 通过用物理基础候选轨迹替代非结构化噪声，StepNav为实际自主导航提供了可靠的轨迹生成方法，显著提升了视觉导航的实用性和可靠性。

Abstract: Visual navigation is fundamental to autonomous systems, yet generating reliable trajectories in cluttered and uncertain environments remains a core challenge. Recent generative models promise end-to-end synthesis, but their reliance on unstructured noise priors often yields unsafe, inefficient, or unimodal plans that cannot meet real-time requirements. We propose StepNav, a novel framework that bridges this gap by introducing structured, multimodal trajectory priors derived from variational principles. StepNav first learns a geometry-aware success probability field to identify all feasible navigation corridors. These corridors are then used to construct an explicit, multi-modal mixture prior that initializes a conditional flow-matching process. This refinement is formulated as an optimal control problem with explicit smoothness and safety regularization. By replacing unstructured noise with physically-grounded candidates, StepNav generates safer and more efficient plans in significantly fewer steps. Experiments in both simulation and real-world benchmarks demonstrate consistent improvements in robustness, efficiency, and safety over state-of-the-art generative planners, advancing reliable trajectory generation for practical autonomous navigation. The code has been released at https://github.com/LuoXubo/StepNav.

</details>


### [2] [AROLA: A Modular Layered Architecture for Scaled Autonomous Racing](https://arxiv.org/abs/2602.02730)
*Fam Shihata,Mohammed Abdelazim,Ahmed Hussein*

Main category: cs.RO

TL;DR: AROLA是一个用于自动驾驶赛车的模块化分层软件架构，通过标准化ROS 2接口将系统分解为可互换的组件层，同时引入Race Monitor框架进行实时性能评估。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶赛车技术的快速发展，现有的软件架构存在碎片化和单体化问题，缺乏模块化和标准化接口，阻碍了快速开发和性能评估。

Method: 提出AROLA模块化分层架构，将自动驾驶流水线分解为感知、预处理、定位与建图、规划、行为、控制等可互换组件层，使用标准化ROS 2接口连接。同时开发Race Monitor框架，实时记录圈速、轨迹质量和计算负载。

Result: AROLA在RoboRacer平台上的仿真和硬件测试中验证成功，包括在2025 RoboRacer IV25竞赛中的部署。系统展示了模块化、透明接口和系统化评估能够加速开发并提高可重复性。

Conclusion: AROLA和Race Monitor证明了模块化架构、标准化接口和系统化性能评估能够显著促进自动驾驶赛车领域的开发效率和结果可重复性。

Abstract: Autonomous racing has advanced rapidly, particularly on scaled platforms, and software stacks must evolve accordingly. In this work, AROLA is introduced as a modular, layered software architecture in which fragmented and monolithic designs are reorganized into interchangeable layers and components connected through standardized ROS 2 interfaces. The autonomous-driving pipeline is decomposed into sensing, pre-processing, perception, localization and mapping, planning, behavior, control, and actuation, enabling rapid module replacement and objective benchmarking without reliance on custom message definitions. To support consistent performance evaluation, a Race Monitor framework is introduced as a lightweight system through which lap timing, trajectory quality, and computational load are logged in real time and standardized post-race analyses are generated. AROLA is validated in simulation and on hardware using the RoboRacer platform, including deployment at the 2025 RoboRacer IV25 competition. Together, AROLA and Race Monitor demonstrate that modularity, transparent interfaces, and systematic evaluation can accelerate development and improve reproducibility in scaled autonomous racing.

</details>


### [3] [PokeNet: Learning Kinematic Models of Articulated Objects from Human Observations](https://arxiv.org/abs/2602.02741)
*Anmol Gupta,Weiwei Gu,Omkar Patil,Jun Ki Lee,Nakul Gopalan*

Main category: cs.RO

TL;DR: PokeNet是一个端到端框架，通过单次人类演示即可估计未知物体的关节参数，无需先验知识，并能推断操作顺序和跟踪关节状态。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖物体先验知识（如关节数量或类型），无法恢复交互中才显露的遮挡关节，需要大量多视角图像，且忽视了多自由度物体中关节操作顺序的重要性。

Method: PokeNet是一个端到端框架，给定人类操作未知物体的点云观测序列，能够预测关节参数、推断操作顺序，并随时间跟踪关节状态。

Result: PokeNet在关节轴和状态估计精度上平均提升超过27%，在包括新颖和未见类别在内的多样化物体上优于现有方法，在仿真和真实环境中均表现出色。

Conclusion: PokeNet通过单次人类演示即可有效学习未知物体的关节模型，解决了现有方法的局限性，为机器人操作提供了更实用的解决方案。

Abstract: Articulation modeling enables robots to learn joint parameters of articulated objects for effective manipulation which can then be used downstream for skill learning or planning. Existing approaches often rely on prior knowledge about the objects, such as the number or type of joints. Some of these approaches also fail to recover occluded joints that are only revealed during interaction. Others require large numbers of multi-view images for every object, which is impractical in real-world settings. Furthermore, prior works neglect the order of manipulations, which is essential for many multi-DoF objects where one joint must be operated before another, such as a dishwasher. We introduce PokeNet, an end-to-end framework that estimates articulation models from a single human demonstration without prior object knowledge. Given a sequence of point cloud observations of a human manipulating an unknown object, PokeNet predicts joint parameters, infers manipulation order, and tracks joint states over time. PokeNet outperforms existing state-of-the-art methods, improving joint axis and state estimation accuracy by an average of over 27% across diverse objects, including novel and unseen categories. We demonstrate these gains in both simulation and real-world environments.

</details>


### [4] [Bimanual High-Density EMG Control for In-Home Mobile Manipulation by a User with Quadriplegia](https://arxiv.org/abs/2602.02773)
*Jehan Yang,Eleanor Hodgson,Cindy Sun,Zackory Erickson,Doug Weber*

Main category: cs.RO

TL;DR: 开发了一套基于双前臂高密度肌电图的移动机械臂控制系统，帮助四肢瘫痪患者在家中进行日常家务活动


<details>
  <summary>Details</summary>
Motivation: 颈椎脊髓损伤患者由于瘫痪无法使用传统机器人控制接口（如操纵杆或键盘），需要开发新的控制方式来帮助他们独立完成日常家务任务

Method: 1) 开发了集成在织物中的双前臂高密度肌电图袖套，捕捉瘫痪肢体的残余神经肌肉活动；2) 结合视觉、语言和运动规划模块，构建了支持用户驱动远程操作的共享自主框架；3) 进行了为期12天的家庭用户研究，评估可穿戴肌电接口的实际使用效果

Result: 该系统成功实现了在真实家庭环境中对移动机械臂的有效控制，使四肢瘫痪患者能够完成日常生活活动和家务任务

Conclusion: 基于高密度肌电图的控制接口结合共享自主框架，为四肢瘫痪患者提供了在家中控制移动机械臂的有效解决方案，显著提升了他们的生活自主性

Abstract: Mobile manipulators in the home can enable people with cervical spinal cord injury (cSCI) to perform daily physical household tasks that they could not otherwise do themselves. However, paralysis in these users often limits access to traditional robot control interfaces such as joysticks or keyboards. In this work, we introduce and deploy the first system that enables a user with quadriplegia to control a mobile manipulator in their own home using bimanual high-density electromyography (HDEMG). We develop a pair of custom, fabric-integrated HDEMG forearm sleeves, worn on both arms, that capture residual neuromotor activity from clinically paralyzed degrees of freedom and support real-time gesture-based robot control. Second, by integrating vision, language, and motion planning modules, we introduce a shared autonomy framework that supports robust and user-driven teleoperation, with particular benefits for navigation-intensive tasks in home environments. Finally, to demonstrate the system in the wild, we present a twelve-day in-home user study evaluating real-time use of the wearable EMG interface for daily robot control. Together, these system components enable effective robot control for performing activities of daily living and other household tasks in a real home environment.

</details>


### [5] [Adaptive Linear Path Model-Based Diffusion](https://arxiv.org/abs/2602.02831)
*Yutaka Shimizu,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: LP-MBD使用线性概率路径替代传统扩散模型调度，简化参数调优；ALP-MBD在此基础上通过强化学习自适应调整扩散步数和噪声水平，提升鲁棒性和实时效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人控制任务中表现出色，但其性能对调度参数选择极为敏感，参数调优成为主要挑战。需要一种更稳定、易于调参的方法来提升扩散模型在控制任务中的实用性和适应性。

Method: 1. LP-MBD：用流匹配启发的线性概率路径替代传统的方差保持调度，获得几何可解释且解耦的参数化方法。2. ALP-MBD：在LP-MBD基础上，利用强化学习根据任务复杂度和环境条件自适应调整扩散步数和噪声水平。

Result: 在数值研究、Brax基准测试和移动机器人轨迹跟踪实验中，LP-MBD在简化调度的同时保持了强大性能；ALP-MBD进一步提升了鲁棒性、适应性和实时效率。

Conclusion: LP-MBD提供了一种几何可解释且解耦的扩散模型参数化方法，显著降低了调优复杂度；ALP-MBD通过自适应机制进一步增强了模型在不同任务和环境条件下的性能表现，为基于扩散模型的机器人控制提供了更稳定和高效的基础。

Abstract: The interest in combining model-based control approaches with diffusion models has been growing. Although we have seen many impressive robotic control results in difficult tasks, the performance of diffusion models is highly sensitive to the choice of scheduling parameters, making parameter tuning one of the most critical challenges. We introduce Linear Path Model-Based Diffusion (LP-MBD), which replaces the variance-preserving schedule with a flow-matching-inspired linear probability path. This yields a geometrically interpretable and decoupled parameterization that reduces tuning complexity and provides a stable foundation for adaptation. Building on this, we propose Adaptive LP-MBD (ALP-MBD), which leverages reinforcement learning to adjust diffusion steps and noise levels according to task complexity and environmental conditions. Across numerical studies, Brax benchmarks, and mobile-robot trajectory tracking, LP-MBD simplifies scheduling while maintaining strong performance, and ALP-MBD further improves robustness, adaptability, and real-time efficiency.

</details>


### [6] [Language Movement Primitives: Grounding Language Models in Robot Motion](https://arxiv.org/abs/2602.02839)
*Yinlong Dai,Benjamin A. Christie,Daniel J. Evans,Dylan P. Losey,Simon Stepputtis*

Main category: cs.RO

TL;DR: 提出Language Movement Primitives (LMPs)框架，通过将视觉语言模型的推理能力与动态运动基元参数化相结合，实现机器人从自然语言指令到低级运动控制的零样本操作


<details>
  <summary>Details</summary>
Motivation: 当前机器人领域面临核心挑战：大型视觉语言模型能够处理视觉场景和语言理解，并能将任务分解为逻辑步骤，但难以将这些步骤落实到具体的机器人运动控制；而机器人基础模型需要领域内微调才能执行新任务。需要解决抽象任务推理与低级运动控制之间的脱节问题

Method: 提出语言运动基元框架，核心洞察是动态运动基元提供少量可解释参数，视觉语言模型可以设置这些参数来指定多样化、连续且稳定的轨迹。将VLM的推理能力与DMP参数化相结合，形成LMP流水线，通过生成一系列DMP运动来完成桌面操作任务

Result: 在20个真实世界操作任务中，LMP实现了80%的任务成功率，而最佳基线方法仅为31%。证明了该框架在零样本机器人操作中的有效性

Conclusion: LMP框架成功地将视觉语言模型的高级任务推理能力与动态运动基元的低级运动控制参数化相结合，有效解决了抽象任务推理与具体运动执行之间的鸿沟，为自然语言驱动的机器人操作提供了有前景的解决方案

Abstract: Enabling robots to perform novel manipulation tasks from natural language instructions remains a fundamental challenge in robotics, despite significant progress in generalized problem solving with foundational models. Large vision and language models (VLMs) are capable of processing high-dimensional input data for visual scene and language understanding, as well as decomposing tasks into a sequence of logical steps; however, they struggle to ground those steps in embodied robot motion. On the other hand, robotics foundation models output action commands, but require in-domain fine-tuning or experience before they are able to perform novel tasks successfully. At its core, there still remains the fundamental challenge of connecting abstract task reasoning with low-level motion control. To address this disconnect, we propose Language Movement Primitives (LMPs), a framework that grounds VLM reasoning in Dynamic Movement Primitive (DMP) parameterization. Our key insight is that DMPs provide a small number of interpretable parameters, and VLMs can set these parameters to specify diverse, continuous, and stable trajectories. Put another way: VLMs can reason over free-form natural language task descriptions, and semantically ground their desired motions into DMPs -- bridging the gap between high-level task reasoning and low-level position and velocity control. Building on this combination of VLMs and DMPs, we formulate our LMP pipeline for zero-shot robot manipulation that effectively completes tabletop manipulation problems by generating a sequence of DMP motions. Across 20 real-world manipulation tasks, we show that LMP achieves 80% task success as compared to 31% for the best-performing baseline. See videos at our website: https://collab.me.vt.edu/lmp

</details>


### [7] [Kino-PAX$^+$: Near-Optimal Massively Parallel Kinodynamic Sampling-based Motion Planner](https://arxiv.org/abs/2602.02846)
*Nicolas Perrault,Qi Heng Ho,Morteza Lahijanian*

Main category: cs.RO

TL;DR: Kino-PAX⁺是一个大规模并行的运动规划算法，在保持概率完备性的同时提供渐近近优保证，比现有串行方法快三个数量级。


<details>
  <summary>Details</summary>
Motivation: 基于采样的运动规划器（SBMPs）在处理高维空间的复杂动力学约束时，由于串行计算设计难以实现实时性能。现有的并行化方法虽然加速了可行解的寻找，但无法保证目标函数的最优化。

Method: Kino-PAX⁺通过将传统串行操作分解为三个大规模并行子程序来构建稀疏的动态可行轨迹树。算法将计算集中在局部邻域内最有希望的节点上进行传播和细化，从而实现解成本的快速改进。

Result: Kino-PAX⁺比现有串行方法快三个数量级，并且比最先进的基于GPU的规划器获得更低的解成本。同时证明了算法在保持概率δ-鲁棒完备性的同时，确保渐近δ-鲁棒近优性。

Conclusion: Kino-PAX⁺是一个具有渐近近优保证的大规模并行运动规划算法，在保持理论保证的同时实现了显著的性能提升，为实时运动规划提供了有效解决方案。

Abstract: Sampling-based motion planners (SBMPs) are widely used for robot motion planning with complex kinodynamic constraints in high-dimensional spaces, yet they struggle to achieve \emph{real-time} performance due to their serial computation design. Recent efforts to parallelize SBMPs have achieved significant speedups in finding feasible solutions; however, they provide no guarantees of optimizing an objective function. We introduce Kino-PAX$^{+}$, a massively parallel kinodynamic SBMP with asymptotic near-optimal guarantees. Kino-PAX$^{+}$ builds a sparse tree of dynamically feasible trajectories by decomposing traditionally serial operations into three massively parallel subroutines. The algorithm focuses computation on the most promising nodes within local neighborhoods for propagation and refinement, enabling rapid improvement of solution cost. We prove that, while maintaining probabilistic $δ$-robust completeness, this focus on promising nodes ensures asymptotic $δ$-robust near-optimality. Our results show that Kino-PAX$^{+}$ finds solutions up to three orders of magnitude faster than existing serial methods and achieves lower solution costs than a state-of-the-art GPU-based planner.

</details>


### [8] [Accelerating Structured Chain-of-Thought in Autonomous Vehicles](https://arxiv.org/abs/2602.02864)
*Yi Gu,Yan Wang,Yuxiao Chen,Yurong You,Wenjie Luo,Yue Wang,Wenhao Ding,Boyi Li,Heng Yang,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: FastDriveCoT通过并行解码加速自动驾驶中的思维链推理，将推理过程分解为依赖图，在单次前向传播中并行生成多个独立推理步骤，实现3-4倍加速


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然增强了自动驾驶视觉-语言-动作模型的决策能力，但其自回归特性引入了显著的推理延迟，无法满足实时应用需求

Method: 提出FastDriveCoT并行解码方法，将模板化思维链推理过程分解为依赖图，识别可以并行生成的子任务（如关键对象识别、交通规则总结等），在单次前向传播中并发生成多个独立推理步骤

Result: 实验表明，该方法在思维链生成上实现3-4倍加速，显著降低端到端延迟，同时保持了思维链推理带来的下游任务性能提升

Conclusion: FastDriveCoT通过并行解码有效解决了思维链推理的实时性问题，为自动驾驶等实时应用中的复杂推理提供了可行的解决方案

Abstract: Chain-of-Thought (CoT) reasoning enhances the decision-making capabilities of vision-language-action models in autonomous driving, but its autoregressive nature introduces significant inference latency, making it impractical for real-time applications. To address this, we introduce FastDriveCoT, a novel parallel decoding method that accelerates template-structured CoT. Our approach decomposes the reasoning process into a dependency graph of distinct sub-tasks, such as identifying critical objects and summarizing traffic rules, some of which can be generated in parallel. By generating multiple independent reasoning steps concurrently within a single forward pass, we significantly reduce the number of sequential computations. Experiments demonstrate a 3-4$\times$ speedup in CoT generation and a substantial reduction in end-to-end latency across various model architectures, all while preserving the original downstream task improvements brought by incorporating CoT reasoning.

</details>


### [9] [Moving On, Even When You're Broken: Fail-Active Trajectory Generation via Diffusion Policies Conditioned on Embodiment and Task](https://arxiv.org/abs/2602.02895)
*Gilberto G. Briscoe-Martinez,Yaashia Gautam,Rahul Shetty,Anuj Pasricha,Marco M. Nicotra,Alessandro Roncone*

Main category: cs.RO

TL;DR: DEFT：一种基于扩散的轨迹生成器，能够在机器人执行器故障时实现"故障主动"操作，通过条件化当前机器人体态和任务约束来生成轨迹，在各种故障类型下完成目标任务。


<details>
  <summary>Details</summary>
Motivation: 机器人故障通常需要人工干预来恢复，这既耗时又具有破坏性。研究旨在实现"故障主动"操作，即在机器人受损情况下仍能安全完成任务，减少对人工干预的依赖。

Method: 提出DEFT方法，这是一种基于扩散模型的轨迹生成器，能够根据机器人当前体态（故障后的关节状态）和任务约束（如目标位置）生成运动轨迹。该方法支持约束和非约束运动，适用于任意类型的执行器故障。

Result: 在模拟环境中，DEFT在数千个关节故障案例中表现优于基线方法达2倍；在未见过的故障类型上仍优于基线，显示出良好的泛化能力。在真实世界实验中，DEFT成功完成了抽屉操作和白板擦除任务，而传统方法在这些任务中失败。

Conclusion: DEFT能够在任意故障配置下实现故障主动操作，并在真实世界部署中表现出色，为机器人故障恢复提供了一种有效的解决方案。

Abstract: Robot failure is detrimental and disruptive, often requiring human intervention to recover. Maintaining safe operation under impairment to achieve task completion, i.e. fail-active operation, is our target. Focusing on actuation failures, we introduce DEFT, a diffusion-based trajectory generator conditioned on the robot's current embodiment and task constraints. DEFT generalizes across failure types, supports constrained and unconstrained motions, and enables task completion under arbitrary failure. We evaluated DEFT in both simulation and real-world scenarios using a 7-DoF robotic arm. In simulation over thousands of joint-failure cases across multiple tasks, DEFT outperformed the baseline by up to 2 times. On failures unseen during training, it continued to outperform the baseline, indicating robust generalization in simulation. Further, we performed real-world evaluations on two multi-step tasks, drawer manipulation and whiteboard erasing. These experiments demonstrated DEFT succeeding on tasks where classical methods failed. Our results show that DEFT achieves fail-active manipulation across arbitrary failure configurations and real-world deployments.

</details>


### [10] [Modular Isoperimetric Soft Robotic Truss for Lunar Applications](https://arxiv.org/abs/2602.02915)
*Mihai Stanciu,Isaac Weaver,Adam Rose,James Wade,Kaden Paxton,Chris Paul,Spencer Stowell,Nathan Usevitch*

Main category: cs.RO

TL;DR: 研究人员开发了一种用于月球应用的大型模块化机器人系统，由可充气织物管构成的三角形桁架组成，通过球形关节连接，能够实现1:18.3的折叠比，无需额外压缩空气即可改变形状，可用于太阳能阵列和移动设备。


<details>
  <summary>Details</summary>
Motivation: 为可持续月球操作和未来太空任务开发一种轻量、模块化、可重构的机器人系统，解决太空应用中的关键挑战。

Method: 系统由可充气织物管构成的三角形桁架组成，通过两个滚轮单元和一个连接单元形成。新开发的球形关节允许最多三个三角形在顶点连接。滚轮单元夹紧管子形成有效关节，电机驱动滚轮单元沿管子移动，通过等周变形改变形状。

Result: 系统实现了1:18.3的折叠比，无需额外压缩空气即可改变形状。演示了12自由度的太阳能阵列（倾斜60度，旋转360度）和14自由度的移动设备（采用步进滑动步态）。

Conclusion: 这种模块化、形状自适应的系统为可持续月球操作和未来太空任务提供了创新解决方案，展示了在太空环境中构建大型可重构结构的潜力。

Abstract: We introduce a large-scale robotic system designed as a lightweight, modular, and reconfigurable structure for lunar applications. The system consists of truss-like robotic triangles formed by continuous inflated fabric tubes routed through two robotic roller units and a connecting unit. A newly developed spherical joint enables up to three triangles to connect at a vertex, allowing construction of truss assemblies beyond a single octahedron. When deflated, the triangles compact to approximately the volume of the roller units, achieving a stowed-to-deployed volume ratio of 1:18.3. Upon inflation, the roller units pinch the tubes, locally reducing bending stiffness to form effective joints. Electric motors then translate the roller units along the tube, shifting the pinch point by lengthening one edge while shortening another at the same rate, thereby preserving a constant perimeter (isoperimetric). This shape-changing process requires no additional compressed air, enabling untethered operation after initial inflation. We demonstrate the system as a 12-degree-of-freedom solar array capable of tilting up to 60 degrees and sweeping 360 degrees, and as a 14-degree-of-freedom locomotion device using a step-and-slide gait. This modular, shape-adaptive system addresses key challenges for sustainable lunar operations and future space missions.

</details>


### [11] [Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control](https://arxiv.org/abs/2602.02960)
*Quanquan Peng,Yunfeng Lin,Yufei Xue,Jiangmiao Pang,Weinan Zhang*

Main category: cs.RO

TL;DR: EAGLE提出了一种迭代的通用-专家蒸馏框架，通过循环训练专家策略并蒸馏回通用策略，使单一策略能够控制多个异构人形机器人，无需为每个机器人单独调整奖励函数。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的人形机器人全身控制器通常针对单一机器人设计，难以适应不同机器人在动力学、自由度和运动学拓扑上的差异。同时，现有方法难以实现既能跨机器人迁移又能支持丰富行为（如蹲下、倾斜等）的通用策略。

Method: EAGLE采用迭代的通用-专家蒸馏框架：1）从当前通用策略派生出针对特定机器人的专家策略；2）在各自机器人上精炼专家策略；3）将新学到的技能通过训练蒸馏回通用策略；4）重复此循环直至性能收敛，最终获得能控制多个异构人形机器人的统一策略。

Result: 在仿真中测试了5个不同机器人，在真实世界中测试了4个机器人（包括Unitree H1、G1和Fourier N1）。定量评估显示，EAGLE相比其他方法具有更高的跟踪精度和鲁棒性。

Conclusion: EAGLE框架成功实现了单一策略控制多个异构人形机器人，无需为每个机器人单独调整奖励函数，为实现可扩展的、面向机群级别的人形机器人控制迈出了重要一步。

Abstract: Humanoid Whole-Body Controllers trained with reinforcement learning (RL) have recently achieved remarkable performance, yet many target a single robot embodiment. Variations in dynamics, degrees of freedom (DoFs), and kinematic topology still hinder a single policy from commanding diverse humanoids. Moreover, obtaining a generalist policy that not only transfers across embodiments but also supports richer behaviors-beyond simple walking to squatting, leaning-remains especially challenging. In this work, we tackle these obstacles by introducing EAGLE, an iterative generalist-specialist distillation framework that produces a single unified policy that controls multiple heterogeneous humanoids without per-robot reward tuning. During each cycle, embodiment-specific specialists are forked from the current generalist, refined on their respective robots, and new skills are distilled back into the generalist by training on the pooled embodiment set. Repeating this loop until performance convergence produces a robust Whole-Body Controller validated on robots such as Unitree H1, G1, and Fourier N1. We conducted experiments on five different robots in simulation and four in real-world settings. Through quantitative evaluations, EAGLE achieves high tracking accuracy and robustness compared to other methods, marking a step toward scalable, fleet-level humanoid control. See more details at https://eagle-wbc.github.io/

</details>


### [12] [RPL: Learning Robust Humanoid Perceptive Locomotion on Challenging Terrains](https://arxiv.org/abs/2602.03002)
*Yuanhang Zhang,Younggyo Seo,Juyue Chen,Yifu Yuan,Koushil Sreenath,Pieter Abbeel,Carmelo Sferrazza,Karen Liu,Rocky Duan,Guanya Shi*

Main category: cs.RO

TL;DR: RPL是一个两阶段训练框架，通过专家策略训练和Transformer策略蒸馏，实现了人形机器人在复杂地形上的多方向运动，并能承受2kg负载。


<details>
  <summary>Details</summary>
Motivation: 虽然人形机器人感知运动已取得显著进展，但在复杂地形上实现稳健的多方向运动仍未被充分探索。现有方法难以处理不对称深度观测和不同地形宽度等挑战。

Method: 采用两阶段训练框架：第一阶段使用特权高度图观测训练地形特定专家策略，掌握解耦的运动和操作技能；第二阶段将专家策略蒸馏到基于Transformer的策略中，该策略利用多个深度相机覆盖广视角。引入深度特征缩放和随机侧边掩码技术来增强多方向运动的鲁棒性。开发高效多深度系统，在并行环境中对动态机器人网格和静态地形网格进行光线投射，速度比现有模拟器快5倍。

Result: 在真实世界实验中展示了稳健的多方向运动能力，能够承受2kg负载，成功穿越20°斜坡、不同步长（22cm、25cm、30cm）的楼梯，以及25cm×25cm、间隔60cm的踏脚石等挑战性地形。

Conclusion: RPL框架成功实现了人形机器人在复杂地形上的稳健多方向运动，通过两阶段训练、深度特征缩放和随机侧边掩码等技术解决了不对称深度观测和地形宽度变化等挑战，为实际应用提供了有效解决方案。

Abstract: Humanoid perceptive locomotion has made significant progress and shows great promise, yet achieving robust multi-directional locomotion on complex terrains remains underexplored. To tackle this challenge, we propose RPL, a two-stage training framework that enables multi-directional locomotion on challenging terrains, and remains robust with payloads. RPL first trains terrain-specific expert policies with privileged height map observations to master decoupled locomotion and manipulation skills across different terrains, and then distills them into a transformer policy that leverages multiple depth cameras to cover a wide range of views. During distillation, we introduce two techniques to robustify multi-directional locomotion, depth feature scaling based on velocity commands and random side masking, which are critical for asymmetric depth observations and unseen widths of terrains. For scalable depth distillation, we develop an efficient multi-depth system that ray-casts against both dynamic robot meshes and static terrain meshes in massively parallel environments, achieving a 5-times speedup over the depth rendering pipelines in existing simulators while modeling realistic sensor latency, noise, and dropout. Extensive real-world experiments demonstrate robust multi-directional locomotion with payloads (2kg) across challenging terrains, including 20° slopes, staircases with different step lengths (22 cm, 25 cm, 30 cm), and 25 cm by 25 cm stepping stones separated by 60 cm gaps.

</details>


### [13] [Training and Simulation of Quadrupedal Robot in Adaptive Stair Climbing for Indoor Firefighting: An End-to-End Reinforcement Learning Approach](https://arxiv.org/abs/2602.03087)
*Baixiao Huang,Baiyu Huang,Yu Hou*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段端到端深度强化学习框架，使四足机器人能够在复杂室内环境中自主导航并攀爬不同类型的楼梯，包括直梯、L形梯和螺旋梯。


<details>
  <summary>Details</summary>
Motivation: 在室内火灾初期，四足机器人用于快速搜索受害者和监测易燃材料，但在复杂室内环境中的态势感知和快速攀爬不同类型楼梯仍然是主要挑战。

Method: 采用两阶段端到端深度强化学习方法：第一阶段在抽象的金字塔楼梯地形训练机器人攀爬技能；第二阶段将学习到的策略迁移到真实的室内楼梯环境，使用基于中心线的导航公式统一学习导航和运动控制。

Result: 提出的方法能够使四足机器人在仅使用局部高度图感知的情况下，成功攀爬多种类型的楼梯，并展示了策略在不同楼梯形状间的泛化能力。

Conclusion: 该研究证明了端到端强化学习方法可以使四足机器人适应不同形状的楼梯，平衡导航和运动控制，为复杂环境中的机器人辅助搜索提供了有效解决方案。

Abstract: Quadruped robots are used for primary searches during the early stages of indoor fires. A typical primary search involves quickly and thoroughly looking for victims under hazardous conditions and monitoring flammable materials. However, situational awareness in complex indoor environments and rapid stair climbing across different staircases remain the main challenges for robot-assisted primary searches. In this project, we designed a two-stage end-to-end deep reinforcement learning (RL) approach to optimize both navigation and locomotion. In the first stage, the quadrupeds, Unitree Go2, were trained to climb stairs in Isaac Lab's pyramid-stair terrain. In the second stage, the quadrupeds were trained to climb various realistic indoor staircases in the Isaac Lab engine, with the learned policy transferred from the previous stage. These indoor staircases are straight, L-shaped, and spiral, to support climbing tasks in complex environments. This project explores how to balance navigation and locomotion and how end-to-end RL methods can enable quadrupeds to adapt to different stair shapes. Our main contributions are: (1) A two-stage end-to-end RL framework that transfers stair-climbing skills from abstract pyramid terrain to realistic indoor stair topologies. (2) A centerline-based navigation formulation that enables unified learning of navigation and locomotion without hierarchical planning. (3) Demonstration of policy generalization across diverse staircases using only local height-map perception. (4) An empirical analysis of success, efficiency, and failure modes under increasing stair difficulty.

</details>


### [14] [A Unified Candidate Set with Scene-Adaptive Refinement via Diffusion for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.03112)
*Zhengfei Wu,Shuaixi Pan,Shuohan Chen,Shuo Yang,Yanjun Huang*

Main category: cs.RO

TL;DR: CdDrive提出了一种混合轨迹规划方法，通过结合固定轨迹词汇和场景自适应扩散生成候选轨迹，使用HATNA技术改善扩散轨迹的平滑性，在自动驾驶规划任务中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统采用多模态规划范式时面临两难：固定轨迹词汇在常规驾驶中稳定但复杂交互中可能错过最优解；场景自适应细化在简单场景中可能过度扰动已有良好轨迹。需要一种方法既能保持稳定性又能适应复杂交互。

Method: CdDrive保留原始固定轨迹词汇候选，同时通过词汇条件扩散去噪生成场景自适应候选轨迹。两种候选轨迹由共享选择模块联合评分。引入HATNA（Horizon-Aware Trajectory Noise Adapter）通过时间平滑和视野感知噪声调制来改善扩散候选轨迹的平滑性和几何连续性。

Result: 在NAVSIM v1和NAVSIM v2数据集上的实验显示领先性能，消融研究验证了每个组件的贡献。

Conclusion: CdDrive通过结合固定轨迹词汇和场景自适应扩散生成，实现了在常规和高度交互场景中的可靠性能，HATNA技术有效提升了扩散生成轨迹的质量。

Abstract: End-to-end autonomous driving is increasingly adopting a multimodal planning paradigm that generates multiple trajectory candidates and selects the final plan, making candidate-set design critical. A fixed trajectory vocabulary provides stable coverage in routine driving but often misses optimal solutions in complex interactions, while scene-adaptive refinement can cause over-correction in simple scenarios by unnecessarily perturbing already strong vocabulary trajectories.We propose CdDrive, which preserves the original vocabulary candidates and augments them with scene-adaptive candidates generated by vocabulary-conditioned diffusion denoising. Both candidate types are jointly scored by a shared selection module, enabling reliable performance across routine and highly interactive scenarios. We further introduce HATNA (Horizon-Aware Trajectory Noise Adapter) to improve the smoothness and geometric continuity of diffusion candidates via temporal smoothing and horizon-aware noise modulation. Experiments on NAVSIM v1 and NAVSIM v2 demonstrate leading performance, and ablations verify the contribution of each component.

</details>


### [15] [Multi-function Robotized Surgical Dissector for Endoscopic Pulmonary Thromboendarterectomy: Preclinical Study and Evaluation](https://arxiv.org/abs/2602.03147)
*Runfeng Zhu,Xin Zhong,Qingxiang Zhao,Jing Lin,Zhong Wu,Kang Li*

Main category: cs.RO

TL;DR: 本文提出了一种基于同心推拉机器人结构的机器人化剥离器，用于慢性严重肺血栓栓塞手术，具有细长结构和双段弯曲灵活性，可实现3.5mm直径进入肺动脉细分支。


<details>
  <summary>Details</summary>
Motivation: 传统肺血栓内膜切除术中使用的工具刚直且缺乏远端灵活性，难以进入肺动脉的细分支，限制了手术效果。需要开发具有更好灵活性和可操作性的器械来改进手术。

Method: 采用同心推拉机器人结构设计机器人化剥离器，具有3.5mm细长直径、双段弯曲灵活性、中空结构容纳冲洗通道、尖端工具和内窥镜信号线。建立了基于优化的运动学模型实现精确定位。

Result: 在开环控制策略下，60mm长的尖端工具定位精度达到2mm。通过实验评估了刚度、运动精度和可操作性等基本物理性能，并在离体猪肺上进行手术模拟验证了其灵活性和在肺血栓内膜切除术中的优势。

Conclusion: 该机器人化剥离器设计成功解决了传统刚性剥离器在肺动脉细分支手术中的局限性，有望将传统肺血栓内膜切除术升级为内窥镜手术，提高手术的精确性和可及性。

Abstract: Patients suffering chronic severe pulmonary thromboembolism need Pulmonary Thromboendarterectomy (PTE) to remove the thromb and intima located inside pulmonary artery (PA). During the surgery, a surgeon holds tweezers and a dissector to delicately strip the blockage, but available tools for this surgery are rigid and straight, lacking distal dexterity to access into thin branches of PA. Therefore, this work presents a novel robotized dissector based on concentric push/pull robot (CPPR) structure, enabling entering deep thin branch of tortuous PA. Compared with conventional rigid dissectors, our design characterizes slenderness and dual-segment-bending dexterity. Owing to the hollow and thin-walled structure of the CPPR-based dissector as it has a slender body of 3.5mm in diameter, the central lumen accommodates two channels for irrigation and tip tool, and space for endoscopic camera's signal wire. To provide accurate surgical manipulation, optimization-based kinematics model was established, realizing a 2mm accuracy in positioning the tip tool (60mm length) under open-loop control strategy. As such, with the endoscopic camera, traditional PTE is possible to be upgraded as endoscopic PTE. Basic physic performance of the robotized dissector including stiffness, motion accuracy and maneuverability was evaluated through experiments. Surgery simulation on ex vivo porcine lung also demonstrates its dexterity and notable advantages in PTE.

</details>


### [16] [When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens](https://arxiv.org/abs/2602.03153)
*Xuetao Li,Pinhan Fu,Wenke Huang,Nengyuan Pan,Songhua Yang,Kaiyan Zhao,Guancheng Wan,Mengde Li,Jifeng Xuan,Miao Li*

Main category: cs.RO

TL;DR: Bera：一种无需重新训练VLA模型的测试时后门擦除框架，通过检测异常注意力、屏蔽可疑区域并重建无触发器图像来保护机器人系统安全


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型的下游微调增强了机器人能力，但也引入了后门攻击风险。现有防御方法要么缺乏对多模态后门的机制理解，要么需要全模型重新训练导致计算成本过高

Method: 发现后门机制：后门会重定向后期注意力并在干净流形附近形成紧凑嵌入簇。基于此提出Bera框架：1）通过潜在空间定位检测异常注意力标记；2）使用深层线索屏蔽可疑区域；3）重建无触发器图像以打破触发器-不安全动作映射

Result: 在多个具身平台和任务上的广泛实验表明，Bera能有效保持正常性能，显著降低攻击成功率，并持续从后门输出中恢复良性行为

Conclusion: Bera提供了一种稳健实用的机器人系统安全防御机制，无需重新训练VLA模型或改变训练流程，为保护机器人系统免受后门攻击提供了有效解决方案

Abstract: Downstream fine-tuning of vision-language-action (VLA) models enhances robotics, yet exposes the pipeline to backdoor risks. Attackers can pretrain VLAs on poisoned data to implant backdoors that remain stealthy but can trigger harmful behavior during inference. However, existing defenses either lack mechanistic insight into multimodal backdoors or impose prohibitive computational costs via full-model retraining. To this end, we uncover a deep-layer attention grabbing mechanism: backdoors redirect late-stage attention and form compact embedding clusters near the clean manifold. Leveraging this insight, we introduce Bera, a test-time backdoor erasure framework that detects tokens with anomalous attention via latent-space localization, masks suspicious regions using deep-layer cues, and reconstructs a trigger-free image to break the trigger-unsafe-action mapping while restoring correct behavior. Unlike prior defenses, Bera requires neither retraining of VLAs nor any changes to the training pipeline. Extensive experiments across multiple embodied platforms and tasks show that Bera effectively maintains nominal performance, significantly reduces attack success rates, and consistently restores benign behavior from backdoored outputs, thereby offering a robust and practical defense mechanism for securing robotic systems.

</details>


### [17] [Estimation of Ground Reaction Forces from Kinematic Data during Locomotion](https://arxiv.org/abs/2602.03177)
*Gautami Golani,Dong Anh Khoa To,Ananda Sidarta,Arun-Kumar Kaliya-Perumal,Oliver Roberts,Lek Syn Lim,Jim Patton,Domenico Campolo*

Main category: cs.RO

TL;DR: 提出一种仅使用运动捕捉标记数据估计地面反作用力的方法，无需专用测力台，适用于临床广泛部署。


<details>
  <summary>Details</summary>
Motivation: 地面反作用力在步态分析中具有重要临床价值，但由于测力台系统的实际限制，在临床工作流程中未得到充分利用。

Method: 使用16个身体节段的运动学数据估计质心，计算地面反作用力，并通过最小化方法将其分解为各个分量。

Result: 实验结果表明仅基于运动学数据估计质心和地面反作用力的可行性，支持无测力台的步态分析。

Conclusion: 该方法能够识别步态支撑相并提供有临床意义的动力学测量，无需专用测力台系统，适合临床广泛部署。

Abstract: Ground reaction forces (GRFs) provide fundamental insight into human gait mechanics and are widely used to assess joint loading, limb symmetry, balance control, and motor function. Despite their clinical relevance, the use of GRF remains underutilised in clinical workflows due to the practical limitations of force plate systems. In this work, we present a force-plate-free approach for estimating GRFs using only marker-based motion capture data. This kinematics only method to estimate and decompose GRF makes it well suited for widespread clinical depolyment. By using kinematics from sixteen body segments, we estimate the centre of mass (CoM) and compute GRFs, which are subsequently decomposed into individual components through a minimization-based approach. Through this framework, we can identify gait stance phases and provide access to clinically meaningful kinetic measures without a dedicated force plate system. Experimental results demonstrate the viability of CoM and GRF estimation based solely on kinematic data, supporting force-plate-free gait analysis.

</details>


### [18] [Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives](https://arxiv.org/abs/2602.03188)
*Yu-Han Shu,Toshiaki Tsuji,Sho Sakaino*

Main category: cs.RO

TL;DR: 提出分层模仿学习框架，通过运动基元与比例合成结合，提高机器人学习的数据效率和适应性


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习需要大量高质量数据且难以处理复杂长时程任务，需要提高数据效率和适应性

Method: 采用两层架构：上层进行长期规划，下层学习个体运动基元，通过特定比例组合。提出三种变体：基于学习的比例模型、基于采样的比例模型、基于回放的比例模型

Result: 通过真实机器人拾放实验，成功生成了基元集中未包含的复杂运动。基于采样和回放的比例模型比标准分层模型更稳定、适应性更强

Conclusion: 比例运动集成方法对实际机器人学习有效，能够提高运动生成的稳定性和适应性

Abstract: Imitation learning (IL) enables robots to acquire human-like motion skills from demonstrations, but it still requires extensive high-quality data and retraining to handle complex or long-horizon tasks. To improve data efficiency and adaptability, this study proposes a hierarchical IL framework that integrates motion primitives with proportion-based motion synthesis. The proposed method employs a two-layer architecture, where the upper layer performs long-term planning, while a set of lower-layer models learn individual motion primitives, which are combined according to specific proportions. Three model variants are introduced to explore different trade-offs between learning flexibility, computational cost, and adaptability: a learning-based proportion model, a sampling-based proportion model, and a playback-based proportion model, which differ in how the proportions are determined and whether the upper layer is trainable. Through real-robot pick-and-place experiments, the proposed models successfully generated complex motions not included in the primitive set. The sampling-based and playback-based proportion models achieved more stable and adaptable motion generation than the standard hierarchical model, demonstrating the effectiveness of proportion-based motion integration for practical robot learning.

</details>


### [19] [HUSKY: Humanoid Skateboarding System via Physics-Aware Whole-Body Control](https://arxiv.org/abs/2602.03205)
*Jinrui Han,Dewei Wang,Chenyun Zhang,Xinzhe Liu,Ping Luo,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 该论文提出了HUSKY框架，用于解决人形机器人滑板控制这一高难度任务，该任务需要在欠驱动轮式平台上实现稳定的动态操控。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人全身控制框架主要依赖静态环境假设，难以处理高动态性和复杂交互的任务。滑板运动需要掌握混合接触动力学和在机械耦合、动态不稳定的滑板上进行鲁棒的平衡控制。

Method: 提出HUSKY学习框架，整合人形-滑板系统建模和物理感知的全身控制。首先建模板倾斜与转向角度的耦合关系，然后利用对抗运动先验学习类人推动动作，采用物理引导、朝向导向的倾斜转向策略，并通过轨迹引导机制确保推动与转向之间的平滑稳定过渡。

Result: 在Unitree G1人形机器人平台上的实验结果表明，该框架能够在真实场景中实现稳定且敏捷的滑板操控。

Conclusion: HUSKY框架成功解决了人形机器人滑板控制这一高难度动态任务，为处理复杂人-物交互和动态环境下的机器人控制提供了有效方案。

Abstract: While current humanoid whole-body control frameworks predominantly rely on the static environment assumptions, addressing tasks characterized by high dynamism and complex interactions presents a formidable challenge. In this paper, we address humanoid skateboarding, a highly challenging task requiring stable dynamic maneuvering on an underactuated wheeled platform. This integrated system is governed by non-holonomic constraints and tightly coupled human-object interactions. Successfully executing this task requires simultaneous mastery of hybrid contact dynamics and robust balance control on a mechanically coupled, dynamically unstable skateboard. To overcome the aforementioned challenges, we propose HUSKY, a learning-based framework that integrates humanoid-skateboard system modeling and physics-aware whole-body control. We first model the coupling relationship between board tilt and truck steering angles, enabling a principled analysis of system dynamics. Building upon this, HUSKY leverages Adversarial Motion Priors (AMP) to learn human-like pushing motions and employs a physics-guided, heading-oriented strategy for lean-to-steer behaviors. Moreover, a trajectory-guided mechanism ensures smooth and stable transitions between pushing and steering. Experimental results on the Unitree G1 humanoid platform demonstrate that our framework enables stable and agile maneuvering on skateboards in real-world scenarios. The project page is available on https://husky-humanoid.github.io/.

</details>


### [20] [Depth Completion in Unseen Field Robotics Environments Using Extremely Sparse Depth Measurements](https://arxiv.org/abs/2602.03209)
*Marco Job,Thomas Stastny,Eleni Kelasidi,Roland Siegwart,Michael Pantic*

Main category: cs.RO

TL;DR: 提出一种用于野外机器人的深度补全模型，利用合成数据和稀疏深度测量在嵌入式平台上实现实时密集度量深度预测


<details>
  <summary>Details</summary>
Motivation: 野外机器人在非结构化环境中需要鲁棒感知，但单目深度估计缺乏可靠尺度线索、纹理条件差且数据集稀缺，限制了低成本相机在野外机器人中的应用

Method: 提出深度补全模型，使用合成数据训练，利用深度传感器的极稀疏测量来预测未见野外环境的密集度量深度；开发面向野外机器人的合成数据集生成流程，利用运动恢复结构的纹理3D网格和逼真渲染进行新视角合成

Result: 在Nvidia Jetson AGX Orin上实现每帧53毫秒的端到端延迟，支持嵌入式平台实时部署；在多样化真实世界野外机器人场景中表现出竞争性性能

Conclusion: 该方法通过合成数据训练和稀疏深度测量，为野外机器人提供了实时、可靠的密集度量深度感知解决方案，克服了传统单目深度估计的局限性

Abstract: Autonomous field robots operating in unstructured environments require robust perception to ensure safe and reliable operations. Recent advances in monocular depth estimation have demonstrated the potential of low-cost cameras as depth sensors; however, their adoption in field robotics remains limited due to the absence of reliable scale cues, ambiguous or low-texture conditions, and the scarcity of large-scale datasets. To address these challenges, we propose a depth completion model that trains on synthetic data and uses extremely sparse measurements from depth sensors to predict dense metric depth in unseen field robotics environments. A synthetic dataset generation pipeline tailored to field robotics enables the creation of multiple realistic datasets for training purposes. This dataset generation approach utilizes textured 3D meshes from Structure from Motion and photorealistic rendering with novel viewpoint synthesis to simulate diverse field robotics scenarios. Our approach achieves an end-to-end latency of 53 ms per frame on a Nvidia Jetson AGX Orin, enabling real-time deployment on embedded platforms. Extensive evaluation demonstrates competitive performance across diverse real-world field robotics scenarios.

</details>


### [21] [Omnidirectional Solid-State mmWave Radar Perception for UAV Power Line Collision Avoidance](https://arxiv.org/abs/2602.03229)
*Nicolaj Haarhøj Malle,Emad Ebeid*

Main category: cs.RO

TL;DR: 基于毫米波雷达的无人机全方位感知系统，用于电力线检测与避障，检测范围达10米，可识别直径1.2毫米的细线


<details>
  <summary>Details</summary>
Motivation: 电力线检测对无人机（无论是人工操控还是自主系统）都是重大挑战，增加了意外碰撞风险，需要可靠的感知解决方案

Method: 集成多个紧凑型固态毫米波雷达模块，合成全方位视场，开发针对电力线环境的专用检测与避障算法

Result: 现场实验显示：检测范围达10米，飞行速度超过10米/秒时仍能成功避障，可检测直径1.2毫米的细线

Conclusion: 该方法适合作为自主和手动无人机飞行的额外安全层，提供可靠的电力线检测与避障能力

Abstract: Detecting and estimating distances to power lines is a challenge for both human UAV pilots and autonomous systems, which increases the risk of unintended collisions. We present a mmWave radar-based perception system that provides spherical sensing coverage around a small UAV for robust power line detection and avoidance. The system integrates multiple compact solid-state mmWave radar modules to synthesize an omnidirectional field of view while remaining lightweight. We characterize the sensing behavior of this omnidirectional radar arrangement in power line environments and develop a robust detection-and-avoidance algorithm tailored to that behavior. Field experiments on real power lines demonstrate reliable detection at ranges up to 10 m, successful avoidance maneuvers at flight speeds upwards of 10 m/s, and detection of wires as thin as 1.2 mm in diameter. These results indicate the approach's suitability as an additional safety layer for both autonomous and manual UAV flight.

</details>


### [22] [A thin and soft optical tactile sensor for highly sensitive object perception](https://arxiv.org/abs/2602.03248)
*Yanchen Shen,Kohei Tsuji,Haruto Koizumi,Jiseon Hong,Tomoaki Niiyama,Hiroyuki Kuwabara,Hayato Ishida,Jun Hiramitsu,Mitsuhito Mase,Satoshi Sunada*

Main category: cs.RO

TL;DR: 提出了一种基于散斑图案的薄型、紧凑、柔软光学触觉传感器，无需复杂光学组件，通过机器学习实现精确力测量和纹理识别。


<details>
  <summary>Details</summary>
Motivation: 现有光学触觉传感器（特别是基于视觉的）依赖复杂的光学组件（镜头和相机），导致体积大、刚性、对校准敏感。需要开发更紧凑、柔软、无需校准的触觉传感器。

Method: 采用软硅胶材料中的散斑图案变化来检测变形，通过机器学习分析散斑图案变化，实现力测量和纹理识别。传感器采用无校准配置，结构简单。

Result: 力测量均方根误差为40 mN，对包括麻将牌在内的9类纹理表面分类准确率达到93.33%。传感器具有紧凑、易制造、机械柔顺的特点。

Conclusion: 基于散斑的方法为光学传感与柔性形状自适应架构提供了桥梁，展示了作为软机器人和可穿戴触觉接口新型触觉传感范式的潜力。

Abstract: Tactile sensing is crucial in robotics and wearable devices for safe perception and interaction with the environment. Optical tactile sensors have emerged as promising solutions, as they are immune to electromagnetic interference and have high spatial resolution. However, existing optical approaches, particularly vision-based tactile sensors, rely on complex optical assemblies that involve lenses and cameras, resulting in bulky, rigid, and alignment-sensitive designs. In this study, we present a thin, compact, and soft optical tactile sensor featuring an alignment-free configuration. The soft optical sensor operates by capturing deformation-induced changes in speckle patterns generated within a soft silicone material, thereby enabling precise force measurements and texture recognition via machine learning. The experimental results show a root-mean-square error of 40 mN in the force measurement and a classification accuracy of 93.33% over nine classes of textured surfaces, including Mahjong tiles. The proposed speckle-based approach provides a compact, easily fabricated, and mechanically compliant platform that bridges optical sensing with flexible shape-adaptive architectures, thereby demonstrating its potential as a novel tactile-sensing paradigm for soft robotics and wearable haptic interfaces.

</details>


### [23] [Collision Detection with Analytical Derivatives of Contact Kinematics](https://arxiv.org/abs/2602.03250)
*Anup Teejo Mathew,Anees Peringal,Daniele Caradonna,Frederic Boyer,Federico Renda*

Main category: cs.RO

TL;DR: iDCOL：一种基于严格凸隐式曲面的可微碰撞检测与接触运动学框架，通过几何正则化解决零曲率或未定义曲率形状的接触映射非光滑问题


<details>
  <summary>Details</summary>
Motivation: 机器人学中基于梯度的方法需要可微的接触运动学，但当形状具有零曲率或未定义曲率时，从机器人状态到接触距离、位置和法向的映射会变得非光滑，这限制了梯度方法的应用

Method: 通过选择性正则化将几何形状转换为严格凸隐式表示，基于几何缩放凸优化公式推导固定大小的非线性系统，应用隐函数定理获得接触运动学量的解析导数，开发快速牛顿求解器

Result: 开发了iDCOL框架及其开源C++实现，通过大量碰撞仿真和基准测试验证了方法的鲁棒性，在梯度运动学路径规划和可微接触物理中展示了应用价值

Conclusion: iDCOL通过几何正则化解决了接触运动学的非光滑问题，为梯度优化方法提供了可靠的可微碰撞检测框架，在机器人运动规划和多体物理仿真中具有重要应用前景

Abstract: Differentiable contact kinematics are essential for gradient-based methods in robotics, yet the mapping from robot state to contact distance, location, and normal becomes non-smooth in degenerate configurations of shapes with zero or undefined curvature. We address this inherent limitation by selectively regularizing such geometries into strictly convex implicit representations, restoring uniqueness and smoothness of the contact map. Leveraging this geometric regularization, we develop iDCOL, an implicit differentiable collision detection and contact kinematics framework. iDCOL represents colliding bodies using strictly convex implicit surfaces and computes collision detection and contact kinematics by solving a fixed-size nonlinear system derived from a geometric scaling-based convex optimization formulation. By applying the Implicit Function Theorem to the resulting system residual, we derive analytical derivatives of the contact kinematic quantities. We develop a fast Newton-based solver for iDCOL and provide an open-source C++ implementation of the framework. The robustness of the approach is evaluated through extensive collision simulations and benchmarking, and applicability is demonstrated in gradient-based kinematic path planning and differentiable contact physics, including multi-body rigid collisions and a soft-robot interaction example.

</details>


### [24] [RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization](https://arxiv.org/abs/2602.03310)
*Songming Liu,Bangguo Li,Kai Ma,Lingxuan Wu,Hengkai Tan,Xiao Ouyang,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: RDT2是一个基于70亿参数视觉语言模型的机器人基础模型，通过创新的三阶段训练方法，实现了在未见过的物体、场景、指令和机器人平台上的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型面临数据稀缺、架构效率低下以及无法跨不同硬件平台泛化的问题，需要开发能够零样本部署到新机器人平台并处理开放词汇任务的通用机器人模型。

Method: 1) 收集了超过10,000小时多样化机器人演示数据，使用增强的、与具体实现无关的通用操作接口；2) 采用创新的三阶段训练方法：通过残差向量量化对齐离散语言知识与连续控制，结合流匹配和蒸馏实现实时推理。

Result: RDT2成为首批能够同时零样本泛化到未见过的物体、场景、指令和机器人平台的模型之一，在灵巧操作、长时程和动态下游任务（如打乒乓球）中超越了现有最先进基线。

Conclusion: RDT2通过大规模数据集和创新的训练方法，成功解决了VLA模型的数据稀缺和泛化问题，为通用机器人系统的发展提供了重要进展，展示了在多样化任务和平台上的强大零样本泛化能力。

Abstract: Vision-Language-Action (VLA) models hold promise for generalist robotics but currently struggle with data scarcity, architectural inefficiencies, and the inability to generalize across different hardware platforms. We introduce RDT2, a robotic foundation model built upon a 7B parameter VLM designed to enable zero-shot deployment on novel embodiments for open-vocabulary tasks. To achieve this, we collected one of the largest open-source robotic datasets--over 10,000 hours of demonstrations in diverse families--using an enhanced, embodiment-agnostic Universal Manipulation Interface (UMI). Our approach employs a novel three-stage training recipe that aligns discrete linguistic knowledge with continuous control via Residual Vector Quantization (RVQ), flow-matching, and distillation for real-time inference. Consequently, RDT2 becomes one of the first models that simultaneously zero-shot generalizes to unseen objects, scenes, instructions, and even robotic platforms. Besides, it outperforms state-of-the-art baselines in dexterous, long-horizon, and dynamic downstream tasks like playing table tennis. See https://rdt-robotics.github.io/rdt2/ for more information.

</details>


### [25] [Manipulation via Force Distribution at Contact](https://arxiv.org/abs/2602.03350)
*Haegu Lee,Yitaek Kim,Casper Hewson Rask,Christoffer Sloth*

Main category: cs.RO

TL;DR: 该研究提出了一种力分布线接触模型，用于接触丰富的操作任务，相比传统点接触模型能生成更高效、更鲁棒的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有接触丰富的操作任务大多依赖点接触模型，虽然计算效率高但存在固有局限性，无法捕捉人类操作中观察到的关键摩擦动力学和扭矩生成，难以实现类人的接触丰富操作。

Method: 提出力分布线接触模型，构建双层优化框架：下层解决接触力计算的优化问题，上层应用iLQR进行轨迹优化。

Result: 通过盒子旋转任务验证，FDLC模型能够沿接触线生成非均匀力分布的轨迹，同时需要更低的控制努力和更少的机器人运动。

Conclusion: 力分布线接触模型相比传统点接触模型在接触丰富的操作任务中具有明显优势，能够生成更高效、更鲁棒的轨迹。

Abstract: Efficient and robust trajectories play a crucial role in contact-rich manipulation, which demands accurate mod- eling of object-robot interactions. Many existing approaches rely on point contact models due to their computational effi- ciency. Simple contact models are computationally efficient but inherently limited for achieving human-like, contact-rich ma- nipulation, as they fail to capture key frictional dynamics and torque generation observed in human manipulation. This study introduces a Force-Distributed Line Contact (FDLC) model in contact-rich manipulation and compares it against conventional point contact models. A bi-level optimization framework is constructed, in which the lower-level solves an optimization problem for contact force computation, and the upper-level optimization applies iLQR for trajectory optimization. Through this framework, the limitations of point contact are demon- strated, and the benefits of the FDLC in generating efficient and robust trajectories are established. The effectiveness of the proposed approach is validated by a box rotating task, demonstrating that FDLC enables trajectories generated via non-uniform force distributions along the contact line, while requiring lower control effort and less motion of the robot.

</details>


### [26] [Learning-based Adaptive Control of Quadruped Robots for Active Stabilization on Moving Platforms](https://arxiv.org/abs/2602.03367)
*Minsung Yoon,Heechan Shin,Jeil Jeong,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: LAS-MP系统通过学习自适应平衡策略和状态估计器，解决四足机器人在六自由度移动平台上的平衡挑战，在多种平台运动下表现出优于基线的平衡性能。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在地铁、公交车、飞机、游艇等六自由度移动平台上工作时，面临平台独立运动和由此产生的多样化惯性力带来的平衡挑战。

Method: 提出LAS-MP系统，包含自适应平衡策略和系统状态估计器。平衡策略根据平台运动调整机器人姿态，估计器基于本体感知传感器数据推断机器人和平台状态。为系统训练设计了平台轨迹生成和调度方法。

Result: 评估显示在多个指标上优于三个基线方法。通过消融研究和估计器评估验证了各组件有效性。

Conclusion: LAS-MP系统能有效解决四足机器人在移动平台上的平衡问题，为机器人在动态环境中的稳定操作提供了解决方案。

Abstract: A quadruped robot faces balancing challenges on a six-degrees-of-freedom moving platform, like subways, buses, airplanes, and yachts, due to independent platform motions and resultant diverse inertia forces on the robot. To alleviate these challenges, we present the Learning-based Active Stabilization on Moving Platforms (\textit{LAS-MP}), featuring a self-balancing policy and system state estimators. The policy adaptively adjusts the robot's posture in response to the platform's motion. The estimators infer robot and platform states based on proprioceptive sensor data. For a systematic training scheme across various platform motions, we introduce platform trajectory generation and scheduling methods. Our evaluation demonstrates superior balancing performance across multiple metrics compared to three baselines. Furthermore, we conduct a detailed analysis of the \textit{LAS-MP}, including ablation studies and evaluation of the estimators, to validate the effectiveness of each component.

</details>


### [27] [PlanTRansformer: Unified Prediction and Planning with Goal-conditioned Transformer](https://arxiv.org/abs/2602.03376)
*Constantin Selzer,Fabina B. Flohr*

Main category: cs.RO

TL;DR: PlanTRansformer (PTR)是一个统一的Transformer框架，将目标条件预测、动态可行性、交互感知和车道级拓扑推理集成在一起，解决了自动驾驶中轨迹预测和规划之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中轨迹预测和规划是分离的组件：预测模型在未知意图下预测周围智能体运动，产生多模态分布；而规划假设已知自车目标并生成确定性轨迹。这种不匹配造成关键瓶颈：预测缺乏对智能体意图的监督，而规划需要这些信息。现有预测模型尽管基准测试表现良好，但往往与规划约束（如避碰和动态可行性）脱节。

Method: 提出Plan Transformer (PTR)，一个统一的高斯混合Transformer框架，集成了目标条件预测、动态可行性、交互感知和车道级拓扑推理。采用师生训练策略，在训练过程中逐步掩码周围智能体命令，以与推理条件（智能体意图不可用）对齐。该架构无关设计可应用于各种基于Transformer的预测模型。

Result: PTR相比基线Motion Transformer (MTR)在边际/联合mAP上分别提升4.3%/3.5%，相比GameFormer在5秒规划视野上减少15.5%的规划误差。

Conclusion: PTR通过统一框架有效连接了自动驾驶中的轨迹预测和规划，解决了两者之间的不匹配问题，在预测准确性和规划性能方面均取得显著提升。

Abstract: Trajectory prediction and planning are fundamental yet disconnected components in autonomous driving. Prediction models forecast surrounding agent motion under unknown intentions, producing multimodal distributions, while planning assumes known ego objectives and generates deterministic trajectories. This mismatch creates a critical bottleneck: prediction lacks supervision for agent intentions, while planning requires this information. Existing prediction models, despite strong benchmarking performance, often remain disconnected from planning constraints such as collision avoidance and dynamic feasibility. We introduce Plan TRansformer (PTR), a unified Gaussian Mixture Transformer framework integrating goal-conditioned prediction, dynamic feasibility, interaction awareness, and lane-level topology reasoning. A teacher-student training strategy progressively masks surrounding agent commands during training to align with inference conditions where agent intentions are unavailable. PTR achieves 4.3%/3.5% improvement in marginal/joint mAP compared to the baseline Motion Transformer (MTR) and 15.5% planning error reduction at 5s horizon compared to GameFormer. The architecture-agnostic design enables application to diverse Transformer-based prediction models. Project Website: https://github.com/SelzerConst/PlanTRansformer

</details>


### [28] [Enhancing Navigation Efficiency of Quadruped Robots via Leveraging Personal Transportation Platforms](https://arxiv.org/abs/2602.03397)
*Minsung Yoon,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出RL-ATR方法让四足机器人骑乘个人交通工具（如Segway）以提高长距离导航效率


<details>
  <summary>Details</summary>
Motivation: 四足机器人依赖腿部运动，长距离导航效率有限，需要扩展其运动模式以提高操作范围和效率

Method: 基于强化学习的主动交通工具骑乘方法，包含骑乘策略和两个状态估计器，策略根据交通工具特定控制动力学设计操纵策略，估计器通过推断不可观测状态解决非惯性系中的传感器模糊问题

Result: 仿真验证显示该方法在不同交通工具-机器人模型上具有熟练的命令跟踪能力，相比腿部运动减少了能量消耗，消融研究量化了各组件贡献

Conclusion: 骑乘能力可以扩展四足机器人的运动模式，潜在地扩大其操作范围和效率

Abstract: Quadruped robots face limitations in long-range navigation efficiency due to their reliance on legs. To ameliorate the limitations, we introduce a Reinforcement Learning-based Active Transporter Riding method (\textit{RL-ATR}), inspired by humans' utilization of personal transporters, including Segways. The \textit{RL-ATR} features a transporter riding policy and two state estimators. The policy devises adequate maneuvering strategies according to transporter-specific control dynamics, while the estimators resolve sensor ambiguities in non-inertial frames by inferring unobservable robot and transporter states. Comprehensive evaluations in simulation validate proficient command tracking abilities across various transporter-robot models and reduced energy consumption compared to legged locomotion. Moreover, we conduct ablation studies to quantify individual component contributions within the \textit{RL-ATR}. This riding ability could broaden the locomotion modalities of quadruped robots, potentially expanding the operational range and efficiency.

</details>


### [29] [Deep-Learning-Based Control of a Decoupled Two-Segment Continuum Robot for Endoscopic Submucosal Dissection](https://arxiv.org/abs/2602.03406)
*Yuancheng Shao,Yao Zhang,Jia Gu,Zixi Chen,Di Wu,Yuqiao Chen,Bo Lu,Wenjie Liu,Cesare Stefanini,Peng Qi*

Main category: cs.RO

TL;DR: DESectBot：一种新型双段连续体机器人，采用GRU深度学习控制器，在ESD手术中实现6自由度尖端灵活性，显著提高轨迹跟踪精度和手术操作成功率。


<details>
  <summary>Details</summary>
Motivation: 传统内镜黏膜下剥离术（ESD）技术要求高，现有单段机器人工具灵活性有限，需要开发更先进的解决方案来提高手术精度和操作便利性。

Method: 开发了DESectBot双段连续体机器人，具有解耦结构和集成手术钳；提出了基于门控循环单元（GRU）的深度学习控制器，用于同时控制尖端位置和方向，有效处理连续体段间的非线性耦合。

Result: GRU控制器在轨迹跟踪任务中表现最佳（位置/方向RMSE：1.11mm/4.62°和0.81mm/2.59°）；在固定位置方向控制中平均RMSE为0.14mm和0.72°；在peg转移任务中成功率100%（120/120），平均转移时间11.8秒；离体ESD演示证实机器人具有足够刚度分割厚胃黏膜。

Conclusion: GRU基控制显著提高了ESD手术训练场景中的精度、可靠性和可用性，DESectBot为大型病变提供了足够的工作空间和操作能力。

Abstract: Manual endoscopic submucosal dissection (ESD) is technically demanding, and existing single-segment robotic tools offer limited dexterity. These limitations motivate the development of more advanced solutions. To address this, DESectBot, a novel dual segment continuum robot with a decoupled structure and integrated surgical forceps, enabling 6 degrees of freedom (DoFs) tip dexterity for improved lesion targeting in ESD, was developed in this work. Deep learning controllers based on gated recurrent units (GRUs) for simultaneous tip position and orientation control, effectively handling the nonlinear coupling between continuum segments, were proposed. The GRU controller was benchmarked against Jacobian based inverse kinematics, model predictive control (MPC), a feedforward neural network (FNN), and a long short-term memory (LSTM) network. In nested-rectangle and Lissajous trajectory tracking tasks, the GRU achieved the lowest position/orientation RMSEs: 1.11 mm/ 4.62° and 0.81 mm/ 2.59°, respectively. For orientation control at a fixed position (four target poses), the GRU attained a mean RMSE of 0.14 mm and 0.72°, outperforming all alternatives. In a peg transfer task, the GRU achieved a 100% success rate (120 success/120 attempts) with an average transfer time of 11.8s, the STD significantly outperforms novice-controlled systems. Additionally, an ex vivo ESD demonstration grasping, elevating, and resecting tissue as the scalpel completed the cut confirmed that DESectBot provides sufficient stiffness to divide thick gastric mucosa and an operative workspace adequate for large lesions.These results confirm that GRU-based control significantly enhances precision, reliability, and usability in ESD surgical training scenarios.

</details>


### [30] [Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators](https://arxiv.org/abs/2602.03418)
*Minsung Yoon,Mincheul Kang,Daehyung Park,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出基于学习的初始轨迹生成方法，通过示例引导的强化学习快速生成高质量初始轨迹，提升轨迹优化的性能


<details>
  <summary>Details</summary>
Motivation: 轨迹优化的性能很大程度上取决于初始轨迹的质量，但高质量初始轨迹的选择非常困难且耗时，因为解轨迹空间极大且缺乏任务约束的先验知识

Method: 采用示例引导的强化学习方法生成高质量初始轨迹，并提出零空间投影模仿奖励来考虑零空间约束，高效学习专家演示中的运动学可行运动

Result: 仿真统计评估显示，当使用本方法输出时，轨迹优化在最优性、效率和适用性方面均有改进，优于三个基线方法。七自由度机械臂的真实实验也验证了性能改进和可行性

Conclusion: 提出的学习型初始轨迹生成方法能够快速生成高质量初始轨迹，显著提升轨迹优化的性能，为冗余机械臂的轨迹规划提供了有效解决方案

Abstract: Trajectory optimization (TO) is an efficient tool to generate a redundant manipulator's joint trajectory following a 6-dimensional Cartesian path. The optimization performance largely depends on the quality of initial trajectories. However, the selection of a high-quality initial trajectory is non-trivial and requires a considerable time budget due to the extremely large space of the solution trajectories and the lack of prior knowledge about task constraints in configuration space. To alleviate the issue, we present a learning-based initial trajectory generation method that generates high-quality initial trajectories in a short time budget by adopting example-guided reinforcement learning. In addition, we suggest a null-space projected imitation reward to consider null-space constraints by efficiently learning kinematically feasible motion captured in expert demonstrations. Our statistical evaluation in simulation shows the improved optimality, efficiency, and applicability of TO when we plug in our method's output, compared with three other baselines. We also show the performance improvement and feasibility via real-world experiments with a seven-degree-of-freedom manipulator.

</details>


### [31] [Model-based Optimal Control for Rigid-Soft Underactuated Systems](https://arxiv.org/abs/2602.03435)
*Daniele Caradonna,Nikhil Nair,Anup Teejo Mathew,Daniel Feliu Talegón,Imran Afgan,Egidio Falotico,Cosimo Della Santina,Federico Renda*

Main category: cs.RO

TL;DR: 本文研究了三种最优控制策略（直接配点法、微分动态规划、非线性模型预测控制）用于欠驱动软体机器人系统的动态摆动任务，解决了高维模型计算成本和数值微分不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 连续体软体机器人本质上是欠驱动的，并受到内在输入约束，使得动态控制特别具有挑战性。现有方法大多关注准静态行为，而动态任务（如摆动）需要准确利用连续体动力学。基于模型的最优控制提供了系统解决方案，但其在刚-软机器人中的应用常受高维模型计算成本和数值微分不准确性的限制。

Method: 基于几何可变应变模型的最新进展（支持解析导数），本研究调查了三种用于欠驱动软体系统的最优控制策略：直接配点法、微分动态规划和非线性模型预测控制。为解决刚性的连续体动力学和受限驱动问题，采用了隐式积分方案和热启动策略以提高数值鲁棒性和计算效率。

Result: 在三个刚-软和高阶软体基准系统（软体小车-杆、软体双摆、软体Furuta摆）的仿真中评估了这些方法，突出了它们的性能和计算权衡。

Conclusion: 通过利用支持解析导数的几何可变应变模型，本研究展示了三种最优控制策略在欠驱动软体机器人动态摆动任务中的可行性，并通过隐式积分和热启动策略解决了计算效率和数值鲁棒性问题。

Abstract: Continuum soft robots are inherently underactuated and subject to intrinsic input constraints, making dynamic control particularly challenging, especially in hybrid rigid-soft robots. While most existing methods focus on quasi-static behaviors, dynamic tasks such as swing-up require accurate exploitation of continuum dynamics. This has led to studies on simple low-order template systems that often fail to capture the complexity of real continuum deformations. Model-based optimal control offers a systematic solution; however, its application to rigid-soft robots is often limited by the computational cost and inaccuracy of numerical differentiation for high-dimensional models. Building on recent advances in the Geometric Variable Strain model that enable analytical derivatives, this work investigates three optimal control strategies for underactuated soft systems-Direct Collocation, Differential Dynamic Programming, and Nonlinear Model Predictive Control-to perform dynamic swing-up tasks. To address stiff continuum dynamics and constrained actuation, implicit integration schemes and warm-start strategies are employed to improve numerical robustness and computational efficiency. The methods are evaluated in simulation on three Rigid-Soft and high-order soft benchmark systems-the Soft Cart-Pole, the Soft Pendubot, and the Soft Furuta Pendulum- highlighting their performance and computational trade-offs.

</details>


### [32] [HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic](https://arxiv.org/abs/2602.03447)
*Yu-Hsiang Chen,Wei-Jer Chang,Christian Kotulla,Thomas Keutgens,Steffen Runde,Tobias Moers,Christoph Klas,Wei Zhan,Masayoshi Tomizuka,Yi-Ting Chen*

Main category: cs.RO

TL;DR: HetroD是一个针对异构交通环境的自动驾驶数据集和基准测试，专注于弱势道路使用者（行人、自行车、摩托车）与车辆混合的复杂交通场景。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据集主要关注结构化、有车道纪律的交通，而现实世界中存在大量弱势道路使用者参与的异构交通场景，这些场景中的复杂行为（如钩形转弯、车道分割、非正式路权协商）对自动驾驶系统构成重大挑战，但目前缺乏相应的数据集支持。

Method: 通过无人机采集大规模数据集，提供厘米级精确标注、高清地图和交通信号状态；开发模块化工具包用于提取每个智能体的场景，支持下游任务开发；数据集包含超过65.4k个高保真智能体轨迹，其中70%来自弱势道路使用者。

Result: 评估结果显示，当前最先进的预测和规划模型在HetroD数据集上表现不佳：无法预测弱势道路使用者的横向移动，不能处理非结构化机动动作，在密集和多智能体场景中性能有限，凸显了异构交通场景需要更鲁棒的方法。

Conclusion: HetroD填补了异构交通环境数据集的空白，为弱势道路使用者行为建模提供了支持，并为预测、规划和仿真任务提供了标准化基准测试，有助于推动自动驾驶系统在复杂现实交通场景中的发展。

Abstract: We present HetroD, a dataset and benchmark for developing autonomous driving systems in heterogeneous environments. HetroD targets the critical challenge of navi- gating real-world heterogeneous traffic dominated by vulner- able road users (VRUs), including pedestrians, cyclists, and motorcyclists that interact with vehicles. These mixed agent types exhibit complex behaviors such as hook turns, lane splitting, and informal right-of-way negotiation. Such behaviors pose significant challenges for autonomous vehicles but remain underrepresented in existing datasets focused on structured, lane-disciplined traffic. To bridge the gap, we collect a large- scale drone-based dataset to provide a holistic observation of traffic scenes with centimeter-accurate annotations, HD maps, and traffic signal states. We further develop a modular toolkit for extracting per-agent scenarios to support downstream task development. In total, the dataset comprises over 65.4k high- fidelity agent trajectories, 70% of which are from VRUs. HetroD supports modeling of VRU behaviors in dense, het- erogeneous traffic and provides standardized benchmarks for forecasting, planning, and simulation tasks. Evaluation results reveal that state-of-the-art prediction and planning models struggle with the challenges presented by our dataset: they fail to predict lateral VRU movements, cannot handle unstructured maneuvers, and exhibit limited performance in dense and multi-agent scenarios, highlighting the need for more robust approaches to heterogeneous traffic. See our project page for more examples: https://hetroddata.github.io/HetroD/

</details>


### [33] [CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains](https://arxiv.org/abs/2602.03511)
*Qixin Zeng,Hongyin Zhang,Shangke Lyu,Junxi Jin,Donglin Wang,Chao Huang*

Main category: cs.RO

TL;DR: 提出CMR框架，通过收缩映射将高维扰动观测映射到潜在空间，增强人形机器人在非结构化地形上的抗干扰鲁棒性


<details>
  <summary>Details</summary>
Motivation: 人形机器人在非结构化地形上的鲁棒抗干扰控制是一个长期挑战，感知信息（如高度图）虽然增强地形感知，但传感器噪声和仿真到现实的差距会导致策略在实际中不稳定

Method: 提出收缩映射鲁棒性（CMR）框架，将高维扰动观测映射到潜在空间，结合对比表示学习和Lipschitz正则化，保持任务相关几何特性同时显式控制敏感性，可作为辅助损失项集成到深度强化学习流程中

Result: 理论分析表明在观测噪声下，当诱导潜在动态具有收缩性时，可以限制回报差距；实验显示CMR在噪声增加情况下显著优于其他运动算法

Conclusion: CMR框架通过收缩映射有效增强人形机器人在非结构化地形上的抗干扰能力，特别是在高噪声环境下表现优异

Abstract: Robust disturbance rejection remains a longstanding challenge in humanoid locomotion, particularly on unstructured terrains where sensing is unreliable and model mismatch is pronounced. While perception information, such as height map, enhances terrain awareness, sensor noise and sim-to-real gaps can destabilize policies in practice. In this work, we provide theoretical analysis that bounds the return gap under observation noise, when the induced latent dynamics are contractive. Furthermore, we present Contractive Mapping for Robustness (CMR) framework that maps high-dimensional, disturbance-prone observations into a latent space, where local perturbations are attenuated over time. Specifically, this approach couples contrastive representation learning with Lipschitz regularization to preserve task-relevant geometry while explicitly controlling sensitivity. Notably, the formulation can be incorporated into modern deep reinforcement learning pipelines as an auxiliary loss term with minimal additional technical effort required. Further, our extensive humanoid experiments show that CMR potently outperforms other locomotion algorithms under increased noise.

</details>


### [34] [Investigating the Influence of Spatial Ability in Augmented Reality-assisted Robot Programming](https://arxiv.org/abs/2602.03544)
*Nicolas Leins,Jana Gonnermann-Müller,Malte Teichmann,Sebastian Pokutta*

Main category: cs.RO

TL;DR: AR辅助机器人编程学习的研究发现，AR本身并未显著改善学习体验，但能补偿空间能力差异的影响，为低空间能力学习者提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着学习日益个性化，考虑学习者个体特征变得更重要。AR在增强学习方面有潜力，但其机制和效果尚未完全理解，特别是在机器人编程学习中AR如何影响不同空间能力学习者的体验。

Method: 采用组间实验设计（N=71），比较传统机器人编程与头戴式AR辅助方法。使用心理旋转测试评估空间能力，通过系统可用性量表（SUS）和认知负荷测量学习体验。

Result: AR支持相比传统方法并未显著改善学习体验。但在控制组中，空间能力与SUS分数显著正相关，与外部认知负荷负相关；而在AR条件下这些关系消失，表明AR补偿了低空间能力学习者的劣势。

Conclusion: AR具有补偿功能，能减少学习者特征的影响。未来研究应进一步探索AR的补偿作用，以指导设计满足不同学习者需求的个性化学习环境，降低认知差异带来的障碍。

Abstract: Augmented Reality (AR) offers promising opportunities to enhance learning, but its mechanisms and effects are not yet fully understood. As learning becomes increasingly personalized, considering individual learner characteristics becomes more important. This study investigates the moderating effect of spatial ability on learning experience with AR in the context of robot programming. A between-subjects experiment ($N=71$) compared conventional robot programming to an AR-assisted approach using a head-mounted display. Participants' spatial ability was assessed using the Mental Rotation Test. The learning experience was measured through the System Usability Scale (SUS) and cognitive load. The results indicate that AR support does not significantly improve the learning experience compared to the conventional approach. However, AR appears to have a compensatory effect on the influence of spatial ability. In the control group, spatial ability was significantly positively associated with SUS scores and negatively associated with extraneous cognitive load, indicating that higher spatial ability predicts a better learning experience. In the AR condition, these relationships were not observable, suggesting that AR mitigated the disadvantage typically experienced by learners with lower spatial abilities. These findings suggest that AR can serve a compensatory function by reducing the influence of learner characteristics. Future research should further explore this compensatory role of AR to guide the design of personalized learning environments that address diverse learner needs and reduce barriers for learners with varying cognitive profiles.

</details>


### [35] [AffordanceGrasp-R1:Leveraging Reasoning-Based Affordance Segmentation with Reinforcement Learning for Robotic Grasping](https://arxiv.org/abs/2602.03547)
*Dingyi Zhou,Mu He,Zhuowei Fang,Xiangtong Yao,Yinlong Liu,Alois Knoll,Hu Cao*

Main category: cs.RO

TL;DR: AffordanceGrasp-R1是一个结合思维链冷启动策略和强化学习的推理驱动抓取框架，通过全局场景点云生成抓取候选并基于指令条件进行过滤，在基准数据集和真实机器人实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前机器人抓取方法在复杂语言条件操作场景中缺乏足够的推理能力和空间基础，需要更智能的感知和决策框架来提升抓取性能。

Method: 1. 结合思维链冷启动策略和强化学习增强推理和空间基础；2. 重新设计抓取流程，从全局场景点云生成抓取候选；3. 使用指令条件affordance掩码进行候选过滤。

Result: 在基准数据集上持续超越最先进方法，真实机器人抓取评估进一步验证了其在复杂语言条件操作场景下的鲁棒性和泛化能力。

Conclusion: AffordanceGrasp-R1通过推理驱动的affordance分割框架，显著提升了机器人抓取在复杂语言条件场景中的性能，为智能机器人操作提供了有效解决方案。

Abstract: We introduce AffordanceGrasp-R1, a reasoning-driven affordance segmentation framework for robotic grasping that combines a chain-of-thought (CoT) cold-start strategy with reinforcement learning to enhance deduction and spatial grounding. In addition, we redesign the grasping pipeline to be more context-aware by generating grasp candidates from the global scene point cloud and subsequently filtering them using instruction-conditioned affordance masks. Extensive experiments demonstrate that AffordanceGrasp-R1 consistently outperforms state-of-the-art (SOTA) methods on benchmark datasets, and real-world robotic grasping evaluations further validate its robustness and generalization under complex language-conditioned manipulation scenarios.

</details>


### [36] [Multi-Player, Multi-Strategy Quantum Game Model for Interaction-Aware Decision-Making in Autonomous Driving](https://arxiv.org/abs/2602.03571)
*Karim Essalmi,Fernando Garrido,Fawzi Nashashibi*

Main category: cs.RO

TL;DR: 提出量子博弈决策模型（QGDM），将量子力学原理（叠加、纠缠、干涉）与经典博弈论结合，用于自动驾驶决策，在复杂交互场景中显著提升成功率和降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶决策方法在处理交互时存在局限性：过度简化自车与周围车辆的交互，忽视车辆间的相互影响；经典博弈论假设理性玩家，而人类行为常具有不确定性和非理性。需要更有效的多玩家多策略决策框架。

Method: 提出量子博弈决策模型（QGDM），融合经典博弈论与量子力学原理（叠加态、纠缠、干涉），处理多玩家多策略决策问题。该模型可在标准计算机上实时运行，无需量子硬件。

Result: 在环岛、并线、高速公路等多种场景的仿真测试中，QGDM相比多种基线方法显著提高了成功率和降低了碰撞率，特别是在高交互场景中表现优异。

Conclusion: QGDM是首个将量子博弈论应用于自动驾驶决策的研究之一，有效解决了交互感知问题，在复杂交通场景中展现出优于经典方法的性能，为自动驾驶决策提供了新思路。

Abstract: Although significant progress has been made in decision-making for automated driving, challenges remain for deployment in the real world. One challenge lies in addressing interaction-awareness. Most existing approaches oversimplify interactions between the ego vehicle and surrounding agents, and often neglect interactions among the agents themselves. A common solution is to model these interactions using classical game theory. However, its formulation assumes rational players, whereas human behavior is frequently uncertain or irrational. To address these challenges, we propose the Quantum Game Decision-Making (QGDM) model, a novel framework that combines classical game theory with quantum mechanics principles (such as superposition, entanglement, and interference) to tackle multi-player, multi-strategy decision-making problems. To the best of our knowledge, this is one of the first studies to apply quantum game theory to decision-making for automated driving. QGDM runs in real time on a standard computer, without requiring quantum hardware. We evaluate QGDM in simulation across various scenarios, including roundabouts, merging, and highways, and compare its performance with multiple baseline methods. Results show that QGDM significantly improves success rates and reduces collision rates compared to classical approaches, particularly in scenarios with high interaction.

</details>


### [37] [Human-in-the-Loop Failure Recovery with Adaptive Task Allocation](https://arxiv.org/abs/2602.03603)
*Lorena Maria Genua,Nikita Boguslavskii,Zhi Li*

Main category: cs.RO

TL;DR: 提出ARFA方法，根据操作员能力、任务紧急性和工作负载分配机器人故障给最合适的人类操作员，减少机器人闲置时间并提高系统性能


<details>
  <summary>Details</summary>
Motivation: 新冠疫情后，移动机械臂和人形辅助机器人在患者护理和生活辅助中的应用增加，但这些机器人在动态非结构化环境中可靠性不足，需要人类干预恢复故障。需要有效的人机协作，将故障分配给最合适的操作员以减少工作负载和任务中断

Method: 提出自适应机器人故障分配方法（ARFA），建模人类操作员能力并基于实际性能持续更新，通过奖励函数计算预期结果（考虑操作员能力、历史数据、任务紧急性和当前工作负载分布），将故障分配给预期奖励最高的操作员

Result: 模拟和用户研究表明，ARFA优于随机分配，显著减少机器人闲置时间，提高整体系统性能，并使操作员间工作负载分布更均衡

Conclusion: ARFA方法通过智能分配机器人故障给最合适的人类操作员，有效提高了人机协作系统的效率和可靠性，为动态环境中的机器人故障恢复提供了实用解决方案

Abstract: Since the recent Covid-19 pandemic, mobile manipulators and humanoid assistive robots with higher levels of autonomy have increasingly been adopted for patient care and living assistance. Despite advancements in autonomy, these robots often struggle to perform reliably in dynamic and unstructured environments and require human intervention to recover from failures. Effective human-robot collaboration is essential to enable robots to receive assistance from the most competent operator, in order to reduce their workload and minimize disruptions in task execution. In this paper, we propose an adaptive method for allocating robotic failures to human operators (ARFA). Our proposed approach models the capabilities of human operators, and continuously updates these beliefs based on their actual performance for failure recovery. For every failure to be resolved, a reward function calculates expected outcomes based on operator capabilities and historical data, task urgency, and current workload distribution. The failure is then assigned to the operator with the highest expected reward. Our simulations and user studies show that ARFA outperforms random allocation, significantly reducing robot idle time, improving overall system performance, and leading to a more distributed workload among operators.

</details>


### [38] [Self-supervised Physics-Informed Manipulation of Deformable Linear Objects with Non-negligible Dynamics](https://arxiv.org/abs/2602.03623)
*Youyuan Long,Gokhan Solak,Sara Zeynalpour,Heng Zhang,Arash Ajoudani*

Main category: cs.RO

TL;DR: SPiD是一个用于可变形线性物体动态操作的物理信息自监督学习框架，通过耦合精确的可变形物体模型和增强的自监督训练策略，在绳稳定任务中表现出色，具有良好的泛化能力和sim-to-real性能。


<details>
  <summary>Details</summary>
Motivation: 解决可变形线性物体（如绳索）的动态操作问题，传统方法难以准确建模复杂变形动力学，需要开发一个数据高效、鲁棒且物理基础扎实的框架。

Method: 1. 扩展质量-弹簧模型以更准确捕捉物体动力学，同时保持轻量化用于自监督学习的高通量推演；2. 使用任务导向成本训练神经控制器，通过可微分物体模型实现端到端优化；3. 提出自监督DAgger变体，检测部署中的分布偏移并执行离线自校正以增强鲁棒性。

Result: 在绳稳定任务中，控制器实现了快速平滑的绳稳定，能够泛化到未见过的初始状态、绳长、质量、非均匀质量分布和外部干扰；开发了经济实惠的无标记绳感知方法，控制器在噪声和低频状态更新下仍保持性能；框架可扩展到绳轨迹跟踪任务。

Conclusion: SPiD提供了一个数据高效、鲁棒且物理基础扎实的可变形线性物体动态操作框架，具有强大的sim-to-real泛化能力，为动态操作任务提供了有效的解决方案。

Abstract: We address dynamic manipulation of deformable linear objects by presenting SPiD, a physics-informed self-supervised learning framework that couples an accurate deformable object model with an augmented self-supervised training strategy. On the modeling side, we extend a mass-spring model to more accurately capture object dynamics while remaining lightweight enough for high-throughput rollouts during self-supervised learning. On the learning side, we train a neural controller using a task-oriented cost, enabling end-to-end optimization through interaction with the differentiable object model. In addition, we propose a self-supervised DAgger variant that detects distribution shift during deployment and performs offline self-correction to further enhance robustness without expert supervision. We evaluate our method primarily on the rope stabilization task, where a robot must bring a swinging rope to rest as quickly and smoothly as possible. Extensive experiments in both simulation and the real world demonstrate that the proposed controller achieves fast and smooth rope stabilization, generalizing across unseen initial states, rope lengths, masses, non-uniform mass distributions, and external disturbances. Additionally, we develop an affordable markerless rope perception method and demonstrate that our controller maintains performance with noisy and low-frequency state updates. Furthermore, we demonstrate the generality of the framework by extending it to the rope trajectory tracking task. Overall, SPiD offers a data-efficient, robust, and physically grounded framework for dynamic manipulation of deformable linear objects, featuring strong sim-to-real generalization.

</details>


### [39] [Variance-Reduced Model Predictive Path Integral via Quadratic Model Approximation](https://arxiv.org/abs/2602.03639)
*Fabian Schramm,Franki Nguimatsia Tiofack,Nicolas Perrin-Gilbert,Marc Toussaint,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出了一种混合方差缩减MPPI框架，通过将目标函数分解为已知近似模型和残差项来降低方差，提高采样效率


<details>
  <summary>Details</summary>
Motivation: 基于采样的控制器（如MPPI）虽然灵活，但存在高方差和低样本效率的问题，需要改进以在实际应用中更实用

Method: 将目标函数分解为已知近似模型和残差项，利用二次近似推导出封闭形式的模型引导先验，使样本集中在信息丰富区域

Result: 在标准优化基准、非线性欠驱动倒立摆控制任务和非光滑动力学的接触丰富操作问题上，相比标准MPPI实现了更快的收敛和更好的低样本性能

Conclusion: 该方法使基于采样的控制策略在样本获取昂贵或有限的场景中更加实用，通过模型引导的方差缩减提高了采样效率

Abstract: Sampling-based controllers, such as Model Predictive Path Integral (MPPI) methods, offer substantial flexibility but often suffer from high variance and low sample efficiency. To address these challenges, we introduce a hybrid variance-reduced MPPI framework that integrates a prior model into the sampling process. Our key insight is to decompose the objective function into a known approximate model and a residual term. Since the residual captures only the discrepancy between the model and the objective, it typically exhibits a smaller magnitude and lower variance than the original objective. Although this principle applies to general modeling choices, we demonstrate that adopting a quadratic approximation enables the derivation of a closed-form, model-guided prior that effectively concentrates samples in informative regions. Crucially, the framework is agnostic to the source of geometric information, allowing the quadratic model to be constructed from exact derivatives, structural approximations (e.g., Gauss- or Quasi-Newton), or gradient-free randomized smoothing. We validate the approach on standard optimization benchmarks, a nonlinear, underactuated cart-pole control task, and a contact-rich manipulation problem with non-smooth dynamics. Across these domains, we achieve faster convergence and superior performance in low-sample regimes compared to standard MPPI. These results suggest that the method can make sample-based control strategies more practical in scenarios where obtaining samples is expensive or limited.

</details>


### [40] [MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction](https://arxiv.org/abs/2602.03668)
*Jung Min Lee,Dohyeok Lee,Seokhun Ju,Taehyun Cho,Jin Woo Koo,Li Zhao,Sangwoo Hong,Jungwoo Lee*

Main category: cs.RO

TL;DR: MVP-LAM通过多视角视频学习离散潜在动作，提高与真实动作的互信息，用于VLA模型预训练，提升下游操作性能


<details>
  <summary>Details</summary>
Motivation: 从多样化人类视频中学习潜在动作可以扩展机器人学习，但现有方法缺乏对真实动作信息的有效编码。需要确保潜在动作包含底层智能体动作信息，尽管没有真实标签。

Method: 提出多视角潜在动作模型(MVP-LAM)，从时间同步的多视角视频中学习离散潜在动作。采用跨视角重建目标训练，使得从一个视角推断的潜在动作必须能解释另一个视角的未来状态，减少对视角特定线索的依赖。

Result: 在Bridge V2数据集上，MVP-LAM产生更具动作中心性的潜在动作，与真实动作的互信息更高，动作预测性能更好，包括在分布外评估中。使用MVP-LAM潜在动作预训练的VLA模型在SIMPLER和LIBERO-Long基准测试中提升了下游操作性能。

Conclusion: MVP-LAM通过多视角学习框架有效编码动作信息，为VLA模型预训练提供高质量的潜在动作标签，显著提升下游机器人操作任务的性能。

Abstract: Learning \emph{latent actions} from diverse human videos enables scaling robot learning beyond embodiment-specific robot datasets, and these latent actions have recently been used as pseudo-action labels for vision-language-action (VLA) model pretraining. To make VLA pretraining effective, latent actions should contain information about the underlying agent's actions despite the absence of ground-truth labels. We propose \textbf{M}ulti-\textbf{V}iew\textbf{P}oint \textbf{L}atent \textbf{A}ction \textbf{M}odel (\textbf{MVP-LAM}), which learns discrete latent actions that are highly informative about ground-truth actions from time-synchronized multi-view videos. MVP-LAM trains latent actions with a \emph{cross-viewpoint reconstruction} objective, so that a latent action inferred from one view must explain the future in another view, reducing reliance on viewpoint-specific cues. On Bridge V2, MVP-LAM produces more action-centric latent actions, achieving higher mutual information with ground-truth actions and improved action prediction, including under out-of-distribution evaluation. Finally, pretraining VLAs with MVP-LAM latent actions improves downstream manipulation performance on the SIMPLER and LIBERO-Long benchmarks.

</details>


### [41] [A Scene Graph Backed Approach to Open Set Semantic Mapping](https://arxiv.org/abs/2602.03781)
*Martin Günther,Felix Igelbrink,Oscar Lima,Lennart Niecksch,Marian Renz,Martin Atzmueller*

Main category: cs.RO

TL;DR: 提出了一种以3D语义场景图作为基础后端的地图架构，将感知与表示统一，支持大规模实时环境中的高级推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法将感知与表示解耦，将场景图作为事后生成的衍生层，这限制了系统的一致性和可扩展性。需要一种能够在大规模真实环境中有效支持高级推理的语义映射方法。

Method: 采用以3D语义场景图作为基础后端的映射架构，利用增量场景图预测技术实时推断和更新图结构，保持拓扑一致性和计算效率，支持平面和层次拓扑的显式空间表示。

Result: 该方法能够在大规模环境中保持拓扑一致性，提供稳定可验证的结构，使知识驱动框架（如知识图谱、本体论和大型语言模型）能够直接利用，增强智能体的可解释性、可信度和与人类概念的契合度。

Conclusion: 通过将3D语义场景图作为基础表示层，统一了感知与表示，为大规模真实环境中的高级推理提供了有效的解决方案，弥合了原始传感器数据与高级符号推理之间的鸿沟。

Abstract: While Open Set Semantic Mapping and 3D Semantic Scene Graphs (3DSSGs) are established paradigms in robotic perception, deploying them effectively to support high-level reasoning in large-scale, real-world environments remains a significant challenge. Most existing approaches decouple perception from representation, treating the scene graph as a derivative layer generated post hoc. This limits both consistency and scalability. In contrast, we propose a mapping architecture where the 3DSSG serves as the foundational backend, acting as the primary knowledge representation for the entire mapping process.
  Our approach leverages prior work on incremental scene graph prediction to infer and update the graph structure in real-time as the environment is explored. This ensures that the map remains topologically consistent and computationally efficient, even during extended operations in large-scale settings. By maintaining an explicit, spatially grounded representation that supports both flat and hierarchical topologies, we bridge the gap between sub-symbolic raw sensor data and high-level symbolic reasoning. Consequently, this provides a stable, verifiable structure that knowledge-driven frameworks, ranging from knowledge graphs and ontologies to Large Language Models (LLMs), can directly exploit, enabling agents to operate with enhanced interpretability, trustworthiness, and alignment to human concepts.

</details>


### [42] [BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks](https://arxiv.org/abs/2602.03793)
*Yixiang Chen,Peiyan Li,Jiabing Yang,Keji He,Xiangnan Wu,Yuan Xu,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.RO

TL;DR: BridgeV2W提出了一种新的具身世界模型，通过将坐标空间动作转换为像素对齐的实体掩码，并注入预训练视频生成模型，解决了动作与视频不对齐、相机视角敏感以及架构不统一的问题。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型面临三个关键挑战：1）坐标空间动作与像素空间视频之间的不对齐；2）对相机视角的敏感性；3）不同实体间架构不统一。这些问题限制了世界模型的泛化能力和实际应用效果。

Method: BridgeV2W将坐标空间动作转换为基于URDF和相机参数渲染的像素对齐实体掩码，通过ControlNet风格的路径注入预训练视频生成模型。该方法实现了动作控制信号与预测视频的对齐，添加了视角特定条件以适应相机视角，并提供了跨实体的统一架构。此外，还引入了基于光流的运动损失来减轻对静态背景的过拟合。

Result: 在单臂（DROID）和双臂（AgiBot-G1）数据集上的实验表明，BridgeV2W在未见过的视角和场景下，相比现有最先进方法显著提高了视频生成质量。进一步展示了BridgeV2W在下游实际任务中的潜力，包括策略评估和目标条件规划。

Conclusion: BridgeV2W通过将坐标空间动作与像素空间视频对齐、适应相机视角变化并提供统一架构，有效解决了现有具身世界模型的关键挑战，在视频生成质量和实际应用方面都表现出优越性能。

Abstract: Embodied world models have emerged as a promising paradigm in robotics, most of which leverage large-scale Internet videos or pretrained video generation models to enrich visual and motion priors. However, they still face key challenges: a misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoint, and non-unified architectures across embodiments. To this end, we present BridgeV2W, which converts coordinate-space actions into pixel-aligned embodiment masks rendered from the URDF and camera parameters. These masks are then injected into a pretrained video generation model via a ControlNet-style pathway, which aligns the action control signals with predicted videos, adds view-specific conditioning to accommodate camera viewpoints, and yields a unified world model architecture across embodiments. To mitigate overfitting to static backgrounds, BridgeV2W further introduces a flow-based motion loss that focuses on learning dynamic and task-relevant regions. Experiments on single-arm (DROID) and dual-arm (AgiBot-G1) datasets, covering diverse and challenging conditions with unseen viewpoints and scenes, show that BridgeV2W improves video generation quality compared to prior state-of-the-art methods. We further demonstrate the potential of BridgeV2W on downstream real-world tasks, including policy evaluation and goal-conditioned planning. More results can be found on our project website at https://BridgeV2W.github.io .

</details>


### [43] [Conformal Reachability for Safe Control in Unknown Environments](https://arxiv.org/abs/2602.03799)
*Xinhang Ma,Junlin Wu,Yiannis Kantaros,Yevgeniy Vorobeychik*

Main category: cs.RO

TL;DR: 提出结合共形预测与可达性分析的未知动态系统概率验证框架，用于学习具有可证明安全保证的控制策略


<details>
  <summary>Details</summary>
Motivation: 现有可证明安全控制方法大多假设系统动态已知、确定或状态/动作空间有限，限制了实际应用范围，需要开发适用于未知动态系统的验证框架

Method: 结合共形预测与可达性分析：使用共形预测获取未知动态在每个时间步的有效不确定性区间，然后通过可达性分析验证在共形不确定性边界内是否保持安全；开发训练控制策略的算法方法，在优化名义奖励的同时最大化具有可靠概率安全保证的规划范围

Result: 在四个领域（cartpole、车道跟随、无人机控制、安全导航）的七个安全控制设置中评估，涵盖仿射和非线性安全规范；学习的策略实现了最强的可证明安全保证，同时保持高平均奖励

Conclusion: 提出的概率验证框架成功解决了未知动态系统的可证明安全控制问题，在保持高性能的同时提供可靠的安全保证，扩展了安全控制的应用范围

Abstract: Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.

</details>
