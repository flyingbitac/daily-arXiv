<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ICP-Based Pallet Tracking for Unloading on Inclined Surfaces by Autonomous Forklifts](https://arxiv.org/abs/2602.16744)
*Takuro Kato,Mitsuharu Morisawa*

Main category: cs.RO

TL;DR: 提出一种用于自主叉车在倾斜表面上卸载托盘的防拖拽控制方法，通过ICP算法实时跟踪托盘与货叉的相对位置和姿态，实现平行对齐后沿倾斜方向撤回货叉


<details>
  <summary>Details</summary>
Motivation: 解决自主叉车在倾斜表面（如卡车货箱）上卸载托盘时，货叉撤回过程中可能拖拽托盘的问题，确保卸载操作的安全性和效率

Method: 使用迭代最近点（ICP）算法处理托盘上部区域的点云数据，实时跟踪托盘与货叉的相对位置和姿态角度差异，根据跟踪结果将货叉与目标表面平行对齐，然后沿倾斜方向撤回货叉完成卸载

Result: 通过动态仿真和真实叉车实验验证了方法的有效性，成功在卡车倾斜货箱上完成卸载操作，避免了托盘拖拽

Conclusion: 提出的基于ICP算法的控制方法能够有效实现自主叉车在倾斜表面上的无拖拽托盘卸载，提高了自动化物料搬运的可靠性和安全性

Abstract: This paper proposes a control method for autonomous forklifts to unload pallets on inclined surfaces, enabling the fork to be withdrawn without dragging the pallets. The proposed method applies the Iterative Closest Point (ICP) algorithm to point clouds measured from the upper region of the pallet and thereby tracks the relative position and attitude angle difference between the pallet and the fork during the unloading operation in real-time. According to the tracking result, the fork is aligned parallel to the target surface. After the fork is aligned, it is possible to complete the unloading process by withdrawing the fork along the tilt, preventing any dragging of the pallet. The effectiveness of the proposed method is verified through dynamic simulations and experiments using a real forklift that replicate unloading operations onto the inclined bed of a truck.

</details>


### [2] [Smooth trajectory generation and hybrid B-splines-Quaternions based tool path interpolation for a 3T1R parallel kinematic milling robot](https://arxiv.org/abs/2602.16758)
*Sina Akhbari,Mehran Mahboubkhah*

Main category: cs.RO

TL;DR: 提出一种用于四自由度并联铣削机器人的平滑轨迹生成方法，结合B样条和四元数插值技术处理解耦的位置和姿态数据点，通过分段贝塞尔曲线同步姿态和弧长参数化位置数据。


<details>
  <summary>Details</summary>
Motivation: 传统插值方法在并联铣削机器人轨迹生成中存在精度不足、速度波动大和计算效率低的问题，需要一种能够同时满足空间约束和时间优化、避免万向节锁死的高效轨迹生成方法。

Method: 采用B样条和四元数插值技术处理解耦的位置和姿态数据；通过分段贝塞尔曲线拟合路径长度与工具姿态的非线性关系，利用贝塞尔曲线的凸包特性确保空间和时间分离约束；使用四元数进行姿态插值避免万向节锁死；采用修正多项式进行位置插值；通过最小加加速度和时间最优的分段贝塞尔曲线进行两阶段优化（任务空间后关节空间）。

Result: 实验结果表明，相比传统插值方法，该方法具有更高的精度、更小的速度波动和更好的计算效率，能够在低成本微控制器上实现。

Conclusion: 该方法成功实现了四自由度并联铣削机器人的平滑轨迹生成，通过创新的同步技术和优化策略，在保证运动质量的同时提高了计算效率，为工业应用提供了实用解决方案。

Abstract: This paper presents a smooth trajectory generation method for a four-degree-of-freedom parallel kinematic milling robot. The proposed approach integrates B-spline and Quaternion interpolation techniques to manage decoupled position and orientation data points. The synchronization of orientation and arc-length-parameterized position data is achieved through the fitting of smooth piece-wise Bezier curves, which describe the non-linear relationship between path length and tool orientation, solved via sequential quadratic programming. By leveraging the convex hull properties of Bezier curves, the method ensures spatial and temporal separation constraints for multi-agent trajectory generation. Unit quaternions are employed for orientation interpolation, providing a robust and efficient representation that avoids gimbal lock and facilitates smooth, continuous rotation. Modifier polynomials are used for position interpolation. Temporal trajectories are optimized using minimum jerk, time-optimal piece-wise Bezier curves in two stages: task space followed by joint space, implemented on a low-cost microcontroller. Experimental results demonstrate that the proposed method offers enhanced accuracy, reduced velocity fluctuations, and computational efficiency compared to conventional interpolation methods.

</details>


### [3] [RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness](https://arxiv.org/abs/2602.16825)
*Ahmad Ahmad,Shuo Liu,Roberto Tron,Calin Belta*

Main category: cs.RO

TL;DR: RRT^η：一种结合算术几何平均鲁棒性度量的采样运动规划框架，用于满足信号时序逻辑规范，相比传统方法在复杂时空约束下表现更优


<details>
  <summary>Details</summary>
Motivation: 传统基于采样运动规划结合信号时序逻辑的方法使用最小-最大鲁棒性度量，只关注关键时间点和子公式，导致非平滑优化景观和尖锐决策边界，阻碍了高效的树探索

Method: 提出RRT^η框架，集成算术几何平均鲁棒性度量评估所有时间点和子公式的满足程度；包括AGM鲁棒性区间语义、高效增量监控算法，以及利用满足优先级逻辑增强的满意度增加方向向量

Result: 框架能够合成满足STL规范的高鲁棒性动态可行控制序列，同时保持RRT*的概率完备性和渐近最优性；在双积分点机器人、独轮车移动机器人和7自由度机械臂上验证，在多重约束场景中优于传统STL鲁棒性规划器

Conclusion: RRT^η框架通过AGM鲁棒性度量解决了传统STL规划中的非平滑优化问题，在复杂时空约束下实现了更高效的采样运动规划

Abstract: Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration.
  We propose RRT$^η$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.

</details>


### [4] [Sound of Touch: Active Acoustic Tactile Sensing via String Vibrations](https://arxiv.org/abs/2602.16846)
*Xili Yi,Ying Xing,Zachary Manchester,Nima Fazeli*

Main category: cs.RO

TL;DR: Sound of Touch：一种基于振动弦的主动声学触觉传感方法，通过少量拾音器检测接触引起的频谱变化，实现毫米级定位、力估计和实时滑移检测。


<details>
  <summary>Details</summary>
Motivation: 分布式触觉传感在大面积应用时面临挑战：密集传感器阵列增加布线、成本和脆弱性，而许多替代方案覆盖有限或无法捕捉快速交互动态。

Method: 使用振动张紧弦作为传感元件，通过电磁连续激励弦，少量接触式麦克风观察接触引起的频谱变化。开发基于物理的弦振动模拟器预测接触位置和力如何改变振动模式，并建立实时推理管道将振动测量映射到接触状态。

Result: 实验证明毫米级定位精度、可靠的力估计和实时滑移检测能力。

Conclusion: 提出了一种轻量级、可扩展的弦基触觉传感硬件概念，适用于机器人表面的大面积传感；开发了物理基础的模拟分析工具和实时推理管道。

Abstract: Distributed tactile sensing remains difficult to scale over large areas: dense sensor arrays increase wiring, cost, and fragility, while many alternatives provide limited coverage or miss fast interaction dynamics. We present Sound of Touch, an active acoustic tactile-sensing methodology that uses vibrating tensioned strings as sensing elements. The string is continuously excited electromagnetically, and a small number of pickups (contact microphones) observe spectral changes induced by contact. From short-duration audio signals, our system estimates contact location and normal force, and detects slip. To guide design and interpret the sensing mechanism, we derive a physics-based string-vibration simulator that predicts how contact position and force shift vibration modes. Experiments demonstrate millimeter-scale localization, reliable force estimation, and real-time slip detection. Our contributions are: (i) a lightweight, scalable string-based tactile sensing hardware concept for instrumenting extended robot surfaces; (ii) a physics-grounded simulation and analysis tool for contact-induced spectral shifts; and (iii) a real-time inference pipeline that maps vibration measurements to contact state.

</details>


### [5] ["Hello, I'm Delivering. Let Me Pass By": Navigating Public Pathways with Walk-along with Robots in Crowded City Streets](https://arxiv.org/abs/2602.16861)
*EunJeong Cheon,Do Yeon Shin*

Main category: cs.RO

TL;DR: 提出"Walk-Along with Robots"方法，用于研究公共空间中自主移动机器人的真实交互


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共空间日益普及，现有HRI研究方法（如受控实验、结构化观察）难以研究真实环境中不受研究者控制的自主机器人（如配送机器人），需要新的研究方法

Method: 借鉴城市研究、地理学和社会学中的公共领域民族志方法，提出Walk-Along with Robots方法，详细阐述了该方法的关键特征、实施步骤、独特见解和评估方式

Result: 提出了一套系统的方法论框架，能够捕捉自主机器人在动态路线和不可预测环境中的真实交互，为研究公共空间中的自主机器人提供了新的研究工具

Conclusion: Walk-Along with Robots方法为研究公共空间中的自主机器人提供了有价值的替代方案，希望激发关于自主机器人研究方法论的进一步讨论

Abstract: As the presence of autonomous robots in public spaces increases-whether navigating campus walkways or neighborhood sidewalks-understanding how to carefully study these robots becomes critical. While HRI research has conducted field studies in public spaces, these are often limited to controlled experiments with prototype robots or structured observational methods, such as the Wizard of Oz technique. However, the autonomous mobile robots we encounter today, particularly delivery robots, operate beyond the control of researchers, navigating dynamic routes and unpredictable environments. To address this challenge, a more deliberate approach is required. Drawing inspiration from public realm ethnography in urban studies, geography, and sociology, this paper proposes the Walk-Along with Robots (WawR) methodology. We outline the key features of this method, the steps we applied in our study, the unique insights it offers, and the ways it can be evaluated. We hope this paper stimulates further discussion on research methodologies for studying autonomous robots in public spaces.

</details>


### [6] [SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation](https://arxiv.org/abs/2602.16863)
*Kushal Kedia,Tyler Ga Wei Lum,Jeannette Bohg,C. Karen Liu*

Main category: cs.RO

TL;DR: SimToolReal：通过程序化生成大量工具状物体基元并训练单一强化学习策略，实现零样本的通用工具操作，无需特定物体或任务训练


<details>
  <summary>Details</summary>
Motivation: 工具操作是机器人灵巧性的重要挑战，需要抓取薄物体、手内旋转和强力交互。由于收集遥操作数据困难，模拟到真实的强化学习是有前景的替代方案，但现有方法需要大量工程努力来建模物体和调整每个任务的奖励函数。

Method: 提出SimToolReal方法：在模拟中程序化生成大量工具状物体基元，训练单一强化学习策略，以将每个物体操纵到随机目标姿态为通用目标。这种方法使系统能够在测试时执行通用灵巧工具操作，无需任何物体或任务特定训练。

Result: SimToolReal比之前的重定向和固定抓取方法性能高出37%，同时与在特定目标物体和任务上训练的专家强化学习策略性能相当。在真实世界中展示了强大的零样本性能：超过120次真实世界测试，涵盖24个任务、12个物体实例和6个工具类别。

Conclusion: SimToolReal通过程序化生成多样化工具状物体和训练通用策略，实现了强大的零样本工具操作能力，为通用模拟到真实强化学习策略在工具操作任务中的泛化迈出了重要一步。

Abstract: The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.

</details>


### [7] [Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads](https://arxiv.org/abs/2602.16870)
*Daniil Lisus,Katya M. Papais,Cedric Le Gentil,Elliot Preston-Krebs,Andrew Lambert,Keith Y. K. Leung,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: Boreas-RT数据集扩展了原有的Boreas数据集，包含9条不同路线的643公里驾驶数据，用于评估自动驾驶算法在多样化真实环境中的表现，特别关注多模态感知和定位算法。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶算法通常在简单环境中表现良好，但在多样化、复杂的真实道路条件下性能会显著下降。需要创建一个包含多种传感器数据、多样化路线和多季节变化的数据集，以更全面地评估算法在实际应用中的鲁棒性。

Method: 使用配备多模态传感器的车辆平台，在9条不同路线上收集60个序列的驾驶数据，包括摄像头、雷达、激光雷达、IMU和轮速编码器等多种传感器数据。提供厘米级精度的GNSS-INS地面真值，以及精确的外参和内参标定。

Result: 基准测试显示，许多最先进的里程计和定位算法在简单的驾驶环境中存在过拟合问题，在更具挑战性的Boreas-RT路线上性能显著下降。该数据集为评估多模态算法在不同道路条件下的表现提供了统一平台。

Conclusion: Boreas-RT数据集填补了自动驾驶算法评估在多样化真实环境中的空白，通过提供多模态传感器数据、精确标定和基准测试平台，有助于推动更鲁棒的自动驾驶算法发展。数据集、开发工具包和排行榜已公开可用。

Abstract: The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomous driving algorithms. Boreas-RT comprises 60 sequences collected over 9 real-world routes, totalling 643 km of driving. Each route is traversed multiple times, enabling evaluation in identical environments under varying traffic and, in some cases, weather conditions. The data collection platform includes a 5MP FLIR Blackfly S camera, a 360 degree Navtech RAS6 Doppler-enabled spinning radar, a 128-channel 360 degree Velodyne Alpha Prime lidar, an Aeva Aeries II FMCW Doppler-enabled lidar, a Silicon Sensing DMU41 inertial measurement unit, and a Dynapar wheel encoder. Centimetre-level ground truth is provided via post-processed Applanix POS LV GNSS-INS data. The dataset includes precise extrinsic and intrinsic calibrations, a publicly available development kit, and a live leaderboard for odometry and metric localization. Benchmark results show that many state-of-the-art odometry and localization algorithms overfit to simple driving environments and degrade significantly on the more challenging Boreas-RT routes. Boreas-RT provides a unified dataset for evaluating multi-modal algorithms across diverse road conditions. The dataset, leaderboard, and development kit are available at www.boreas.utias.utoronto.ca.

</details>


### [8] [MALLVI: a multi agent framework for integrated generalized robotics manipulation](https://arxiv.org/abs/2602.16898)
*Iman Ahmadi,Mehrshad Taji,Arad Mahdinezhad Kashani,AmirHossein Jadidi,Saina Kashani,Babak Khalaj*

Main category: cs.RO

TL;DR: MALLVi是一个多智能体大语言视觉框架，通过闭环反馈驱动的机器人操作，使用专门的智能体协调完成感知、定位、推理和规划，提高零样本操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的机器人任务规划方法通常依赖专门模型、微调或提示调整，且以开环方式运行，缺乏鲁棒的环境反馈，在动态环境中表现脆弱。

Method: MALLVi采用多智能体协调框架，包含分解器、定位器、思考器和反射器等专门智能体，通过视觉语言模型评估环境反馈，实现闭环控制。反射器支持针对性错误检测和恢复，避免完全重新规划。

Result: 在仿真和真实世界环境中的实验表明，迭代闭环多智能体协调提高了泛化能力，并显著增加了零样本操作任务的成功率。

Conclusion: MALLVi框架通过多智能体协调和闭环反馈机制，为动态环境中的机器人操作提供了更鲁棒、更通用的解决方案，代码已开源。

Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step.Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.

</details>


### [9] [SparTa: Sparse Graphical Task Models from a Handful of Demonstrations](https://arxiv.org/abs/2602.16911)
*Adrian Röfer,Nick Heppert,Abhinav Valada*

Main category: cs.RO

TL;DR: 该论文提出了一种从演示中学习长时程操作任务的方法，通过图形化对象关系表示场景状态演化，使用演示分割和池化技术提取操作图，并利用预训练视觉特征进行对象匹配以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高效学习长时程操作任务是机器人从演示中学习的关键挑战。现有方法主要关注在动作域直接学习任务，而本文关注推断机器人应该实现什么（目标），而不是如何实现（方法）。

Method: 使用图形化对象关系表示演化场景状态；提出演示分割和池化方法提取操作图并估计任务各阶段的对象状态分布；利用预训练视觉特征进行对象匹配以提高多演示学习的鲁棒性。

Result: 在广泛实验中评估了演示分割准确性以及从多演示中学习寻找期望最小任务模型的效用；在仿真和真实机器人上部署拟合模型，证明所得任务表示支持跨环境的可靠执行。

Conclusion: 该方法能够有效学习长时程操作任务，通过图形化表示和对象匹配技术，实现了从演示中提取鲁棒的任务模型，并在不同环境中可靠执行。

Abstract: Learning long-horizon manipulation tasks efficiently is a central challenge in robot learning from demonstration. Unlike recent endeavors that focus on directly learning the task in the action domain, we focus on inferring what the robot should achieve in the task, rather than how to do so. To this end, we represent evolving scene states using a series of graphical object relationships. We propose a demonstration segmentation and pooling approach that extracts a series of manipulation graphs and estimates distributions over object states across task phases. In contrast to prior graph-based methods that capture only partial interactions or short temporal windows, our approach captures complete object interactions spanning from the onset of control to the end of the manipulation. To improve robustness when learning from multiple demonstrations, we additionally perform object matching using pre-trained visual features. In extensive experiments, we evaluate our method's demonstration segmentation accuracy and the utility of learning from multiple demonstrations for finding a desired minimal task model. Finally, we deploy the fitted models both in simulation and on a real robot, demonstrating that the resulting task representations support reliable execution across environments.

</details>


### [10] [Benchmarking the Effects of Object Pose Estimation and Reconstruction on Robotic Grasping Success](https://arxiv.org/abs/2602.17101)
*Varun Burde,Pavel Burget,Torsten Sattler*

Main category: cs.RO

TL;DR: 该论文提出了一个基于物理的大规模基准测试，用于评估6D姿态估计器和3D网格模型在机器人抓取任务中的功能有效性，揭示了重建质量对下游任务的影响。


<details>
  <summary>Details</summary>
Motivation: 当前3D重建方法虽然能产生视觉和几何上令人印象深刻的网格，但标准几何评估无法反映重建质量如何影响机器人抓取等下游任务性能。需要填补这一空白。

Method: 引入大规模物理基准测试，在不同重建的3D网格上生成抓取姿态，然后在真实模型上执行这些姿态，模拟使用不完美模型生成的抓取姿态如何影响与真实物体的交互。

Result: 重建伪影显著减少了抓取姿态候选数量，但在姿态估计准确的情况下对抓取性能影响可忽略；抓取成功与姿态误差的关系主要由空间误差主导，即使简单的平移误差也能为对称物体的抓取成功提供洞察。

Conclusion: 这项工作为理解感知系统如何与机器人物体操作相关联提供了洞察，建立了重建质量与下游任务性能之间的功能联系。

Abstract: 3D reconstruction serves as the foundational layer for numerous robotic perception tasks, including 6D object pose estimation and grasp pose generation. Modern 3D reconstruction methods for objects can produce visually and geometrically impressive meshes from multi-view images, yet standard geometric evaluations do not reflect how reconstruction quality influences downstream tasks such as robotic manipulation performance. This paper addresses this gap by introducing a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on their functional efficacy in grasping. We analyze the impact of model fidelity by generating grasps on various reconstructed 3D meshes and executing them on the ground-truth model, simulating how grasp poses generated with an imperfect model affect interaction with the real object. This assesses the combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction. Our results show that reconstruction artifacts significantly decrease the number of grasp pose candidates but have a negligible effect on grasping performance given an accurately estimated pose. Our results also reveal that the relationship between grasp success and pose error is dominated by spatial error, and even a simple translation error provides insight into the success of the grasping pose of symmetric objects. This work provides insight into how perception systems relate to object manipulation using robots.

</details>


### [11] [Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching](https://arxiv.org/abs/2602.17110)
*Tanisha Parulekar,Ge Shi,Josh Pinskier,David Howard,Jen Jen Chung*

Main category: cs.RO

TL;DR: 提出使用条件流匹配(CFM)将刚性夹爪的抓取姿态映射到软体Fin-ray夹爪的新框架，显著提升软体夹爪的抓取成功率


<details>
  <summary>Details</summary>
Motivation: 现有抓取合成方法主要针对刚性平行夹爪设计，直接应用于软体夹爪时无法捕捉其独特的顺应性行为，导致数据需求大且准确性低，需要在刚性夹爪和软体夹爪之间建立有效的抓取姿态映射

Method: 提出基于条件流匹配(CFM)的生成模型框架，包括：1) 数据收集管道生成配对的刚性-软体抓取姿态；2) 使用U-Net自编码器从深度图像中提取物体几何特征作为CFM的条件；3) 学习从初始Anygrasp姿态到稳定Fin-ray夹爪姿态的连续映射

Result: 在7-DOF机器人上验证，CFM生成的姿态相比基线刚性姿态显著提升：整体成功率从6%/25%提升到34%/46%（已见/未见物体）；圆柱体成功率从50%/100%提升到50%/100%；球体成功率从25%/31%提升到25%/31%；模型能有效泛化到未见物体

Conclusion: CFM是一种数据高效且有效的方法，可用于在刚性夹爪和软体夹爪之间转移抓取策略，为其他软体机器人系统提供了可扩展的方法论

Abstract: A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.

</details>


### [12] [Physical Human-Robot Interaction for Grasping in Augmented Reality via Rigid-Soft Robot Synergy](https://arxiv.org/abs/2602.17128)
*Huishi Huang,Jack Klusmann,Haozhe Wang,Shuchen Ji,Fengkang Ying,Yiyuan Zhang,John Nassour,Gordon Cheng,Daniela Rus,Jun Liu,Marcelo H Ang,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出基于增强现实的混合刚柔机器人遥操作框架，通过AR头显实现虚拟仿真与物理系统的叠加，引入实-仿参数识别确保一致性


<details>
  <summary>Details</summary>
Motivation: 混合刚柔机器人结合了刚性机械臂的精确性和软体手臂的顺应性，在非结构化环境中具有应用潜力，但协调控制面临建模、感知和跨域运动学的挑战

Method: 开发AR人机交互框架，用户通过AR头显与集成在通用物理引擎中的机器人仿真模型交互，模型叠加在真实系统上；引入基于软体机器人几何特性的实-仿参数识别管道，准确建模静态动态行为和控制响应

Result: 实现了混合刚柔机器人的直接遥操作，支持简单的到达和抓取任务，确保虚拟机器人与物理机器人行为一致

Conclusion: AR框架为混合刚柔机器人提供直观的交互方式，参数识别管道解决了建模挑战，为在非结构化环境中部署此类系统奠定了基础

Abstract: Hybrid rigid-soft robots combine the precision of rigid manipulators with the compliance and adaptability of soft arms, offering a promising approach for versatile grasping in unstructured environments. However, coordinating hybrid robots remains challenging, due to difficulties in modeling, perception, and cross-domain kinematics. In this work, we present a novel augmented reality (AR)-based physical human-robot interaction framework that enables direct teleoperation of a hybrid rigid-soft robot for simple reaching and grasping tasks. Using an AR headset, users can interact with a simulated model of the robotic system integrated into a general-purpose physics engine, which is superimposed on the real system, allowing simulated execution prior to real-world deployment. To ensure consistent behavior between the virtual and physical robots, we introduce a real-to-simulation parameter identification pipeline that leverages the inherent geometric properties of the soft robot, enabling accurate modeling of its static and dynamic behavior as well as the control system's response.

</details>


### [13] [Geometric Inverse Flight Dynamics on SO(3) and Application to Tethered Fixed-Wing Aircraft](https://arxiv.org/abs/2602.17166)
*Antonio Franchi,Chiara Gabellieri*

Main category: cs.RO

TL;DR: 提出了一种用于固定翼飞机的无坐标逆飞行动力学公式，在SO(3)上建立几何框架，避免局部姿态坐标，推导出轨迹到输入的闭式映射，并应用于系留飞行分析。


<details>
  <summary>Details</summary>
Motivation: 将机器人学中的几何建模方法与航空领域的逆仿真相结合，为轨迹设计和可行性检查提供严格的数学基础，避免传统方法中依赖局部坐标的局限性。

Method: 在SO(3)上建立无坐标公式：平移力平衡在世界坐标系中表达，旋转动力学在机体坐标系中表达；几何定义气动方向（阻力、升力、侧力）；强制协调飞行（无侧滑），推导出闭式的轨迹到输入映射。

Result: 得到了姿态、角速度、推力-攻角对的闭式解，并恢复气动力矩系数分量；应用于球形平行线上的系留飞行，获得了所需滚转角的解析表达式，识别出零滚转轨迹；在简单升力/阻力定律下，最小推力攻角有闭式解。

Conclusion: 该框架连接了航空逆仿真与机器人几何建模，为轨迹设计和可行性检查提供了严格的构建模块；点态准稳态逆解在轨迹和旋转动力学时不变时成为稳态飞行配平解。

Abstract: We present a robotics-oriented, coordinate-free formulation of inverse flight dynamics for fixed-wing aircraft on SO(3). Translational force balance is written in the world frame and rotational dynamics in the body frame; aerodynamic directions (drag, lift, side) are defined geometrically, avoiding local attitude coordinates. Enforcing coordinated flight (no sideslip), we derive a closed-form trajectory-to-input map yielding the attitude, angular velocity, and thrust-angle-of-attack pair, and we recover the aerodynamic moment coefficients component-wise. Applying such a map to tethered flight on spherical parallels, we obtain analytic expressions for the required bank angle and identify a specific zero-bank locus where the tether tension exactly balances centrifugal effects, highlighting the decoupling between aerodynamic coordination and the apparent gravity vector. Under a simple lift/drag law, the minimal-thrust angle of attack admits a closed form. These pointwise quasi-steady inversion solutions become steady-flight trim when the trajectory and rotational dynamics are time-invariant. The framework bridges inverse simulation in aeronautics with geometric modeling in robotics, providing a rigorous building block for trajectory design and feasibility checks.

</details>


### [14] [Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place](https://arxiv.org/abs/2602.17199)
*Antonio Rapuano,Yaolei Shen,Federico Califano,Chiara Gabellieri,Antonio Franchi*

Main category: cs.RO

TL;DR: 该论文提出了一个用于空中操纵可伸缩电缆的框架，结合了基于偏微分方程的高保真模型和适用于实时控制的降阶表示，实现了无人机携带柔性电缆的实时动态感知控制。


<details>
  <summary>Details</summary>
Motivation: 无人机携带柔性电缆进行空中操纵时面临复杂的动力学挑战，需要高保真模型来准确描述电缆变形，同时需要计算效率高的模型来实现实时控制。现有方法难以同时满足精度和实时性要求。

Method: 采用偏微分方程建模电缆动力学，使用有限差分法离散化，通过本征正交分解提取降阶模型以保留主要变形模式并降低计算复杂度。基于降阶模型构建非线性模型预测控制方案，能够稳定电缆振荡并处理有效载荷附着/分离等混合过渡。

Result: 仿真结果验证了降阶模型的稳定性、效率和鲁棒性，控制器在各种操作条件下都能有效调节电缆动力学。额外仿真展示了降阶模型在受限环境中进行轨迹规划的应用，证明了方法的通用性。

Conclusion: 该框架成功实现了无人机携带悬挂柔性电缆的实时动态感知控制，结合了高保真建模和计算效率，为空中电缆操纵提供了有效的解决方案。

Abstract: This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.

</details>


### [15] [Multi-session Localization and Mapping Exploiting Topological Information](https://arxiv.org/abs/2602.17226)
*Lorenzo Montano-Olivan,Julio A. Placed,Luis Montano,Maria T. Lazaro*

Main category: cs.RO

TL;DR: 提出了一种新颖的多会话建图框架，通过基于地图的定位和拓扑感知的决策机制，在重复访问环境中优化建图和定位性能。


<details>
  <summary>Details</summary>
Motivation: 自主系统在重复访问相同环境时面临建图和定位的挑战，传统方法贪婪地运行完整SLAM会话并尝试在结果地图间建立对应关系存在局限性。

Method: 采用基于地图的定位方法，结合拓扑感知、不确定性感知的决策机制，分析位姿图结构以检测低连通性区域，选择性触发建图和闭环检测模块。

Result: 在重叠序列数据集和真实矿井环境中验证了方法的有效性，能够减少累积误差并增强全局一致性。

Conclusion: 提出的多会话框架通过智能决策机制优化了重复环境中的建图和定位性能，为自主系统在复杂环境中的长期运行提供了有效解决方案。

Abstract: Operating in previously visited environments is becoming increasingly crucial for autonomous systems, with direct applications in autonomous driving, surveying, and warehouse or household robotics. This repeated exposure to observing the same areas poses significant challenges for mapping and localization -- key components for enabling any higher-level task. In this work, we propose a novel multi-session framework that builds on map-based localization, in contrast to the common practice of greedily running full SLAM sessions and trying to find correspondences between the resulting maps. Our approach incorporates a topology-informed, uncertainty-aware decision-making mechanism that analyzes the pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. The resulting map and pose-graph are seamlessly integrated into the existing model, reducing accumulated error and enhancing global consistency. We validate our method on overlapping sequences from datasets and demonstrate its effectiveness in a real-world mine-like environment.

</details>


### [16] [FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment](https://arxiv.org/abs/2602.17259)
*Han Zhao,Jingbo Wang,Wenxuan Song,Shuai Chen,Yang Liu,Yan Wang,Haoang Li,Donglin Wang*

Main category: cs.RO

TL;DR: FRAPPE方法通过两阶段微调策略解决VLA模型在环境动态预测中的像素重建过度强调和误差累积问题，提升机器人策略的世界感知能力


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在环境动态预测中存在两个主要问题：1.训练目标迫使模型过度强调像素级重建，限制了语义学习和泛化能力；2.推理过程中依赖预测的未来观测导致误差累积

Method: 提出FRAPPE方法，采用两阶段微调策略：中期训练阶段学习预测未来观测的潜在表示；后期训练阶段并行扩展计算负载，同时与多个不同的视觉基础模型对齐表示

Result: 在RoboTwin基准测试和真实世界任务中，FRAPPE优于最先进方法，在长时程和未见场景中表现出强大的泛化能力

Conclusion: FRAPPE通过显著提高微调效率和减少对动作标注数据的依赖，为增强通用机器人策略的世界感知能力提供了可扩展且数据高效的途径

Abstract: Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.

</details>


### [17] [Contact-Anchored Proprioceptive Odometry for Quadruped Robots](https://arxiv.org/abs/2602.17393)
*Minxing Sun,Yao Mao*

Main category: cs.RO

TL;DR: 提出了一种仅使用IMU和电机测量的纯本体感知状态估计器，通过接触腿作为运动学锚点来抑制长期漂移，适用于双足、四足和轮腿机器人


<details>
  <summary>Details</summary>
Motivation: 解决无摄像头或激光雷达的腿式机器人里程计问题，克服IMU漂移和关节速度噪声，实现可靠的本体感知状态估计

Method: 1) 将接触腿作为运动学锚点，基于关节力矩的足部力估计选择可靠接触点；2) 引入轻量级高度聚类和时间衰减校正防止高度漂移；3) 使用逆运动学立方体卡尔曼滤波器改善足端速度观测；4) 通过多接触几何一致性减少偏航漂移

Result: 在四个四足平台上测试：Astrall点足机器人A完成约200米水平回路误差0.1638米，约15米垂直回路误差0.219米；轮腿机器人B相应误差为0.2264米和0.199米；轮腿机器人C约700米水平回路误差7.68米，约20米垂直回路误差0.540米；Unitree Go2 EDU约120米水平回路误差2.2138米，约8米垂直回路垂直误差小于0.1米

Conclusion: 该方法仅使用IMU和电机测量就能实现可靠的位姿和速度估计，适用于多种腿式机器人平台，有效抑制了长期漂移问题

Abstract: Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\sim$200\,m horizontal loop and a $\sim$15\,m vertical loop return with 0.1638\,m and 0.219\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\,m and 0.199\,m. On wheel-legged robot~C, a $\sim$700\,m horizontal loop yields 7.68\,m error and a $\sim$20\,m vertical loop yields 0.540\,m error. Unitree Go2 EDU closes a $\sim$120\,m horizontal loop with 2.2138\,m error and a $\sim$8\,m vertical loop with less than 0.1\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git

</details>


### [18] [3D-printed Soft Optical sensor with a Lens (SOLen) for light guidance in mechanosensing](https://arxiv.org/abs/2602.17421)
*Diana Cafiso,Petr Trunin,Carolina Gay,Lucia Beccai*

Main category: cs.RO

TL;DR: 提出了一种名为SOLen的3D打印软光学传感方法，通过打印透镜在Y形波导中实现变形传感，利用透镜旋转和焦点平移来重新分配两个分支的光功率，从而编码运动方向和幅度。


<details>
  <summary>Details</summary>
Motivation: 增材制造使得软机器人具有越来越复杂的几何形状，需要与单材料、一步制造兼容的传感解决方案。光学软传感器适合整体打印，但其性能常受环境耦合、泄漏、散射等不受控光传播影响，而常见的缓解策略通常需要多材料界面。

Method: 在Y形波导的发射器前放置打印透镜，传感机制依赖于变形引起的透镜旋转和焦点平移，重新分配两个分支之间的光功率，产生编码运动方向和幅度的差分输出。使用丙烯酸聚氨酯树脂改性提高柔顺性和光学透射率，通过单层光学表征获得波长相关的折射率和透射率，模拟设计透镜轮廓并实现亚毫米精度打印。

Result: 旋转测试证明在多个周期内可重复的分支选择性信号切换。建立了从材料到光学的可转移工作流程，为下一代软机器人提供了具有新功能的光学传感器。

Conclusion: SOLen方法为软光学传感器提供了一种可转移的材料到光学工作流程，通过打印透镜实现了新的功能，为下一代软机器人提供了兼容单材料、一步制造的传感解决方案。

Abstract: Additive manufacturing is enabling soft robots with increasingly complex geometries, creating a demand for sensing solutions that remain compatible with single-material, one-step fabrication. Optical soft sensors are attractive for monolithic printing, but their performance is often degraded by uncontrolled light propagation (ambient coupling, leakage, scattering), while common miti- gation strategies typically require multimaterial interfaces. Here, we present an approach for 3D printed soft optical sensing (SOLen), in which a printed lens is placed in front of an emitter within a Y-shaped waveguide. The sensing mechanism relies on deformation-induced lens rotation and focal-spot translation, redistributing optical power between the two branches to generate a differential output that encodes both motion direction and amplitude. An acrylate polyurethane resin was modified with lauryl acrylate to improve compliance and optical transmittance, and single-layer optical characterization was used to derive wavelength-dependent refractive index and transmittance while minimizing DLP layer-related artifacts. The measured refractive index was used in simulations to design a lens profile for a target focal distance, which was then printed with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. These results establish a transferable material-to-optics workflow for soft optical sensors with lens with new functionalities for next-generation soft robots

</details>


### [19] [A Cost-Effective and Climate-Resilient Air Pressure System for Rain Effect Reduction on Automated Vehicle Cameras](https://arxiv.org/abs/2602.17472)
*Mohamed Sabry,Joseba Gorospe,Cristina Olaverri-Monreal*

Main category: cs.RO

TL;DR: 本文提出了一种低成本硬件解决方案，用于提高自动驾驶车辆在雨天条件下的感知性能，特别适用于车辆编队等关键应用场景。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶车辆在恶劣天气条件下的研究主要集中在感知算法改进，而物理硬件解决方案研究有限。现有方法如亲水/疏水镜头和喷雾只能部分缓解问题，工业级保护系统成本高且难以在汽车领域规模化部署。

Method: 提出了一种成本效益高的硬件解决方案，专门针对雨天条件设计，能够同时兼容多个摄像头。该系统与现有摄像头传感平台兼容，无需额外高成本传感器或硬件更换。

Result: 该系统将深度学习模型的行人检测准确率从8.3%提升至41.6%，显著提高了雨天条件下的感知性能。

Conclusion: 该硬件解决方案不仅提高了自动驾驶车辆在恶劣天气条件下的可靠性，还支持交通系统的可持续发展目标，通过减少资源消耗、支持模块化升级，促进自动驾驶技术更经济高效的部署。

Abstract: Recent advances in automated vehicles have focused on improving perception performance under adverse weather conditions; however, research on physical hardware solutions remains limited, despite their importance for perception critical applications such as vehicle platooning. Existing approaches, such as hydrophilic or hydrophobic lenses and sprays, provide only partial mitigation, while industrial protection systems imply high cost and they do not enable scalability for automotive deployment.
  To address these limitations, this paper presents a cost-effective hardware solution for rainy conditions, designed to be compatible with multiple cameras simultaneously.
  Beyond its technical contribution, the proposed solution supports sustainability goals in transportation systems. By enabling compatibility with existing camera-based sensing platforms, the system extends the operational reliability of automated vehicles without requiring additional high-cost sensors or hardware replacements. This approach reduces resource consumption, supports modular upgrades, and promotes more cost-efficient deployment of automated vehicle technologies, particularly in challenging weather conditions where system failures would otherwise lead to inefficiencies and increased emissions. The proposed system was able to increase pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6%.

</details>


### [20] [Optically Sensorized Electro-Ribbon Actuator (OS-ERA)](https://arxiv.org/abs/2602.17474)
*Carolina Gay,Petr Trunin,Diana Cafiso,Yuejun Xu,Majid Taghavi,Lucia Beccai*

Main category: cs.RO

TL;DR: OS-ERA：一种光学传感的Electro-Ribbon执行器，通过嵌入软光学波导传感器实现高精度弯曲状态分类，解决了传统电容传感精度不足的问题，为闭环控制铺平道路。


<details>
  <summary>Details</summary>
Motivation: 传统Electro-Ribbon执行器（ERAs）虽然具有超高的位移和快速运动能力，但其嵌入式传感依赖于精度有限的电容传感器，这阻碍了精确控制。需要一种不影响驱动性能的可靠传感解决方案。

Method: 设计了OS-ERA，在ERA中嵌入两个软光学波导传感器来分析复杂曲率运动。训练分类器将传感信号映射到八个弯曲状态。通过六个保留试验验证模型，并与训练运行中学习的信号轨迹进行比较。

Result: 在所有测试中，传感输出信号遵循训练流形，预测序列反映实际性能并确认可重复性。即使在驱动速度故意不匹配的情况下，信号轨迹仍保持形状，分类保持准确，展示了电压和速度不变性。

Conclusion: OS-ERA能够高保真地分类弯曲状态，快速且可重复，解决了ERA长期存在的瓶颈问题，为实现闭环控制迈出了重要一步。

Abstract: Electro-Ribbon Actuators (ERAs) are lightweight flexural actuators that exhibit ultrahigh displacement and fast movement. However, their embedded sensing relies on capacitive sensors with limited precision, which hinders accurate control. We introduce OS-ERA, an optically sensorized ERA that yields reliable proprioceptive information, and we focus on the design and integration of a sensing solution without affecting actuation. To analyse the complex curvature of an ERA in motion, we design and embed two soft optical waveguide sensors. A classifier is trained to map the sensing signals in order to distinguish eight bending states. We validate our model on six held-out trials and compare it against signals' trajectories learned from training runs. Across all tests, the sensing output signals follow the training manifold, and the predicted sequence mirrors real performance and confirms repeatability. Despite deliberate train-test mismatches in actuation speed, the signal trajectories preserve their shape, and classification remains consistently accurate, demonstrating practical voltage- and speed-invariance. As a result, OS-ERA classifies bending states with high fidelity; it is fast and repeatable, solving a longstanding bottleneck of the ERA, enabling steps toward closed-loop control.

</details>


### [21] [Proximal powered knee placement: a case study](https://arxiv.org/abs/2602.17502)
*Kyle R. Embry,Lorenzo Vianello,Jim Lipsey,Frank Ursetta,Michael Stephens,Zhi Wang,Ann M. Simon,Andrea J. Ikeda,Suzanne B. Finucane,Shawana Anarwala,Levi J. Hargrove*

Main category: cs.RO

TL;DR: 研究探索了动力假肢膝关节的电机放置位置（膝上vs膝下），发现膝上配置能改善步行速度和步频，表明优化质量分布而非单纯减重可能更有效。


<details>
  <summary>Details</summary>
Motivation: 下肢截肢影响全球数百万人，导致行动能力受损、步行速度下降和日常社交活动受限。动力假肢膝关节能主动辅助膝关节扭矩，改善步态对称性、坐站转换和步行速度，但增加的重量可能抵消这些益处，影响步态力学并增加代谢成本。

Method: 探索性研究，在小规模队列中评估动力假肢膝关节膝上放置的可行性。与膝下配置对比，测量步行速度、步频、步态对称性、膝关节活动范围和峰值速度等参数。在坡道和楼梯上进行额外测试验证控制策略的鲁棒性。

Result: 膝上配置相比膝下配置：一名参与者的步行速度提高9.2%，步频提高3.6%，步态对称性效果不一。运动学测量显示膝关节活动范围和峰值速度在两种配置中相似。坡道和楼梯测试证实控制策略在多种运动任务中具有鲁棒性。

Conclusion: 膝上放置功能上可行，精心设计的质量分布可以在保留动力辅助益处的同时减轻额外重量的负面影响。需要进一步研究确认这些趋势并为设计和临床建议提供指导。

Abstract: Lower limb amputation affects millions worldwide, leading to impaired mobility, reduced walking speed, and limited participation in daily and social activities. Powered prosthetic knees can partially restore mobility by actively assisting knee joint torque, improving gait symmetry, sit-to-stand transitions, and walking speed. However, added mass from powered components may diminish these benefits, negatively affecting gait mechanics and increasing metabolic cost. Consequently, optimizing mass distribution, rather than simply minimizing total mass, may provide a more effective and practical solution. In this exploratory study, we evaluated the feasibility of above-knee powertrain placement for a powered prosthetic knee in a small cohort. Compared to below-knee placement, the above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%), with mixed effects on gait symmetry. Kinematic measures indicated similar knee range of motion and peak velocity across configurations. Additional testing on ramps and stairs confirmed the robustness of the control strategy across multiple locomotion tasks. These preliminary findings suggest that above-knee placement is functionally feasible and that careful mass distribution can preserve the benefits of powered assistance while mitigating adverse effects of added weight. Further studies are needed to confirm these trends and guide design and clinical recommendations.

</details>


### [22] [IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control](https://arxiv.org/abs/2602.17537)
*Qilong Cheng,Matthew Mackay,Ali Bereyhi*

Main category: cs.RO

TL;DR: IRIS是一个低成本、基于学习的6自由度机器人摄像系统，通过模仿学习和Transformer架构实现自主电影级运动控制


<details>
  <summary>Details</summary>
Motivation: 工业级机器人摄像系统成本高、操作复杂，限制了其广泛应用。需要开发低成本、易用、能自主执行电影级运动的机器人摄像系统。

Method: 采用3D打印轻量化硬件设计，结合基于Action Chunking with Transformers (ACT)的目标条件视觉运动模仿学习框架，直接从人类演示中学习物体感知和感知平滑的相机轨迹。

Result: 系统成本低于1000美元，支持1.5公斤负载，重复精度约1毫米。实验显示准确的轨迹跟踪、可靠的自主执行能力，并能泛化到多种电影级运动。

Conclusion: IRIS系统成功实现了低成本、基于学习的机器人摄像平台，无需显式几何编程即可生成高质量的电影级运动，为机器人摄像系统的普及提供了可行方案。

Abstract: Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.

</details>


### [23] [FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations](https://arxiv.org/abs/2602.17573)
*Konstantinos Foteinos,Georgios Angelidis,Aggelos Psiris,Vasileios Argyriou,Panagiotis Sarigiannidis,Georgios Th. Papadopoulos*

Main category: cs.RO

TL;DR: 本文提出了FR-GESTURE数据集，专门用于应急响应人员通过手势控制无人地面车辆，包含12种手势命令、3312个RGBD图像对，并提供了基准实验。


<details>
  <summary>Details</summary>
Motivation: 灾难强度和频率不断增加，使得应急响应人员的工作更加困难。人工智能和机器人解决方案可以协助他们的操作，弥补这些困难。目前缺乏专门为应急响应人员手势控制无人地面车辆设计的数据集。

Method: 设计了12种手势命令，灵感来自现有应急响应人员手势和战术手语，并经过经验丰富的应急响应人员反馈完善。从2个视角和7个距离收集了3312个RGBD图像对。定义了评估协议并进行基准实验。

Result: 创建了FR-GESTURE数据集，这是首个专门为应急响应人员手势控制无人地面车辆设计的数据集。数据集已公开可用，并提供了基准实验结果供后续改进。

Conclusion: FR-GESTURE数据集填补了应急响应人员手势控制机器人领域的数据空白，为未来研究提供了基础，有望促进人工智能和机器人技术在灾难响应中的应用。

Abstract: The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: https://doi.org/10.5281/zenodo.18131333.

</details>


### [24] [Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes](https://arxiv.org/abs/2602.17574)
*Joshua A. Robbins,Andrew F. Thompson,Jonah J. Glunt,Herschel C. Pangborn*

Main category: cs.RO

TL;DR: 提出基于混合Zonotope和ADMM混合整数规划启发式的混合系统运动规划框架，降低内存复杂度，提高收敛速度


<details>
  <summary>Details</summary>
Motivation: 嵌入式混合系统优化规划面临混合整数规划计算量大、对数值公式敏感的挑战，需要更高效的规划方法

Method: 结合混合Zonotope集合表示和ADMM混合整数规划启发式，提出分段仿射系统可达性分析通用方法，并扩展到最优规划问题

Result: 提出的方法相比现有技术产生更低内存复杂度和更紧凸松弛的集合，ADMM启发式在混合Zonotope结构上收敛速度优于现有混合整数规划启发式

Conclusion: 该框架在自动驾驶行为与运动规划场景中得到实验验证，为嵌入式硬件上的混合系统规划提供了有效解决方案

Abstract: Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.

</details>


### [25] [Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space](https://arxiv.org/abs/2602.17586)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Deep-Flow：基于最优传输条件流匹配的无监督安全关键异常检测框架，用于自动驾驶车辆的安全验证，通过低秩谱流形约束生成过程，实现稳定、确定性的对数似然估计。


<details>
  <summary>Details</summary>
Motivation: L4级自动驾驶车辆的安全验证目前受限于无法通过传统基于规则的启发式方法扩展检测罕见、高风险的长尾场景。需要一种能够有效识别安全关键异常行为的无监督方法。

Method: 1. 使用最优传输条件流匹配（OT-CFM）来表征专家人类驾驶行为的连续概率密度；2. 通过PCA瓶颈将生成过程约束到低秩谱流形，确保运动学平滑性；3. 采用具有车道感知目标条件的早期融合Transformer编码器，处理复杂路口的多模态模糊性；4. 引入运动学复杂性加权方案，在无模拟训练过程中优先处理高能量机动。

Result: 在Waymo开放运动数据集（WOMD）上评估，框架实现了0.766的AUC-ROC（相对于安全关键事件的启发式黄金集）。更重要的是，分析揭示了运动学危险和语义违规之间的根本区别，识别出传统安全过滤器忽略的分布外行为。

Conclusion: Deep-Flow为定义统计安全门提供了数学严谨的基础，使自动驾驶车队的安全部署能够进行客观、数据驱动的验证。该框架能够识别传统方法忽略的关键可预测性差距，如车道边界违规和非规范性路口机动。

Abstract: Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.

</details>
