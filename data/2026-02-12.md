<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning](https://arxiv.org/abs/2602.10285)
*Ananya Trivedi,Anjian Li,Mohamed Elnoor,Yusuf Umut Ciftci,Avinash Singh,Jovin D'sa,Sangjae Bae,David Isele,Taskin Padir,Faizan M. Tariq*

Main category: cs.RO

TL;DR: 提出基于条件流匹配的自动驾驶框架，实时预测周围车辆运动并规划自车轨迹，通过轻量级方差估计器动态选择推理步数，结合凸二次规划后处理提升轨迹质量，在Waymo数据集上实现20Hz更新率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要与周围交通交互推理。现有大规模模仿学习方法需要实时运行，但扩散模型推理延迟高，一致性模型依赖精心调谐的噪声调度且难以适应多模态动作分布，调整调度需要昂贵重训练。

Method: 基于条件流匹配的框架，联合预测周围智能体未来运动并规划自车轨迹；训练轻量级方差估计器在线选择推理步数，无需重训练平衡运行时间和性能；引入凸二次规划轨迹后处理步骤，计算开销可忽略。

Result: 在Waymo Open Motion Dataset上训练，能够执行变道、巡航控制、无保护左转等操作，无需场景特定调优；在NVIDIA RTX 3070 GPU上保持20Hz更新率；相比Transformer、扩散模型和一致性模型基线，轨迹更平滑且更好地遵守动态约束。

Conclusion: 提出的条件流匹配框架解决了现有方法在实时性和多模态分布建模方面的限制，通过自适应推理步数和轨迹后处理，实现了高性能的在线自动驾驶轨迹规划，适合实际部署。

Abstract: Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.

</details>


### [2] [A Human-in-the-Loop Confidence-Aware Failure Recovery Framework for Modular Robot Policies](https://arxiv.org/abs/2602.10289)
*Rohan Banerjee,Krishna Palempalli,Bohan Yang,Jiaying Fang,Alif Abdullah,Tom Silver,Sarah Dean,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: 提出模块化机器人策略的人机协同故障恢复框架，通过模块级不确定性估计和人工干预成本模型，智能决定何时、向哪个模块请求人类帮助，以平衡恢复效率和用户工作负荷。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化人类环境中（特别是护理场景）经常发生故障，虽然人类可以帮助恢复，但过多或不恰当的查询会给人类伙伴带来不必要的认知和身体负担。需要一种更智能的故障恢复机制。

Method: 开发模块化机器人策略的人机协同故障恢复框架：1）使用校准的模块级不确定性估计和人工干预成本模型；2）分离两个决策：模块选择器识别最可能导致故障的模块，查询算法决定是否请求人类输入；3）评估多种模块选择策略和查询算法。

Result: 在受控合成实验中揭示了恢复效率、系统鲁棒性和用户工作负荷之间的权衡关系。在机器人辅助进食系统的实际部署中，针对有行动障碍的用户研究表明，该框架提高了恢复成功率，同时减少了用户的工作负荷。

Conclusion: 通过显式考虑机器人不确定性和人类努力，可以实现更高效、以用户为中心的协作机器人故障恢复，为机器人护理等应用提供了实用的人机协同解决方案。

Abstract: Robots operating in unstructured human environments inevitably encounter failures, especially in robot caregiving scenarios. While humans can often help robots recover, excessive or poorly targeted queries impose unnecessary cognitive and physical workload on the human partner. We present a human-in-the-loop failure-recovery framework for modular robotic policies, where a policy is composed of distinct modules such as perception, planning, and control, any of which may fail and often require different forms of human feedback. Our framework integrates calibrated estimates of module-level uncertainty with models of human intervention cost to decide which module to query and when to query the human. It separates these two decisions: a module selector identifies the module most likely responsible for failure, and a querying algorithm determines whether to solicit human input or act autonomously. We evaluate several module-selection strategies and querying algorithms in controlled synthetic experiments, revealing trade-offs between recovery efficiency, robustness to system and user variables, and user workload. Finally, we deploy the framework on a robot-assisted bite acquisition system and demonstrate, in studies involving individuals with both emulated and real mobility limitations, that it improves recovery success while reducing the workload imposed on users. Our results highlight how explicitly reasoning about both robot uncertainty and human effort can enable more efficient and user-centered failure recovery in collaborative robots. Supplementary materials and videos can be found at: http://emprise.cs.cornell.edu/modularhil

</details>


### [3] [Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning](https://arxiv.org/abs/2602.10365)
*Nick Gorman,Gage MacLin,Maxwell Hammond,Venanzio Cichella*

Main category: cs.RO

TL;DR: 提出基于复合伯恩斯坦多项式的轨迹规划方法，用于自主系统在复杂环境中的导航，通过符号优化框架实现连续路径和精确轨迹形状控制。


<details>
  <summary>Details</summary>
Motivation: 自主系统在复杂环境中需要高效、平滑且安全的轨迹规划方法，特别是在计算资源有限的情况下（如航天器），需要能够处理连续障碍场而非离散边界的方法。

Method: 使用复合伯恩斯坦多项式表示轨迹，在符号优化框架中实现。将障碍物编码为连续成本场，通过高斯表面不等式约束最小障碍物间距，结合测地线方程引导路径沿成本表面高效方向，并施加边界约束。

Result: 方法能够高效生成平滑、无碰撞的路径，在多障碍物场景中保持安全间距，无需大量采样或后处理。适用于地面、空中、水下和空间系统，特别在航天器轨迹规划中表现出高数值效率。

Conclusion: 该方法为自主系统在复杂环境中的轨迹规划提供了有效的解决方案，可作为独立规划器或复杂运动规划问题的初始化方法，特别适合计算资源有限的应用场景。

Abstract: This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.

</details>


### [4] [LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies](https://arxiv.org/abs/2602.10399)
*I Made Aswin Nahrendra,Seunghyun Lee,Dongkyu Lee,Hyun Myung*

Main category: cs.RO

TL;DR: 该论文提出了一种将基础模型的高级常识推理融入腿式机器人运动适应的方法，通过语言模型合成技能数据库，视觉语言模型提取环境语义，实现基于指令的实时运动适应，指令跟随准确率达87%


<details>
  <summary>Details</summary>
Motivation: 当前腿式机器人运动学习主要依赖环境几何表示，限制了机器人对高级语义（如人类指令）的响应能力。需要将高级常识推理融入运动适应过程，使机器人能理解环境语义并执行人类指令。

Method: 1. 使用预训练大语言模型合成针对腿式机器人的指令接地技能数据库；2. 使用预训练视觉语言模型提取高级环境语义并将其与技能数据库关联；3. 训练风格条件策略，生成多样化且鲁棒的运动技能；4. 实现实时技能建议，无需在线查询云端基础模型。

Result: 实现了腿式机器人基于高级环境语义和指令的实时运动适应，指令跟随准确率达到87%，无需在线查询云端基础模型，展示了首个基于高级推理的腿式机器人实时适应系统。

Conclusion: 该方法成功将基础模型的高级推理能力融入腿式机器人运动控制，突破了传统几何表示的局限，使机器人能够理解环境语义并响应人类指令，为智能腿式机器人发展提供了新方向。

Abstract: Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.

</details>


### [5] [Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.10503)
*Yuan Liu,Haoran Li,Shuai Tian,Yuxing Qin,Yuhui Chen,Yupeng Zheng,Yongzhen Huang,Dongbin Zhao*

Main category: cs.RO

TL;DR: LifeLong-RFT是一种用于视觉语言动作模型的强化微调策略，通过多维过程奖励机制解决监督微调的数据需求大和灾难性遗忘问题，在持续学习中表现优异。


<details>
  <summary>Details</summary>
Motivation: VLA模型虽然具有强大的泛化能力，但传统的监督微调需要大量任务特定数据且容易发生灾难性遗忘，限制了其在持续学习场景中的应用。

Method: 提出LifeLong-RFT方法，结合块级策略强化学习和多维过程奖励机制（MDPR），包括量化动作一致性奖励（QACR）、连续轨迹对齐奖励（CTAR）和格式合规奖励（FCR）。

Result: 在SimplerEnv、LIBERO和真实世界任务中表现优异，在LIBERO基准测试的持续学习中，平均成功率比SFT提高22%，仅需20%的训练数据即可适应新任务。

Conclusion: LifeLong-RFT为VLA模型提供了一个有前景的后训练范式，有效解决了监督微调的数据需求和灾难性遗忘问题。

Abstract: Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.

</details>


### [6] [Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.10514)
*Shihao Dong,Yeke Chen,Zeren Luo,Jiahui Zhang,Bowen Xu,Jinghan Lin,Yimin Han,Ji Ma,Zhiyou Yu,Yudong Zhao,Peng Lu*

Main category: cs.RO

TL;DR: 双足机器人协同跳跃框架，通过去中心化强化学习实现无通信同步，跳跃高度提升144%


<details>
  <summary>Details</summary>
Motivation: 单个腿式机器人受限于物理驱动能力，需要突破这些限制以实现更强的运动性能

Method: 使用多智能体近端策略优化（MAPPO）结合渐进式课程策略，在去中心化设置下处理高脉冲接触动力学，仅依赖本体感知反馈实现同步

Result: 在仿真和物理硬件上实现稳健性能，成功完成高达1.5米平台的多方向跳跃，其中一台机器人脚端高度达到1.1米，比单机器人0.45米跳跃高度提升144%

Conclusion: 建立了无通信协作运动的基础，展示了在受限环境中仅通过本体感知实现精确协调的可行性

Abstract: While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. Our framework leverages Multi-Agent Proximal Policy Optimization (MAPPO) enhanced by a progressive curriculum strategy, which effectively overcomes the sparse-reward exploration challenges inherent in mechanically coupled systems. We demonstrate robust performance in simulation and successful transfer to physical hardware, executing multi-directional jumps onto platforms up to 1.5 m in height. Specifically, one of the robots achieves a foot-end elevation of 1.1 m, which represents a 144% improvement over the 0.45 m jump height of a standalone quadrupedal robot, demonstrating superior vertical performance. Notably, this precise coordination is achieved solely through proprioceptive feedback, establishing a foundation for communication-free collaborative locomotion in constrained environments.

</details>


### [7] [LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.10556)
*Lihan Zha,Asher J. Hancock,Mingtong Zhang,Tenny Yin,Yixuan Huang,Dhruv Shah,Allen Z. Ren,Anirudha Majumdar*

Main category: cs.RO

TL;DR: LAP-3B：首个实现零样本跨机器人本体迁移的视觉-语言-动作模型，无需特定本体微调，在未见过的机器人上达到50%以上成功率


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型（VLAs）虽然经过大规模多本体预训练，但仍紧密耦合于训练时的机器人本体，需要昂贵的微调才能适应新机器人。需要一种能零样本部署到新机器人本体的通用策略。

Method: 提出语言-动作预训练（LAP）方法，将低级机器人动作直接用自然语言表示，使动作监督与预训练视觉-语言模型的输入输出分布对齐。无需学习分词器、昂贵标注或特定本体架构设计。

Result: LAP-3B在多个未见过的机器人和操作任务中达到超过50%的平均零样本成功率，比先前最强的VLA提升约2倍。同时支持高效适应和有利的扩展性。

Conclusion: LAP-3B是首个实现实质性零样本跨机器人本体迁移的VLA，统一了动作预测和视觉问答的共享语言-动作格式，通过联合训练获得额外收益。

Abstract: A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.

</details>


### [8] [Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots](https://arxiv.org/abs/2602.10561)
*Chongxi Meng,Da Zhao,Yifei Zhao,Minghao Zeng,Yanmin Zhou,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 提出一个异构模块化机器人的闭环自动化框架，涵盖从形态构建到自适应控制的全流程，包括分层规划器和GPU加速的退火方差MPPI控制器。


<details>
  <summary>Details</summary>
Motivation: 解决大规模异构模块化机器人重构中的状态空间爆炸问题，以及未知装配配置的自适应运动控制需求。

Method: 1. 移动机械臂处理异构功能模块（结构、关节、轮式模块）动态组装；2. 分层规划器：高层使用带类型惩罚项的双向启发式搜索生成模块处理序列，低层使用A*搜索计算最优执行轨迹；3. GPU加速的退火方差MPPI控制器，采用多阶段方差退火策略平衡全局探索和局部收敛。

Result: 1. 类型惩罚项对异构场景规划鲁棒性至关重要；2. 贪婪启发式比匈牙利启发式产生更低物理执行成本的计划；3. 退火方差MPPI在速度跟踪精度和控制频率上显著优于标准MPPI，实现50Hz实时控制；4. 框架验证了模块组装、机器人合并拆分和动态运动生成的完整流程。

Conclusion: 该框架成功实现了异构模块化机器人的全周期闭环自动化，从形态构建到自适应控制，为解决大规模异构重构和未知配置控制问题提供了有效解决方案。

Abstract: This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.

</details>


### [9] [Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning](https://arxiv.org/abs/2602.10594)
*Runze Tang,Penny Sweetser*

Main category: cs.RO

TL;DR: SFCrP方法通过场景流预测模型和流裁剪点云条件策略，利用人类视频减少机器人演示需求，在跨具身学习和空间泛化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习需要大量机器人演示，成本高昂。现有方法使用流作为中间表示来利用人类视频，但存在三个问题：1) 流通常关注物体或特定点，无法描述交互运动；2) 仅依赖流难以泛化到仅有人类视频的场景；3) 基于场景观察的条件策略可能过拟合训练任务，削弱流指示的泛化能力。

Method: 提出SFCrP框架，包含两个核心组件：1) SFCr（跨具身学习的场景流预测模型），从机器人和人类视频中学习并预测任意点轨迹；2) FCrP（流和裁剪点云条件策略），遵循流的一般运动模式，同时基于观察调整动作以实现精确任务执行。

Result: 方法在各种真实世界任务设置中优于现有最先进基线，同时在仅有人类视频的场景中展现出强大的空间和实例泛化能力。

Conclusion: SFCrP通过结合场景流预测和条件策略，有效解决了模仿学习中人类视频利用不足和泛化能力有限的问题，显著减少了机器人演示需求并提升了跨具身学习性能。

Abstract: Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.

</details>


### [10] [Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion](https://arxiv.org/abs/2602.10610)
*Chongxun Wang,Zikang Shen,Apoorav Rathore,Akanimoh Udombeh,Harrison Teng,Fangzhou Xia*

Main category: cs.RO

TL;DR: 该论文提出了一个基于非线性模型的磁控胶囊机器人俯仰角控制框架，使用四线圈电磁阵列驱动，通过有限元模拟和模型预测控制实现快速稳定的俯仰调节，并融合惯性传感与视觉测量应对临床成像限制。


<details>
  <summary>Details</summary>
Motivation: 现有的磁控胶囊机器人系统大多忽略了俯仰角的控制，而俯仰自由度对于胶囊与倾斜胃壁的接触式交互至关重要。需要开发能够精确控制俯仰角的系统，以实现更有效的胃肠道诊断和治疗。

Method: 1. 使用四线圈电磁阵列驱动含有永磁体的可摄入胶囊机器人
2. 通过三维有限元模拟表征角度相关的磁力和扭矩，并嵌入控制导向的刚体俯仰模型
3. 设计带约束的模型预测控制器（MPC）调节俯仰角，同时考虑硬件电流和变化率限制
4. 采用扩展卡尔曼滤波器（EKF）融合惯性传感与间歇性视觉测量，实现稳定的闭环控制

Result: 1. 在柔性胃模拟表面实验中，实现了从水平和垂直配置的稳健俯仰重定向
2. 相比开关控制，实现了约3-5倍的更快稳定时间和减少的振荡运动
3. 当相机更新率从30Hz降至1Hz时，仍能保持稳定的闭环控制，模拟临床实际成像限制
4. 验证了有限元信息MPC与传感器融合策略的有效性

Conclusion: 该研究建立了有限元信息MPC与传感器融合作为可扩展的俯仰调节策略，为受控对接和未来多自由度胶囊运动奠定了基础，推动了磁控胶囊机器人在胃肠道诊断和治疗中的应用。

Abstract: Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.

</details>


### [11] [Free-Flying Crew Cooperative Robots on the ISS: A Joint Review of Astrobee, CIMON, and Int-Ball Operations](https://arxiv.org/abs/2602.10686)
*Seiko Piotr Yamaguchi,Andres Mora Vargas,Till Eisenberg,Christian Rogon,Tatsuya Yamamoto,Shona Inoue,Christoph Kössl,Brian Coltin,Trey Smith,Jose V. Benavides*

Main category: cs.RO

TL;DR: 对国际空间站上三种自由飞行机器人（Astrobee、CIMON、Int-Ball）的首次联合分析，总结了从设计到在轨运行的全生命周期经验教训


<details>
  <summary>Details</summary>
Motivation: 随着自由飞行机器人在载人航天任务中日益重要，需要总结NASA、DLR和JAXA三个机构开发的不同机器人的共同经验，为未来机器人开发提供指导

Method: 由三个机器人开发与运营团队成员共同撰写，对Astrobee、CIMON、Int-Ball进行详细比较分析，包括目标、设计和在轨操作等方面

Result: 尽管机器人起源和设计理念不同，但在开发和运营过程中出现了各种趋同现象，识别出了从设计到在轨运行的全生命周期共同经验教训

Conclusion: 总结的经验教训可作为未来自由飞行机器人开发的设计建议，促进载人航天任务中机器人辅助技术的发展

Abstract: Intra-vehicular free-flying robots are anticipated to support various work in human spaceflight while working side-by-side with astronauts. Such example of robots includes NASA's Astrobee, DLR's CIMON, and JAXA's Int-Ball, which are deployed on the International Space Station. This paper presents the first joint analyses of these robot's shared experiences, co-authored by their development and operation team members. Despite the different origins and design philosophies, the development and operations of these platforms encountered various convergences. Hence, this paper presents a detailed overview of these robots, presenting their objectives, design, and onboard operations. Hence, joint lessons learned across the lifecycle are presented, from design to on-orbit operations. These lessons learned are anticipated to serve for future development and research as design recommendations.

</details>


### [12] [3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot](https://arxiv.org/abs/2602.10688)
*Jin Zhou,Chongxun Wang,Zikang Shen,Fangzhou Xia*

Main category: cs.RO

TL;DR: 提出了一种紧凑的3D打印软胶囊机器人，采用磁性涂层替代传统内部磁铁，保留完整内部腔体用于医疗载荷，实现了稳定双向滚动、全向转向和越障能力。


<details>
  <summary>Details</summary>
Motivation: 传统磁性胶囊机器人在两端嵌入笨重的永磁体，减少了约10-20毫米可用腔体空间，限制了功能模块的集成。需要一种能保留完整内部空间的新型胶囊机器人设计。

Method: 采用3D打印软胶囊机器人，表面涂覆硅胶-磁性复合材料替代内部磁铁。通过编程的NSSN/SNNS磁极分布提供强各向异性和可靠扭矩生成，实现稳定运动控制。

Result: 胶囊机器人实现了稳定双向滚动、全向转向、7.5度斜坡爬升和5毫米突起跨越。当胶囊处磁场达到至少0.3 mT时能维持滚动运动，对应30毫米有效驱动深度。

Conclusion: 涂层基胶囊机器人设计保留了完整内部腔体，改善了可吞咽性，为可靠临床部署奠定了基础。未来将通过材料优化和闭环反馈系统进一步提升性能和可操作性。

Abstract: Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.

</details>


### [13] [A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner](https://arxiv.org/abs/2602.10702)
*Alejandro Mendoza Barrionuevo,Dame Seck Diop,Alejandro Casado Pérez,Daniel Gutiérrez Reina,Sergio L. Toral Marín,Samuel Yanes Luis*

Main category: cs.RO

TL;DR: GuadalPlanner：一个统一的路径规划架构，将高层决策与车辆特定控制解耦，支持算法在不同抽象级别和部署环境中的一致性评估


<details>
  <summary>Details</summary>
Motivation: 自主车辆信息路径规划算法的评估常受限于碎片化的执行流程以及仿真与真实世界部署之间的可移植性问题

Method: 提出统一架构，通过GuadalPlanner实现，定义规划、感知和车辆执行之间的标准化接口，基于ROS2、MAVLink和MQTT等机器人技术构建

Result: 验证了相同算法逻辑可在完全仿真环境、软件在环配置和物理自主车辆中使用相同的执行流程部署，并在自主水面车辆上进行水质监测的实际部署验证

Conclusion: GuadalPlanner提供了一个开放可扩展的研究工具，支持离散图基环境和可互换规划策略，解决了路径规划算法评估的一致性和可移植性问题

Abstract: The evaluation of informative path planning algorithms for autonomous vehicles is often hindered by fragmented execution pipelines and limited transferability between simulation and real-world deployment. This paper introduces a unified architecture that decouples high-level decision-making from vehicle-specific control, enabling algorithms to be evaluated consistently across different abstraction levels without modification. The proposed architecture is realized through GuadalPlanner, which defines standardized interfaces between planning, sensing, and vehicle execution. It is an open and extensible research tool that supports discrete graph-based environments and interchangeable planning strategies, and is built upon widely adopted robotics technologies, including ROS2, MAVLink, and MQTT. Its design allows the same algorithmic logic to be deployed in fully simulated environments, software-in-the-loop configurations, and physical autonomous vehicles using an identical execution pipeline. The approach is validated through a set of experiments, including real-world deployment on an autonomous surface vehicle performing water quality monitoring with real-time sensor feedback.

</details>


### [14] [Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs](https://arxiv.org/abs/2602.10703)
*Martijn B. J. Brummelhuis,Nathan F. Lepora,Salua Hamaza*

Main category: cs.RO

TL;DR: 无人机使用双机械臂形态和动量观测器，通过物理接触盲测屋顶倾斜度，实现30.5度倾斜表面的鲁棒着陆


<details>
  <summary>Details</summary>
Motivation: 城市环境中无人机需要在屋顶着陆，但传统视觉或声学传感方法受天气和表面材料影响，测量不可靠。需要一种能准确检测屋顶倾斜度的新方法。

Method: 提出新型无人机机械臂形态：双机械臂空中操纵器，具有全方位3D工作空间和扩展范围。基于动量扭矩观测器开发本体感知接触检测和定位策略，通过物理交互盲测倾斜表面。

Result: 飞行实验验证了该方法，在倾斜度高达30.5度的表面上实现鲁棒着陆，在9个不同倾斜角度的实验中平均倾斜估计误差为2.87度。

Conclusion: 提出的双机械臂无人机形态和基于动量观测器的接触检测策略，能够通过物理交互准确推断倾斜表面角度，为城市环境中无人机在复杂屋顶上的可靠着陆提供了有效解决方案。

Abstract: Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.

</details>


### [15] [Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation](https://arxiv.org/abs/2602.10717)
*Songen Gu,Yunuo Cai,Tianyu Wang,Simo Wu,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出一个快速预测的视频条件动作框架，通过视频生成模型预测未来状态，结合对抗蒸馏加速生成，训练动作模型利用生成视频和真实观察纠正空间误差，提升机器人操作的时空一致性和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作系统缺乏预测环境演化的能力，导致错误和低效。视觉语言模型只能提供高层指导，无法显式预测未来状态；现有世界模型要么只能预测短时程，要么产生空间不一致的帧。

Method: 1) 选择并适配鲁棒的视频生成模型以确保可靠的未来预测；2) 应用对抗蒸馏实现快速、少步的视频生成；3) 训练动作模型，利用生成视频和真实观察来纠正空间误差。

Result: 实验表明该方法能产生时间连贯、空间准确的视频预测，直接支持精确操作，在具身一致性、空间指代能力和任务完成率方面显著优于现有基线。

Conclusion: 提出的框架通过可靠的未来预测和快速视频生成，有效提升了机器人操作的预测能力和执行精度，为机器人操作提供了新的解决方案。

Abstract: Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.

</details>


### [16] [Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -](https://arxiv.org/abs/2602.10904)
*Kenta Tabata,Ryosuke Oku,Jun Ito,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 开发并验证了一种仿生蝠鲼机器人，用于水下自主探索，采用扑翼运动推进以减少海底扰动并提高效率


<details>
  <summary>Details</summary>
Motivation: 传统螺旋桨推进方式容易扰动海底环境，仿生蝠鲼机器人的扑翼运动可以最小化对海底的干扰，提高推进效率，适用于需要生态友好型探索的水下环境

Method: 设计仿生蝠鲼机器人，采用伺服电机驱动的胸鳍实现扑翼运动，流线型控制箱减少流体阻力，基于树莓派3B的控制系统集成IMU和压力传感器进行实时监测和控制，在泳池中进行游泳和潜水能力测试

Result: 实验结果显示机器人能够实现稳定的游泳和潜水运动，PD控制效果良好，适用于水族馆、鱼苗养殖场等需要最小扰动和高效机动性的环境

Conclusion: 仿生机器人设计在生态监测和水下探索方面具有潜力，能够减少环境干扰并提高探索效率，为生态友好型水下机器人开发提供了新思路

Abstract: This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.

</details>


### [17] [Safe mobility support system using crowd mapping and avoidance route planning using VLM](https://arxiv.org/abs/2602.10910)
*Sena Saito,Kenta Tabata,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 提出结合视觉语言模型和高斯过程回归的框架，生成动态人群密度图，提升自主机器人在拥挤环境中的导航安全性


<details>
  <summary>Details</summary>
Motivation: 自主移动机器人能解决劳动力短缺问题，但在动态环境特别是拥挤区域的安全有效导航仍然具有挑战性，需要更好的方法来处理动态人群

Method: 提出新颖框架，整合视觉语言模型（VLM）和高斯过程回归（GPR），利用VLM识别抽象环境概念（如人群密度），通过GPR进行概率表示，生成动态人群密度图（抽象地图）

Result: 在大学校园的真实世界试验中，机器人成功生成了避开静态障碍物和动态人群的路径，提高了导航安全性和适应性

Conclusion: 该框架有效提升了自主机器人在动态拥挤环境中的导航能力，通过结合VLM的抽象概念识别和GPR的概率表示，实现了更安全、适应性更强的导航

Abstract: Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.

</details>


### [18] [Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces](https://arxiv.org/abs/2602.10961)
*Simone Orelli,Mirko Mizzoni,Antonio Franchi*

Main category: cs.RO

TL;DR: 该论文首次为受寄生力影响的浮动刚体系统提供了形式化的稳定性分析，填补了现有理论空白。


<details>
  <summary>Details</summary>
Motivation: 标准几何控制依赖于力-力矩解耦假设，但在许多航空平台中，控制力矩会自然诱导寄生力，导致该假设失效。虽然已有针对此类耦合系统的实验验证策略，但缺乏严格的理论稳定性认证。

Method: 引入一个规范模型，并构建基于李雅普诺夫方法的证明，建立悬停平衡点的局部指数稳定性。该分析明确处理了结构挑战——特别是诱导的非最小相位行为——这些挑战阻碍了标准级联论证的应用。

Result: 成功为受寄生力影响的通用浮动刚体类提供了首个形式化稳定性分析，证明了悬停平衡点的局部指数稳定性。

Conclusion: 该工作填补了理论空白，为受寄生力影响的耦合系统提供了严格的稳定性认证框架，克服了非最小相位行为带来的分析挑战。

Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.

</details>


### [19] [RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation](https://arxiv.org/abs/2602.10980)
*Yuhao Chen,Zhihao Zhan,Xiaoxin Lin,Zijian Song,Hao Liu,Qinhan Lyu,Yubo Zu,Xiao Chen,Zhiyuan Liu,Tao Pu,Tianshui Chen,Keze Wang,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: RADAR基准测试旨在解决VLA模型在现实世界评估中的不足，通过引入物理动态、空间推理任务和全自动3D评估来测试模型的真实泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型评估存在现实差距，模拟环境下的优秀表现掩盖了在多样化物理环境中的泛化能力不足。现有基准测试存在三个系统性缺陷：未能建模真实世界动态、忽视空间物理智能、缺乏可扩展的全自动评估。

Method: 提出RADAR基准测试，包含三个核心组件：1）物理动态原则性套件；2）专门测试空间推理和物理理解的任务；3）基于3D指标的全自动评估管道，无需人工监督。

Result: 应用RADAR对多个最先进的VLA模型进行审计，发现其表面能力下的严重脆弱性。在适度物理动态下性能急剧下降（3D IoU从0.261降至0.068），模型表现出有限的空间推理能力。

Conclusion: RADAR为VLA模型的可靠和可泛化的现实世界评估提供了必要基准，揭示了当前模型在真实物理环境中的局限性，为未来改进指明了方向。

Abstract: VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.

</details>


### [20] [Scaling World Model for Hierarchical Manipulation Policies](https://arxiv.org/abs/2602.10983)
*Qian Long,Yueze Wang,Jiaxi Song,Junbo Zhang,Peiyan Li,Wenxuan Wang,Yuqi Wang,Haoyang Li,Shaoxuan Xie,Guocai Yao,Hanbo Zhang,Xinlong Wang,Zhongyuan Wang,Xuguang Lan,Huaping Liu,Xinghang Li*

Main category: cs.RO

TL;DR: 提出VISTA框架，通过预训练世界模型进行视觉子任务分解，提升VLA模型在分布外场景下的泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在分布外场景下表现脆弱，特别是在真实机器人数据有限的情况下，存在泛化瓶颈

Method: 提出分层VLA框架，高层使用预训练世界模型将任务分解为带目标图像的子任务序列，低层VLA策略根据文本和视觉指导生成动作序列

Result: 在大量分布外场景中验证了视觉目标合成和分层VLA策略的有效性，相同结构VLA在新场景中的性能从14%提升到69%

Conclusion: 该方法明显优于先前基线，特别是在分布外场景中，通过世界模型生成的指导显著提升了VLA模型的泛化能力

Abstract: Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>


### [21] [ContactGaussian-WM: Learning Physics-Grounded World Model from Videos](https://arxiv.org/abs/2602.11021)
*Meizhong Wang,Wanxin Jin,Kun Cao,Lihua Xie,Yiguang Hong*

Main category: cs.RO

TL;DR: 提出ContactGaussian-WM，一种基于可微分物理的刚体世界模型，能够从稀疏的接触丰富视频序列中学习复杂物理规律，用于机器人规划与仿真。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据稀缺和复杂接触丰富动态运动条件下难以准确建模环境，需要开发能够直接从稀疏视觉观测中学习物理规律的世界模型。

Method: 包含两个核心组件：(1) 视觉外观和碰撞几何的统一高斯表示；(2) 端到端可微分学习框架，通过闭式物理引擎进行微分，从稀疏视觉观测推断物理属性。

Result: 在模拟和真实世界评估中，ContactGaussian-WM在复杂场景学习方面优于现有最先进方法，展现出强大的泛化能力。

Conclusion: 该框架在数据合成和实时模型预测控制等下游应用中具有实际效用，为机器人规划和仿真提供了有效的物理基础世界模型。

Abstract: Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.

</details>


### [22] [RISE: Self-Improving Robot Policy with Compositional World Model](https://arxiv.org/abs/2602.11075)
*Jiazhi Yang,Kunyang Lin,Jinwei Li,Wencong Zhang,Tianwei Lin,Longyan Wu,Zhizhong Su,Hao Zhao,Ya-Qin Zhang,Li Chen,Ping Luo,Xiangyu Yue,Hongyang Li*

Main category: cs.RO

TL;DR: RISE框架通过组合世界模型在想象空间中进行机器人强化学习，避免了物理交互成本，在动态操作任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在接触丰富和动态操作任务中仍然脆弱，而物理世界中的强化学习受到安全风险、硬件成本和环境重置的限制

Method: 提出RISE框架，包含组合世界模型：可控动力学模型预测多视角未来，进度价值模型评估想象结果，生成优势信号用于策略改进，在想象空间中进行闭环自改进

Result: 在三个真实世界任务中显著超越先前方法：动态积木分拣性能提升超过35%，背包打包提升45%，盒子关闭提升35%

Conclusion: RISE框架通过组合世界模型在想象空间中进行强化学习，有效解决了物理世界机器人学习的限制，显著提升了动态操作任务的性能

Abstract: Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.

</details>


### [23] [Digging for Data: Experiments in Rock Pile Characterization Using Only Proprioceptive Sensing in Excavation](https://arxiv.org/abs/2602.11082)
*Unal Artan,Martin Magnusson,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 提出一种仅使用轮式装载机挖掘时的本体感知数据（而非外部传感器）来估计碎石堆相对粒径的新方法，通过小波分析构建与岩石破碎程度成比例的特征。


<details>
  <summary>Details</summary>
Motivation: 在采矿和采石行业中，岩石破碎特征化是基础任务。传统方法依赖外部传感器（如摄像头或激光雷达），但本研究探索仅使用挖掘机本体感知数据来估计岩石粒径分布，提供更简单、更经济的解决方案。

Method: 使用小波分析从挖掘机挖掘时的惯性响应数据中构建特征。该方法假设不同碎石堆中挖掘时获得的小波特征比值近似等于两个碎石堆的平均粒径比值。在运营采石场使用18吨电池电动装载机进行全尺寸挖掘实验验证。

Result: 通过大量现场实验证明，从不同粒径分布的碎石堆挖掘数据构建的小波特征比值确实近似等于两个碎石堆的平均粒径比值。该方法生成的相对粒径估计与基于视觉的破碎分析工具和筛分采样材料的结果进行了比较验证。

Conclusion: 仅使用轮式装载机挖掘时的本体感知数据（惯性响应）就能有效估计碎石堆的相对粒径，为岩石破碎特征化提供了一种无需外部传感器的实用方法，在采矿和采石行业具有应用潜力。

Abstract: Characterization of fragmented rock piles is a fundamental task in the mining and quarrying industries, where rock is fragmented by blasting, transported using wheel loaders, and then sent for further processing. This field report studies a novel method for estimating the relative particle size of fragmented rock piles from only proprioceptive data collected while digging with a wheel loader. Rather than employ exteroceptive sensors (e.g., cameras or LiDAR sensors) to estimate rock particle sizes, the studied method infers rock fragmentation from an excavator's inertial response during excavation. This paper expands on research that postulated the use of wavelet analysis to construct a unique feature that is proportional to the level of rock fragmentation. We demonstrate through extensive field experiments that the ratio of wavelet features, constructed from data obtained by excavating in different rock piles with different size distributions, approximates the ratio of the mean particle size of the two rock piles. Full-scale excavation experiments were performed with a battery electric, 18-tonne capacity, load-haul-dump (LHD) machine in representative conditions in an operating quarry. The relative particle size estimates generated with the proposed sensing methodology are compared with those obtained from both a vision-based fragmentation analysis tool and from sieving of sampled materials.

</details>


### [24] [Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows](https://arxiv.org/abs/2602.11142)
*Shaswat Garg,Matin Moezzi,Brandon Da Silva*

Main category: cs.RO

TL;DR: NF-HIQL提出了一种基于归一化流的分层隐式Q学习框架，用表达能力更强的归一化流策略替代传统的高斯策略，在数据稀缺情况下显著提升了分层目标条件强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 传统分层目标条件强化学习（H-GCRL）在实际应用中面临数据效率低下和策略表达能力有限的问题，特别是在离线或数据稀缺的场景下。现有方法通常使用单峰高斯策略，难以建模复杂的多模态行为。

Method: 提出NF-HIQL框架，在分层结构的高层和低层都使用归一化流策略替代传统的高斯策略。该设计支持可处理的似然计算、高效采样，并能建模丰富的多模态行为。同时提供了理论保证，包括RealNVP策略的KL散度边界和PAC风格的样本效率结果。

Result: 在运动、运球和多步操作等多样化的长时程任务上进行评估，NF-HIQL始终优于先前的目标条件和分层基线方法，在有限数据下表现出更强的鲁棒性。

Conclusion: NF-HIQL证明了基于流架构在可扩展、数据高效的分层强化学习中的潜力，通过提升策略表达能力解决了传统方法在数据稀缺场景下的局限性。

Abstract: Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.

</details>
