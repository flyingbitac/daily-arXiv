{"id": "2601.00087", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00087", "abs": "https://arxiv.org/abs/2601.00087", "authors": ["Zhaoan Wang", "Junchao Li", "Mahdi Mohammad", "Shaoping Xiao"], "title": "Reinforcement learning with timed constraints for robotics motion planning", "comment": null, "summary": "Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized B\u00fcchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \\times 5$ grid-world formulated as an MDP, a $10 \\times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728MDP\u548cPOMDP\u4e2d\u5408\u6210\u6ee1\u8db3MITL\u65f6\u5e8f\u903b\u8f91\u7ea6\u675f\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u65f6\u95f4\u9650\u5236\u786e\u5b9a\u6027\u5e7f\u4e49B\u00fcchi\u81ea\u52a8\u673a\u548c\u5956\u52b1\u7ed3\u6784\u786e\u4fdd\u65f6\u95f4\u6b63\u786e\u6027\u3002", "motivation": "\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u590d\u6742\u65f6\u5e8f\u7ea6\u675f\u7684\u89c4\u5212\u5668\uff0c\u4f46\u5c06MITL\u65f6\u5e8f\u903b\u8f91\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u9762\u4e34\u968f\u673a\u52a8\u6001\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u6311\u6218\u3002", "method": "\u5c06MITL\u516c\u5f0f\u8f6c\u6362\u4e3a\u65f6\u95f4\u9650\u5236\u786e\u5b9a\u6027\u5e7f\u4e49B\u00fcchi\u81ea\u52a8\u673a\uff0c\u4e0e\u5e95\u5c42\u51b3\u7b56\u8fc7\u7a0b\u540c\u6b65\u6784\u5efa\u4ea7\u54c1\u65f6\u95f4\u6a21\u578b\uff0c\u8bbe\u8ba1\u7b80\u5355\u4f46\u8868\u8fbe\u529b\u5f3a\u7684\u5956\u52b1\u7ed3\u6784\uff0c\u4f7f\u7528Q-learning\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u4eff\u771f\u7814\u7a76\u4e2d\u9a8c\u8bc1\uff1a5\u00d75\u7f51\u683c\u4e16\u754cMDP\u300110\u00d710\u7f51\u683c\u4e16\u754cPOMDP\u548c\u529e\u516c\u5ba4\u670d\u52a1\u673a\u5668\u4eba\u573a\u666f\uff0c\u6846\u67b6\u80fd\u5b66\u4e60\u6ee1\u8db3\u4e25\u683c\u65f6\u95f4\u7ea6\u675f\u7684\u7b56\u7565\uff0c\u53ef\u6269\u5c55\u5230\u66f4\u5927\u72b6\u6001\u7a7a\u95f4\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u6709\u6548\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65f6\u95f4\u5173\u952e\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u53ef\u9760\u673a\u5668\u4eba\u89c4\u5212\u63d0\u4f9b\u4e86\u6f5c\u529b\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u5b66\u4e60\u6ee1\u8db3\u4e25\u683c\u65f6\u95f4\u7ea6\u675f\u7684\u7b56\u7565\uff0c\u5e76\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u4fdd\u6301\u6709\u6548\u6027\u3002"}}
{"id": "2601.00126", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00126", "abs": "https://arxiv.org/abs/2601.00126", "authors": ["Utkarsh A Mishra", "David He", "Yongxin Chen", "Danfei Xu"], "title": "Compositional Diffusion with Guided search for Long-Horizon Planning", "comment": "38 pages, 18 figures", "summary": "Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \\emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/", "AI": {"tldr": "CDGS\u901a\u8fc7\u5c06\u641c\u7d22\u5d4c\u5165\u6269\u6563\u53bb\u566a\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u7ec4\u5408\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6a21\u5f0f\u5e73\u5747\u95ee\u9898\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u3001\u5168\u666f\u56fe\u50cf\u548c\u957f\u89c6\u9891\u751f\u6210\u4e2d\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\u89c4\u5212\u3002", "motivation": "\u7ec4\u5408\u751f\u6210\u6a21\u578b\u5728\u5efa\u6a21\u957f\u65f6\u7a0b\u4efb\u52a1\u5206\u5e03\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5f53\u5c40\u90e8\u5206\u5e03\u662f\u591a\u6a21\u6001\u65f6\uff0c\u73b0\u6709\u7ec4\u5408\u65b9\u6cd5\u4f1a\u5e73\u5747\u4e0d\u517c\u5bb9\u7684\u6a21\u5f0f\uff0c\u5bfc\u81f4\u89c4\u5212\u65e2\u4e0d\u53ef\u884c\u4e5f\u4e0d\u8fde\u8d2f\u3002", "method": "CDGS\u5c06\u641c\u7d22\u76f4\u63a5\u5d4c\u5165\u6269\u6563\u53bb\u566a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u57fa\u4e8e\u79cd\u7fa4\u7684\u91c7\u6837\u63a2\u7d22\u5c40\u90e8\u6a21\u5f0f\u7ec4\u5408\uff0c\u4f7f\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u8fc7\u6ee4\u526a\u679d\u4e0d\u53ef\u884c\u5019\u9009\uff0c\u5e76\u901a\u8fc7\u91cd\u53e0\u6bb5\u95f4\u7684\u8fed\u4ee3\u91cd\u91c7\u6837\u5f3a\u5236\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "\u57287\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8fbe\u5230oracle\u6027\u80fd\uff0c\u4f18\u4e8e\u7f3a\u4e4f\u7ec4\u5408\u6027\u6216\u9700\u8981\u957f\u65f6\u7a0b\u8bad\u7ec3\u6570\u636e\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u8de8\u9886\u57df\u6cdb\u5316\u5230\u6587\u672c\u5f15\u5bfc\u7684\u5168\u666f\u56fe\u50cf\u548c\u957f\u89c6\u9891\u751f\u6210\u3002", "conclusion": "CDGS\u6709\u6548\u89e3\u51b3\u4e86\u7ec4\u5408\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6a21\u5f0f\u5e73\u5747\u95ee\u9898\uff0c\u901a\u8fc7\u5c40\u90e8\u5230\u5168\u5c40\u7684\u6d88\u606f\u4f20\u9012\u5b9e\u73b0\u4e86\u8fde\u8d2f\u7684\u957f\u65f6\u7a0b\u89c4\u5212\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.00238", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00238", "abs": "https://arxiv.org/abs/2601.00238", "authors": ["Julia Di", "Kenneth A. W. Hoffmann", "Tony G. Chen", "Tian-Ao Ren", "Mark R. Cutkosky"], "title": "SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks", "comment": "Paper accepted to IEEE Aerospace Conference 2026. This is a pre-print", "summary": "Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.", "AI": {"tldr": "SLAP\u7cfb\u7edf\u4e3a\u65e0\u4eba\u673a\u5728\u5782\u76f4\u6811\u5e72\u4e0a\u5b9e\u73b0\u8f7b\u67d4\u6816\u606f\u548c\u6545\u969c\u6062\u590d\uff0c\u901a\u8fc7\u89c6\u89c9\u68c0\u6d4b\u3001IMU\u6545\u969c\u68c0\u6d4b\u3001\u59ff\u6001\u63a7\u5236\u3001\u8fd1\u8ddd\u79bb\u5149\u5b66\u68c0\u6d4b\u548c\u5f39\u6027\u6293\u53d6\u5668\uff0c\u57281.2kg\u56db\u65cb\u7ffc\u4e0a\u5b9e\u73b075%\u6816\u606f\u6210\u529f\u7387\u548c100%\u6545\u969c\u6062\u590d\u3002", "motivation": "\u73b0\u6709\u5782\u76f4\u8868\u9762\u6816\u606f\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u8f7b\u91cf\u5316\u673a\u68b0\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7ea7\u96c6\u6210\uff0c\u4e14\u901a\u5e38\u9700\u8981\u9ad8\u901f\u3001\u6fc0\u8fdb\u7684\u7740\u9646\u64cd\u4f5c\uff0c\u5bf9\u642d\u8f7d\u654f\u611f\u7535\u5b50\u8bbe\u5907\u7684\u65e0\u4eba\u673a\u5b58\u5728\u5371\u9669\u3002\u9700\u8981\u4e00\u79cd\u9002\u5408\u8f83\u5927\u578b\u65e0\u4eba\u673a\u3001\u80fd\u8f7b\u67d4\u6816\u606f\u5e76\u80fd\u4ece\u6816\u606f\u5931\u8d25\u4e2d\u6062\u590d\u7684\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1SLAP\u7cfb\u7edf\uff0c\u5305\u542b\uff1a1) \u57fa\u4e8e\u89c6\u89c9\u7684\u6816\u606f\u70b9\u68c0\u6d4b\u5668\uff1b2) IMU\u57fa\u7840\u7684\u6816\u606f\u6545\u969c\u68c0\u6d4b\u5668\uff1b3) \u7528\u4e8e\u8f7b\u67d4\u6816\u606f\u7684\u59ff\u6001\u63a7\u5236\u5668\uff1b4) \u5149\u5b66\u8fd1\u8ddd\u79bb\u68c0\u6d4b\u7cfb\u7edf\uff1b5) \u57fa\u4e8e\u5e02\u552eslapbands\u7684\u5feb\u901f\u4e3b\u52a8\u5f39\u6027\u6293\u53d6\u5668\uff08\u5e26\u5fae\u523a\uff09\u3002\u57281.2kg\u5546\u7528\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u8fdb\u884c\u6539\u88c5\u548c\u9a8c\u8bc1\u3002", "result": "\u5ba4\u5185\u81ea\u4e3b\u98de\u884c\u5b9e\u9a8c\u4e2d\uff0c\u5728\u771f\u5b9e\u6a61\u6811\u6bb5\u4e0a\u8fdb\u884c20\u6b21\u98de\u884c\u6d4b\u8bd5\uff0c\u8fbe\u523075%\u7684\u6816\u606f\u6210\u529f\u7387\u3002\u57282\u6b21\u8bf1\u5bfc\u6545\u969c\u7684\u98de\u884c\u4e2d\uff0c\u5b9e\u73b0\u4e86100%\u7684\u6816\u606f\u6545\u969c\u6062\u590d\u7387\u3002", "conclusion": "SLAP\u7cfb\u7edf\u4e3a\u8f83\u5927\u578b\u65e0\u4eba\u673a\u63d0\u4f9b\u4e86\u4e00\u79cd\u80fd\u5728\u5782\u76f4\u6811\u5e72\u4e0a\u8f7b\u67d4\u6816\u606f\u5e76\u80fd\u4ece\u6816\u606f\u5931\u8d25\u4e2d\u6062\u590d\u7684\u6709\u6548\u65b9\u6848\uff0c\u901a\u8fc7\u7cfb\u7edf\u7ea7\u96c6\u6210\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.00271", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.00271", "abs": "https://arxiv.org/abs/2601.00271", "authors": ["Yuya Nagai", "Hiromitsu Nakamura", "Narito Shinmachi", "Yuta Higashizono", "Satoshi Ono"], "title": "Vehicle Painting Robot Path Planning Using Hierarchical Optimization", "comment": null, "summary": "In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8f66\u8f86\u55b7\u6f06\u8fc7\u7a0b\u4e2d\u591a\u673a\u68b0\u81c2\u7684\u8def\u5f84\u89c4\u5212\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u624b\u5de5\u8bbe\u8ba1\u8017\u65f6\u4e14\u96be\u4ee5\u5e94\u7528\u73b0\u6709\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u6280\u672f\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u8f66\u8f86\u751f\u4ea7\u5de5\u5382\u4e2d\uff0c\u55b7\u6f06\u8fc7\u7a0b\u9700\u8981\u591a\u4e2a\u673a\u68b0\u81c2\u540c\u65f6\u5bf9\u4f20\u9001\u5e26\u4e0a\u7684\u8f66\u8eab\u8fdb\u884c\u55b7\u6f06\u3002\u76ee\u524d\u55b7\u6f06\u8def\u5f84\u8bbe\u8ba1\u4ecd\u662f\u5de5\u7a0b\u5e08\u8017\u65f6\u7684\u624b\u52a8\u4efb\u52a1\uff0c\u9700\u8981\u81ea\u52a8\u5316\u548c\u7f29\u77ed\u8bbe\u8ba1\u65f6\u95f4\u3002\u55b7\u6f06\u8fc7\u7a0b\u7684\u72ec\u7279\u7ea6\u675f\u963b\u788d\u4e86\u4f20\u7edf\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u6280\u672f\uff08\u5982\u710a\u63a5\u4e2d\u4f7f\u7528\u7684\u6280\u672f\uff09\u7684\u76f4\u63a5\u5e94\u7528\u3002", "method": "\u5c06\u55b7\u6f06\u8def\u5f84\u8bbe\u8ba1\u5efa\u6a21\u4e3a\u5206\u5c42\u4f18\u5316\u95ee\u9898\uff1a\u4e0a\u5c42\u5b50\u95ee\u9898\u7c7b\u4f3c\u4e8e\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08VRP\uff09\uff0c\u8d1f\u8d23\u5206\u914d\u8f66\u8eab\u533a\u57df\u7ed9\u673a\u68b0\u81c2\uff1b\u4e0b\u5c42\u5b50\u95ee\u9898\u6d89\u53ca\u8be6\u7ec6\u7684\u8def\u5f84\u89c4\u5212\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5728\u6bcf\u5c42\u4f7f\u7528\u4e0d\u540c\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u53d8\u91cf\u8868\u793a\u3001\u7ea6\u675f\u3001\u4fee\u590d\u7b97\u5b50\u548c\u521d\u59cb\u5316\u8fc7\u7a0b\uff0c\u7075\u6d3b\u5904\u7406\u8f66\u8f86\u55b7\u6f06\u8fc7\u7a0b\u7279\u6709\u7684\u7ea6\u675f\u3002", "result": "\u5728\u4e09\u79cd\u5546\u7528\u8f66\u8f86\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u8bbe\u8ba1\u51fa\u6ee1\u8db3\u6240\u6709\u8f66\u8f86\u55b7\u6f06\u7ea6\u675f\u7684\u8def\u5f84\uff0c\u5176\u8d28\u91cf\u4e0e\u5de5\u7a0b\u5e08\u624b\u52a8\u521b\u5efa\u7684\u8def\u5f84\u76f8\u5f53\u3002", "conclusion": "\u8be5\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8f66\u8f86\u55b7\u6f06\u8def\u5f84\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u95ee\u9898\uff0c\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u6240\u6709\u5de5\u827a\u7ea6\u675f\u7684\u9ad8\u8d28\u91cf\u8def\u5f84\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bbe\u8ba1\u65f6\u95f4\uff0c\u4e3a\u8f66\u8f86\u751f\u4ea7\u5de5\u5382\u7684\u55b7\u6f06\u8fc7\u7a0b\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00275", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00275", "abs": "https://arxiv.org/abs/2601.00275", "authors": ["Dusan Nemec", "Gal Versano", "Itai Savin", "Vojtech Simak", "Juraj Kekelak", "Itzik Klein"], "title": "Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors", "comment": null, "summary": "Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.", "AI": {"tldr": "WiCHINS\uff1a\u4e00\u79cd\u7ed3\u5408\u8f6e\u8f7d\u548c\u8f66\u4f53\u60ef\u6027\u4f20\u611f\u5668\u7684\u8f6e\u5f0f\u5e95\u76d8\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728GNSS\u53d7\u9650\u6216\u5149\u7167\u6761\u4ef6\u5dee\u7684\u73af\u5883\u4e0b\u5b9e\u73b0\u7cbe\u786e\u7684\u7eaf\u60ef\u6027\u5bfc\u822a\u3002", "motivation": "\u5728GNSS\u4fe1\u53f7\u53d7\u9650\u6216\u5149\u7167\u6761\u4ef6\u6076\u52a3\u7684\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u81ea\u4e3b\u8f66\u8f86\u548c\u8f6e\u5f0f\u673a\u5668\u4eba\u7684\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u53ef\u80fd\u53ea\u80fd\u4f9d\u8d56\u60ef\u6027\u4f20\u611f\u5668\uff0c\u800c\u60ef\u6027\u6d4b\u91cf\u8bef\u5dee\u4f1a\u5bfc\u81f4\u968f\u65f6\u95f4\u6f02\u79fb\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faWiCHINS\u7cfb\u7edf\uff0c\u5c06\u8f6e\u8f7d\u60ef\u6027\u4f20\u611f\u5668\u4e0e\u8f66\u4f53\u60ef\u6027\u4f20\u611f\u5668\u7ed3\u5408\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u6bcf\u4e2a\u9636\u6bb5\u4f7f\u7528\u4e13\u7528\u7684\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u5145\u5206\u5229\u7528\u8f6e\u5b50\u548c\u8f66\u8eab\u4f4d\u7f6e\u7684\u4f18\u52bf\u8fdb\u884c\u4f30\u8ba1\u3002", "result": "\u4f7f\u75285\u4e2a\u60ef\u6027\u6d4b\u91cf\u5355\u5143\u3001\u603b\u8bb0\u5f55\u65f6\u95f4228.6\u5206\u949f\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e0e4\u4e2a\u5176\u4ed6\u60ef\u6027\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0c\u5e73\u5747\u4f4d\u7f6e\u8bef\u5dee\u4e3a11.4\u7c73\uff0c\u5360\u5e73\u5747\u884c\u9a76\u8ddd\u79bb\u76842.4%\uff08\u4f7f\u7528\u4e24\u4e2a\u8f6e\u5b50\u548c\u4e00\u4e2a\u8f66\u4f53\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u5bfc\u822a\uff0c\u6709\u52a9\u4e8e\u7f29\u5c0f\u7eaf\u60ef\u6027\u5bfc\u822a\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2601.00305", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00305", "abs": "https://arxiv.org/abs/2601.00305", "authors": ["Prashant Kumar", "Yukiyasu Domae", "Weiwei Wan", "Kensuke Harada"], "title": "Replaceable Bit-based Gripper for Picking Cluttered Food Items", "comment": null, "summary": "The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u66f4\u6362\u5939\u722a\u5934\u7684\u6293\u53d6\u7cfb\u7edf\uff0c\u7528\u4e8e\u5904\u7406\u6742\u4e71\u98df\u54c1\u5305\u88c5\u4e2d\u7684\u91cd\u91cf\u63a7\u5236\u95ee\u9898\uff0c\u9488\u5bf9\u9c91\u9c7c\u5b50\u548c\u610f\u5927\u5229\u9762\u4e24\u79cd\u67d4\u6027\u98df\u54c1\u8bbe\u8ba1\u4e86\u4e13\u7528\u5939\u722a\u5934\uff0c\u5b9e\u73b0\u4e8680%\u548c95%\u4ee5\u4e0a\u7684\u91cd\u91cf\u63a7\u5236\u7cbe\u5ea6\u3002", "motivation": "\u98df\u54c1\u5305\u88c5\u884c\u4e1a\u9762\u4e34\u5feb\u901f\u53d8\u5316\u7684\u98df\u54c1\u79cd\u7c7b\u548c\u91cd\u91cf\u5904\u7406\u9700\u6c42\uff0c\u7279\u522b\u662f\u4ece\u5355\u4ef6\u98df\u54c1\u5230\u67d4\u6027\u3001\u957f\u6761\u72b6\u3001\u6742\u4e71\u5806\u79ef\u7684\u98df\u54c1\u3002\u4f20\u7edf\u6293\u53d6\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u8fd9\u7c7b\u6742\u4e71\u98df\u54c1\u7684\u91cd\u91cf\u63a7\u5236\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u53ef\u66f4\u6362\u5939\u722a\u5934\u7684\u6293\u53d6\u7cfb\u7edf\uff0c\u5305\u62ec\u4e13\u7528\u98df\u54c1\u5939\u722a\u5934\uff08bits\uff09\u548c\u76ae\u5e26\u66f4\u6362\u7cfb\u7edf\u3002\u9488\u5bf9\u9c91\u9c7c\u5b50\uff08\u7c98\u6027\u9897\u7c92\u98df\u54c1\uff09\u548c\u610f\u5927\u5229\u9762\uff08\u957f\u6761\u72b6\u7c98\u6027\u6742\u4e71\u98df\u54c1\uff09\u4e24\u79cd\u4ee3\u8868\u6027\u98df\u54c1\u8bbe\u8ba1\u4e86\u4e13\u7528\u5939\u722a\u5934\uff0c\u5b9e\u73b0\u7279\u5b9a\u91cd\u91cf\u7684\u6293\u53d6\u548c\u6295\u653e\u3002", "result": "\u6293\u53d6\u7cfb\u7edf\u6210\u529f\u6293\u53d6\u4e86\u610f\u5927\u5229\u9762\u548c\u9c91\u9c7c\u5b50\uff0c\u91cd\u91cf\u63a7\u5236\u6295\u653e\u7cbe\u5ea6\u5206\u522b\u8d85\u8fc780%\u548c95%\u3002\u7cfb\u7edf\u8fd8\u5c55\u793a\u4e86\u5feb\u901f\u66f4\u6362\u4e0d\u540c\u5939\u722a\u5934\u7684\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u591a\u79cd\u98df\u54c1\u7c7b\u578b\u3002", "conclusion": "\u53ef\u66f4\u6362\u5939\u722a\u5934\u7684\u6293\u53d6\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5904\u7406\u6742\u4e71\u98df\u54c1\u5305\u88c5\u4e2d\u7684\u91cd\u91cf\u63a7\u5236\u95ee\u9898\uff0c\u9488\u5bf9\u4e0d\u540c\u98df\u54c1\u7279\u6027\u8bbe\u8ba1\u4e13\u7528\u5939\u722a\u5934\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u91cd\u91cf\u63a7\u5236\uff0c\u7cfb\u7edf\u5177\u6709\u5feb\u901f\u5207\u6362\u80fd\u529b\uff0c\u9002\u5408\u98df\u54c1\u5305\u88c5\u884c\u4e1a\u7684\u591a\u6837\u5316\u9700\u6c42\u3002"}}
{"id": "2601.00555", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00555", "abs": "https://arxiv.org/abs/2601.00555", "authors": ["Abu Hanif Muhammad Syarubany", "Farhan Zaki Rahmani", "Trio Widianto"], "title": "LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration", "comment": null, "summary": "This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u7aef\u5230\u7aef\u673a\u5668\u4eba\u63a2\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u5ba4\u5185\u8d2d\u7269\u4efb\u52a1\uff0c\u5728Gazebo\u4eff\u771f\u548c\u771f\u5b9e\u8d70\u5eca\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u901a\u8fc7\u8bed\u4e49\u5730\u56fe\u6784\u5efa\u548c\u6a21\u5757\u5316\u8fd0\u52a8\u63a7\u5236\u5b9e\u73b0\u591a\u5e97\u94fa\u5bfc\u822a\u548c\u7269\u54c1\u6293\u53d6\u3002", "motivation": "\u89e3\u51b3\u5ba4\u5185\u8d2d\u7269\u573a\u666f\u4e2d\u673a\u5668\u4eba\u81ea\u4e3b\u63a2\u7d22\u3001\u8bed\u4e49\u7406\u89e3\u548c\u4efb\u52a1\u6267\u884c\u7684\u95ee\u9898\uff0c\u901a\u8fc7LLM\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5230\u673a\u5668\u4eba\u52a8\u4f5c\u7684\u8f6c\u6362\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u548c\u53ef\u8c03\u8bd5\u6027\u3002", "method": "1) \u589e\u91cf\u6784\u5efa\u8f7b\u91cf\u7ea7\u8bed\u4e49\u5730\u56fe\uff0c\u68c0\u6d4b\u8def\u53e3\u6807\u8bc6\u724c\u5e76\u5b58\u50a8\u65b9\u5411-POI\u5173\u7cfb\uff1b2) \u4f7f\u7528AprilTags\u4f5c\u4e3a\u53ef\u91cd\u590d\u7684\u951a\u70b9\u8fdb\u884c\u5b9a\u4f4d\u548c\u5bf9\u9f50\uff1b3) LLM\u6839\u636e\u81ea\u7136\u8bed\u8a00\u8d2d\u7269\u8bf7\u6c42\u5728\u6bcf\u4e2a\u8def\u53e3\u751f\u6210\u7ea6\u675f\u79bb\u6563\u52a8\u4f5c\uff1b4) ROS\u6709\u9650\u72b6\u6001\u4e3b\u63a7\u5236\u5668\u901a\u8fc7\u95e8\u63a7\u6a21\u5757\u5316\u8fd0\u52a8\u57fa\u5143\u6267\u884c\u51b3\u7b56\u3002", "result": "\u96c6\u6210\u7cfb\u7edf\u80fd\u591f\u4ece\u7528\u6237\u6307\u4ee4\u5230\u591a\u5e97\u94fa\u5bfc\u822a\u548c\u7269\u54c1\u6293\u53d6\u6267\u884c\u7aef\u5230\u7aef\u4efb\u52a1\uff0c\u540c\u65f6\u901a\u8fc7\u57fa\u4e8e\u6587\u672c\u7684\u5730\u56fe\u548c\u8bb0\u5f55\u51b3\u7b56\u5386\u53f2\u4fdd\u6301\u6a21\u5757\u5316\u548c\u53ef\u8c03\u8bd5\u6027\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5747\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684LLM-based agentic exploration\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u5ba4\u5185\u8d2d\u7269\u4efb\u52a1\u7684\u7aef\u5230\u7aef\u6267\u884c\uff0c\u5c55\u793a\u4e86LLM\u5728\u673a\u5668\u4eba\u8bed\u4e49\u7406\u89e3\u548c\u51b3\u7b56\u4e2d\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u67b6\u6784\u548c\u53ef\u8c03\u8bd5\u6027\u3002"}}
{"id": "2601.00580", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.00580", "abs": "https://arxiv.org/abs/2601.00580", "authors": ["Kanghoon Lee", "Hyeonjun Kim", "Jiachen Li", "Jinkyoo Park"], "title": "Priority-Aware Multi-Robot Coverage Path Planning", "comment": "IEEE Robotics and Automation Letters, 8 pages, 10 figures", "summary": "Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f18\u5148\u7ea7\u611f\u77e5\u7684\u591a\u673a\u5668\u4eba\u8986\u76d6\u8def\u5f84\u89c4\u5212\uff08PA-MCPP\uff09\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6846\u67b6\u4f18\u5316\u4f18\u5148\u7ea7\u533a\u57df\u7684\u52a0\u6743\u5ef6\u8fdf\u548c\u603b\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edf\u591a\u673a\u5668\u4eba\u8986\u76d6\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u5047\u8bbe\u6240\u6709\u533a\u57df\u91cd\u8981\u6027\u76f8\u540c\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u67d0\u4e9b\u533a\u57df\u9700\u8981\u4f18\u5148\u8986\u76d6\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u4f18\u5148\u7ea7\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u8d2a\u5fc3\u533a\u57df\u5206\u914d\u7ed3\u5408\u5c40\u90e8\u641c\u7d22\u548c\u57fa\u4e8e\u751f\u6210\u6811\u7684\u8def\u5f84\u89c4\u5212\uff1b2\uff09\u65af\u5766\u7eb3\u6811\u5f15\u5bfc\u7684\u5269\u4f59\u8986\u76d6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6807\u51c6MCPP\u57fa\u7ebf\u663e\u8457\u964d\u4f4e\u4e86\u4f18\u5148\u7ea7\u52a0\u6743\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u603b\u5b8c\u6210\u65f6\u95f4\uff0c\u4e14\u80fd\u6709\u6548\u901a\u8fc7\u8c03\u6574\u4f18\u5148\u7ea7\u6743\u91cd\u63a7\u5236\u533a\u57df\u8986\u76d6\u884c\u4e3a\u3002", "conclusion": "PA-MCPP\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u4f18\u5148\u7ea7\u533a\u57df\u8986\u76d6\u95ee\u9898\uff0c\u5728\u51cf\u5c11\u4f18\u5148\u7ea7\u52a0\u6743\u5ef6\u8fdf\u7684\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u591a\u673a\u5668\u4eba\u8986\u76d6\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00610", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00610", "abs": "https://arxiv.org/abs/2601.00610", "authors": ["Mehdi Heydari Shahna", "Pauli Mustalahti", "Jouni Mattila"], "title": "Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework", "comment": null, "summary": "Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5927\u578b\u673a\u5668\u4eba\u7684\u5b89\u5168\u76ee\u6807\u5230\u8fbe\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u89c4\u5212\u3001\u6df1\u5ea6\u5b66\u4e60\u5efa\u6a21\u548c\u9c81\u68d2\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u786e\u4fdd\u5728\u6613\u6ed1\u5730\u5f62\u4e0a\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u9700\u8981\u5927\u91cf\u63a2\u7d22\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\uff0c\u671f\u95f4\u884c\u4e3a\u53ef\u80fd\u4e0d\u5b89\u5168\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u5730\u5f62\u4e0a\u8fd0\u884c\u7684\u5927\u578b\u673a\u5668\u4eba\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u5b89\u5168\u7684\u76ee\u6807\u5230\u8fbe\u63a7\u5236\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u7cfb\u7edf\u5206\u89e3\u4e3a\u7d27\u5bc6\u8026\u5408\u7684\u529f\u80fd\u6a21\u5757\uff1a1)\u5b9e\u65f6\u89c6\u89c9\u59ff\u6001\u4f30\u8ba1\u63d0\u4f9b\u51c6\u786e\u673a\u5668\u4eba\u72b6\u6001\uff1b2)\u5f3a\u5316\u5b66\u4e60\u8fd0\u52a8\u89c4\u5212\u5668\u751f\u6210\u5e73\u6ed1\u8fd0\u52a8\u6307\u4ee4\uff1b3)\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6355\u83b7\u673a\u5668\u4eba\u590d\u6742\u52a8\u529b\u5b66\uff1b4)\u57fa\u4e8e\u6a21\u578b\u7684\u9c81\u68d2\u81ea\u9002\u5e94\u63a7\u5236\u5668\u786e\u4fdd\u8f6e\u5b50\u8ddf\u8e2a\u8fd0\u52a8\u6307\u4ee4\uff1b5)\u6570\u5b66\u5b89\u5168\u76d1\u7763\u5668\u76d1\u63a7\u673a\u5668\u4eba\u5b89\u5168\u3002", "result": "\u8be5\u6846\u67b6\u4fdd\u8bc1\u4e86\u9a71\u52a8\u7cfb\u7edf\u7684\u5747\u5300\u6307\u6570\u7a33\u5b9a\u6027\u548c\u6574\u4e2a\u64cd\u4f5c\u7684\u5b89\u5168\u6027\u3002\u57286000\u516c\u65a4\u673a\u5668\u4eba\u4e0a\u7684\u4e0d\u540c\u573a\u666f\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u5757\u5316\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5927\u578b\u673a\u5668\u4eba\u5728\u4e0d\u7a33\u5b9a\u5730\u5f62\u4e0a\u5b89\u5168\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u6280\u672f\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2601.00614", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.00614", "abs": "https://arxiv.org/abs/2601.00614", "authors": ["Mogens Plessen"], "title": "From 2D to 3D terrain-following area coverage path planning", "comment": "6 pages, 10 figures, 1 table", "summary": "An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u7ef4\u5730\u5f62\u8ddf\u968f\u7684\u533a\u57df\u8986\u76d6\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u591a\u6761\u76f8\u90bb\u8def\u5f84\uff0c\u5728\u4fdd\u6301\u673a\u68b0\u5de5\u4f5c\u5bbd\u5ea6\u95f4\u8ddd\u7684\u540c\u65f6\uff0c\u5728\u7279\u5b9a\u5de5\u4f5c\u9ad8\u5ea6\u4e0a\u8ddf\u968f\u5730\u5f62\u8d77\u4f0f\u3002", "motivation": "\u5728\u519c\u4e1a\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u5728\u590d\u6742\u4e09\u7ef4\u5730\u5f62\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u533a\u57df\u8986\u76d6\u4f5c\u4e1a\uff0c\u800c\u4f20\u7edf\u7684\u4e8c\u7ef4\u8def\u5f84\u89c4\u5212\u65e0\u6cd5\u9002\u5e94\u5730\u5f62\u8d77\u4f0f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8ddf\u968f\u5730\u5f62\u7684\u4e09\u7ef4\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528\u9006\u8ddd\u79bb\u52a0\u6743\u65b9\u6cd5\u751f\u6210\u5747\u5300\u95f4\u8ddd\u7684\u9ad8\u7a0b\u6570\u636e\uff0c\u7ed3\u5408\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\uff0c\u751f\u6210\u591a\u6761\u76f8\u90bb\u8def\u5f84\uff0c\u8fd9\u4e9b\u8def\u5f84\u5728\u4fdd\u6301\u673a\u68b0\u5de5\u4f5c\u5bbd\u5ea6\u95f4\u8ddd\u7684\u540c\u65f6\uff0c\u5728\u7279\u5b9a\u5de5\u4f5c\u9ad8\u5ea6\u4e0a\u8ddf\u968f\u5730\u5f62\u8d77\u4f0f\u3002", "result": "\u7b97\u6cd5\u5728\u5b9e\u9645\u519c\u4e1a\u573a\u666f\u7684\u4e09\u7ef4\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u6210\u529f\u751f\u6210\u4e86\u9002\u5e94\u5730\u5f62\u8d77\u4f0f\u7684\u533a\u57df\u8986\u76d6\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u4e09\u7ef4\u5730\u5f62\u8ddf\u968f\u533a\u57df\u8986\u76d6\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u5730\u5f62\uff0c\u76f8\u6bd4\u4e8c\u7ef4\u7b97\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\uff0c\u5728\u519c\u4e1a\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.00675", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.00675", "abs": "https://arxiv.org/abs/2601.00675", "authors": ["Tony Lee", "Andrew Wagenmaker", "Karl Pertsch", "Percy Liang", "Sergey Levine", "Chelsea Finn"], "title": "RoboReward: General-Purpose Vision-Language Reward Models for Robotics", "comment": null, "summary": "A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \\textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \\emph{negative examples data augmentation} pipeline that generates calibrated \\emph{negatives} and \\emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86RoboReward\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u5956\u52b1\u5efa\u6a21\u80fd\u529b\uff0c\u5e76\u8bad\u7ec3\u4e864B/8B\u53c2\u6570\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u9886\u57df\uff0c\u83b7\u53d6\u6709\u6548\u7684\u5956\u52b1\u51fd\u6570\u901a\u5e38\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u6216\u624b\u5de5\u8bbe\u8ba1\u7684\u76ee\u6807\u51fd\u6570\uff0c\u8fd9\u65e2\u8017\u65f6\u53c8\u8106\u5f31\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\u4f5c\u4e3a\u81ea\u52a8\u5956\u52b1\u6a21\u578b\uff0c\u4f46\u5b83\u4eec\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002", "method": "1) \u6784\u5efaRoboReward\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u57fa\u4e8eOpen X-Embodiment\u548cRoboArena\u7684\u5927\u89c4\u6a21\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\uff1b2) \u63d0\u51fa\u8d1f\u6837\u672c\u6570\u636e\u589e\u5f3a\u6d41\u7a0b\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u91cd\u6807\u6ce8\u548c\u65f6\u95f4\u88c1\u526a\u751f\u6210\u6821\u51c6\u7684\u8d1f\u6837\u672c\u548c\u63a5\u8fd1\u6210\u529f\u6837\u672c\uff1b3) \u8bad\u7ec34B\u548c8B\u53c2\u6570\u7684\u89c6\u89c9\u8bed\u8a00\u5956\u52b1\u6a21\u578b\u3002", "result": "1) \u8bc4\u4f30\u663e\u793a\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u5747\uff0c\u6709\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\uff1b2) \u8bad\u7ec3\u76844B/8B\u53c2\u6570\u6a21\u578b\u5728\u77ed\u89c6\u754c\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u4f18\u4e8e\u66f4\u5927\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff1b3) 8B\u53c2\u6570\u5956\u52b1\u6a21\u578b\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u4e2d\u5927\u5e45\u4f18\u4e8eGemini Robotics-ER 1.5\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u4eba\u5de5\u63d0\u4f9b\u5956\u52b1\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u673a\u5668\u4eba\u5956\u52b1\u51fd\u6570\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u7684RoboReward\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u8bad\u7ec3\u7684\u5c0f\u578b\u6a21\u578b\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u81ea\u52a8\u5956\u52b1\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.00702", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00702", "abs": "https://arxiv.org/abs/2601.00702", "authors": ["Samuel Cerezo", "Javier Civera"], "title": "DefVINS: Visual-Inertial Odometry for Deformable Scenes", "comment": "4 figures, 3 tables. Submitted to RA-L", "summary": "Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.", "AI": {"tldr": "DefVINS\u662f\u4e00\u4e2a\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u521a\u6027IMU\u951a\u5b9a\u72b6\u6001\u4e0e\u975e\u521a\u6027\u53d8\u5f62\u56fe\u5206\u79bb\uff0c\u89e3\u51b3\u53ef\u53d8\u5f62\u573a\u666f\u4e2d\u7684VIO\u95ee\u9898\uff0c\u5229\u7528\u53ef\u89c2\u6d4b\u6027\u5206\u6790\u6307\u5bfc\u53d8\u5f62\u6fc0\u6d3b\u7b56\u7565\uff0c\u63d0\u9ad8\u975e\u521a\u6027\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u53ef\u53d8\u5f62\u573a\u666f\u8fdd\u53cd\u4e86\u4f20\u7edf\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u7684\u521a\u6027\u5047\u8bbe\uff0c\u5bfc\u81f4\u5bb9\u6613\u8fc7\u62df\u5408\u5c40\u90e8\u975e\u521a\u6027\u8fd0\u52a8\u6216\u5728\u53d8\u5f62\u4e3b\u5bfc\u89c6\u89c9\u89c6\u5dee\u65f6\u4ea7\u751f\u4e25\u91cd\u6f02\u79fb\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u975e\u521a\u6027\u73af\u5883\u4e0b\u7684\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\u3002", "method": "\u63d0\u51faDefVINS\u6846\u67b6\uff0c\u5c06\u521a\u6027IMU\u951a\u5b9a\u72b6\u6001\u4e0e\u975e\u521a\u6027\u53d8\u5f62\u56fe\u8868\u793a\u7684\u53d8\u5f62\u5206\u79bb\u3002\u7cfb\u7edf\u5148\u7528\u6807\u51c6VIO\u7a0b\u5e8f\u521d\u59cb\u5316\uff0c\u56fa\u5b9a\u91cd\u529b\u3001\u901f\u5ea6\u548cIMU\u504f\u5dee\uff0c\u7136\u540e\u6839\u636e\u4f30\u8ba1\u6761\u4ef6\u9010\u6b65\u6fc0\u6d3b\u975e\u521a\u6027\u81ea\u7531\u5ea6\u3002\u5305\u542b\u53ef\u89c2\u6d4b\u6027\u5206\u6790\u6765\u8868\u5f81\u60ef\u6027\u6d4b\u91cf\u5982\u4f55\u7ea6\u675f\u521a\u6027\u8fd0\u52a8\uff0c\u5e76\u6307\u5bfc\u57fa\u4e8e\u6761\u4ef6\u7684\u6fc0\u6d3b\u7b56\u7565\u4ee5\u9632\u6b62\u5728\u6fc0\u52b1\u4e0d\u8db3\u65f6\u7684\u75c5\u6001\u66f4\u65b0\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u5c06\u60ef\u6027\u7ea6\u675f\u4e0e\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u7684\u53d8\u5f62\u6fc0\u6d3b\u76f8\u7ed3\u5408\uff0c\u5728\u975e\u521a\u6027\u73af\u5883\u4e0b\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002\u53ef\u89c2\u6d4b\u6027\u5206\u6790\u663e\u793a\u60ef\u6027\u6d4b\u91cf\u4f7f\u539f\u672c\u4e0d\u53ef\u89c2\u6d4b\u7684\u6a21\u5f0f\u5728\u5b58\u5728\u53d8\u5f62\u65f6\u53d8\u5f97\u53ef\u8bc6\u522b\u3002", "conclusion": "DefVINS\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u521a\u6027\u72b6\u6001\u548c\u975e\u521a\u6027\u53d8\u5f62\uff0c\u7ed3\u5408\u60ef\u6027\u7ea6\u675f\u548c\u53ef\u89c2\u6d4b\u6027\u6307\u5bfc\u7684\u6fc0\u6d3b\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u53d8\u5f62\u573a\u666f\u4e2d\u7684\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5728\u975e\u521a\u6027\u73af\u5883\u4e0b\u7684\u4f30\u8ba1\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.00754", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.00754", "abs": "https://arxiv.org/abs/2601.00754", "authors": ["Maria Teresa Parreira", "Isabel Neto", "Filipa Rocha", "Wendy Ju"], "title": "Calling for Backup: How Children Navigate Successive Robot Communication Failures", "comment": null, "summary": "How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u513f\u7ae5\u5bf9\u673a\u5668\u4eba\u91cd\u590d\u9519\u8bef\u7684\u53cd\u5e94\uff0c\u53d1\u73b0\u513f\u7ae5\u4e0e\u6210\u4eba\u65e2\u6709\u76f8\u4f3c\u8c03\u6574\u884c\u4e3a\uff0c\u4e5f\u6709\u66f4\u591a\u8131\u79bb\u4e92\u52a8\u884c\u4e3a\uff0c\u4f46\u9519\u8bef\u4e0d\u5f71\u54cd\u513f\u7ae5\u5bf9\u673a\u5668\u4eba\u7684\u611f\u77e5\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u8ba8\u6210\u4eba\u5bf9\u8fde\u7eed\u673a\u5668\u4eba\u9519\u8bef\u7684\u53cd\u5e94\uff0c\u4f46\u513f\u7ae5\u5bf9\u6b64\u7684\u53cd\u5e94\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u513f\u7ae5\u5bf9\u673a\u5668\u4eba\u793e\u4ea4\u9519\u8bef\u548c\u6027\u80fd\u9519\u8bef\u7684\u53cd\u5e94\uff0c\u7279\u522b\u662f\u91cd\u590d\u5bf9\u8bdd\u9519\u8bef\u3002", "method": "\u7814\u7a76\u590d\u5236\u4e86Liu\u7b49\u4eba\u7684\u8fde\u7eed\u673a\u5668\u4eba\u5931\u8d25\u8303\u5f0f\uff0c\u62db\u52df59\u540d8-10\u5c81\u513f\u7ae5\u53c2\u4e0e\u3002\u513f\u7ae5\u4e0e\u673a\u5668\u4eba\u4e92\u52a8\uff0c\u673a\u5668\u4eba\u8fde\u7eed\u4e09\u6b21\u65e0\u6cd5\u7406\u89e3\u4ed6\u4eec\u7684\u63d0\u793a\u3002\u901a\u8fc7\u89c6\u9891\u8bb0\u5f55\u548c\u5206\u6790\u513f\u7ae5\u7684\u884c\u4e3a\u53cd\u5e94\u3002", "result": "\u513f\u7ae5\u53cd\u5e94\u4e0e\u6210\u4eba\u65e2\u6709\u76f8\u4f3c\u4e5f\u6709\u5dee\u5f02\uff1a\u76f8\u4f3c\u4e4b\u5904\u5305\u62ec\u8c03\u6574\u63d0\u793a\u3001\u6539\u53d8\u8bed\u6c14\u3001\u60c5\u7eea\u5316\u975e\u8bed\u8a00\u53cd\u5e94\u589e\u52a0\uff1b\u5dee\u5f02\u5728\u4e8e\u513f\u7ae5\u8868\u73b0\u51fa\u66f4\u591a\u8131\u79bb\u884c\u4e3a\uff08\u5982\u6682\u65f6\u5ffd\u7565\u673a\u5668\u4eba\u6216\u5bfb\u6c42\u6210\u4eba\u5e2e\u52a9\uff09\u3002\u9519\u8bef\u4e0d\u5f71\u54cd\u513f\u7ae5\u5bf9\u673a\u5668\u4eba\u7684\u611f\u77e5\u3002", "conclusion": "\u513f\u7ae5\u5bf9\u673a\u5668\u4eba\u9519\u8bef\u8868\u73b0\u51fa\u66f4\u7075\u6d3b\u7684\u5bf9\u8bdd\u671f\u671b\uff0c\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u4e3a\u5e74\u8f7b\u7528\u6237\u8bbe\u8ba1\u66f4\u6709\u6548\u3001\u66f4\u9002\u5408\u53d1\u5c55\u9636\u6bb5\u7684\u673a\u5668\u4eba\u4ea4\u4e92\u7cfb\u7edf\u3002"}}
