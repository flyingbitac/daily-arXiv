<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 27]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Trust in LLM-controlled Robotics: a Survey of Security Threats, Defenses and Challenges](https://arxiv.org/abs/2601.02377)
*Xinyu Huang,Shyam Karthick V B,Taozhao Chen,Mitch Bryson,Thomas Chaffey,Huaming Chen,Kim-Kwang Raymond Choo,Ian R. Manchester*

Main category: cs.RO

TL;DR: 本文系统综述了LLM控制机器人的安全威胁与防御策略，重点关注"具身鸿沟"带来的独特安全挑战，提出了攻击向量分类和防御机制分析，为安全可靠的LLM机器人系统发展提供路线图。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)与机器人技术的融合带来了革命性进步，但同时也引入了关键的安全漏洞。这种"具身鸿沟"——LLM的抽象推理与机器人物理、上下文依赖特性之间的不匹配——导致了独特的安全威胁，现有基于文本LLM的安全解决方案往往无法应对这些威胁，因为恶意输出可能表现为危险的物理行动而非仅仅有害文本。

Method: 采用系统性综述方法，总结LLM控制机器人的新兴威胁格局和相应防御策略。具体包括：1) 提出全面的攻击向量分类学，涵盖越狱攻击、后门攻击、多模态提示注入等主题；2) 分析并分类各种防御机制，包括形式化安全规范、运行时执行、多LLM监督和提示强化；3) 回顾用于评估这些具身系统鲁棒性的关键数据集和基准测试。

Result: 通过综合当前研究，本文系统梳理了LLM机器人安全领域的关键问题，建立了攻击和防御的分类框架，识别了现有解决方案的不足，特别是针对具身系统独特安全挑战的应对策略。

Conclusion: LLM控制机器人的安全需要上下文感知的安全解决方案，本文为开发安全、可靠、可信的LLM控制机器人系统提供了基础路线图，强调了应对"具身鸿沟"带来的独特安全挑战的紧迫性。

Abstract: The integration of Large Language Models (LLMs) into robotics has revolutionized their ability to interpret complex human commands and execute sophisticated tasks. However, such paradigm shift introduces critical security vulnerabilities stemming from the ''embodiment gap'', a discord between the LLM's abstract reasoning and the physical, context-dependent nature of robotics. While security for text-based LLMs is an active area of research, existing solutions are often insufficient to address the unique threats for the embodied robotic agents, where malicious outputs manifest not merely as harmful text but as dangerous physical actions. In this work, we present a systematic survey, summarizing the emerging threat landscape and corresponding defense strategies for LLM-controlled robotics. Specifically, we discuss a comprehensive taxonomy of attack vectors, covering topics such as jailbreaking, backdoor attacks, and multi-modal prompt injection. In response, we analyze and categorize a range of defense mechanisms, from formal safety specifications and runtime enforcement to multi-LLM oversight and prompt hardening. Furthermore, we review key datasets and benchmarks used to evaluate the robustness of these embodied systems. By synthesizing current research, this work highlights the urgent need for context-aware security solutions and provides a foundational roadmap for the development of safe, secure, and reliable LLM-controlled robotics.

</details>


### [2] [Modeling the Mental World for Embodied AI: A Comprehensive Review](https://arxiv.org/abs/2601.02378)
*Biyuan Liu,Daigang Xu,Lei Jiang,Wenjun Guo,Ping Chen*

Main category: cs.RO

TL;DR: 本文系统综述了具身AI中的心理世界模型研究，构建了完整的理论框架，区分了心理世界模型与物理世界模型的本质差异，定义了心理元素表示范式，分析了心智理论推理方法，并整合了神经符号混合架构趋势和评估基准。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI在虚拟化身、可穿戴设备和机器人系统中的深入应用，研究核心挑战已从物理环境交互转向社会互动的准确理解。传统物理世界模型无法满足社会智能建模需求，而心理世界模型作为人类内部心理状态的结构化表示，是实现自然人机协作和动态社会适应的关键认知基础。当前MWM研究面临概念框架碎片化、推理机制脱节、评估与实践分离等瓶颈。

Method: 本文系统综合了100多项权威研究，首次构建了完整的MWM理论框架：1）明确区分MWM与PWM的本质差异；2）通过两种心理元素表示范式系统定义MWM关键组件；3）全面分析两种核心ToM推理范式及19种ToM方法；4）阐明神经符号混合架构的融合趋势；5）综合26个ToM评估基准。

Result: 建立了具身AI中MWM研究的系统化理论框架，为心理世界模型提供了清晰的概念界定和分类体系，整合了不同心智理论推理方法，明确了技术路径和应用场景，为评估与实践的结合提供了基准参考。

Conclusion: 该综述工作通过构建完整的MWM理论框架，解决了当前研究的碎片化和脱节问题，推动了具身AI中社会智能建模的深入发展，有助于促进具身智能体融入人类社会，推动人机协同交互的深度发展。

Abstract: As the application of Embodied AI Agents in avatars, wearable devices, and robotic systems continues to deepen, their core research challenges have gradually shifted from physical environment interaction to the accurate understanding of social interactions. Traditional physical world models (PWM) focus on quantifiable physical attributes such as space and motion, failing to meet the needs of social intelligence modeling. In contrast, the Mental World Model (MWM), as a structured representation of humans' internal mental states, has become the critical cognitive foundation for embodied agents to achieve natural human-machine collaboration and dynamic social adaptation. However, current MWM research faces significant bottlenecks: such as fragmented conceptual framework with vague boundaries between MWM and PWM, disjointed reasoning mechanisms for the technical pathways and applicable scenarios of different Theory of Mind (ToM) reasoning paradigms, and detachment between evaluation and practice.
  To address these issues, this review systematically synthesizes over 100 authoritative studies to provide a comprehensive overview of MWM research for embodied AI. Its core contributions are threefold: First, it constructs a complete theoretical framework for MWM for the first time. Specifically, it distinguishes the essential differences between MWM and PWMs. Second, it systematically defines the key components of MWM through two paradigms for mental element representation. Third, it comprehensively analyzes two core ToM reasoning paradigms with 19 ToM methods. Finally, it also clarifies the integration trend of neuro-symbolic hybrid architectures, and synthesizes 26 ToM evaluation benchmarks. This work aims to promote the integration of embodied agents into human society and advance the in-depth development of human-machine collaborative interaction.

</details>


### [3] [InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456)
*Junhao Cai,Zetao Cai,Jiafei Cao,Yilun Chen,Zeyu He,Lei Jiang,Hang Li,Hengjie Li,Yang Li,Yufei Liu,Yanan Lu,Qi Lv,Haoxiang Ma,Jiangmiao Pang,Yu Qiao,Zherui Qiu,Yanqing Shen,Xu Shi,Yang Tian,Bolun Wang,Hanqing Wang,Jiaheng Wang,Tai Wang,Xueyuan Wei,Chao Wu,Yiman Xie,Boyang Xing,Yuqiang Yang,Yuyin Yang,Qiaojun Yu,Feng Yuan,Jia Zeng,Jingjing Zhang,Shenghan Zhang,Shi Zhang,Zhuoma Zhaxi,Bowen Zhou,Yuanzhen Zhou,Yunsong Zhou,Hongrui Zhu,Yangkun Zhu,Yuchen Zhu*

Main category: cs.RO

TL;DR: InternVLA-A1是一个结合语义理解和动态预测能力的视觉-语言-动作模型，采用统一的Mixture-of-Transformers架构，在12个真实世界机器人任务中显著优于现有领先模型。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型虽然擅长语义理解，但缺乏对物理世界动态的推理能力；而基于视频预测的世界模型又缺乏语义基础且对预测错误敏感。需要将语义理解与动态预测能力相结合。

Method: 采用统一的Mixture-of-Transformers架构，协调三个专家模块：场景理解、视觉预测生成和动作执行，通过统一的掩码自注意力机制交互。基于InternVL3和Qwen3-VL构建2B和3B参数规模的模型，在混合合成-真实数据集上进行预训练。

Result: 在12个真实世界机器人任务和仿真基准测试中，显著优于pi0和GR00T N1.5等领先模型，日常任务提升14.5%，动态场景（如传送带分拣）提升40%-73.3%。

Conclusion: InternVLA-A1成功地将语义理解与动态预测能力相结合，通过统一的架构和混合训练策略，在机器人任务中实现了卓越的性能，为VLA模型的发展提供了新方向。

Abstract: Prevalent Vision-Language-Action (VLA) models are typically built upon Multimodal Large Language Models (MLLMs) and demonstrate exceptional proficiency in semantic understanding, but they inherently lack the capability to deduce physical world dynamics. Consequently, recent approaches have shifted toward World Models, typically formulated via video prediction; however, these methods often suffer from a lack of semantic grounding and exhibit brittleness when handling prediction errors. To synergize semantic understanding with dynamic predictive capabilities, we present InternVLA-A1. This model employs a unified Mixture-of-Transformers architecture, coordinating three experts for scene understanding, visual foresight generation, and action execution. These components interact seamlessly through a unified masked self-attention mechanism. Building upon InternVL3 and Qwen3-VL, we instantiate InternVLA-A1 at 2B and 3B parameter scales. We pre-train these models on hybrid synthetic-real datasets spanning InternData-A1 and Agibot-World, covering over 533M frames. This hybrid training strategy effectively harnesses the diversity of synthetic simulation data while minimizing the sim-to-real gap. We evaluated InternVLA-A1 across 12 real-world robotic tasks and simulation benchmark. It significantly outperforms leading models like pi0 and GR00T N1.5, achieving a 14.5\% improvement in daily tasks and a 40\%-73.3\% boost in dynamic settings, such as conveyor belt sorting.

</details>


### [4] [Learning and Optimizing the Efficacy of Spatio-Temporal Task Allocation under Temporal and Resource Constraints](https://arxiv.org/abs/2601.02505)
*Jiazhen Liu,Glen Neville,Jinwoo Park,Sonia Chernova,Harish Ravichandar*

Main category: cs.RO

TL;DR: STEAM问题框架结合了异构多机器人系统的任务分配、调度和路径规划，E-ITAGS算法通过主动学习特征-效能映射来优化任务性能并满足时空约束


<details>
  <summary>Details</summary>
Motivation: 复杂多机器人任务需要异构团队在严格约束下联合优化任务分配、调度和路径规划，现有基于特征的方法通常采用二元成功-失败模型，无法准确建模任务性能

Method: 提出STEAM问题框架，引入特征-效能映射来量化任务性能；开发E-ITAGS算法，通过可实性感知的主动学习模块学习特征-效能映射，同时优化任务分配、调度和路径规划

Result: E-ITAGS相比基线方法能生成更高效能的任务分配，同时满足资源和时空约束；主动学习方法样本高效，建立了数据与计算效率之间的原则性权衡

Conclusion: STEAM框架和E-ITAGS算法为复杂多机器人任务提供了有效的解决方案，通过可实性感知的主动学习克服了特征-效能映射难以指定的挑战

Abstract: Complex multi-robot missions often require heterogeneous teams to jointly optimize task allocation, scheduling, and path planning to improve team performance under strict constraints. We formalize these complexities into a new class of problems, dubbed Spatio-Temporal Efficacy-optimized Allocation for Multi-robot systems (STEAM). STEAM builds upon trait-based frameworks that model robots using their capabilities (e.g., payload and speed), but goes beyond the typical binary success-failure model by explicitly modeling the efficacy of allocations as trait-efficacy maps. These maps encode how the aggregated capabilities assigned to a task determine performance. Further, STEAM accommodates spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan). To solve STEAM problems, we contribute a novel algorithm named Efficacy-optimized Incremental Task Allocation Graph Search (E-ITAGS) that simultaneously optimizes task performance and respects time budgets by interleaving task allocation, scheduling, and path planning. Motivated by the fact that trait-efficacy maps are difficult, if not impossible, to specify, E-ITAGS efficiently learns them using a realizability-aware active learning module. Our approach is realizability-aware since it explicitly accounts for the fact that not all combinations of traits are realizable by the robots available during learning. Further, we derive experimentally-validated bounds on E-ITAGS' suboptimality with respect to efficacy. Detailed numerical simulations and experiments using an emergency response domain demonstrate that E-ITAGS generates allocations of higher efficacy compared to baselines, while respecting resource and spatio-temporal constraints. We also show that our active learning approach is sample efficient and establishes a principled tradeoff between data and computational efficiency.

</details>


### [5] [Making Infeasible Tasks Feasible: Planning to Reconfigure Disconnected 3D Environments with Movable Objects](https://arxiv.org/abs/2601.02645)
*Samarth Kalluraya,Yiannis Kantaros*

Main category: cs.RO

TL;DR: BRiDGE：针对3D环境中目标区域不可达的问题，提出基于采样的规划器，通过移动物体搭建桥梁连接分离的支撑面


<details>
  <summary>Details</summary>
Motivation: 现有路径规划器假设目标区域可达，但在实际3D环境中，支撑面可能因高度差、孔洞或横向分离而断开，导致目标区域无法到达。需要让机器人能够与环境互动，重新排列可移动物体来创建新的可穿越连接

Method: 开发BRiDGE（基于块的3D几何环境断开连接重构）采样规划器，在机器人和物体配置上增量构建树，计算指定移动哪些物体、放置位置和顺序的可行计划，同时考虑可移动物体数量有限。引入非均匀采样策略加速规划

Result: 方法具有概率完备性，通过大量数值和硬件实验验证了有效性

Conclusion: BRiDGE能够有效解决3D环境中目标区域不可达的问题，通过移动物体搭建桥梁连接分离的支撑面，扩展了导航与可移动物体交互的能力

Abstract: Several planners have been developed to compute dynamically feasible, collision-free robot paths from an initial to a goal configuration. A key assumption in these works is that the goal region is reachable; an assumption that often fails in practice when environments are disconnected. Motivated by this limitation, we consider known 3D environments comprising objects, also called blocks, that form distinct navigable support surfaces (planes), and that are either non-movable (e.g., tables) or movable (e.g., boxes). These surfaces may be mutually disconnected due to height differences, holes, or lateral separations. Our focus is on tasks where the robot must reach a goal region residing on an elevated plane that is unreachable. Rather than declaring such tasks infeasible, an effective strategy is to enable the robot to interact with the environment, rearranging movable objects to create new traversable connections; a problem known as Navigation Among Movable Objects (NAMO). Existing NAMO planners typically address 2D environments, where obstacles are pushed aside to clear a path. These methods cannot directly handle the considered 3D setting; in such cases, obstacles must be placed strategically to bridge these physical disconnections. We address this challenge by developing BRiDGE (Block-based Reconfiguration in Disconnected 3D Geometric Environments), a sampling-based planner that incrementally builds trees over robot and object configurations to compute feasible plans specifying which objects to move, where to place them, and in what order, while accounting for a limited number of movable objects. To accelerate planning, we introduce non-uniform sampling strategies. We show that our method is probabilistically complete and we provide extensive numerical and hardware experiments validating its effectiveness.

</details>


### [6] [Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search](https://arxiv.org/abs/2601.02649)
*Jiangyi Fang,Bowen Zhou,Haotian Wang,Xin Zhu,Leye Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合前瞻信息的在线3D装箱方法，通过模型预测控制和蒙特卡洛树搜索框架，在物流系统中应对短期分布偏移问题，显著提升了装箱效率。


<details>
  <summary>Details</summary>
Motivation: 在线3D装箱在物流中至关重要，但现有深度强化学习方法在面对现实世界中不同批次货物到达导致的短期分布偏移时，性能会显著下降。作者认为现代物流系统中可用的短期前瞻信息是缓解这一问题的关键。

Method: 将带有前瞻包裹的在线3D装箱问题建模为模型预测控制问题，采用蒙特卡洛树搜索框架求解。设计了动态探索先验来自动平衡学习到的RL策略和鲁棒随机策略，并设计了辅助奖励来惩罚个体放置造成的长期空间浪费。

Result: 在真实数据集上的大量实验表明，该方法在分布偏移下获得超过10%的性能提升，在线部署平均改进4%，最佳情况下超过8%，始终优于现有最先进基线方法。

Conclusion: 该框架通过有效利用前瞻信息和平衡策略探索，显著提升了在线3D装箱在分布偏移下的鲁棒性和性能，证明了前瞻信息在现代物流系统中的重要性。

Abstract: Online 3D Bin Packing (3D-BP) with robotic arms is crucial for reducing transportation and labor costs in modern logistics. While Deep Reinforcement Learning (DRL) has shown strong performance, it often fails to adapt to real-world short-term distribution shifts, which arise as different batches of goods arrive sequentially, causing performance drops. We argue that the short-term lookahead information available in modern logistics systems is key to mitigating this issue, especially during distribution shifts. We formulate online 3D-BP with lookahead parcels as a Model Predictive Control (MPC) problem and adapt the Monte Carlo Tree Search (MCTS) framework to solve it. Our framework employs a dynamic exploration prior that automatically balances a learned RL policy and a robust random policy based on the lookahead characteristics. Additionally, we design an auxiliary reward to penalize long-term spatial waste from individual placements. Extensive experiments on real-world datasets show that our method consistently outperforms state-of-the-art baselines, achieving over 10\% gains under distributional shifts, 4\% average improvement in online deployment, and up to more than 8\% in the best case--demonstrating the effectiveness of our framework.

</details>


### [7] [Learning to Nudge: A Scalable Barrier Function Framework for Safe Robot Interaction in Dense Clutter](https://arxiv.org/abs/2601.02686)
*Haixin Jin,Nikhil Uday Shinde,Soofiyan Atar,Hongzhan Yu,Dylan Hirsch,Sicun Gao,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出Dense Contact Barrier Functions(DCBF)方法，通过学习可组合的对象中心函数来隐式捕获物理交互中的安全约束，解决密集杂乱环境中机器人操作的安全问题。


<details>
  <summary>Details</summary>
Motivation: 机器人在日常密集杂乱环境中操作时，与周围物体的物理接触不可避免。传统安全框架将接触视为不安全，限制机器人只能避免碰撞，这限制了它们在密集日常环境中的功能。随着物体数量增加，基于模型的安全操作方法计算上变得不可行，而学习方法通常将安全性与特定任务绑定，难以迁移到新任务。

Method: 引入Dense Contact Barrier Functions(DCBF)方法，通过离线学习与少量物体交互的可组合、对象中心函数，隐式捕获物理交互产生的安全约束。该方法绕过显式建模多物体动态的复杂性，学习到的DCBF在运行时可以跨任意物体集组合，产生单个全局安全过滤器。

Result: 在密集杂乱环境的模拟实验中验证了该方法，证明其能够实现无碰撞导航和在合适环境中的安全、接触丰富的交互。该方法线性扩展，无需重新训练即可跨任务迁移。

Conclusion: DCBF方法为机器人在密集杂乱环境中的安全操作提供了一种可扩展、可迁移的解决方案，通过学习隐式安全约束函数，克服了传统方法在计算复杂性和任务特异性方面的限制。

Abstract: Robots operating in everyday environments must navigate and manipulate within densely cluttered spaces, where physical contact with surrounding objects is unavoidable. Traditional safety frameworks treat contact as unsafe, restricting robots to collision avoidance and limiting their ability to function in dense, everyday settings. As the number of objects grows, model-based approaches for safe manipulation become computationally intractable; meanwhile, learned methods typically tie safety to the task at hand, making them hard to transfer to new tasks without retraining. In this work we introduce Dense Contact Barrier Functions(DCBF). Our approach bypasses the computational complexity of explicitly modeling multi-object dynamics by instead learning a composable, object-centric function that implicitly captures the safety constraints arising from physical interactions. Trained offline on interactions with a few objects, the learned DCBFcomposes across arbitrary object sets at runtime, producing a single global safety filter that scales linearly and transfers across tasks without retraining. We validate our approach through simulated experiments in dense clutter, demonstrating its ability to enable collision-free navigation and safe, contact-rich interaction in suitable settings.

</details>


### [8] [Analysis of Various Manipulator Configurations Based on Multi-Objective Black-Box Optimization](https://arxiv.org/abs/2601.02704)
*Kento Kawaharazuka,Keita Yoneda,Takahiro Hattori,Shintaro Inoue,Kei Okada*

Main category: cs.RO

TL;DR: 本文通过多目标优化方法研究6-7自由度机械臂的最优结构设计，从末端执行器可达性和关节扭矩两个角度进行分析，为未来机械臂设计提供见解。


<details>
  <summary>Details</summary>
Motivation: 虽然已有多种6-7自由度机械臂被开发，但其关节配置和连杆长度比通常基于经验确定。随着机器人基础模型的发展，需要支持这些模型的各种机械臂，但现有机械臂结构各不相同。因此需要探讨机械臂的最优结构。

Method: 采用多目标优化方法，从末端执行器可达性和关节扭矩两个角度对机械臂结构进行优化。分析现有机械臂结构在优化采样结果中的位置。

Result: 通过优化分析，确定了现有机械臂结构在优化空间中的位置，揭示了不同结构设计的性能表现。

Conclusion: 研究为未来机械臂设计提供了重要见解，通过多目标优化方法可以指导更优的机械臂结构设计，平衡可达性和扭矩性能。

Abstract: Various 6-degree-of-freedom (DOF) and 7-DOF manipulators have been developed to date. Over a long history, their joint configurations and link length ratios have been determined empirically. In recent years, the development of robotic foundation models has become increasingly active, leading to the continuous proposal of various manipulators to support these models. However, none of these manipulators share exactly the same structure, as the order of joints and the ratio of link lengths differ among robots. Therefore, in order to discuss the optimal structure of a manipulator, we performed multi-objective optimization from the perspectives of end-effector reachability and joint torque. We analyze where existing manipulator structures stand within the sampling results of the optimization and provide insights for future manipulator design.

</details>


### [9] [Loop Closure using AnyLoc Visual Place Recognition in DPV-SLAM](https://arxiv.org/abs/2601.02723)
*Wenzheng Zhang,Kazuki Adachi,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 提出一种改进DPV-SLAM中闭环检测性能的方法，用基于学习的AnyLoc视觉位置识别技术替代传统的词袋模型，并引入自适应相似度阈值机制


<details>
  <summary>Details</summary>
Motivation: 闭环检测对视觉SLAM的精度和一致性至关重要，传统词袋模型依赖手工特征，在视角和光照变化下不够鲁棒，需要手动调参

Method: 1) 用基于深度特征表示的AnyLoc技术替代传统词袋模型进行闭环检测；2) 提出自适应机制动态调整相似度阈值，无需手动调参

Result: 在室内外数据集上的实验表明，该方法在闭环检测准确性和鲁棒性方面显著优于原始DPV-SLAM

Conclusion: 该方法为现代SLAM系统提供了实用且可扩展的闭环检测性能增强方案

Abstract: Loop closure is crucial for maintaining the accuracy and consistency of visual SLAM. We propose a method to improve loop closure performance in DPV-SLAM. Our approach integrates AnyLoc, a learning-based visual place recognition technique, as a replacement for the classical Bag of Visual Words (BoVW) loop detection method. In contrast to BoVW, which relies on handcrafted features, AnyLoc utilizes deep feature representations, enabling more robust image retrieval across diverse viewpoints and lighting conditions. Furthermore, we propose an adaptive mechanism that dynamically adjusts similarity threshold based on environmental conditions, removing the need for manual tuning. Experiments on both indoor and outdoor datasets demonstrate that our method significantly outperforms the original DPV-SLAM in terms of loop closure accuracy and robustness. The proposed method offers a practical and scalable solution for enhancing loop closure performance in modern SLAM systems.

</details>


### [10] [Optimizing Control-Friendly Trajectories with Self-Supervised Residual Learning](https://arxiv.org/abs/2601.02738)
*Kexin Guo,Zihan Yang,Yuhang Liu,Jindou Jia,Xiang Yu*

Main category: cs.RO

TL;DR: 提出自监督残差学习和轨迹优化框架，通过混合动力学模型学习未知动态效应，优化轨迹以最小化残差物理影响，实现四旋翼无人机敏捷飞行的精确跟踪


<details>
  <summary>Details</summary>
Motivation: 现实物理系统难以精确建模，复杂机器人系统存在残余物理效应，导致跟踪激进轨迹时精度不足，需要解决控制器合成中的残差物理问题

Method: 1. 自监督残差学习：将闭环模型中的未知动态效应作为标称动力学的残差学习，形成混合模型；2. 使用轨迹级数据和解析梯度实现学习；3. 开发轨迹优化器，计算最优参考轨迹并最小化沿轨迹的残差物理

Result: 通过混合动力学模型，优化器能够输出可精确跟踪的激进运动，四旋翼无人机敏捷飞行实验验证了方法的有效性

Conclusion: 提出的自监督残差学习和轨迹优化框架能够有效处理复杂机器人系统中的未知动态效应，生成对后续控制层级友好的轨迹，实现激进运动的高精度跟踪

Abstract: Real-world physics can only be analytically modeled with a certain level of precision for modern intricate robotic systems. As a result, tracking aggressive trajectories accurately could be challenging due to the existence of residual physics during controller synthesis. This paper presents a self-supervised residual learning and trajectory optimization framework to address the aforementioned challenges. At first, unknown dynamic effects on the closed-loop model are learned and treated as residuals of the nominal dynamics, jointly forming a hybrid model. We show that learning with analytic gradients can be achieved using only trajectory-level data while enjoying accurate long-horizon prediction with an arbitrary integration step size. Subsequently, a trajectory optimizer is developed to compute the optimal reference trajectory with the residual physics along it minimized. It ends up with trajectories that are friendly to the following control level. The agile flight of quadrotors illustrates that by utilizing the hybrid dynamics, the proposed optimizer outputs aggressive motions that can be precisely tracked.

</details>


### [11] [Unified Meta-Representation and Feedback Calibration for General Disturbance Estimation](https://arxiv.org/abs/2601.02762)
*Zihan Yang,Jindou Jia,Meng Wang,Yuhang Liu,Kexin Guo,Xiang Yu*

Main category: cs.RO

TL;DR: 该论文提出了一个基于元学习和反馈校准在线适应的通用扰动估计框架，用于处理机器人应用中的非结构性时变扰动。


<details>
  <summary>Details</summary>
Motivation: 现代机器人应用中精确控制面临未知时变扰动的挑战。现有基于元学习的方法需要共享环境结构表示，缺乏对现实非结构性扰动的灵活性，且表示误差和分布偏移会导致预测精度严重下降。

Method: 通过从过去观测的有限时间窗口中提取特征，学习无需预定义结构假设的统一表示来捕捉一般非结构性扰动。在线适应过程通过状态反馈机制校准，以减弱来自表示和泛化能力限制的学习残差。

Result: 理论分析表明在线学习误差和扰动估计误差可以同时收敛。通过统一元表示，该框架能有效估计多种快速变化的扰动，四旋翼飞行实验验证了其有效性。

Conclusion: 该工作提出了一个通用扰动估计框架，结合元学习和反馈校准在线适应，能够有效处理非结构性时变扰动，为机器人精确控制提供了新方法。

Abstract: Precise control in modern robotic applications is always an open issue due to unknown time-varying disturbances. Existing meta-learning-based approaches require a shared representation of environmental structures, which lack flexibility for realistic non-structural disturbances. Besides, representation error and the distribution shifts can lead to heavy degradation in prediction accuracy. This work presents a generalizable disturbance estimation framework that builds on meta-learning and feedback-calibrated online adaptation. By extracting features from a finite time window of past observations, a unified representation that effectively captures general non-structural disturbances can be learned without predefined structural assumptions. The online adaptation process is subsequently calibrated by a state-feedback mechanism to attenuate the learning residual originating from the representation and generalizability limitations. Theoretical analysis shows that simultaneous convergence of both the online learning error and the disturbance estimation error can be achieved. Through the unified meta-representation, our framework effectively estimates multiple rapidly changing disturbances, as demonstrated by quadrotor flight experiments. See the project page for video, supplementary material and code: https://nonstructural-metalearn.github.io.

</details>


### [12] [Advancing Assistive Robotics: Multi-Modal Navigation and Biophysical Monitoring for Next-Generation Wheelchairs](https://arxiv.org/abs/2601.02766)
*Md. Anowar Hossain,Mohd. Ehsanul Hoque*

Main category: cs.RO

TL;DR: 本文提出了一种多模态电动轮椅控制系统，集成了四种控制接口（操纵杆、语音、手势、眼电图）和连续生命体征监测，旨在提高残疾患者的独立性和护理人员的实时监护能力。


<details>
  <summary>Details</summary>
Motivation: 电动轮椅对于肌萎缩侧索硬化症、中风后偏瘫、痴呆相关行动障碍等患者至关重要。现有系统缺乏多模态控制和实时健康监测的集成，无法同时满足患者独立性和护理人员监护需求。

Method: 开发了集成四种控制接口（操纵杆、语音、手势、EOG）的多模态控制系统，结合连续生命体征监测（心率变异性、血氧饱和度、皮肤温度）。采用两点校准方法，通过加密云传输实现实时数据共享，开发Android应用供护理人员接收警报。

Result: 传感器校准误差：心率≤2 bpm，皮肤温度≤0.5°C，血氧饱和度≤1%。20名参与者执行500条室内导航指令，识别准确率：操纵杆99%，语音97±2%，手势95±3%，平均闭环延迟20±0.5毫秒。系统符合ISO 7176-31和IEC 80601-2-78安全标准。

Conclusion: 该原型系统通过集成多模态移动控制和云健康监测，解决了辅助机器人关键技术挑战，为未来自适应机器学习增强奠定了基础，同时提高了患者独立性和护理监护能力。

Abstract: Assistive electric-powered wheelchairs (EPWs) have become essential mobility aids for people with disabilities such as amyotrophic lateral sclerosis (ALS), post-stroke hemiplegia, and dementia-related mobility impairment. This work presents a novel multi-modal EPW control system designed to prioritize patient needs while allowing seamless switching between control modes. Four complementary interfaces, namely joystick, speech, hand gesture, and electrooculography (EOG), are integrated with a continuous vital sign monitoring framework measuring heart rate variability, oxygen saturation (SpO2), and skin temperature. This combination enables greater patient independence while allowing caregivers to maintain real-time supervision and early intervention capability.
  Two-point calibration of the biophysical sensors against clinical reference devices resulted in root mean square errors of at most 2 bpm for heart rate, 0.5 degree Celsius for skin temperature, and 1 percent for SpO2. Experimental evaluation involved twenty participants with mobility impairments executing a total of 500 indoor navigation commands. The achieved command recognition accuracies were 99 percent for joystick control, 97 percent plus or minus 2 percent for speech, and 95 percent plus or minus 3 percent for hand gesture, with an average closed-loop latency of 20 plus or minus 0.5 milliseconds. Caregivers receive real-time alerts through an Android application following encrypted cloud transmission of physiological data. By integrating multi-modal mobility control with cloud-enabled health monitoring and reporting latency and energy budgets, the proposed prototype addresses key challenges in assistive robotics, contributes toward compliance with ISO 7176-31 and IEC 80601-2-78 safety standards, and establishes a foundation for future adaptive machine learning enhancements.

</details>


### [13] [M-SEVIQ: A Multi-band Stereo Event Visual-Inertial Quadruped-based Dataset for Perception under Rapid Motion and Challenging Illumination](https://arxiv.org/abs/2601.02777)
*Jingcheng Cao,Chaoran Xiong,Jianmin Song,Shang Yan,Jiachen Liu,Ling Pei*

Main category: cs.RO

TL;DR: M-SEVIQ是一个多波段立体事件视觉和惯性四足机器人数据集，用于解决敏捷运动机器人视觉感知的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统帧式相机在四足机器人快速运动时容易产生模糊图像，特别是在低光照条件下。事件相机具有低延迟、高时间分辨率和高动态范围的优势，但现有事件相机数据集在立体配置和多波段感知方面存在局限性。

Method: 使用Unitree Go2四足机器人配备立体事件相机、帧式相机、惯性测量单元和关节编码器，采集了超过30个真实世界序列，涵盖不同速度水平、照明波长和光照条件，并提供完整的校准数据。

Result: 创建了M-SEVIQ数据集，包含多波段立体事件视觉和惯性数据，支持传感器融合和基准测试，可用于敏捷机器人感知研究。

Conclusion: M-SEVIQ数据集填补了现有事件相机数据集的空白，为敏捷机器人感知、传感器融合、语义分割和多模态视觉研究提供了重要资源。

Abstract: Agile locomotion in legged robots poses significant challenges for visual perception. Traditional frame-based cameras often fail in these scenarios for producing blurred images, particularly under low-light conditions. In contrast, event cameras capture changes in brightness asynchronously, offering low latency, high temporal resolution, and high dynamic range. These advantages make them suitable for robust perception during rapid motion and under challenging illumination. However, existing event camera datasets exhibit limitations in stereo configurations and multi-band sensing domains under various illumination conditions. To address this gap, we present M-SEVIQ, a multi-band stereo event visual and inertial quadruped dataset collected using a Unitree Go2 equipped with stereo event cameras, a frame-based camera, an inertial measurement unit (IMU), and joint encoders. This dataset contains more than 30 real-world sequences captured across different velocity levels, illumination wavelengths, and lighting conditions. In addition, comprehensive calibration data, including intrinsic, extrinsic, and temporal alignments, are provided to facilitate accurate sensor fusion and benchmarking. Our M-SEVIQ can be used to support research in agile robot perception, sensor fusion, semantic segmentation and multi-modal vision in challenging environments.

</details>


### [14] [Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation](https://arxiv.org/abs/2601.02778)
*Haoyu Dong,Zhengmao He,Yang Li,Zhibin Li,Xinyu Yi,Zhe Zhao*

Main category: cs.RO

TL;DR: 提出了一种实用的仿真到真实强化学习框架，通过密集触觉反馈和关节扭矩传感实现灵巧手控制策略的零样本部署


<details>
  <summary>Details</summary>
Motivation: 多指灵巧手虽然具备人类级别的操作能力，但由于接触丰富的物理特性和不完美的驱动系统，直接在真实硬件上部署控制策略仍然困难

Method: 1) 计算快速的触觉仿真，通过并行前向运动学计算密集虚拟触觉单元与物体之间的距离；2) 电流到扭矩的校准，无需扭矩传感器；3) 驱动器动力学建模，通过随机化非理想效应（如间隙、扭矩-速度饱和）来弥合驱动差距；使用非对称actor-critic PPO管道在仿真中训练

Result: 策略直接部署到五指手上，实现了两种基本技能：1) 基于命令的可控抓握力跟踪；2) 手中物体的重新定向，两者均无需在机器人上进行微调即可稳健执行

Conclusion: 通过将触觉和扭矩结合在观测空间中，并配合有效的传感/驱动建模，该系统为实现可靠的灵巧操作提供了实用解决方案，这是首次在仿真中完全训练并在真实硬件上零样本迁移的多指灵巧手可控抓握演示

Abstract: Human-like dexterous hands with multiple fingers offer human-level manipulation capabilities, but training control policies that can directly deploy on real hardware remains difficult due to contact-rich physics and imperfect actuation. We close this gap with a practical sim-to-real reinforcement learning (RL) framework that utilizes dense tactile feedback combined with joint torque sensing to explicitly regulate physical interactions. To enable effective sim-to-real transfer, we introduce (i) a computationally fast tactile simulation that computes distances between dense virtual tactile units and the object via parallel forward kinematics, providing high-rate, high-resolution touch signals needed by RL; (ii) a current-to-torque calibration that eliminates the need for torque sensors on dexterous hands by mapping motor current to joint torque; and (iii) actuator dynamics modeling to bridge the actuation gaps with randomization of non-ideal effects such as backlash, torque-speed saturation. Using an asymmetric actor-critic PPO pipeline trained entirely in simulation, our policies deploy directly to a five-finger hand. The resulting policies demonstrated two essential skills: (1) command-based, controllable grasp force tracking, and (2) reorientation of objects in the hand, both of which were robustly executed without fine-tuning on the robot. By combining tactile and torque in the observation space with effective sensing/actuation modeling, our system provides a practical solution to achieve reliable dexterous manipulation. To our knowledge, this is the first demonstration of controllable grasping on a multi-finger dexterous hand trained entirely in simulation and transferred zero-shot on real hardware.

</details>


### [15] [Reinforcement Learning for Follow-the-Leader Robotic Endoscopic Navigation via Synthetic Data](https://arxiv.org/abs/2601.02798)
*Sicong Gao,Chen Qian,Laurence Xian,Liao Wu,Maurice Pagnucco,Yang Song*

Main category: cs.RO

TL;DR: 提出一种基于柔性连续结构的跟随式内窥镜机器人，采用视觉深度强化学习框架实现肠道自主导航，通过单目深度估计减少与肠壁接触


<details>
  <summary>Details</summary>
Motivation: 医疗和工业内窥镜机器人需要自主导航能力，但传统方法难以避免与狭窄管状环境内壁接触，导致患者不适。需要开发能最小化接触的自主导航系统。

Method: 1) 设计柔性连续结构的内窥镜机器人；2) 提出基于单目深度估计的视觉深度强化学习框架；3) 在NVIDIA Omniverse构建真实肠道仿真环境；4) 生成合成图像微调Depth Anything模型实现密集3D感知；5) 引入几何感知的奖励惩罚机制实现精确管腔跟踪。

Result: 相比原始Depth Anything模型，深度准确度δ1提升39.2%；相比次优方法，导航J指数降低0.67，证明方法的鲁棒性和有效性。

Conclusion: 提出的跟随式内窥镜机器人和视觉深度强化学习框架能有效减少与肠壁接触，提高自主导航性能，为医疗内窥镜机器人提供了新的解决方案。

Abstract: Autonomous navigation is crucial for both medical and industrial endoscopic robots, enabling safe and efficient exploration of narrow tubular environments without continuous human intervention, where avoiding contact with the inner walls has been a longstanding challenge for prior approaches. We present a follow-the-leader endoscopic robot based on a flexible continuum structure designed to minimize contact between the endoscope body and intestinal walls, thereby reducing patient discomfort. To achieve this objective, we propose a vision-based deep reinforcement learning framework guided by monocular depth estimation. A realistic intestinal simulation environment was constructed in \textit{NVIDIA Omniverse} to train and evaluate autonomous navigation strategies. Furthermore, thousands of synthetic intraluminal images were generated using NVIDIA Replicator to fine-tune the Depth Anything model, enabling dense three-dimensional perception of the intestinal environment with a single monocular camera. Subsequently, we introduce a geometry-aware reward and penalty mechanism to enable accurate lumen tracking. Compared with the original Depth Anything model, our method improves $δ_{1}$ depth accuracy by 39.2% and reduces the navigation J-index by 0.67 relative to the second-best method, demonstrating the robustness and effectiveness of the proposed approach.

</details>


### [16] [Soft Responsive Materials Enhance Humanoid Safety](https://arxiv.org/abs/2601.02857)
*Chunzheng Wang,Yiyuan Zhang,Annan Tang,Ziqiu Zeng,Haoran Chen,Quan Gao,Zixuan Zhuang,Boyu Li,Zhilin Xiong,Aoqian Zhang,Ce Hao,Siyuan Luo,Tongyang Zhao,Cecilia Laschi,Fan Shi*

Main category: cs.RO

TL;DR: 提出了一种软硬协同设计框架，利用非牛顿流体软响应材料增强人形机器人安全性，材料在正常交互时保持柔顺，在冲击下迅速硬化吸收能量


<details>
  <summary>Details</summary>
Motivation: 人形机器人作为通用平台在人类中心环境中应用受限，主要因为易摔倒风险以及刚性金属塑料结构对人员和环境造成的危险

Method: 采用软硬协同设计框架，使用非牛顿流体基软响应材料；通过物理模拟指导保护器放置和厚度，并学习主动摔倒策略

Result: 应用于42公斤全尺寸人形机器人，保护器显著降低峰值冲击，允许重复摔倒而无硬件损坏，包括从3米高处跌落和长楼梯翻滚

Conclusion: 通过结合响应材料、结构协同设计和基于学习的控制，该工作推进了交互安全、工业就绪的人形机器人发展

Abstract: Humanoid robots are envisioned as general-purpose platforms in human-centered environments, yet their deployment is limited by vulnerability to falls and the risks posed by rigid metal-plastic structures to people and surroundings. We introduce a soft-rigid co-design framework that leverages non-Newtonian fluid-based soft responsive materials to enhance humanoid safety. The material remains compliant during normal interaction but rapidly stiffens under impact, absorbing and dissipating fall-induced forces. Physics-based simulations guide protector placement and thickness and enable learning of active fall policies. Applied to a 42 kg life-size humanoid, the protector markedly reduces peak impact and allows repeated falls without hardware damage, including drops from 3 m and tumbles down long staircases. Across diverse scenarios, the approach improves robot robustness and environmental safety. By uniting responsive materials, structural co-design, and learning-based control, this work advances interact-safe, industry-ready humanoid robots.

</details>


### [17] [Warm-Starting Collision-Free Model Predictive Control With Object-Centric Diffusion](https://arxiv.org/abs/2601.02873)
*Arthur Haffemayer,Alexandre Chapin,Armand Jordana,Krzysztof Wojciechowski,Florent Lamiraux,Nicolas Mansard,Vladimir Petrik*

Main category: cs.RO

TL;DR: 提出了一种结合扩散模型和模型预测控制的混合方法，用于在复杂环境中生成可靠、高效的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统优化控制器在存在多个障碍物时难以快速生成可行解，而扩散模型虽然能生成多样轨迹但缺乏对场景结构的高效条件化方法。

Method: 使用基于对象中心的槽注意力机制为扩散变换器提供紧凑的障碍物表示，生成初始轨迹，然后通过模型预测控制器进行优化，强制执行刚体动力学和碰撞约束。

Result: 在基准任务中，该方法比基于采样的规划器或单独组件具有更高的成功率和更低的延迟，真实机器人实验证实了可靠和安全的执行。

Conclusion: 结合扩散模型的条件化预热和碰撞感知的模型预测控制，能够在严格时间限制下实现可靠高效的运动生成。

Abstract: Acting in cluttered environments requires predicting and avoiding collisions while still achieving precise control. Conventional optimization-based controllers can enforce physical constraints, but they struggle to produce feasible solutions quickly when many obstacles are present. Diffusion models can generate diverse trajectories around obstacles, yet prior approaches lacked a general and efficient way to condition them on scene structure. In this paper, we show that combining diffusion-based warm-starting conditioned with a latent object-centric representation of the scene and with a collision-aware model predictive controller (MPC) yields reliable and efficient motion generation under strict time limits. Our approach conditions a diffusion transformer on the system state, task, and surroundings, using an object-centric slot attention mechanism to provide a compact obstacle representation suitable for control. The sampled trajectories are refined by an optimal control problem that enforces rigid-body dynamics and signed-distance collision constraints, producing feasible motions in real time. On benchmark tasks, this hybrid method achieved markedly higher success rates and lower latency than sampling-based planners or either component alone. Real-robot experiments with a torque-controlled Panda confirm reliable and safe execution with MPC.

</details>


### [18] [LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments](https://arxiv.org/abs/2601.02905)
*Sara Micol Ferraina,Michele Brienza,Francesco Argenziano,Emanuele Musumeci,Vincenzo Suriani,Domenico D. Bloisi,Daniele Nardi*

Main category: cs.RO

TL;DR: 提出LOST-3DSG：一种轻量级开放词汇3D场景图方法，用于动态环境中的物体跟踪，避免使用重型基础模型，基于语义嵌入实现高效跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有动态物体跟踪方法依赖重型基础模型导致效率低下，需要一种轻量级且能处理开放词汇场景的解决方案。

Method: 采用基于word2vec和句子嵌入的语义实体跟踪方法，构建开放词汇3D场景图，避免存储密集的CLIP视觉特征。

Result: 在真实3D环境中使用TIAGo机器人进行实验，LOST-3DSG在动态物体跟踪方面表现出优于依赖高维视觉嵌入方法的性能。

Conclusion: LOST-3DSG提供了一种高效、轻量级的动态物体跟踪解决方案，在真实环境中验证了其有效性和效率。

Abstract: Tracking objects that move within dynamic environments is a core challenge in robotics. Recent research has advanced this topic significantly; however, many existing approaches remain inefficient due to their reliance on heavy foundation models. To address this limitation, we propose LOST-3DSG, a lightweight open-vocabulary 3D scene graph designed to track dynamic objects in real-world environments. Our method adopts a semantic approach to entity tracking based on word2vec and sentence embeddings, enabling an open-vocabulary representation while avoiding the necessity of storing dense CLIP visual features. As a result, LOST-3DSG achieves superior performance compared to approaches that rely on high-dimensional visual embeddings. We evaluate our method through qualitative and quantitative experiments conducted in a real 3D environment using a TIAGo robot. The results demonstrate the effectiveness and efficiency of LOST-3DSG in dynamic object tracking. Code and supplementary material are publicly available on the project website at https://lab-rococo-sapienza.github.io/lost-3dsg/.

</details>


### [19] [Parameter-Robust MPPI for Safe Online Learning of Unknown Parameters](https://arxiv.org/abs/2601.02948)
*Matti Vahs,Jaeyoun Choi,Niklas Schmid,Jana Tumova,Chuchu Fan*

Main category: cs.RO

TL;DR: PRMPPI控制框架结合在线参数学习和概率安全约束，通过并行优化性能驱动和安全备份轨迹，在动态环境中实现机器人安全控制


<details>
  <summary>Details</summary>
Motivation: 动态环境中的机器人需要在关键物理参数不确定或随时间变化的情况下保持安全，现有方法难以同时处理参数不确定性和安全约束

Method: 集成在线参数学习与概率安全约束，使用Stein变分梯度下降维护参数粒子信念，通过Conformal Prediction评估安全约束，并行优化性能驱动和安全备份轨迹

Result: 仿真和硬件实验显示比基线方法更高的成功率、更低的跟踪误差和更准确的参数估计

Conclusion: PRMPPI框架能够在参数学习过程中保持谨慎，随着参数学习改进性能，并确保全程安全，为动态环境中的机器人控制提供了有效解决方案

Abstract: Robots deployed in dynamic environments must remain safe even when key physical parameters are uncertain or change over time. We propose Parameter-Robust Model Predictive Path Integral (PRMPPI) control, a framework that integrates online parameter learning with probabilistic safety constraints. PRMPPI maintains a particle-based belief over parameters via Stein Variational Gradient Descent, evaluates safety constraints using Conformal Prediction, and optimizes both a nominal performance-driven and a safety-focused backup trajectory in parallel. This yields a controller that is cautious at first, improves performance as parameters are learned, and ensures safety throughout. Simulation and hardware experiments demonstrate higher success rates, lower tracking error, and more accurate parameter estimates than baselines.

</details>


### [20] [Learning to Act Robustly with View-Invariant Latent Actions](https://arxiv.org/abs/2601.02994)
*Youngjoon Jeong,Junha Chun,Taesup Kim*

Main category: cs.RO

TL;DR: VILA提出了一种基于潜在动作的视角不变表示学习方法，通过建模轨迹间的转移模式来学习基于物理动力学的视角不变表示，显著提升了视觉策略在视角变化下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的机器人策略在视角变化时表现脆弱，现有方法通常在场景层面从多视角观测中学习不变性，但仅依赖视觉外观而忽略了物理动力学，难以实现鲁棒泛化。

Method: VILA通过建模捕捉轨迹间转移模式的潜在动作来学习基于物理动力学的视角不变表示，使用基于真实动作序列的动作引导目标在不同视角间对齐这些潜在动作。

Result: 在仿真和真实世界的实验中，基于VILA的策略能有效泛化到未见过的视角，并能很好地迁移到新任务上，证明了VILA作为预训练框架能显著提升鲁棒性和下游学习性能。

Conclusion: VILA通过将物理动力学融入视角不变表示学习，为视觉机器人策略提供了强大的预训练框架，显著增强了在视角变化下的鲁棒性和泛化能力。

Abstract: Vision-based robotic policies often struggle with even minor viewpoint changes, underscoring the need for view-invariant visual representations. This challenge becomes more pronounced in real-world settings, where viewpoint variability is unavoidable and can significantly disrupt policy performance. Existing methods typically learn invariance from multi-view observations at the scene level, but such approaches rely on visual appearance and fail to incorporate the physical dynamics essential for robust generalization. We propose View-Invariant Latent Action (VILA), which models a latent action capturing transition patterns across trajectories to learn view-invariant representations grounded in physical dynamics. VILA aligns these latent actions across viewpoints using an action-guided objective based on ground-truth action sequences. Experiments in both simulation and the real world show that VILA-based policies generalize effectively to unseen viewpoints and transfer well to new tasks, establishing VILA as a strong pretraining framework that improves robustness and downstream learning performance.

</details>


### [21] [A Bi-directional Adaptive Framework for Agile UAV Landing](https://arxiv.org/abs/2601.03037)
*Chunhui Zhao,Xirui Kao,Yilin Lu,Yang Lyu*

Main category: cs.RO

TL;DR: 提出双向协同降落框架，将移动平台从被动目标转变为主动参与者，通过平台倾斜创造最佳降落姿态，实现对齐与下降阶段的并行化，显著提升无人机动态降落效率。


<details>
  <summary>Details</summary>
Motivation: 传统"跟踪-下降"范式在高度动态场景中效率低下，将移动平台视为被动目标，迫使无人机执行复杂的顺序机动。需要突破这一限制，重新定义车辆与平台的角色关系。

Method: 引入双向协同降落框架，将问题从单智能体跟踪转变为耦合系统优化。平台主动倾斜表面为无人机创造稳定终端姿态，无人机规划时间最优、动态可行的轨迹，实现对齐与下降的并行执行。

Result: 在动态场景中验证了框架有效性，显著提高了自主四旋翼回收的效率、精度和鲁棒性，能够在复杂和时间受限任务中实现敏捷恢复。

Conclusion: 通过将移动平台重新定义为主动参与者，提出的双向协同框架突破了传统顺序降落范式的限制，实现了更高效、精确和鲁棒的动态自主降落。

Abstract: Autonomous landing on mobile platforms is crucial for extending quadcopter operational flexibility, yet conventional methods are often too inefficient for highly dynamic scenarios. The core limitation lies in the prevalent ``track-then-descend'' paradigm, which treats the platform as a passive target and forces the quadcopter to perform complex, sequential maneuvers. This paper challenges that paradigm by introducing a bi-directional cooperative landing framework that redefines the roles of the vehicle and the platform. The essential innovation is transforming the problem from a single-agent tracking challenge into a coupled system optimization. Our key insight is that the mobile platform is not merely a target, but an active agent in the landing process. It proactively tilts its surface to create an optimal, stable terminal attitude for the approaching quadcopter. This active cooperation fundamentally breaks the sequential model by parallelizing the alignment and descent phases. Concurrently, the quadcopter's planning pipeline focuses on generating a time-optimal and dynamically feasible trajectory that minimizes energy consumption. This bi-directional coordination allows the system to execute the recovery in an agile manner, characterized by aggressive trajectory tracking and rapid state synchronization within transient windows. The framework's effectiveness, validated in dynamic scenarios, significantly improves the efficiency, precision, and robustness of autonomous quadrotor recovery in complex and time-constrained missions.

</details>


### [22] [Validating Generalist Robots with Situation Calculus and STL Falsification](https://arxiv.org/abs/2601.03038)
*Changwen Li,Rongjie Yan,Chih-Hong Cheng,Jian Zhang*

Main category: cs.RO

TL;DR: 提出一个两层验证框架，结合抽象推理和具体系统证伪，用于验证通用机器人系统，在桌面操作任务中成功发现NVIDIA GR00T控制器的故障案例。


<details>
  <summary>Details</summary>
Motivation: 通用机器人能够解释自然语言指令并执行多样化操作，但验证面临挑战，因为每个任务都有其独特的操作环境和正确性规范，超出了传统验证方法的假设范围。

Method: 采用两层验证框架：抽象层使用情境演算建模世界并推导最弱前置条件，通过约束感知的组合测试系统生成多样化、语义有效的世界-任务配置；具体层将这些配置实例化，使用STL监控进行基于仿真的证伪。

Result: 在桌面操作任务上的实验表明，该框架能够有效发现NVIDIA GR00T控制器的故障案例，展示了验证通用机器人自主性的潜力。

Conclusion: 提出的两层验证框架结合了抽象推理和具体系统证伪，为验证通用机器人系统提供了一种有效方法，能够发现传统方法难以检测的故障。

Abstract: Generalist robots are becoming a reality, capable of interpreting natural language instructions and executing diverse operations. However, their validation remains challenging because each task induces its own operational context and correctness specification, exceeding the assumptions of traditional validation methods. We propose a two-layer validation framework that combines abstract reasoning with concrete system falsification. At the abstract layer, situation calculus models the world and derives weakest preconditions, enabling constraint-aware combinatorial testing to systematically generate diverse, semantically valid world-task configurations with controllable coverage strength. At the concrete layer, these configurations are instantiated for simulation-based falsification with STL monitoring. Experiments on tabletop manipulation tasks show that our framework effectively uncovers failure cases in the NVIDIA GR00T controller, demonstrating its promise for validating general-purpose robot autonomy.

</details>


### [23] [SOP: A Scalable Online Post-Training System for Vision-Language-Action Models](https://arxiv.org/abs/2601.03044)
*Mingjie Pan,Siyuan Feng,Qinglin Zhang,Xinchen Li,Jianheng Song,Chendi Qu,Yi Wang,Chuankang Li,Ziyu Xiong,Zhi Chen,Yi Liu,Jianlan Luo*

Main category: cs.RO

TL;DR: SOP系统通过在线分布式多任务后训练，在物理世界中提升通用VLA模型的专家级任务性能，实现小时级高效学习且性能随机器人数量线性扩展。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型后训练方法多为离线、单机器人或任务特定，限制了在策略适应和从真实世界交互中可扩展学习的能力，需要一种能在物理世界中实现高效在线后训练的系统。

Method: 提出SOP系统，采用闭环架构：机器人舰队持续流式传输在策略经验和人工干预信号到云端学习器，异步接收更新策略。系统支持两种后训练算法：交互式模仿学习(HG-DAgger)和强化学习(RECAP)。

Result: 在布料折叠、箱子组装、杂货补货等真实世界操作任务中，SOP显著提升大型预训练VLA模型性能，同时保持跨任务共享策略。仅需数小时真实世界交互即可有效后训练，性能随机器人数量近线性扩展。

Conclusion: 在线学习与舰队规模部署的紧密耦合是实现通用机器人策略在物理世界中高效、可靠、可扩展后训练的关键。

Abstract: Vision-language-action (VLA) models achieve strong generalization through large-scale pre-training, but real-world deployment requires expert-level task proficiency in addition to broad generality. Existing post-training approaches for VLA models are typically offline, single-robot, or task-specific, limiting effective on-policy adaptation and scalable learning from real-world interaction. We introduce a Scalable Online Post-training (SOP) system that enables online, distributed, multi-task post-training of generalist VLA models directly in the physical world. SOP tightly couples execution and learning through a closed-loop architecture in which a fleet of robots continuously streams on-policy experience and human intervention signals to a centralized cloud learner, and asynchronously receives updated policies. This design supports prompt on-policy correction, scales experience collection through parallel deployment, and preserves generality during adaptation. SOP is agnostic to the choice of post-training algorithm; we instantiate it with both interactive imitation learning (HG-DAgger) and reinforcement learning (RECAP). Across a range of real-world manipulation tasks including cloth folding, box assembly, and grocery restocking, we show that SOP substantially improves the performance of large pretrained VLA models while maintaining a single shared policy across tasks. Effective post-training can be achieved within hours of real-world interaction, and performance scales near-linearly with the number of robots in the fleet. These results suggest that tightly coupling online learning with fleet-scale deployment is instrumental to enabling efficient, reliable, and scalable post-training of generalist robot policies in the physical world.

</details>


### [24] [A Fast Semidefinite Convex Relaxation for Optimal Control Problems With Spatio-Temporal Constraints](https://arxiv.org/abs/2601.03055)
*Shiying Dong,Zhipeng Shen,Rudolf Reiter,Hailong Huang,Bingzhao Gao,Hong Chen,Wen-Hua Chen*

Main category: cs.RO

TL;DR: 提出一种时间缩放直接多重打靶方案，通过分段预测时域与特征时间约束对齐，结合基于半定规划的凸松弛方法，高效求解具有时空约束的最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 自主智能体在时空约束下的最优控制问题（如自动驾驶生态驾驶、四旋翼导航）求解困难，传统方法通过预定义航点时间或非凸轨迹优化简化问题，但往往得到次优解。

Method: 提出时间缩放直接多重打靶方案，将预测时域分段并与特征时间约束对齐；开发基于半定规划的快速凸松弛方法，利用提升公式的稀疏模式。

Result: 综合仿真研究表明该方法在求解最优性和计算效率方面表现优异；在四旋翼航点飞行任务（具有约束开放时间窗口）的真实世界实验中验证了在复杂环境中的实际适用性。

Conclusion: 所提出的时间缩放直接多重打靶方案结合凸松弛方法，能够高效、最优地求解具有时空约束的最优控制问题，在理论和实际应用中均表现出色。

Abstract: Solving optimal control problems (OCPs) of autonomous agents operating under spatial and temporal constraints fast and accurately is essential in applications ranging from eco-driving of autonomous vehicles to quadrotor navigation. However, the nonlinear programs approximating the OCPs are inherently nonconvex due to the coupling between the dynamics and the event timing, and therefore, they are challenging to solve. Most approaches address this challenge by predefining waypoint times or just using nonconvex trajectory optimization, which simplifies the problem but often yields suboptimal solutions. To significantly improve the numerical properties, we propose a formulation with a time-scaling direct multiple shooting scheme that partitions the prediction horizon into segments aligned with characteristic time constraints. Moreover, we develop a fast semidefinite-programming-based convex relaxation that exploits the sparsity pattern of the lifted formulation. Comprehensive simulation studies demonstrate the solution optimality and computational efficiency. Furthermore, real-world experiments on a quadrotor waypoint flight task with constrained open time windows validate the practical applicability of the approach in complex environments.

</details>


### [25] [HEXAR: a Hierarchical Explainability Architecture for Robots](https://arxiv.org/abs/2601.03070)
*Tamlin Love,Ferran Gebellí,Pradip Pramanick,Antonio Andriella,Guillem Alenyà,Anais Garrell,Raquel Ros,Silvia Rossi*

Main category: cs.RO

TL;DR: HEXAR是一个用于机器人系统的分层可解释性框架，通过专门的组件解释器和解释器选择器，提供模块化的解释生成，在家庭辅助任务中显著优于端到端和聚合基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统日益复杂，对可解释决策的需求变得至关重要。现有的机器人可解释性方法要么关注单个模块（难以从高层行为角度查询），要么采用整体方法（无法利用机器人架构的模块化特性）。

Method: 提出HEXAR（机器人分层可解释性架构），这是一个插件式分层框架，包含专门针对特定机器人模块的组件解释器（使用LLM推理、因果模型、特征重要性等技术），由解释器选择器根据查询选择最合适的解释器。

Result: 在TIAGo机器人执行家庭辅助任务的180个场景-查询变体上评估，HEXAR在根本原因识别、错误信息排除和运行时间方面显著优于端到端和聚合基线方法。

Conclusion: HEXAR为透明自主系统提供了一个有前景的方向，通过分层模块化方法有效解决了机器人系统的可解释性问题。

Abstract: As robotic systems become increasingly complex, the need for explainable decision-making becomes critical. Existing explainability approaches in robotics typically either focus on individual modules, which can be difficult to query from the perspective of high-level behaviour, or employ monolithic approaches, which do not exploit the modularity of robotic architectures. We present HEXAR (Hierarchical EXplainability Architecture for Robots), a novel framework that provides a plug-in, hierarchical approach to generate explanations about robotic systems. HEXAR consists of specialised component explainers using diverse explanation techniques (e.g., LLM-based reasoning, causal models, feature importance, etc) tailored to specific robot modules, orchestrated by an explainer selector that chooses the most appropriate one for a given query. We implement and evaluate HEXAR on a TIAGo robot performing assistive tasks in a home environment, comparing it against end-to-end and aggregated baseline approaches across 180 scenario-query variations. We observe that HEXAR significantly outperforms baselines in root cause identification, incorrect information exclusion, and runtime, offering a promising direction for transparent autonomous systems.

</details>


### [26] [Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees](https://arxiv.org/abs/2601.03097)
*Omayra Yago Nieto,Alexandre Anahory Simoes,Juan I. Giribet,Leonardo Colombo*

Main category: cs.RO

TL;DR: 提出一种基于学习的SE(3)运动机器人轨迹跟踪控制器，使用对偶四元数框架和GP回归在线补偿未知扰动，具有形式化稳定性保证。


<details>
  <summary>Details</summary>
Motivation: 针对自主机器人平台在SE(3)上的运动控制问题，需要处理未知的状态相关扰动、建模不完善以及传感器引起的干扰、未建模的驱动耦合和环境不确定性等挑战。

Method: 1. 在对偶四元数框架中设计几何反馈控制器；2. 集成高斯过程回归在线学习和补偿未知扰动；3. 在速度层面操作，直接控制角速度和线速度；4. 不依赖未知效应的显式参数模型；5. 基于Lyapunov分析提供概率稳定性保证。

Result: 仿真结果表明，在存在现实局部扰动（包括磁力计扰动引起的相关旋转和平移效应）的情况下，控制器能够实现准确平滑的轨迹跟踪。证明了结合几何建模和概率学习实现鲁棒、数据高效位姿控制的潜力。

Conclusion: 该研究提出了一种结合几何控制和概率学习的SE(3)轨迹跟踪控制器，能够在存在未知扰动的情况下提供形式化稳定性保证，为自主机器人系统的鲁棒位姿控制提供了有效解决方案。

Abstract: We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.
  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.
  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.

</details>


### [27] [A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting](https://arxiv.org/abs/2601.03200)
*Ziyang Sun,Lingfan Bao,Tianhu Peng,Jingcheng Sun,Chengxu Zhou*

Main category: cs.RO

TL;DR: 提出一个基于3D高斯泼溅的快速数字孪生框架，能在几分钟内从稀疏RGB输入构建高质量数字孪生，支持机器人运动规划和真实世界执行。


<details>
  <summary>Details</summary>
Motivation: 现有数字孪生方法存在重建速度慢、视觉保真度有限、难以将逼真模型转换为规划就绪的碰撞几何等问题，阻碍了从仿真到真实环境的闭环运动规划和可靠执行。

Method: 使用3D高斯泼溅(3DGS)作为统一场景表示进行快速逼真重建；通过可见性感知语义融合实现精确3D标注；采用基于滤波的高效几何转换方法生成碰撞就绪模型；与Unity-ROS2-MoveIt物理引擎无缝集成。

Result: 在Franka Emika Panda机器人执行拾放任务的实验中，增强的几何精度有效支持了真实世界试验中的稳健操作，证明了该框架的实用性。

Conclusion: 基于3DGS的数字孪生，通过语义和几何一致性增强，为无结构环境中从感知到操作提供了快速、可靠且可扩展的路径。

Abstract: Developing high-fidelity, interactive digital twins is crucial for enabling closed-loop motion planning and reliable real-world robot execution, which are essential to advancing sim-to-real transfer. However, existing approaches often suffer from slow reconstruction, limited visual fidelity, and difficulties in converting photorealistic models into planning-ready collision geometry. We present a practical framework that constructs high-quality digital twins within minutes from sparse RGB inputs. Our system employs 3D Gaussian Splatting (3DGS) for fast, photorealistic reconstruction as a unified scene representation. We enhance 3DGS with visibility-aware semantic fusion for accurate 3D labelling and introduce an efficient, filter-based geometry conversion method to produce collision-ready models seamlessly integrated with a Unity-ROS2-MoveIt physics engine. In experiments with a Franka Emika Panda robot performing pick-and-place tasks, we demonstrate that this enhanced geometric accuracy effectively supports robust manipulation in real-world trials. These results demonstrate that 3DGS-based digital twins, enriched with semantic and geometric consistency, offer a fast, reliable, and scalable path from perception to manipulation in unstructured environments.

</details>
