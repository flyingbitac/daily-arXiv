{"id": "2601.05336", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05336", "abs": "https://arxiv.org/abs/2601.05336", "authors": ["Tracey Yee Hsin Tay", "Xu Yan", "Jonathan Ouyang", "Daniel Wu", "William Jiang", "Jonathan Kao", "Yuchen Cui"], "title": "Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models", "comment": "Accepted to 2025 RSS Robot Planning in the Era of Foundation Models (FM4RoboPlan) Workshop", "summary": "Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/", "AI": {"tldr": "GAMMA\u7cfb\u7edf\u7ed3\u5408\u773c\u52a8\u8ffd\u8e2a\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6ce8\u89c6\u70b9\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u81ea\u4e3b\u64cd\u4f5c\u4efb\u52a1\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3", "motivation": "\u8bbe\u8ba1\u76f4\u89c2\u7684\u673a\u5668\u4eba\u63a7\u5236\u754c\u9762\u662f\u4fc3\u8fdb\u6709\u6548\u4eba\u673a\u4ea4\u4e92\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8f85\u52a9\u62a4\u7406\u573a\u666f\u4e2d\u3002\u773c\u52a8\u6ce8\u89c6\u63d0\u4f9b\u5feb\u901f\u3001\u975e\u4fb5\u5165\u6027\u4e14\u610f\u56fe\u4e30\u5bcc\u7684\u8f93\u5165\u65b9\u5f0f\uff0c\u662f\u4f20\u8fbe\u7528\u6237\u76ee\u6807\u7684\u7406\u60f3\u901a\u9053", "method": "GAMMA\u7cfb\u7edf\u5229\u7528\u81ea\u6211\u4e2d\u5fc3\u773c\u52a8\u8ffd\u8e2a\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u6ce8\u89c6\u70b9\u7f6e\u4e8e\u573a\u666f\u4e0a\u4e0b\u6587\u4e2d\uff0c\u5c06\u89c6\u89c9\u6ce8\u610f\u529b\u6620\u5c04\u5230\u9ad8\u7ea7\u8bed\u4e49\u7406\u89e3\uff0c\u5b9e\u73b0\u6280\u80fd\u9009\u62e9\u548c\u53c2\u6570\u5316\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3", "result": "\u5728\u591a\u79cd\u684c\u9762\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8bc4\u4f30GAMMA\uff0c\u5e76\u4e0e\u65e0\u63a8\u7406\u7684\u57fa\u7ebf\u773c\u52a8\u63a7\u5236\u5bf9\u6bd4\u3002\u7ed3\u679c\u663e\u793aGAMMA\u63d0\u4f9b\u9c81\u68d2\u3001\u76f4\u89c2\u4e14\u53ef\u6cdb\u5316\u7684\u63a7\u5236", "conclusion": "GAMMA\u5c55\u793a\u4e86\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u773c\u52a8\u8ffd\u8e2a\u5b9e\u73b0\u81ea\u7136\u3001\u53ef\u6269\u5c55\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u7684\u6f5c\u529b\uff0c\u4e3a\u76f4\u89c2\u7684\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.05491", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05491", "abs": "https://arxiv.org/abs/2601.05491", "authors": ["Luca Nunziante", "Kentaro Uno", "Gustavo H. Diaz", "Shreya Santra", "Alessandro De Luca", "Kazuya Yoshida"], "title": "Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction", "comment": "This is the authors' version of a paper accepted for publication in IEEE/SICE International Symposium on System Integration (SII), 2025, (c) IEEE", "summary": "Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u6708\u7403\u592a\u9633\u80fd\u677f\u81ea\u4e3b\u7ec4\u88c5\u7684\u89c6\u89c9-\u63a7\u5236-\u786c\u4ef6\u96c6\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u673a\u68b0\u81c2\u673a\u5668\u4eba\u5b9e\u73b0\u4e86\u6a21\u5757\u5316\u592a\u9633\u80fd\u677f\u7684\u8fde\u63a5\u88c5\u914d\u3002", "motivation": "\u968f\u7740\u4eba\u7c7b\u91cd\u8fd4\u6708\u7403\u8ba1\u5212\u7684\u63a8\u8fdb\uff0c\u9700\u8981\u5efa\u7acb\u6708\u7403\u524d\u54e8\u7ad9\uff0c\u5176\u4e2d\u592a\u9633\u80fd\u53d1\u7535\u5854\u7b49\u57fa\u7840\u8bbe\u65bd\u7684\u5efa\u8bbe\u81f3\u5173\u91cd\u8981\u3002\u7c7b\u4f3c\u4e8e\u56fd\u9645\u7a7a\u95f4\u7ad9\u7684\u5efa\u9020\u65b9\u5f0f\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u7ec4\u4ef6\u8fd0\u8f93\u548c\u73b0\u573a\u7ec4\u88c5\u662f\u5b9e\u7528\u65b9\u6848\u3002\u673a\u5668\u4eba\u7cfb\u7edf\u5c06\u5728\u5b89\u5168\u9ad8\u6548\u5efa\u7acb\u57fa\u7840\u8bbe\u65bd\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7528\u4e8e\u592a\u9633\u80fd\u677f\u6a21\u5757\u7ec4\u88c5\u7684\u611f\u77e5\u4e0e\u63a7\u5236\u6d41\u7a0b\uff0c\u5f00\u53d1\u4e86\u4e13\u7528\u786c\u4ef6\u7cfb\u7edf\u3002\u91c7\u7528\u6a21\u5757\u5316\u592a\u9633\u80fd\u677f\u6a21\u62df\u88c5\u7f6e\u548c\u4e3b\u52a8-\u88ab\u52a8\u8fde\u63a5\u5668\uff0c\u5c06\u6293\u53d6\u5939\u5177\u7684\u63a7\u5236\u96c6\u6210\u5230\u63d0\u51fa\u7684\u6d41\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u53cc\u673a\u68b0\u81c2\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u89c6\u89c9\u3001\u63a7\u5236\u548c\u786c\u4ef6\u7cfb\u7edf\u96c6\u6210\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u53cc\u673a\u68b0\u81c2\u673a\u5668\u4eba\u5bf9\u4efb\u610f\u653e\u7f6e\u7684\u592a\u9633\u80fd\u677f\u6a21\u5757\u7684\u6709\u6548\u8fde\u63a5\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u590d\u6742\u7a7a\u95f4\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u89c6\u89c9\u3001\u63a7\u5236\u548c\u786c\u4ef6\u7cfb\u7edf\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u53cc\u673a\u68b0\u81c2\u673a\u5668\u4eba\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u6267\u884c\u592a\u9633\u80fd\u677f\u6a21\u5757\u7684\u81ea\u4e3b\u7ec4\u88c5\u4efb\u52a1\uff0c\u4e3a\u672a\u6765\u6708\u7403\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u7684\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u96c6\u6210\u7cfb\u7edf\u5728\u590d\u6742\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.05499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05499", "abs": "https://arxiv.org/abs/2601.05499", "authors": ["Weishang Wu", "Yifei Shi", "Zhiping Cai"], "title": "TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds", "comment": "Accepted to AAAI 2026", "summary": "Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFlowGrasp\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u5bfc\u5411\u7684\u5f62\u72b6\u8865\u5168\u548c\u6761\u4ef6\u6d41\u5339\u914d\u6a21\u578b\uff0c\u89e3\u51b3\u4e25\u91cd\u90e8\u5206\u89c2\u6d4b\u4e0b\u7684\u7075\u5de7\u6293\u53d6\u95ee\u9898\uff0c\u5728\u6293\u53d6\u4f4d\u79fb\u548cChamfer\u8ddd\u79bb\u6307\u6807\u4e0a\u5206\u522b\u63d0\u534716.17%\u548c55.26%\u3002", "motivation": "\u5728\u4e25\u91cd\u90e8\u5206\u89c2\u6d4b\u4e0b\uff0c\u901a\u7528\u5f62\u72b6\u8865\u5168\u65b9\u6cd5\u56e0\u5927\u91cf\u7f3a\u5931\u6570\u636e\u800c\u5931\u6548\uff0c\u5bfc\u81f4\u4efb\u52a1\u5bfc\u5411\u7684\u7075\u5de7\u6293\u53d6\u9762\u4e34\u6311\u6218\u3002\u4f5c\u8005\u8ba4\u4e3a\u6293\u53d6\u4efb\u52a1\u7684\u5f62\u72b6\u8865\u5168\u5e94\u660e\u786e\u53d7\u4e0b\u6e38\u64cd\u4f5c\u4efb\u52a1\u6307\u5bfc\u3002", "method": "1. \u5229\u7528\u591a\u4e2a\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u96f6\u6837\u672c\u80fd\u529b\u751f\u6210\u591a\u4e2a\u4efb\u52a1\u5bfc\u5411\u5f62\u72b6\u8865\u5168\u5019\u9009\uff1b2. \u63d0\u51fa3D\u5224\u522b\u81ea\u7f16\u7801\u5668\u8bc4\u4f30\u6bcf\u4e2a\u5019\u9009\u7684\u5408\u7406\u6027\u5e76\u5168\u5c40\u4f18\u5316\u6700\u5408\u7406\u5019\u9009\uff1b3. \u5f00\u53d1\u6761\u4ef6\u6d41\u5339\u914d\u6a21\u578bFlowGrasp\u4ece\u4f18\u5316\u5f62\u72b6\u751f\u6210\u4efb\u52a1\u5bfc\u5411\u7075\u5de7\u6293\u53d6\u3002", "result": "\u5728\u4efb\u52a1\u5bfc\u5411\u7075\u5de7\u6293\u53d6\u548c\u4efb\u52a1\u5bfc\u5411\u5f62\u72b6\u8865\u5168\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u6293\u53d6\u4f4d\u79fb\u63d0\u534716.17%\uff0cChamfer\u8ddd\u79bb\u63d0\u534755.26%\u3002\u5728\u4e25\u91cd\u7f3a\u5931\u6570\u636e\u5bf9\u8c61\u6293\u53d6\u3001\u5f00\u653e\u96c6\u7c7b\u522b\u548c\u4efb\u52a1\u5904\u7406\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u80fd\u529b\u3002", "conclusion": "FlowGrasp\u65b9\u6cd5\u901a\u8fc7\u4efb\u52a1\u5bfc\u5411\u5f62\u72b6\u8865\u5168\u548c\u6761\u4ef6\u6d41\u5339\u914d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e25\u91cd\u90e8\u5206\u89c2\u6d4b\u4e0b\u7684\u7075\u5de7\u6293\u53d6\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.05533", "categories": ["cs.RO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.05533", "abs": "https://arxiv.org/abs/2601.05533", "authors": ["Kandai Watanabe", "Nicholas Renninger", "Sriram Sankaranarayanan", "Morteza Lahijanian"], "title": "Learning specifications for reactive synthesis with safety constraints", "comment": null, "summary": "This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u5f62\u5f0f\u8bed\u8a00\u5efa\u6a21\u6f5c\u5728\u4efb\u52a1\uff0c\u7ed3\u5408\u5b89\u5168\u7ea6\u675f\u5b66\u4e60\u548c\u591a\u76ee\u6807\u53cd\u5e94\u5f0f\u5408\u6210\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u5728\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u8ba9\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b89\u5168\u3001\u9ad8\u6548\u5730\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u540c\u65f6\u5e73\u8861\u673a\u5668\u4eba\u6210\u672c\u4e0e\u7528\u6237\u4efb\u52a1\u504f\u597d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5b66\u4e60\u5b89\u5168\u7ea6\u675f\u4efb\u52a1\u89c4\u8303\u5e76\u751f\u6210\u6700\u4f18\u7b56\u7565\u7684\u6846\u67b6\u3002", "method": "1. \u5c06\u6f5c\u5728\u4efb\u52a1\u5efa\u6a21\u4e3a\u6982\u7387\u5f62\u5f0f\u8bed\u8a00\uff1b2. \u5f15\u5165\u5b89\u5168\u7ea6\u675f\u5b66\u4e60\uff0c\u5c06\u4efb\u52a1\u89c4\u8303\u63a8\u65ad\u4e3a\u6982\u7387\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a(PDFA)\uff1b3. \u5f00\u53d1\u591a\u76ee\u6807\u53cd\u5e94\u5f0f\u5408\u6210\u7b97\u6cd5\uff0c\u5c06\u4ea4\u4e92\u5efa\u6a21\u4e3a\u673a\u5668\u4eba\u4e0e\u73af\u5883\u7684\u4e8c\u4eba\u535a\u5f08\uff1b4. \u63d0\u51fa\u8ba1\u7b97\u53ef\u884c\u7684\u503c\u8fed\u4ee3\u7b97\u6cd5\u751f\u6210\u5e15\u7d2f\u6258\u524d\u6cbf\u548c\u786e\u5b9a\u6027\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1. \u5b66\u4e60\u7684PDFA\u4ece\u4e0d\u5305\u542b\u4e0d\u5b89\u5168\u884c\u4e3a\uff1b2. \u5408\u6210\u7684\u7b56\u7565\u59cb\u7ec8\u80fd\u5b8c\u6210\u4efb\u52a1\uff0c\u540c\u65f6\u6ee1\u8db3\u673a\u5668\u4eba\u6210\u672c\u548c\u7528\u6237\u504f\u597d\u8981\u6c42\uff1b3. \u65b9\u6cd5\u5728\u5404\u79cd\u673a\u5668\u4eba\u548c\u4efb\u52a1\u4e2d\u90fd\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5b89\u5168\u7ea6\u675f\u7684\u4efb\u52a1\u5b66\u4e60\u4e0e\u591a\u76ee\u6807\u4f18\u5316\u7b56\u7565\u5408\u6210\uff0c\u4e3a\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u6027\u3001\u4efb\u52a1\u5b8c\u6210\u5ea6\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2601.05653", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05653", "abs": "https://arxiv.org/abs/2601.05653", "authors": ["Phu-Hoa Pham", "Chi-Nguyen Tran", "Duy-Minh Dao-Sy", "Phu-Quy Nguyen-Lam", "Trung-Kiet Huynh"], "title": "EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium", "comment": "11 pages, 5 figures", "summary": "Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.", "AI": {"tldr": "EvoQRE\uff1a\u57fa\u4e8e\u91cf\u5b50\u54cd\u5e94\u5747\u8861\u548c\u6f14\u5316\u535a\u5f08\u52a8\u529b\u5b66\u7684\u65b0\u578b\u4ea4\u901a\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u5b89\u5168\u5173\u952e\u4ea4\u901a\u4ea4\u4e92\uff0c\u8003\u8651\u4eba\u7c7b\u6709\u9650\u7406\u6027\u884c\u4e3a\uff0c\u5728Waymo\u548cnuPlan\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u771f\u5b9e\u6027\u548c\u5b89\u5168\u6027", "motivation": "\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76\u4ea4\u901a\u4eff\u771f\u6846\u67b6\u901a\u5e38\u57fa\u4e8e\u6a21\u4eff\u5b66\u4e60\u6216\u535a\u5f08\u8bba\u65b9\u6cd5\uff0c\u5047\u8bbe\u5b8c\u7f8e\u7406\u6027\u667a\u80fd\u4f53\uff0c\u4f46\u4eba\u7c7b\u9a7e\u9a76\u5458\u8868\u73b0\u51fa\u6709\u9650\u7406\u6027\uff0c\u5728\u8ba4\u77e5\u548c\u611f\u77e5\u7ea6\u675f\u4e0b\u505a\u51fa\u8fd1\u4f3c\u6700\u4f18\u51b3\u7b56\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5efa\u6a21\u4eba\u7c7b\u6709\u9650\u7406\u6027\u884c\u4e3a\u7684\u4ea4\u901a\u4ea4\u4e92\u6846\u67b6", "method": "\u63d0\u51faEvoQRE\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u5173\u952e\u4ea4\u901a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u4e00\u822c\u548c\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u901a\u8fc7\u91cf\u5b50\u54cd\u5e94\u5747\u8861\u548c\u6f14\u5316\u535a\u5f08\u52a8\u529b\u5b66\u6c42\u89e3\u3002\u6574\u5408\u9884\u8bad\u7ec3\u7684\u751f\u6210\u4e16\u754c\u6a21\u578b\u4e0e\u71b5\u6b63\u5219\u5316\u590d\u5236\u5668\u52a8\u529b\u5b66\uff0c\u6355\u6349\u968f\u673a\u4eba\u7c7b\u884c\u4e3a\u540c\u65f6\u4fdd\u6301\u5747\u8861\u7ed3\u6784\u3002\u5c06QRE\u6269\u5c55\u5230\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\uff0c\u4f7f\u7528\u57fa\u4e8e\u6df7\u5408\u548c\u57fa\u4e8e\u80fd\u91cf\u7684\u7b56\u7565\u8868\u793a", "result": "\u63d0\u4f9b\u4e25\u683c\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u8bc1\u660e\u6240\u63d0\u52a8\u529b\u5b66\u5728\u5f31\u5355\u8c03\u6027\u5047\u8bbe\u4e0b\u4ee5O(log k / k^{1/3})\u6536\u655b\u901f\u7387\u6536\u655b\u5230Logit-QRE\u3002\u5728Waymo\u5f00\u653e\u8fd0\u52a8\u6570\u636e\u96c6\u548cnuPlan\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEvoQRE\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u771f\u5b9e\u6027\u3001\u6539\u8fdb\u7684\u5b89\u5168\u6307\u6807\uff0c\u4ee5\u53ca\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u7406\u6027\u53c2\u6570\u53ef\u63a7\u751f\u6210\u591a\u6837\u5316\u5b89\u5168\u5173\u952e\u573a\u666f", "conclusion": "EvoQRE\u662f\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u5b89\u5168\u5173\u952e\u4ea4\u901a\u4ea4\u4e92\uff0c\u8003\u8651\u4eba\u7c7b\u6709\u9650\u7406\u6027\uff0c\u901a\u8fc7\u91cf\u5b50\u54cd\u5e94\u5747\u8861\u548c\u6f14\u5316\u535a\u5f08\u52a8\u529b\u5b66\u5b9e\u73b0\u66f4\u771f\u5b9e\u7684\u4ea4\u901a\u4eff\u771f\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.05661", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05661", "abs": "https://arxiv.org/abs/2601.05661", "authors": ["Matija Markulin", "Luka Matijevi\u0107", "Luka Siktar", "Janko Jurdana", "Branimir Caran", "Marko \u0160vaco", "Filip \u0160uligoj", "Bojan \u0160ekoranja"], "title": "Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures", "comment": "Submitted for ICRA 2026", "summary": "Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\\% fitness and 0.35 mm RMSE for S-H registration, 84.1\\% fitness and 0.37 mm RMSE for S-V registration and 79.4\\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.", "AI": {"tldr": "\u5f00\u53d1\u7528\u4e8e\u524d\u5217\u817a\u8d85\u58f0\u68c0\u67e5\u7684\u673a\u5668\u4eba\u8f85\u52a9\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u4f5c\u673a\u68b0\u81c2\u81ea\u4e3b\u626b\u63cf\u524d\u5217\u817a\u6a21\u578b\uff0c\u4fdd\u6301\u8d85\u58f0\u63a2\u5934\u4e0e\u524d\u5217\u817a\u76f8\u5bf9\u4f4d\u7f6e\u6052\u5b9a\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u7684\u524d\u5217\u817a3D\u91cd\u5efa\uff0c\u4e3a\u6d3b\u68c0\u89c4\u5212\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u524d\u5217\u817a\u764c\u662f\u7537\u6027\u5e38\u89c1\u764c\u75c7\uff0c\u4f20\u7edf\u6d3b\u68c0\u8bca\u65ad\u9ad8\u5ea6\u4f9d\u8d56\u5916\u79d1\u533b\u751f\u7684\u4e13\u4e1a\u6280\u80fd\uff0c\u7ed3\u679c\u5b58\u5728\u64cd\u4f5c\u8005\u4f9d\u8d56\u6027\u3002\u9700\u8981\u5f00\u53d1\u673a\u5668\u4eba\u8f85\u52a9\u7cfb\u7edf\u6765\u964d\u4f4e\u64cd\u4f5c\u8981\u6c42\uff0c\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u3001\u66f4\u53ef\u53ca\u7684\u524d\u5217\u817a\u6d3b\u68c0\u3002", "method": "\u5f00\u53d1\u5b9e\u9a8c\u5ba4\u8bbe\u7f6e\uff0c\u4f7f\u7528\u534f\u4f5c\u673a\u68b0\u81c2\u81ea\u4e3b\u626b\u63cf\u524d\u5217\u817a\u6a21\u578b\uff0c\u5e76\u5c06\u6a21\u578b\u8fde\u63a5\u5230\u6a21\u62df\u60a3\u8005\u8fd0\u52a8\u7684\u533b\u7597\u673a\u68b0\u81c2\u3002\u626b\u63cf\u673a\u5668\u4eba\u4fdd\u6301\u8d85\u58f0\u63a2\u5934\u4e0e\u524d\u5217\u817a\u76f8\u5bf9\u4f4d\u7f6e\u6052\u5b9a\uff0c\u786e\u4fdd\u4e00\u81f4\u7684\u524d\u5217\u817a\u91cd\u5efa\u65b9\u6cd5\u3002\u901a\u8fc7\u5206\u5272\u6bcf\u4e2a\u5207\u7247\u751f\u6210\u524d\u5217\u817a\u8f6e\u5ed3\uff0c\u8f6c\u6362\u4e3a3D\u70b9\u4e91\u7528\u4e8e\u6d3b\u68c0\u89c4\u5212\u3002", "result": "\u524d\u5217\u817a\u5e73\u5747\u626b\u63cf\u65f6\u95f430\u79d2\uff0c\u5e73\u57473D\u91cd\u5efa\u65f6\u95f43\u79d2\u3002\u5728\u56db\u79cd\u8fd0\u52a8\u573a\u666f\u4e0b\u6d4b\u8bd5\uff1a\u9759\u6b62(S)\u3001\u6c34\u5e73\u8fd0\u52a8(H)\u3001\u5782\u76f4\u8fd0\u52a8(V)\u3001\u7ec4\u5408\u8fd0\u52a8(C)\u3002\u901a\u8fc7ICP\u914d\u51c6\u9a8c\u8bc1\u7cfb\u7edf\uff0cS-H\u914d\u51c6\u5e73\u574783.2%\u62df\u5408\u5ea6\u548c0.35mm RMSE\uff0cS-V\u4e3a84.1%\u548c0.37mm\uff0cS-C\u4e3a79.4%\u548c0.37mm\u3002\u6700\u5927\u673a\u5668\u4eba\u8ddf\u8e2a\u8bef\u5dee3mm\uff0c\u8fd0\u52a8\u8865\u507f\u6700\u5927\u5ef6\u8fdf0.5\u79d2\u3002", "conclusion": "\u5f00\u53d1\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8865\u507f\u60a3\u8005\u8fd0\u52a8\uff0c\u4fdd\u6301\u8d85\u58f0\u63a2\u5934\u4e0e\u524d\u5217\u817a\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u7684\u524d\u5217\u817a3D\u91cd\u5efa\u3002\u6839\u636e\u533b\u5b66\u6587\u732e\uff0c3mm\u7684\u8ddf\u8e2a\u8bef\u5dee\u53ef\u80fd\u8db3\u4ee5\u6ee1\u8db3\u524d\u5217\u817a\u6d3b\u68c0\u9700\u6c42\uff0c\u4e3a\u673a\u5668\u4eba\u8f85\u52a9\u524d\u5217\u817a\u6d3b\u68c0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2601.05805", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05805", "abs": "https://arxiv.org/abs/2601.05805", "authors": ["Simon Archieri", "Ahmet Cinar", "Shu Pan", "Jonatan Scharff Willners", "Michele Grimald", "Ignacio Carlucho", "Yvan Petillot"], "title": "InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection", "comment": null, "summary": "This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.", "AI": {"tldr": "InsSo3D\uff1a\u4e00\u79cd\u4f7f\u75283D\u58f0\u7eb3\u548c\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\u8fdb\u884c\u5927\u89c4\u6a213D SLAM\u7684\u51c6\u786e\u9ad8\u6548\u65b9\u6cd5\uff0c\u5728\u6d51\u6d4a\u6c34\u57df\u4e2d\u5b9e\u73b0\u6c34\u4e0b\u7ed3\u6784\u5b89\u5168\u68c0\u6d4b", "motivation": "\u4f20\u7edf\u58f0\u7eb3\u53ea\u80fd\u751f\u6210\u5305\u542b\u8ddd\u79bb\u548c\u65b9\u4f4d\u4fe1\u606f\u76842D\u56fe\u50cf\uff0c\u7f3a\u4e4f\u9ad8\u7a0b\u4fe1\u606f\uff0c\u5b58\u5728\u9ad8\u7a0b\u6a21\u7cca\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u75283D\u58f0\u7eb3\u70b9\u4e91\u6570\u636e\uff0c\u5728\u6d51\u6d4a\u6c34\u57df\u6761\u4ef6\u4e0b\u5b9e\u73b0\u51c6\u786e\u6c34\u4e0b\u5b9a\u4f4d\u548c\u5efa\u56fe\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faInsSo3D\u65b9\u6cd5\uff0c\u5c063D\u58f0\u7eb3\u6570\u636e\u4e0e\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\uff08INS\uff09\u5148\u9a8c\u4fe1\u606f\u7ed3\u5408\uff0c\u6784\u5efa\u7a33\u5065\u7684\u73b0\u4ee3SLAM\u6846\u67b6\uff0c\u5305\u62ec\u95ed\u73af\u68c0\u6d4b\u548c\u59ff\u6001\u56fe\u4f18\u5316\u3002", "result": "\u5728\u6d4b\u8bd5\u6c34\u7bb1\u548c\u5ba4\u5916\u6df9\u6ca1\u91c7\u77f3\u573a\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e0e\u6c34\u4e0b\u8fd0\u52a8\u8ddf\u8e2a\u7cfb\u7edf\u548c\u89c6\u89c9SFM\u53c2\u8003\u8f68\u8ff9\u5bf9\u6bd4\u300250\u5206\u949f\u4efb\u52a1\u4e2d\u5e73\u5747\u8f68\u8ff9\u8bef\u5dee\u4f4e\u4e8e21cm\uff0c\u751f\u621010m\u00d720m\u5730\u56fe\uff0c\u5e73\u5747\u91cd\u5efa\u8bef\u5dee9cm\uff0c\u6709\u6548\u6821\u6b63\u91cc\u7a0b\u8ba1\u6f02\u79fb\u3002", "conclusion": "InsSo3D\u80fd\u591f\u9ad8\u6548\u6821\u6b63\u91cc\u7a0b\u8ba1\u6f02\u79fb\uff0c\u5728\u6d51\u6d4a\u6c34\u57df\u6761\u4ef6\u4e0b\u5b9e\u73b0\u51c6\u786e\u7684\u6c34\u4e0b\u5b9a\u4f4d\u548c\u5efa\u56fe\uff0c\u4e3a\u81ea\u7136\u6216\u4eba\u5de5\u6c34\u4e0b\u7ed3\u6784\u7684\u5b89\u5168\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.05806", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05806", "abs": "https://arxiv.org/abs/2601.05806", "authors": ["Marvin Seegert", "Korbinian Moller", "Johannes Betz"], "title": "Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving", "comment": "Submitted to the IEEE Intelligent Vehicles Symposium (IV 2026), Detroit, MI, United States", "summary": "Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u6846\u67b6\uff0c\u901a\u8fc7DSL\u7ffb\u8bd1\u548c\u5b89\u5168\u9a8c\u8bc1\u5c42\uff0c\u5c06\u590d\u6742\u7684\u4eba\u7c7b\u8bed\u8a00\u6307\u4ee4\u6620\u5c04\u5230\u7ed3\u6784\u5316\u81ea\u52a8\u9a7e\u9a76\u52a8\u4f5c\u7a7a\u95f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8d85\u8d8a\u4f20\u7edf\u521a\u6027\u8f93\u5165\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u673a\u4f1a\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4eba\u7c7b\u8bed\u8a00\u590d\u6742\u6027\u5230\u7ed3\u6784\u5316\u81ea\u52a8\u9a7e\u9a76\u52a8\u4f5c\u7a7a\u95f4\u7684\u6620\u5c04\u6311\u6218\u3002", "method": "\u63d0\u51fa\u96c6\u6210LLM\u4ea4\u4e92\u5c42\u4e0eAutoware\u81ea\u52a8\u9a7e\u9a76\u8f6f\u4ef6\u7684\u4e09\u7ec4\u4ef6\u6846\u67b6\uff1a\u4ea4\u4e92\u7c7b\u522b\u5206\u7c7b\u3001\u9762\u5411\u5e94\u7528\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u547d\u4ee4\u7ffb\u8bd1\u3001\u5b89\u5168\u4fdd\u62a4\u9a8c\u8bc1\u5c42\uff0c\u91c7\u7528\u4e24\u9636\u6bb5LLM\u67b6\u6784\u786e\u4fdd\u9ad8\u900f\u660e\u5ea6\u3002", "result": "\u8bc4\u4f30\u8bc1\u5b9e\u7cfb\u7edf\u7684\u65f6\u95f4\u6548\u7387\u548c\u7ffb\u8bd1\u9c81\u68d2\u6027\uff0c\u4eff\u771f\u6210\u529f\u9a8c\u8bc1\u4e86\u6240\u6709\u4e94\u4e2a\u4ea4\u4e92\u7c7b\u522b\u7684\u547d\u4ee4\u6267\u884c\uff0c\u4e3a\u6a21\u5757\u5316\u5b89\u5168\u81ea\u52a8\u9a7e\u9a76\u5806\u6808\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684DSL\u8f85\u52a9\u4ea4\u4e92\u57fa\u7840\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6a21\u5757\u5316\u548c\u6ce8\u91cd\u5b89\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u5806\u6808\u4e2d\u7684\u53ef\u6269\u5c55DSL\u8f85\u52a9\u4ea4\u4e92\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u4ece\u72b6\u6001\u67e5\u8be2\u5230\u9a7e\u9a76\u884c\u4e3a\u4fee\u6539\u7684\u9ad8\u5c42\u547d\u4ee4\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002"}}
{"id": "2601.05836", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05836", "abs": "https://arxiv.org/abs/2601.05836", "authors": ["Sheng-Kai Chen", "Jyh-Horng Wu"], "title": "Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning", "comment": "Published in TANET 2025 (Paper No. T0404)", "summary": "This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u5b89\u5168\u7cfb\u7edf\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684UR10\u673a\u68b0\u81c2\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u5947\u5f02\u70b9\u68c0\u6d4b\u4e0e\u89c4\u907f\uff0c\u5b9e\u73b0\u4e8690%\u7684\u76ee\u6807\u4f4d\u7f6e\u5230\u8fbe\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u673a\u68b0\u81c2\u64cd\u4f5c\u4e2d\u7684\u5947\u5f02\u70b9\u95ee\u9898\uff0c\u8fd9\u4e9b\u5947\u5f02\u70b9\u53ef\u80fd\u5bfc\u81f4\u63a7\u5236\u5931\u6548\u548c\u8bbe\u5907\u635f\u574f\uff0c\u662f\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u5b9e\u65f6\u5947\u5f02\u70b9\u68c0\u6d4b\uff08\u4f7f\u7528\u53ef\u64cd\u4f5c\u6027\u5ea6\u91cf\u3001\u6761\u4ef6\u6570\u5206\u6790\uff09\u3001\u6a21\u7cca\u903b\u8f91\u51b3\u7b56\u7cfb\u7edf\uff0c\u7ed3\u5408\u7a33\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u81ea\u9002\u5e94\u8def\u5f84\u89c4\u5212\u3002\u7cfb\u7edf\u6574\u5408\u4e86PyBullet\u4eff\u771f\u8bad\u7ec3\u548cURSim\u5b9e\u9645\u90e8\u7f72\u8fde\u63a5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u5728\u4fdd\u6301\u4e0e\u5947\u5f02\u914d\u7f6e\u5b89\u5168\u8ddd\u79bb\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e8690%\u7684\u76ee\u6807\u4f4d\u7f6e\u5230\u8fbe\u6210\u529f\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u7efc\u5408\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86UR10\u673a\u68b0\u81c2\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u5947\u5f02\u70b9\u68c0\u6d4b\u4e0e\u89c4\u907f\u95ee\u9898\uff0c\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u5b89\u5168\u7cfb\u7edf\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
