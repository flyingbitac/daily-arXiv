<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.10071)
*Junjie Bai,Yu-Wei Chao,Qizhi Chen,Jinwei Gu,Moo Jin Kim,Zhaoshuo Li,Xuan Li,Tsung-Yi Lin,Ming-Yu Liu,Nic Ma,Kaichun Mo,Delin Qu,Shangkun Sun,Hongchi Xia,Fangyin Wei,Xiaohui Zeng*

Main category: cs.RO

TL;DR: 本文介绍了在2025 BEHAVIOR挑战赛中获得第二名的方法，通过系统研究训练技术和数据，展示了预训练和后训练阶段的扩展能力，为具身AI社区提供了实用建议。


<details>
  <summary>Details</summary>
Motivation: BEHAVIOR-1K专注于日常家庭任务，这些任务引入了真实环境中的长时程移动操作挑战，旨在弥合当前研究与现实世界、以人为中心的应用之间的差距。

Method: 基于π₀.₅框架，通过系统研究训练技术和数据的影响，进行仔细的消融实验，展示预训练和后训练阶段的扩展能力。

Result: 在2025 BEHAVIOR挑战赛中获得非常接近的第二名，并显著优于其他提交方案。

Conclusion: 总结了实用的经验教训和设计建议，为更广泛的具身AI社区在将强大的基础模型适应复杂具身场景时提供可操作的见解。

Abstract: The 2025 BEHAVIOR Challenge is designed to rigorously track progress toward solving long-horizon tasks by physical agents in simulated environments. BEHAVIOR-1K focuses on everyday household tasks that people most want robots to assist with and these tasks introduce long-horizon mobile manipulation challenges in realistic settings, bridging the gap between current research and real-world, human-centric applications. This report presents our solution to the 2025 BEHAVIOR Challenge in a very close 2nd place and substantially outperforms the rest of the submissions. Building on $π_{0.5}$, we focus on systematically building our solution by studying the effects of training techniques and data. Through careful ablations, we show the scaling power in pre-training and post-training phases for competitive performance. We summarize our practical lessons and design recommendations that we hope will provide actionable insights for the broader embodied AI community when adapting powerful foundation models to complex embodied scenarios.

</details>


### [2] [Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation](https://arxiv.org/abs/2512.10099)
*Steven Caro,Stephen L. Smith*

Main category: cs.RO

TL;DR: HeRD：分层强化学习-扩散策略，将非抓取推物任务分解为高层目标选择和底层轨迹生成，结合RL的长期奖励优化与扩散模型的生成能力。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作（如推物）在杂乱环境中面临复杂接触动力学和长时程规划的挑战，需要有效的方法来处理这些困难。

Method: 提出HeRD分层策略：高层使用RL智能体选择中间空间目标，底层使用目标条件扩散模型生成可行高效的轨迹到达这些目标。

Result: 在2D仿真环境中评估，在成功率、路径效率和跨多种环境配置的泛化能力方面优于现有最优基线方法。

Conclusion: 分层控制结合生成式底层规划是非抓取操作可扩展、目标导向的有前景方向。

Abstract: Nonprehensile manipulation, such as pushing objects across cluttered environments, presents a challenging control problem due to complex contact dynamics and long-horizon planning requirements. In this work, we propose HeRD, a hierarchical reinforcement learning-diffusion policy that decomposes pushing tasks into two levels: high-level goal selection and low-level trajectory generation. We employ a high-level reinforcement learning (RL) agent to select intermediate spatial goals, and a low-level goal-conditioned diffusion model to generate feasible, efficient trajectories to reach them.
  This architecture combines the long-term reward maximizing behaviour of RL with the generative capabilities of diffusion models. We evaluate our method in a 2D simulation environment and show that it outperforms the state-of-the-art baseline in success rate, path efficiency, and generalization across multiple environment configurations. Our results suggest that hierarchical control with generative low-level planning is a promising direction for scalable, goal-directed nonprehensile manipulation. Code, documentation, and trained models are available: https://github.com/carosteven/HeRD.

</details>


### [3] [Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks](https://arxiv.org/abs/2512.10116)
*Andrew Razjigaev,Hans Lohr,Alejandro Vargas-Uscategui,Peter King,Tirthankar Bandyopadhyay*

Main category: cs.RO

TL;DR: 提出一种新颖的功能冗余逆运动学算法，用于六轴机械臂在对称工具轴情况下的快速运动规划，特别适用于冷喷涂涂层应用中的工具路径优化。


<details>
  <summary>Details</summary>
Motivation: 六轴工业机械臂在许多制造任务中存在功能冗余（由于对称工具轴实际上变为五轴任务），现有逆运动学算法在快速反应框架中未充分利用，而离线规划方法计算成本过高。

Method: 采用任务空间分解方法、阻尼最小二乘法和Halley方法相结合的新算法，实现快速鲁棒的功能冗余逆运动学求解，减少关节运动。

Result: 算法能够快速求解最小化关节运动的运动规划，扩展复杂工具路径的可行操作空间，并在ABB工业机械臂和冷喷涂枪上验证了计算工具路径的有效性。

Conclusion: 提出的功能冗余逆运动学算法为对称工具轴制造任务提供了快速、鲁棒的运动规划解决方案，特别适用于非平面表面的冷喷涂涂层应用优化。

Abstract: Industrial automation with six-axis robotic arms is critical for many manufacturing tasks, including welding and additive manufacturing applications; however, many of these operations are functionally redundant due to the symmetrical tool axis, which effectively makes the operation a five-axis task. Exploiting this redundancy is crucial for achieving the desired workspace and dexterity required for the feasibility and optimisation of toolpath planning. Inverse kinematics algorithms can solve this in a fast, reactive framework, but these techniques are underutilised over the more computationally expensive offline planning methods. We propose a novel algorithm to solve functionally redundant inverse kinematics for robotic manipulation utilising a task space decomposition approach, the damped least-squares method and Halley's method to achieve fast and robust solutions with reduced joint motion. We evaluate our methodology in the case of toolpath optimisation in a cold spray coating application on a non-planar surface. The functionally redundant inverse kinematics algorithm can quickly solve motion plans that minimise joint motion, expanding the feasible operating space of the complex toolpath. We validate our approach on an industrial ABB manipulator and cold-spray gun executing the computed toolpath.

</details>


### [4] [Inertial Magnetic SLAM Systems Using Low-Cost Sensors](https://arxiv.org/abs/2512.10128)
*Chuan Huang,Gustaf Hendeby,Isaac Skog*

Main category: cs.RO

TL;DR: 提出两种惯性磁SLAM系统（松耦合与紧耦合），使用低成本IMU、磁力计阵列和气压计，在低能见度条件下实现定位与建图，典型误差为每100米行程数米级。


<details>
  <summary>Details</summary>
Motivation: 现有磁SLAM系统通常需要视觉里程计或轮式编码器提供的低漂移里程数据，限制了在无地图区域的定位能力。需要开发不依赖视觉、在低能见度条件下仍能工作的定位系统。

Method: 提出松耦合和紧耦合两种惯性磁SLAM系统，均使用低成本传感器（IMU、磁力计阵列、气压计）。松耦合系统将局部和全局磁场模型分别用于两个状态空间模型，而紧耦合系统将它们集成到单一状态空间模型中。

Result: 实验结果显示，紧耦合IM-SLAM系统在大多数场景下比松耦合系统具有更低的定位误差，典型误差为每100米行程数米级。

Conclusion: 证明了使用低成本传感器开发完整3D IM-SLAM系统的可行性，这些系统在矿井/火灾救援等应急响应场景中具有应用潜力。

Abstract: Spatially inhomogeneous magnetic fields offer a valuable, non-visual information source for positioning. Among systems leveraging this, magnetic field-based simultaneous localization and mapping (SLAM) systems are particularly attractive because they can provide positioning information and build a magnetic field map on the fly. Moreover, they have bounded error within mapped regions. However, state-of-the-art methods typically require low-drift odometry data provided by visual odometry or a wheel encoder, etc. This is because these systems need to minimize/reduce positioning errors while exploring, which happens when they are in unmapped regions. To address these limitations, this work proposes a loosely coupled and a tightly coupled inertial magnetic SLAM (IM-SLAM) system. The proposed systems use commonly available low-cost sensors: an inertial measurement unit (IMU), a magnetometer array, and a barometer. The use of non-visual data provides a significant advantage over visual-based systems, making it robust to low-visibility conditions. Both systems employ state-space representations, and magnetic field models on different scales. The difference lies in how they use a local and global magnetic field model. The loosely coupled system uses these models separately in two state-space models, while the tightly coupled system integrates them into one state-space model. Experiment results show that the tightly coupled IM-SLAM system achieves lower positioning errors than the loosely coupled system in most scenarios, with typical errors on the order of meters per 100 meters traveled. These results demonstrate the feasiblity of developing a full 3D IM-SLAM systems using low-cost sensors and the potential of applying these systems in emergency response scenarios such as mine/fire rescue.

</details>


### [5] [Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine](https://arxiv.org/abs/2512.10235)
*Hui Li,Akhlak Uz Zaman,Fujian Yan,Hongsheng He*

Main category: cs.RO

TL;DR: 提出了一种结合上下文奖励机制的强化学习框架，用于任务导向抓取，通过将复杂任务分解为子任务并引入阶段特定上下文，显著提高了学习效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 任务导向抓取通常涉及复杂的决策过程，传统方法在处理多样化物体、功能属性和抓取拓扑时面临状态-动作空间过大、学习效率低下的挑战。需要一种能够有效分解任务复杂性并指导探索的方法。

Method: 提出上下文奖励机制框架，将抓取任务分解为可管理的子任务，每个子任务关联阶段特定上下文（包括奖励函数、动作空间和状态抽象函数）。引入转移奖励来鼓励或惩罚阶段间转移，引导模型朝向理想的阶段序列。该方法与近端策略优化算法集成。

Result: 在1000个模拟抓取任务中达到95%的成功率，涵盖多样化物体、功能属性和抓取拓扑。在学习和成功率方面均优于现有最先进方法。迁移到真实机器人上，在60个抓取任务中达到83.3%的成功率，涵盖六个功能属性。

Conclusion: 该方法通过上下文奖励机制有效分解任务复杂性，减少状态-动作空间，提供明确的探索边界，显著提高了任务导向抓取的准确性、数据效率和学习效率，在模拟和真实环境中都展现出优越性能。

Abstract: This paper presents a reinforcement learning framework that incorporates a Contextual Reward Machine for task-oriented grasping. The Contextual Reward Machine reduces task complexity by decomposing grasping tasks into manageable sub-tasks. Each sub-task is associated with a stage-specific context, including a reward function, an action space, and a state abstraction function. This contextual information enables efficient intra-stage guidance and improves learning efficiency by reducing the state-action space and guiding exploration within clearly defined boundaries. In addition, transition rewards are introduced to encourage or penalize transitions between stages which guides the model toward desirable stage sequences and further accelerates convergence. When integrated with the Proximal Policy Optimization algorithm, the proposed method achieved a 95% success rate across 1,000 simulated grasping tasks encompassing diverse objects, affordances, and grasp topologies. It outperformed the state-of-the-art methods in both learning speed and success rate. The approach was transferred to a real robot, where it achieved a success rate of 83.3% in 60 grasping tasks over six affordances. These experimental results demonstrate superior accuracy, data efficiency, and learning efficiency. They underscore the model's potential to advance task-oriented grasping in both simulated and real-world settings.

</details>


### [6] [Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups](https://arxiv.org/abs/2512.10294)
*Luís Marques,Maani Ghaffari,Dmitry Berenson*

Main category: cs.RO

TL;DR: CLAPS是一种基于保形预测的对称感知算法，为机器人动作构建保证包含特定概率下系统配置的预测集，适用于非欧几里得配置空间如SE(2)。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法通常需要强假设误差分布或依赖未校准的不确定性估计，而传统保形预测方法将机器人视为欧几里得点，无法处理具有非欧几里得配置空间的系统（如SE(2)移动机器人）。

Method: 使用李群严格分析配置误差，将欧几里得空间的保形预测理论保证扩展到SE(2)空间，提出对称感知的非符合性评分，构建保证包含结果配置的预测集。

Result: 通过考虑配置空间结构，对称感知的非符合性评分产生了更体积高效的预测区域，比现有方法更好地表示底层不确定性，在模拟JetBot和真实MBot上验证有效。

Conclusion: CLAPS为具有非欧几里得配置空间的机器人系统提供了分布无关的概率保证，无需对系统动态、不确定性源或近似模型质量做强假设，实现了更准确的不确定性表示。

Abstract: We propose Conformal Lie-group Action Prediction Sets (CLAPS), a symmetry-aware conformal prediction-based algorithm that constructs, for a given action, a set guaranteed to contain the resulting system configuration at a user-defined probability. Our assurance holds under both aleatoric and epistemic uncertainty, non-asymptotically, and does not require strong assumptions about the true system dynamics, the uncertainty sources, or the quality of the approximate dynamics model. Typically, uncertainty quantification is tackled by making strong assumptions about the error distribution or magnitude, or by relying on uncalibrated uncertainty estimates - i.e., with no link to frequentist probabilities - which are insufficient for safe control. Recently, conformal prediction has emerged as a statistical framework capable of providing distribution-free probabilistic guarantees on test-time prediction accuracy. While current conformal methods treat robots as Euclidean points, many systems have non-Euclidean configurations, e.g., some mobile robots have SE(2). In this work, we rigorously analyze configuration errors using Lie groups, extending previous Euclidean Space theoretical guarantees to SE(2). Our experiments on a simulated JetBot, and on a real MBot, suggest that by considering the configuration space's structure, our symmetry-informed nonconformity score leads to more volume-efficient prediction regions which represent the underlying uncertainty better than existing approaches.

</details>


### [7] [Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot](https://arxiv.org/abs/2512.10319)
*Muhammad Usama,Muhammad Ibrahim Khan,Ahmad Hasan,Muhammad Shaaf Nadeem,Khawaja Fahad Iqbal,Jawad Aslam,Mian Ashfaq Ali,Asad Nisar Awan*

Main category: cs.RO

TL;DR: 本文提出了一种使用低能量激光束进行杂草清除的自主除草机器人，该机器人采用六轮设计和新型双四杆悬挂系统提高稳定性，通过三维线性驱动机制引导激光对准检测到的杂草。


<details>
  <summary>Details</summary>
Motivation: 传统机械除草在大面积农田中效率低下，而除草剂会破坏土壤生态系统。激光除草作为一种可持续的精准农业替代方案，需要开发能够有效导航农田地形并精确清除杂草的自主机器人系统。

Method: 设计了一个六轮自主除草机器人，采用新型双四杆悬挂系统提高稳定性。机器人配备低能量激光束除草系统，通过三维线性驱动机制将激光精确引导至检测到的杂草位置。

Result: 现场测试显示，机器人能够有效导航农田地形，克服高达15厘米的障碍。在42.5厘米/秒的最优速度下，杂草检测率达到86.2%，每米操作时间为87秒。激光驱动机制保持1.54毫米的最小平均位置误差，命中率高达97%。

Conclusion: 该自主激光除草机器人在速度、精度和效率方面的优异表现，展示了其在显著提升精准农业实践方面的巨大潜力，为可持续农业除草提供了有效的技术解决方案。

Abstract: Mobile robots are increasingly utilized in agriculture to automate labor-intensive tasks such as weeding, sowing, harvesting and soil analysis. Recently, agricultural robots have been developed to detect and remove weeds using mechanical tools or precise herbicide sprays. Mechanical weeding is inefficient over large fields, and herbicides harm the soil ecosystem. Laser weeding with mobile robots has emerged as a sustainable alternative in precision farming. In this paper, we present an autonomous weeding robot that uses controlled exposure to a low energy laser beam for weed removal. The proposed robot is six-wheeled with a novel double four-bar suspension for higher stability. The laser is guided towards the detected weeds by a three-dimensional linear actuation mechanism. Field tests have demonstrated the robot's capability to navigate agricultural terrains effectively by overcoming obstacles up to 15 cm in height. At an optimal speed of 42.5 cm/s, the robot achieves a weed detection rate of 86.2\% and operating time of 87 seconds per meter. The laser actuation mechanism maintains a minimal mean positional error of 1.54 mm, combined with a high hit rate of 97\%, ensuring effective and accurate weed removal. This combination of speed, accuracy, and efficiency highlights the robot's potential for significantly enhancing precision farming practices.

</details>


### [8] [Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing](https://arxiv.org/abs/2512.10349)
*Quan Yuan,Zhenting Du,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 提出一种欠驱动腱驱动机器人手指，采用同步腱绳布线实现所有关节机械耦合，单电机驱动，在保持刚度和顺应性的同时减少执行器数量。


<details>
  <summary>Details</summary>
Motivation: 腱驱动欠驱动机器人手指在灵巧操作中具有优势，但如何在紧凑结构中同时实现高负载能力和自适应顺应性仍具挑战性。

Method: 设计同步腱绳布线方案，机械耦合所有关节并固定角速度比，使整个手指可由单个执行器驱动；建立包含腱弹性的运动学和静力学模型预测结构刚度。

Result: 单指原型测试显示平均偏转预测误差1.0mm（总指长0.322%），3kg指尖负载下测量刚度为1.2×10^3 N/m；集成五指机械手可有效操作多种物体。

Conclusion: 提出的同步腱绳布线方案实现了可预测的刚度和可靠的抓取性能，同时最小化执行器数量，验证了该欠驱动腱驱动机器人手指设计的有效性。

Abstract: Tendon-driven under-actuated robotic fingers provide advantages for dexterous manipulation through reduced actuator requirements and simplified mechanical design. However, achieving both high load capacity and adaptive compliance in a compact form remains challenging. This paper presents an under-actuated tendon-driven robotic finger (UTRF) featuring a synchronous tendon routing that mechanically couples all joints with fixed angular velocity ratios, enabling the entire finger to be actuated by a single actuator. This approach significantly reduces the number of actuators required in multi-finger hands, resulting in a lighter and more compact structure without sacrificing stiffness or compliance. The kinematic and static models of the finger are derived, incorporating tendon elasticity to predict structural stiffness. A single-finger prototype was fabricated and tested under static loading, showing an average deflection prediction error of 1.0 mm (0.322% of total finger length) and a measured stiffness of 1.2x10^3 N/m under a 3 kg tip load. Integration into a five-finger robotic hand (UTRF-RoboHand) demonstrates effective object manipulation across diverse scenarios, confirming that the proposed routing achieves predictable stiffness and reliable grasping performance with a minimal actuator count.

</details>


### [9] [RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI](https://arxiv.org/abs/2512.10394)
*Weifan Guan,Huasen Xi,Chenxiao Zhang,Aosheng Li,Qinghao Hu,Jian Cheng*

Main category: cs.RO

TL;DR: RoboNeuron是一个将大语言模型和视觉-语言-动作模型与ROS系统深度集成的通用机器人部署框架，通过MCP协议实现语义桥接，显著提升跨场景适应性和模块化程度。


<details>
  <summary>Details</summary>
Motivation: 当前具身AI系统面临跨场景适应性差、模块间耦合度高、推理加速碎片化等工程障碍，需要一种能够克服这些限制的通用部署框架。

Method: 1) 首次深度集成LLM/VLA模型的认知能力与ROS实时执行系统；2) 使用MCP协议作为语义桥接，让LLM动态编排底层机器人工具；3) 建立高度模块化架构，通过ROS统一通信接口严格解耦感知、推理和控制；4) 引入自动化工具将ROS消息转换为可调用的MCP函数。

Result: RoboNeuron显著增强了跨场景适应性和组件灵活性，同时建立了系统化的横向性能基准测试平台，为可扩展的真实世界具身应用奠定了坚实基础。

Conclusion: RoboNeuron通过深度集成认知模型与机器人执行系统，解决了当前具身AI系统的关键工程障碍，为可扩展的具身智能应用提供了通用部署框架。

Abstract: Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS's unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.

</details>


### [10] [Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots](https://arxiv.org/abs/2512.10477)
*Timur Ishuov,Michele Folgheraiter,Madi Nurmanov,Goncalo Gordo,Richárd Farkas,József Dombi*

Main category: cs.RO

TL;DR: 提出Symphony算法，通过"襁褓"正则化、确定性策略和渐消回放缓冲区等技术，实现人形机器人从零开始的安全高效训练。


<details>
  <summary>Details</summary>
Motivation: 人类学习需要时间，但机器人训练不能等待数百万步。现有方法存在安全性问题，高斯噪声会损坏电机和齿轮箱，需要更安全高效的训练方法。

Method: 提出Symphony算法：1) "襁褓"正则化限制动作强度；2) 确定性策略与有限参数噪声；3) 渐消回放缓冲区结合近期和长期记忆；4) 时间优势实现单次更新。

Result: 相比随机算法，该方法显著提高训练安全性，保护环境和机器人机制，同时保持样本效率和动作安全性。

Conclusion: Symphony算法通过创新的正则化、噪声控制和记忆管理机制，为人形机器人从零开始训练提供了安全高效的解决方案。

Abstract: In our work we not explicitly hint that it is a misconception to think that humans learn fast. Learning process takes time. Babies start learning to move in the restricted liquid area called placenta. Children often are limited by underdeveloped body. Even adults are not allowed to participate in complex competitions right away. However, with robots, when learning from scratch, we often don't have the privilege of waiting for dozen millions of steps. "Swaddling" regularization is responsible for restraining an agent in rapid but unstable development penalizing action strength in a specific way not affecting actions directly. The Symphony, Transitional-policy Deterministic Actor and Critic algorithm, is a concise combination of different ideas for possibility of training humanoid robots from scratch with Sample Efficiency, Sample Proximity and Safety of Actions in mind. It is no secret that continuous increase in Gaussian noise without appropriate smoothing is harmful for motors and gearboxes. Compared to Stochastic algorithms, we set a limited parametric noise and promote a reduced strength of actions, safely increasing entropy, since the actions are kind of immersed in weaker noise. When actions require more extreme values, actions rise above the weak noise. Training becomes empirically much safer for both the environment around and the robot's mechanisms. We use Fading Replay Buffer: using a fixed formula containing the hyperbolic tangent, we adjust the batch sampling probability: the memory contains a recent memory and a long-term memory trail. Fading Replay Buffer allows us to use Temporal Advantage when we improve the current Critic Network prediction compared to the exponential moving average. Temporal Advantage allows us to update Actor and Critic in one pass, as well as combine Actor and Critic in one Object and implement their Losses in one line.

</details>


### [11] [Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS/UWB/IMU Fusion: A Comparison of EKF, FGO, and PF](https://arxiv.org/abs/2512.10480)
*Jiaqiang Zhang,Xianjia Yu,Sier Ha,Paola Torrico Moron,Sahar Salimpour,Farhad Kerama,Haizhou Zhang,Tomi Westerlund*

Main category: cs.RO

TL;DR: 本文提出了一个统一的GNSS/UWB/IMU融合框架，用于无缝行人定位，并比较了三种概率后端方法：误差状态扩展卡尔曼滤波器、滑动窗口因子图优化和粒子滤波器。


<details>
  <summary>Details</summary>
Motivation: 室外-室内环境中的准确连续行人定位仍然具有挑战性，因为GNSS、UWB和惯性PDR在信号阻塞、多径和漂移情况下具有互补性但各自脆弱。

Method: 系统使用胸部安装的IMU-based PDR作为运动骨干，集成室外GNSS和室内UWB的绝对更新。引入基于OpenStreetMap建筑足迹的轻量级地图可行性约束，增强过渡鲁棒性并减轻城市GNSS退化。

Result: 评估了三种场景：室内(UWB+PDR)、室外(GNSS+PDR)和室外-室内无缝(GNSS+UWB+PDR)。结果显示，在实现中ESKF提供了最一致的整体性能。

Conclusion: 提出的统一融合框架在ROS 2中实时运行，通过地图约束增强鲁棒性，ESKF在比较的三种后端方法中表现最佳。

Abstract: Accurate and continuous pedestrian positioning across outdoor-indoor environments remains challenging because GNSS, UWB, and inertial PDR are complementary yet individually fragile under signal blockage, multipath, and drift. This paper presents a unified GNSS/UWB/IMU fusion framework for seamless pedestrian localization and provides a controlled comparison of three probabilistic back-ends: an error-state extended Kalman filter, sliding-window factor graph optimization, and a particle filter. The system uses chest-mounted IMU-based PDR as the motion backbone and integrates absolute updates from GNSS outdoors and UWB indoors. To enhance transition robustness and mitigate urban GNSS degradation, we introduce a lightweight map-based feasibility constraint derived from OpenStreetMap building footprints, treating most building interiors as non-navigable while allowing motion inside a designated UWB-instrumented building. The framework is implemented in ROS 2 and runs in real time on a wearable platform, with visualization in Foxglove. We evaluate three scenarios: indoor (UWB+PDR), outdoor (GNSS+PDR), and seamless outdoor-indoor (GNSS+UWB+PDR). Results show that the ESKF provides the most consistent overall performance in our implementation.

</details>


### [12] [Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks](https://arxiv.org/abs/2512.10481)
*Gaozhao Wang,Xing Liu,Zhenduo Ye,Zhengxiong Liu,Panfeng Huang*

Main category: cs.RO

TL;DR: 提出Contact SLAM方法，仅使用触觉传感和先验知识在视觉遮挡环境下实现接触丰富的操作


<details>
  <summary>Details</summary>
Motivation: 在视觉被遮挡的"盲操作"场景中，机器人无法通过视觉反馈获取实时场景状态信息，需要新的感知方法来实现接触丰富的操作

Method: 提出物理驱动的接触认知方法Contact SLAM，仅使用触觉传感和场景先验知识来估计环境状态；同时设计了主动探索策略，逐步减少操作场景中的不确定性

Result: 实验结果表明，该方法在多个接触丰富的任务中表现出有效性和准确性，包括困难的插座装配任务和方块推动任务

Conclusion: Contact SLAM方法能够在视觉受限的盲操作环境中，仅依靠触觉传感实现准确的环境状态估计和操作执行

Abstract: Contact-rich manipulation is difficult for robots to execute and requires accurate perception of the environment. In some scenarios, vision is occluded. The robot can then no longer obtain real-time scene state information through visual feedback. This is called ``blind manipulation". In this manuscript, a novel physically-driven contact cognition method, called ``Contact SLAM", is proposed. It estimates the state of the environment and achieves manipulation using only tactile sensing and prior knowledge of the scene. To maximize exploration efficiency, this manuscript also designs an active exploration policy. The policy gradually reduces uncertainties in the manipulation scene. The experimental results demonstrated the effectiveness and accuracy of the proposed method in several contact-rich tasks, including the difficult and delicate socket assembly task and block-pushing task.

</details>


### [13] [LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator](https://arxiv.org/abs/2512.10605)
*Lihuang Chen,Xiangyu Luo,Jun Meng*

Main category: cs.RO

TL;DR: LEO-RobotAgent是一个通用的语言驱动智能体框架，让大语言模型能够操作不同类型的机器人完成跨场景的复杂任务，具有模块化工具集和人机交互机制。


<details>
  <summary>Details</summary>
Motivation: 现有机器人任务规划研究大多关注单一任务场景和单一机器人类型，算法结构复杂且缺乏泛化能力，需要一种通用的、结构简洁的框架来提升大模型在机器人控制中的独立思考和规划能力。

Method: 设计了一个结构简洁的框架，让大模型能够在其中独立思考、规划和行动；提供了模块化且易于注册的工具集，使大模型能够灵活调用各种工具；集成了人机交互机制，使算法能够像伙伴一样与人类协作。

Result: 实验验证该框架能够轻松适配主流机器人平台（无人机、机械臂、轮式机器人），并高效执行不同复杂度的精心设计任务。

Conclusion: LEO-RobotAgent框架具有强大的泛化性、鲁棒性和效率，能够增强双向人机意图理解，降低人机交互门槛，为通用机器人智能体提供了有效的解决方案。

Abstract: We propose LEO-RobotAgent, a general-purpose language-driven intelligent agent framework for robots. Under this framework, LLMs can operate different types of robots to complete unpredictable complex tasks across various scenarios. This framework features strong generalization, robustness, and efficiency. The application-level system built around it can fully enhance bidirectional human-robot intent understanding and lower the threshold for human-robot interaction. Regarding robot task planning, the vast majority of existing studies focus on the application of large models in single-task scenarios and for single robot types. These algorithms often have complex structures and lack generalizability. Thus, the proposed LEO-RobotAgent framework is designed with a streamlined structure as much as possible, enabling large models to independently think, plan, and act within this clear framework. We provide a modular and easily registrable toolset, allowing large models to flexibly call various tools to meet different requirements. Meanwhile, the framework incorporates a human-robot interaction mechanism, enabling the algorithm to collaborate with humans like a partner. Experiments have verified that this framework can be easily adapted to mainstream robot platforms including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robot, and efficiently execute a variety of carefully designed tasks with different complexity levels. Our code is available at https://github.com/LegendLeoChen/LEO-RobotAgent.

</details>


### [14] [Evaluating Gemini Robotics Policies in a Veo World Simulator](https://arxiv.org/abs/2512.10675)
*Gemini Robotics Team,Coline Devin,Yilun Du,Debidatta Dwibedi,Ruiqi Gao,Abhishek Jindal,Thomas Kipf,Sean Kirmani,Fangchen Liu,Anirudha Majumdar,Andrew Marmon,Carolina Parada,Yulia Rubanova,Dhruv Shah,Vikas Sindhwani,Jie Tan,Fei Xia,Ted Xiao,Sherry Yang,Wenhao Yu,Allan Zhou*

Main category: cs.RO

TL;DR: 视频生成模型可用于机器人策略的全方位评估，包括正常性能、分布外泛化、物理和语义安全性测试


<details>
  <summary>Details</summary>
Motivation: 当前视频模型在机器人领域的应用主要局限于分布内评估，缺乏对策略在多样化场景下表现的全面评估能力

Method: 基于前沿视频基础模型Veo构建生成式评估系统，支持机器人动作条件化和多视图一致性，集成生成式图像编辑和多视图补全技术

Result: 系统能准确模拟包含新交互对象、新视觉背景和新干扰物的场景，可预测策略在正常和分布外条件下的相对性能，识别不同泛化轴对性能的影响，并进行红队测试

Conclusion: 视频模型可用于机器人策略的全面评估，包括性能评估、泛化能力测试和安全性验证，通过1600+真实世界评估验证了系统的有效性

Abstract: Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.

</details>


### [15] [How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning](https://arxiv.org/abs/2512.10698)
*Jianbo Wang,Galina Sidorenko,Johan Thunberg*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度强化学习和分析方法的混合方法，用于多车跟随场景中的紧急制动决策，以提高安全性和减少总体伤害。


<details>
  <summary>Details</summary>
Motivation: 联网自动驾驶车辆（CAV）虽然能提升驾驶安全，但传统的保守控制策略会降低灵活性并影响整体性能。需要在多车跟随的紧急制动场景中，通过车辆间通信实现伦理性的紧急制动策略选择，以追求总体伤害减少而非单辆车安全。

Method: 提出了一种混合方法，将深度强化学习（DRL）与基于分析表达式选择最优恒定减速度的现有方法相结合。DRL利用车辆间通信在多车跟随场景中学习紧急制动策略，而分析方法提供可靠性保障。

Result: 混合方法相比单独使用DRL提高了可靠性，同时在总体伤害减少和碰撞避免方面实现了更优的性能表现。

Conclusion: 结合DRL和分析方法的混合方法能够在多车跟随的紧急制动场景中有效平衡安全性和性能，为联网自动驾驶车辆的安全部署提供了可行的解决方案。

Abstract: Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.

</details>


### [16] [On the Stabilization of Rigid Formations on Regular Curves](https://arxiv.org/abs/2512.10700)
*Mohamed Elobaid,Shinkyu Park,Eric Feron*

Main category: cs.RO

TL;DR: 提出了一种在多智能体系统中将等边多边形编队稳定在平面曲线上的方法，包括曲线扫描和编队收敛


<details>
  <summary>Details</summary>
Motivation: 解决多智能体刚性编队在一般平面曲线上稳定化的问题，特别是在路径扫描后将等边多边形编队稳定在闭合可微曲线上

Method: 使用随机多起点牛顿类算法寻找曲线上内接正多边形，然后设计连续反馈控制律保证曲线收敛、充分扫描，并最终收敛到期望编队顶点，同时确保智能体间避碰

Result: 通过数值仿真验证了该方法在不同类型曲线和不同刚性编队上的有效性

Conclusion: 提出的方法能够成功实现多智能体在平面曲线上形成稳定等边多边形编队，并保证智能体间的避碰安全

Abstract: This work deals with the problem of stabilizing a multi-agent rigid formation on a general class of planar curves. Namely, we seek to stabilize an equilateral polygonal formation on closed planar differentiable curves after a path sweep. The task of finding an inscribed regular polygon centered at the point of interest is solved via a randomized multi-start Newton-Like algorithm for which one is able to ascertain the existence of a minimizer. Then we design a continuous feedback law that guarantees convergence to, and sufficient sweeping of the curve, followed by convergence to the desired formation vertices while ensuring inter-agent avoidance. The proposed approach is validated through numerical simulations for different classes of curves and different rigid formations. Code: https://github.com/mebbaid/paper-elobaid-ifacwc-2026

</details>


### [17] [AERMANI-Diffusion: Regime-Conditioned Diffusion for Dynamics Learning in Aerial Manipulators](https://arxiv.org/abs/2512.10773)
*Samaksh Ujjawal,Shivansh Pratap Singh,Naveen Sudheer Nair,Rishabh Dev Yadav,Wei Pan,Spandan Roy*

Main category: cs.RO

TL;DR: 提出一种基于条件扩散过程的框架，用于建模空中机械臂的残余力分布，结合轻量级时间编码器和自适应控制器，显著提升实际测试中的跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂在快速运动中经历配置相关的惯性耦合力和空气动力变化，使得精确动力学建模成为可靠控制的核心挑战。传统解析模型在非线性和非平稳效应下失去精度，而标准数据驱动方法无法表示不同操作条件下出现的多样化残余行为。

Method: 提出一种机制条件扩散框架，使用条件扩散过程建模残余力的完整分布，结合轻量级时间编码器提取近期运动和配置的紧凑摘要。该框架能够通过自适应控制器实现动力学不确定性补偿。

Result: 该框架即使在突然过渡或未见负载情况下也能实现一致的残余预测，在实际测试中显著提高了跟踪精度。

Conclusion: 机制条件扩散框架能够有效建模空中机械臂的复杂残余力分布，结合自适应控制器实现了可靠的动力学不确定性补偿，在实际应用中表现出优越的跟踪性能。

Abstract: Aerial manipulators undergo rapid, configuration-dependent changes in inertial coupling forces and aerodynamic forces, making accurate dynamics modeling a core challenge for reliable control. Analytical models lose fidelity under these nonlinear and nonstationary effects, while standard data-driven methods such as deep neural networks and Gaussian processes cannot represent the diverse residual behaviors that arise across different operating conditions. We propose a regime-conditioned diffusion framework that models the full distribution of residual forces using a conditional diffusion process and a lightweight temporal encoder. The encoder extracts a compact summary of recent motion and configuration, enabling consistent residual predictions even through abrupt transitions or unseen payloads. When combined with an adaptive controller, the framework enables dynamics uncertainty compensation and yields markedly improved tracking accuracy in real-world tests.

</details>


### [18] [Iterative Compositional Data Generation for Robot Control](https://arxiv.org/abs/2512.10891)
*Anh-Quan Pham,Marcel Hussing,Shubhankar P. Patankar,Dani S. Bassett,Jorge Mendez-Mendez,Eric Eaton*

Main category: cs.RO

TL;DR: 提出语义组合扩散变换器，通过分解机器人、物体、障碍物和目标组件来生成未见任务组合的合成数据，结合离线强化学习进行迭代自改进


<details>
  <summary>Details</summary>
Motivation: 机器人操作数据收集成本高昂，难以覆盖多物体、多机器人、多环境场景的组合爆炸空间。现有生成模型难以利用机器人领域的组合结构，无法泛化到未见任务组合

Method: 提出语义组合扩散变换器，将状态转移分解为机器人、物体、障碍物和目标特定组件，通过注意力机制学习组件间交互。训练后能零样本生成高质量转移数据，用于学习未见任务组合的控制策略。引入迭代自改进流程：通过离线强化学习验证合成数据并纳入后续训练

Result: 方法在零样本性能上显著优于单体和硬编码组合基线，最终解决了几乎所有保留任务，并在学习表示中展现出有意义的组合结构

Conclusion: 通过组合建模和迭代自改进，能够高效生成高质量合成数据，解决机器人操作中的组合泛化问题，为数据稀缺的多任务场景提供有效解决方案

Abstract: Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.

</details>


### [19] [Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit](https://arxiv.org/abs/2512.10934)
*Zamirddine Mari,Jérôme Pasquet,Julien Seinturier*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的无人机自主导航方法，能够在未知三维管道环境中仅依靠局部LiDAR观测和条件视觉检测进行导航，无需管道几何先验知识。


<details>
  <summary>Details</summary>
Motivation: 受限管道环境中的自主无人机导航面临重大挑战，包括管道几何约束、壁面接近以及此类场景固有的感知限制。现有方法通常需要明确的几何模型，这在未知环境中难以实现。

Method: 采用强化学习（PPO算法）方法，仅依赖LiDAR局部观测和条件视觉检测管道中心。通过渐进式课程学习策略训练，逐步暴露给更弯曲的几何形状。引入基于直接可见性、方向记忆和LiDAR对称性线索的转弯协商机制来处理部分可观测性。

Result: PPO策略获得了鲁棒且可泛化的行为，在缺乏几何信息的情况下仍持续优于具有明确中心线访问权限的确定性控制器（Pure Pursuit算法）。在高保真3D环境中的验证进一步证实了学习行为向连续物理动力学的可迁移性。

Conclusion: 该方法为未知管道环境中的自主导航提供了完整框架，为工业、地下或医疗应用开辟了前景，在这些应用中通过狭窄且感知能力弱的管道前进是核心挑战。

Abstract: Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics.
  The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.

</details>


### [20] [ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning](https://arxiv.org/abs/2512.10946)
*Wendi Chen,Han Xue,Yi Wang,Fangyuan Zhou,Jun Lv,Yang Jin,Shirun Tang,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ImplicitRDP：一种统一的端到端视觉-力扩散策略，通过结构慢-快学习和虚拟目标表示正则化，整合视觉规划和反应式力控制，在接触丰富任务中显著优于纯视觉和分层基线方法。


<details>
  <summary>Details</summary>
Motivation: 人类级别的接触丰富操作依赖于两种关键模态：视觉提供空间丰富但时间缓慢的全局上下文，而力传感捕捉快速、高频的局部接触动态。由于它们的基本频率和信息差异，整合这些信号具有挑战性。

Method: 提出ImplicitRDP，一种统一的端到端视觉-力扩散策略，包含两个关键技术：1) 结构慢-快学习机制，利用因果注意力同时处理异步视觉和力令牌，使策略能够在力频率下进行闭环调整，同时保持动作块的时间连贯性；2) 虚拟目标表示正则化，将力反馈映射到与动作相同的空间，提供比原始力预测更强的物理基础学习信号，缓解模态崩溃问题。

Result: 在接触丰富任务上的大量实验表明，ImplicitRDP显著优于纯视觉和分层基线方法，实现了更高的反应性和成功率，同时具有简化的训练流程。

Conclusion: ImplicitRDP通过统一的端到端框架成功整合了视觉规划和反应式力控制，解决了多模态整合中的频率差异和模态崩溃问题，为接触丰富操作任务提供了有效的解决方案。

Abstract: Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.

</details>
