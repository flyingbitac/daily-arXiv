<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 19]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 本文系统综述了社交机器人在健康行为改变干预中的应用，分析了行为改变策略和评估方法，为未来HRI研究提供指导。


<details>
  <summary>Details</summary>
Motivation: 社交机器人在健康行为改变干预中的应用日益增多，但缺乏指导其设计和评估的可操作知识。本研究旨在填补这一空白，为社交机器人作为行为改变干预工具提供系统性的知识基础。

Method: 通过系统数据库检索和手工检索识别相关文献，对39项研究进行分析，总结行为改变策略和评估方法。

Result: 分析揭示了四类主要行为改变策略：指导策略、咨询策略、社会影响策略和增强说服力策略。同时识别了当前评估实践的关键特征，包括研究设计、设置、持续时间和结果测量。

Conclusion: 社交机器人作为行为改变干预具有独特优势，提出的策略为设计提供了启发。基于当前评估实践，为未来HRI研究提出了若干方向建议。

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [2] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 本研究设计并制造了一种受牛鼻魟启发的磁响应微型软体机器人，采用NdFeB和PDMS材料制成，通过三维亥姆霍兹线圈产生振荡谐波磁场驱动，在B=5 mT、f=11 Hz时达到最快游泳速度5.25 mm/s（约0.5体长/秒），并能实现直线、转弯和定向等多种游泳模式。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、非结构化的水下环境（如环境监测和微创医疗）中，微型软体机器人因其灵活运动能力和小尺寸具有独特优势。仿生技术应用于微型软体机器人结构设计可显著提高其游泳性能，但由于微型化限制，这些机器人难以内部供电，通常采用无线供电方式。

Method: 设计并制造基于牛鼻魟游泳原理的磁响应微型软体机器人，采用NdFeB和PDMS材料制成。使用三维亥姆霍兹线圈产生振荡谐波磁场进行游泳实验，探索磁场参数对机器人游泳性能的影响，并通过调整线圈电流方向和频率实现不同游泳模式。

Result: 实验结果表明，在B=5 mT和f=11 Hz时游泳速度最快，达到5.25 mm/s（约0.5体长/秒）。通过调整线圈电流方向和频率，机器人可实现直线游泳、转弯游泳和定向游泳等不同模式。采用逐步调整方法可有效减少响应误差对机器人轨迹的影响。

Conclusion: 本研究展示了一种磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定了基础。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [3] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出一个可扩展的跨具身人形机器人控制框架，通过共享潜在表示统一人类和多样化人形平台的运动，支持单臂、双臂和腿式人形机器人。


<details>
  <summary>Details</summary>
Motivation: 解决跨不同形态人形机器人的统一控制问题，实现人类运动到多样化机器人平台的准确迁移，避免为每个机器人单独训练策略。

Method: 采用两阶段方法：1) 使用对比学习构建解耦的潜在空间，捕捉不同身体部位的局部运动模式，引入结合关节旋转和末端执行器定位的相似性度量；2) 在潜在空间中训练目标条件控制策略，使用条件变分自编码器预测潜在空间位移。

Result: 训练的策略可直接部署到多个机器人上无需适配，支持通过轻量级机器人特定嵌入层高效添加新机器人，实现鲁棒、可扩展、具身无关的机器人控制。

Conclusion: 该方法为跨多样化人形机器人平台提供了统一、可扩展的控制框架，实现了人类运动到不同形态机器人的准确迁移和直接部署。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [4] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型上下文协议（MCP）的通用无人机控制接口，将大语言模型与无人机控制系统连接，实现自然语言到无人机控制的转换。


<details>
  <summary>Details</summary>
Motivation: 当前AI在无人机控制中的应用面临挑战：虽然大语言模型具有丰富的地理知识和实时信息处理能力，但将其与无人机控制系统连接需要大量定制化工作，缺乏通用接口。

Method: 采用模型上下文协议（MCP）标准，开发基于云的Linux服务器作为MCP服务器，支持Mavlink协议（无人机通用控制语言），实现LLM与无人机控制系统的通用接口。

Result: 成功实现了真实无人机的飞行控制，并在模拟环境中展示了结合Google Maps MCP服务器的实时导航能力，验证了该通用接口的有效性。

Conclusion: 该研究提供了一种通用、易用的无人机控制接口，将现代AI技术与无人机技术无缝集成，实现了自然语言到无人机控制的转换，为物理AI领域提供了新范式。

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [5] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出CompliantVLA-adaptor，通过VLM感知任务上下文来调整变阻抗控制参数，增强VLA模型在接触丰富任务中的安全性和有效性


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统通常只输出位置控制，缺乏力感知适应能力，导致在涉及接触、柔顺或不确定性的物理任务中出现不安全或失败的情况

Method: 使用视觉语言模型从图像和自然语言中解释任务上下文，调整变阻抗控制器的刚度和阻尼参数，并通过实时力/力矩反馈调节这些参数以确保交互力保持在安全阈值内

Result: 在仿真和真实硬件上的复杂接触丰富任务中，该方法优于VLA基线，提高了成功率并减少了力违规。所有任务的总成功率从9.86%提高到17.29%

Conclusion: CompliantVLA-adaptor为使用VLA进行安全接触丰富操作提供了一条有前景的路径，通过结合VLM的上下文感知和变阻抗控制来增强安全性和有效性

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [6] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的紧凑型低成本移动磁控平台，用于胃肠道靶向药物递送，解决了传统磁控系统的模型校准瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 胃肠道磁控机器人靶向给药有前景，但控制困难。固定磁系统工作空间有限，移动系统存在"模型校准瓶颈"，需要复杂、耗时的预校准物理模型。

Method: 开发紧凑型四电磁铁阵列安装在UR5协作机器人上，采用基于Soft Actor-Critic的深度强化学习控制策略，通过仿真到现实的训练管道实现快速部署。

Result: 控制器在15分钟内完成策略部署，显著减少设置时间。7毫米磁胶囊沿2D轨迹控制，方形路径RMSE为1.18毫米，圆形路径RMSE为1.50毫米，在30cm×20cm临床相关工作空间内成功跟踪。

Conclusion: 该工作展示了一种快速部署、无模型的控制框架，能够在大型工作空间内实现精确磁控，并通过2D胃肠道模型验证。

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [7] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 小型四旋翼无人机通过定制气流传感器实现化学羽流追踪与气流源寻找的互补方法


<details>
  <summary>Details</summary>
Motivation: 随着环境灾害频发，寻找污染物源变得日益重要。小型四旋翼无人机能够在人类周围和受限空间飞行，但受限于气体传感器的低灵敏度和长响应时间，羽流追踪面临挑战。

Method: 开发了能够感知气流大小和方向的定制气流传感器（适用于<100g的小型四旋翼），并基于此实现了改进的"Cast and Surge"算法，利用气流方向感知来寻找和导航至气流源。

Result: 表征实验验证系统能在飞行中检测气流并重新定向无人机朝向气流。多次随机起始位置和方向的试验表明，该源寻找算法能够可靠地找到气流源。

Conclusion: 这项工作为未来平台奠定了基础，使气流传感器能够与其他传感器协同工作，实现更丰富的羽流追踪数据收集和源寻找能力。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [8] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: AION是一个用于空中物体目标导航的端到端双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，在未知环境中无需外部定位或全局地图即可实现视觉导航。


<details>
  <summary>Details</summary>
Motivation: 现有物体目标导航研究主要关注二维运动，而将其扩展到具有三维运动能力的空中平台尚未充分探索。空中机器人虽然具有优越的机动性和搜索效率，但也带来了空间感知、动态控制和安全保障等新挑战。

Method: 提出AION框架，这是一个端到端的双策略强化学习系统，将探索和目标到达行为解耦为两个专门策略，无需依赖外部定位或全局地图，仅基于视觉信息实现空中物体目标导航。

Result: 在AI2-THOR基准测试中表现出色，并在IsaacSim中使用高保真无人机模型验证了实时性能，在探索、导航效率和安全性等综合评价指标上均取得优越表现。

Conclusion: AION框架成功解决了空中物体目标导航的挑战，通过双策略设计实现了高效的探索和精确的目标到达，为无人机在未知环境中的自主导航提供了有效解决方案。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [9] [D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot](https://arxiv.org/abs/2601.15707)
*Qifan Hu,Branko Celler,Weidong Mu,Steven W. Su*

Main category: cs.RO

TL;DR: 提出两阶段校准框架用于3自由度踝关节康复机器人，通过Kronecker积线性参数识别和PPO智能体选择最优4个姿态，显著提高校准效率和信息矩阵行列式值。


<details>
  <summary>Details</summary>
Motivation: 多自由度康复机器人的精确对准对于安全有效的患者训练至关重要，需要高效的校准方法来提高参数估计的鲁棒性。

Method: 1) 基于Kronecker积的开环校准方法，将输入输出对准转化为线性参数识别问题；2) 使用D最优准则作为实验设计目标；3) 训练PPO智能体从50个候选姿态中选择4个信息量最大的姿态。

Result: PPO选择的姿态组合比随机选择的信息矩阵行列式值高两个数量级以上，方差更小；仅用4个D最优姿态获得的参数向量比50个非结构化姿态具有更强的跨周期预测一致性。

Conclusion: 该框架在保持鲁棒参数估计的同时提高了校准效率，为多自由度康复机器人的高精度对准提供了实用指导。

Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.

</details>


### [10] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: Glove2UAV是一个可穿戴IMU手套接口，通过手势控制无人机，并配有振动触觉警告系统，当飞行速度超过预设阈值时提供警报。


<details>
  <summary>Details</summary>
Motivation: 开发一种直观、轻便、易于部署的可穿戴接口，用于无人机控制，通过手势操作和触觉反馈提升动态飞行中的安全性和可预测性。

Method: 使用可穿戴IMU手套实时流式传输惯性测量数据，采用基于中值的异常值抑制和Madgwick方向估计算法处理手掌和手指方向，将运动估计映射到飞行控制原语，并集成振动触觉反馈系统。

Result: 在模拟和实际飞行中验证了实时可行性，结果显示快速的手势命令执行、手势动态与平台运动的稳定耦合、核心命令集的正确操作以及及时的振动警告提示。

Conclusion: Glove2UAV提供了一个有效的手势控制无人机接口，结合触觉反馈增强了飞行安全性，在动态环境中实现了直观、可预测的交互。

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [11] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 本文提出了LM-Calibr标定方法和EVA-LIO定位方法，解决了旋转驱动LiDAR的标定通用性和特征缺失区域定位鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 现有方法需要针对不同安装配置参数化外参，限制了通用性；旋转驱动LiDAR不可避免地扫描特征缺失区域，需要在扫描覆盖度和定位鲁棒性之间平衡

Method: 基于Denavit-Hartenberg约定提出无目标LiDAR-电机标定方法LM-Calibr；提出环境自适应LiDAR-惯性里程计EVA-LIO，根据空间尺度自适应选择下采样率和地图分辨率

Result: LM-Calibr在不同场景、安装角度和初始值下表现出高精度和收敛性；EVA-LIO使执行器能以最大速度运行，提高扫描完整性，同时在LiDAR短暂扫描特征缺失区域时确保鲁棒定位

Conclusion: 提出的LM-Calibr和EVA-LIO方法有效解决了旋转驱动LiDAR系统的标定通用性和特征缺失环境下的定位鲁棒性问题，代码和硬件设计已开源

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [12] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: PUMA是一个端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练中，用于四足机器人的跑酷任务，实现了出色的敏捷性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类运动员能够有效感知环境特征来选择适当的落脚点进行障碍穿越，但赋予腿式机器人类似的感知推理能力仍然是一个重大挑战。现有方法通常依赖遵循预计算落脚点的分层控制器，这限制了机器人的实时适应性和强化学习的探索潜力。

Method: 提出了PUMA端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练过程中。该方法利用地形特征估计以自我为中心的极坐标落脚点先验（包括相对距离和航向），指导机器人进行主动姿态适应以完成跑酷任务。

Result: 在模拟和真实世界环境中对各种离散复杂地形进行了广泛实验，证明了PUMA在具有挑战性的场景中具有出色的敏捷性和鲁棒性。

Conclusion: PUMA框架通过集成视觉感知和落脚点先验，成功解决了四足机器人跑酷任务中的感知推理挑战，实现了类似人类运动员的环境适应能力。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [13] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 提出HumanoidPF表示方法，通过编码人形机器人与障碍物的碰撞自由运动方向，显著促进基于强化学习的穿越技能学习，并在杂乱室内场景中实现从仿真到真实世界的成功迁移。


<details>
  <summary>Details</summary>
Motivation: 研究人形机器人在杂乱室内场景中的无碰撞穿越问题，如跨越地面障碍物、蹲伏通过低矮障碍或挤过狭窄通道。现有方法缺乏有效表示人形机器人与障碍物在避碰过程中的关系，导致难以直接学习相应的穿越技能映射。

Method: 提出Humanoid Potential Field (HumanoidPF)表示方法，将人形机器人与障碍物的关系编码为碰撞自由运动方向；采用混合场景生成方法，结合真实3D室内场景裁剪和程序化合成的障碍物；开发基于强化学习的穿越策略学习框架。

Result: HumanoidPF作为感知表示展现出惊人的可忽略的仿真到真实差距；成功将策略迁移到真实世界，开发了单点击操作的远程控制系统；在仿真和真实世界中进行广泛实验验证了方法的有效性。

Conclusion: HumanoidPF能够有效表示人形机器人与障碍物的碰撞自由运动关系，显著促进穿越技能学习，并具有出色的仿真到真实迁移能力，结合混合场景生成方法，实现了在多样化杂乱室内场景中的通用穿越能力。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [14] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER通过接触式具身推理生成灵巧抓取，引入接触标记作为中间表示，将任务语义与物理约束连接，显著提升成功率和意图对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接将观察映射到抓取参数，缺乏对物理交互的中间推理。语言驱动的灵巧抓取生成需要理解任务语义、3D几何和复杂的手-物体交互。

Method: 提出DextER方法，采用接触式具身推理进行多指操作。关键思路是预测手部链接在物体表面的接触位置，作为连接任务语义与物理约束的具身感知中间表示。方法自回归生成具身接触标记（指定哪些手指链接接触物体表面的哪些位置），然后生成编码手部配置的抓取标记。

Result: 在DexGYS数据集上，DextER达到67.14%的成功率，比最先进方法提升3.83个百分点，意图对齐度提升96.4%。还展示了通过部分接触规范进行可引导生成，实现对抓取合成的细粒度控制。

Conclusion: 接触式具身推理为灵巧抓取生成提供了有效的中间表示，显著提升了性能和控制能力，为语言驱动的多指操作提供了新思路。

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [15] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了SE2(3)李群导航模型的自洽性问题，发现在考虑地球旋转和惯性器件偏差的高精度导航中，传统方法因科里奥利力项而难以保持自洽，并提出了一种新的模型构建方法以提高自洽性。


<details>
  <summary>Details</summary>
Motivation: 当前基于李群的扩展卡尔曼滤波研究显示，在低精度应用（如不考虑地球旋转和惯性偏差的MEMS导航）中，SE2(3)李群框架具有误差传播自洽性优势。但在考虑地球旋转和惯性器件偏差的高精度导航状态估计中，保持这种自洽性极为困难。

Method: 本文对SE2(3)群基高精度导航模型在惯性系、地球系和世界系下的自洽性进行理论分析。通过分析发现传统SE2(3)群导航建模方法的局限性在于非惯性系中速度引入的科里奥利力项。因此提出了一种SE2(3)群导航模型的构建方法，使导航模型更接近完全自洽。

Result: 理论分析表明，传统SE2(3)群导航建模方法在考虑地球旋转和惯性偏差的高精度导航中存在自洽性限制，主要原因是非惯性系中速度引入的科里奥利力项。提出的新构建方法能够提高导航模型的自洽性。

Conclusion: SE2(3)李群框架在高精度导航中的自洽性受到科里奥利力项的限制，通过提出的新模型构建方法可以显著提高导航模型的自洽性，使其更接近完全自洽状态。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [16] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文通过实际SINS/ODO实验和蒙特卡洛仿真验证了改进的SE2(3)群导航模型的性能，作为前一篇理论分析论文的对应研究。


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势在于误差传播的自主性。前一篇论文已从理论上分析了惯性、地球和世界坐标系中导航模型的自主性特性，本文旨在通过实际实验验证改进的SE2(3)群导航模型的性能。

Method: 提出了SE2(3)群导航模型的构建方法，以改进非惯性导航模型实现完全自主性。通过实际SINS/ODO（捷联惯性导航系统/里程计）实验和蒙特卡洛仿真来验证模型性能。

Result: 实验和仿真结果验证了改进的SE2(3)群导航模型在高精度导航中的性能表现，展示了该模型在实际应用中的有效性。

Conclusion: 本文通过实际实验验证了改进的SE2(3)群导航模型的有效性，为前一篇理论分析论文提供了实证支持，证明了该模型在高精度导航应用中的实用价值。

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [17] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出结合模型控制与残差强化学习的框架，通过模型控制器作为基础策略，用残差RL处理不确定性，利用特权信息监督训练，实现稳健的双足行走


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人在真实世界中面临的不确定性挑战，包括不准确的动力学建模和传感器噪声，实现鲁棒和自适应的行走能力

Method: 整合模型控制（DCM轨迹规划器和全身控制器）作为基础策略，引入残差RL策略处理不确定性，使用具有特权信息的模型监督残差策略学习

Result: 方法在多种随机条件下表现出改进的鲁棒性和泛化能力，为双足行走的仿真到现实迁移提供了可扩展的解决方案

Conclusion: 提出的框架通过结合模型控制和残差RL，利用特权监督训练，有效处理真实世界不确定性，实现了稳健的双足行走控制

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [18] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: IVRA是一种轻量级、无需训练的方法，通过利用视觉编码器内置的亲和性提示来增强VLA模型的空间理解能力，提升机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将图像块展平为1D标记序列，削弱了精确操作所需的2D空间线索。需要一种无需外部编码器或重新训练的方法来增强空间理解能力。

Method: IVRA利用模型内置视觉编码器中已有的亲和性提示，在推理时将这些亲和性信号选择性地注入到包含实例级特征的语言模型层中，重新对齐视觉标记交互并保持几何结构。

Result: 在2D VIMA基准测试中，IVRA在低数据情况下比基线LLaRA平均成功率提高4.2%；在3D LIBERO基准测试中，对OpenVLA和FLOWER基线均带来一致提升，包括在基线准确率接近饱和时（96.3%到97.1%）仍有改进。

Conclusion: IVRA是一种通用、轻量级且无需训练的方法，能够有效增强VLA模型的空间理解能力，在多种架构和任务上均表现出性能提升，为机器人操作任务提供了实用的解决方案。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>


### [19] [Point Bridge: 3D Representations for Cross Domain Policy Learning](https://arxiv.org/abs/2601.16212)
*Siddhant Haldar,Lars Johannsmeier,Lerrel Pinto,Abhishek Gupta,Dieter Fox,Yashraj Narang,Ajay Mandlekar*

Main category: cs.RO

TL;DR: Point Bridge框架通过统一的点云表示实现零样本仿真到现实的策略迁移，无需视觉或对象级对齐，在合成数据上训练真实世界操作智能体


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型发展受限于大规模真实世界操作数据稀缺，仿真和合成数据生成存在视觉域差距问题

Method: 结合视觉语言模型自动提取点云表示、基于transformer的策略学习、高效推理流程，利用合成数据训练真实操作智能体

Result: 零样本仿真到现实迁移提升44%，结合少量真实数据后提升66%，在单任务和多任务设置中均优于现有视觉方法

Conclusion: Point Bridge通过域无关的点云表示有效桥接仿真与现实，为大规模合成数据在机器人学习中的应用提供了可行方案

Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/

</details>
