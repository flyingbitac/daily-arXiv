<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation](https://arxiv.org/abs/2602.20200)
*Zaijing Li,Bing Hu,Rui Shao,Gongwei Chen,Dongmei Jiang,Pengwei Xie,Jianye Hao,Liqiang Nie*

Main category: cs.RO

TL;DR: OptimusVLA：一种具有全局先验记忆和局部一致性记忆的双记忆VLA框架，通过任务级先验和时序一致性约束解决机器人操作中推理效率低和鲁棒性差的问题。


<details>
  <summary>Details</summary>
Motivation: 当前分层视觉-语言-动作（VLA）模型在机器人操作中存在两个主要瓶颈：1）推理效率低，各向同性噪声先验与目标动作分布之间存在显著分布差距，导致去噪步骤增多和不可行样本增加；2）鲁棒性差，现有策略仅基于当前观测，忽略了历史序列约束，缺乏任务进度意识和时序一致性。

Method: 提出OptimusVLA双记忆框架：1）全局先验记忆（GPM）：用从语义相似轨迹中检索的任务级先验替代高斯噪声，缩短生成路径并减少函数评估次数；2）局部一致性记忆（LCM）：动态建模已执行动作序列以推断任务进度，并注入学习到的一致性约束来增强轨迹的时序一致性和平滑性。

Result: 在三个仿真基准测试中表现优异：LIBERO上达到98.6%平均成功率，CALVIN上比pi_0提升13.5%，RoboTwin 2.0 Hard上达到38%平均成功率。在真实世界评估中，在泛化和长时程任务上表现最佳，分别超越pi_0 42.9%和52.4%，同时实现2.9倍推理加速。

Conclusion: OptimusVLA通过引入双记忆机制有效解决了VLA模型在机器人操作中的推理效率和鲁棒性问题，在仿真和真实世界任务中均展现出显著性能提升，为分层VLA模型的发展提供了新思路。

Abstract: Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.

</details>


### [2] [Vision-Based Reasoning with Topology-Encoded Graphs for Anatomical Path Disambiguation in Robot-Assisted Endovascular Navigation](https://arxiv.org/abs/2602.20215)
*Jiyuan Zhao,Zhengyu Shi,Wentong Tian,Tianliang Yao,Dong Liu,Tao Liu,Yizhe Wu,Peng Qi*

Main category: cs.RO

TL;DR: 提出SCAR-UNet-GAT两阶段框架，用于机器人辅助PCI的实时路径规划，解决2D DSA投影导致的血管分叉歧义问题


<details>
  <summary>Details</summary>
Motivation: 机器人辅助PCI受限于2D DSA投影，缺乏空间上下文和触觉反馈，导致血管分叉处出现投影歧义，需要智能路径规划方法

Method: 两阶段框架：第一阶段使用SCAR-UNet进行冠状动脉血管分割，第二阶段使用GAT在图结构上推理，识别解剖一致且临床可行的轨迹

Result: SCAR-UNet Dice系数93.1%；GAT路径消歧成功率95.0%，目标到达成功率90.0%，显著优于传统最短路径和启发式方法

Conclusion: 提出的SCAR-UNet-GAT框架能有效解决2D DSA投影歧义问题，在机器人平台上验证了实用性和鲁棒性，为机器人辅助PCI提供可靠路径规划

Abstract: Robotic-assisted percutaneous coronary intervention (PCI) is constrained by the inherent limitations of 2D Digital Subtraction Angiography (DSA). Unlike physicians, who can directly manipulate guidewires and integrate tactile feedback with their prior anatomical knowledge, teleoperated robotic systems must rely solely on 2D projections. This mode of operation, simultaneously lacking spatial context and tactile sensation, may give rise to projection-induced ambiguities at vascular bifurcations. To address this challenge, we propose a two-stage framework (SCAR-UNet-GAT) for real-time robotic path planning. In the first stage, SCAR-UNet, a spatial-coordinate-attention-regularized U-Net, is employed for accurate coronary vessel segmentation. The integration of multi-level attention mechanisms enhances the delineation of thin, tortuous vessels and improves robustness against imaging noise. From the resulting binary masks, vessel centerlines and bifurcation points are extracted, and geometric descriptors (e.g., branch diameter, intersection angles) are fused with local DSA patches to construct node features. In the second stage, a Graph Attention Network (GAT) reasons over the vessel graph to identify anatomically consistent and clinically feasible trajectories, effectively distinguishing true bifurcations from projection-induced false crossings. On a clinical DSA dataset, SCAR-UNet achieved a Dice coefficient of 93.1%. For path disambiguation, the proposed GAT-based method attained a success rate of 95.0% and a target-arrival success rate of 90.0%, substantially outperforming conventional shortest-path planning (60.0% and 55.0%) and heuristic-based planning (75.0% and 70.0%). Validation on a robotic platform further confirmed the practical feasibility and robustness of the proposed framework.

</details>


### [3] [Sample-Efficient Learning with Online Expert Correction for Autonomous Catheter Steering in Endovascular Bifurcation Navigation](https://arxiv.org/abs/2602.20216)
*Hao Wang,Tianliang Yao,Bo Lu,Zhiqiang Pei,Liu Dong,Lei Ma,Peng Qi*

Main category: cs.RO

TL;DR: 提出结合在线专家校正的样本高效强化学习框架，用于血管分叉导航中的自主导管操控，相比基线方法训练收敛更快、定位误差更小。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在自主导管操控中存在奖励稀疏、依赖静态血管模型的问题，导致样本效率低且难以适应术中变化。需要开发能高效学习、适应复杂血管结构的自主导航方法。

Method: 提出三组件框架：1)基于分割的姿态估计模块提供实时状态反馈；2)模糊控制器进行分叉感知的方向调整；3)结合专家先验的结构化奖励生成器指导策略学习。通过在线专家校正减少探索低效性。

Result: 在机器人平台上使用透明血管模型验证，仅需123个训练回合即可收敛，比基线SAC算法减少25.9%训练量，平均位置误差降至基线的83.8%。

Conclusion: 结合样本高效强化学习与在线专家校正的方法能够实现可靠准确的导管操控，特别是在血管分叉等解剖结构复杂的场景中，为血管内导航提供了有效解决方案。

Abstract: Robot-assisted endovascular intervention offers a safe and effective solution for remote catheter manipulation, reducing radiation exposure while enabling precise navigation. Reinforcement learning (RL) has recently emerged as a promising approach for autonomous catheter steering; however, conventional methods suffer from sparse reward design and reliance on static vascular models, limiting their sample efficiency and generalization to intraoperative variations. To overcome these challenges, this paper introduces a sample-efficient RL framework with online expert correction for autonomous catheter steering in endovascular bifurcation navigation. The proposed framework integrates three key components: (1) A segmentation-based pose estimation module for accurate real-time state feedback, (2) A fuzzy controller for bifurcation-aware orientation adjustment, and (3) A structured reward generator incorporating expert priors to guide policy learning. By leveraging online expert correction, the framework reduces exploration inefficiency and enhances policy robustness in complex vascular structures. Experimental validation on a robotic platform using a transparent vascular phantom demonstrates that the proposed approach achieves convergence in 123 training episodes -- a 25.9% reduction compared to the baseline Soft Actor-Critic (SAC) algorithm -- while reducing average positional error to 83.8% of the baseline. These results indicate that combining sample-efficient RL with online expert correction enables reliable and accurate catheter steering, particularly in anatomically challenging bifurcation scenarios critical for endovascular navigation.

</details>


### [4] [An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction](https://arxiv.org/abs/2602.20219)
*Guanting Shen,Zi Tian*

Main category: cs.RO

TL;DR: 提出了一种结合视觉语言模型、语音处理和模糊逻辑的多模态人机交互框架，用于精确控制Dobot机械臂，通过语音命令实现物体操作，实验显示75%的命令执行准确率。


<details>
  <summary>Details</summary>
Motivation: 准确理解人类意图是人机交互的核心挑战，也是实现更自然、直观的人机协作的关键要求。当前需要更可靠和自适应的系统来提升人机协作的自然性。

Method: 采用多模态HRI框架，结合Florence-2进行物体检测，Llama 3.1进行自然语言理解，Whisper进行语音识别，并使用模糊逻辑实现精确的自适应控制。

Result: 在消费级硬件上进行的实验评估显示，系统实现了75%的命令执行准确率，证明了系统的鲁棒性和适应性。

Conclusion: 该架构为未来HRI研究提供了灵活可扩展的基础，通过紧密耦合的语音和视觉语言处理，为实现更复杂、更自然的人机协作提供了实用途径。

Abstract: Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, speech processing, and fuzzy logic to enable precise and adaptive control of a Dobot Magician robotic arm. The proposed system integrates Florence-2 for object detection, Llama 3.1 for natural language understanding, and Whisper for speech recognition, providing users with a seamless and intuitive interface for object manipulation through spoken commands. By jointly addressing scene perception and action planning, the approach enhances the reliability of command interpretation and execution. Experimental evaluations conducted on consumer-grade hardware demonstrate a command execution accuracy of 75\%, highlighting both the robustness and adaptability of the system. Beyond its current performance, the proposed architecture serves as a flexible and extensible foundation for future HRI research, offering a practical pathway toward more sophisticated and natural human-robot collaboration through tightly coupled speech and vision-language processing.

</details>


### [5] [What Matters for Simulation to Online Reinforcement Learning on Real Robots](https://arxiv.org/abs/2602.20220)
*Yarden As,Dhruva Tirumala,René Zurbrügg,Chenhao Li,Stelian Coros,Andreas Krause,Markus Wulfmeier*

Main category: cs.RO

TL;DR: 本文通过100次真实机器人训练实验，系统研究了在线强化学习在物理机器人上的成功设计选择，发现了一些常用默认设置的危害性，并确定了一套稳健的设计方案


<details>
  <summary>Details</summary>
Motivation: 研究在物理机器人上成功实施在线强化学习的具体设计选择，填补现有研究中通常隐含的设计决策缺乏系统性实证研究的空白

Method: 在三个不同的机器人平台上进行了100次真实世界训练实验，系统性地消融分析了算法、系统和实验决策，这些决策在先前工作中通常被隐含处理

Result: 发现一些广泛使用的默认设置可能有害，而标准RL实践中一套稳健且易于采用的设计选择能够在不同任务和硬件上实现稳定学习

Conclusion: 这是首次对此类设计选择进行大规模实证研究，使从业者能够以较低的工程努力部署在线强化学习

Abstract: We investigate what specific design choices enable successful online reinforcement learning (RL) on physical robots. Across 100 real-world training runs on three distinct robotic platforms, we systematically ablate algorithmic, systems, and experimental decisions that are typically left implicit in prior work. We find that some widely used defaults can be harmful, while a set of robust, readily adopted design choices within standard RL practice yield stable learning across tasks and hardware. These results provide the first large-sample empirical study of such design choices, enabling practitioners to deploy online RL with lower engineering effort.

</details>


### [6] [FACTO: Function-space Adaptive Constrained Trajectory Optimization for Robotic Manipulators](https://arxiv.org/abs/2602.20225)
*Yichang Feng,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: FACTO是一种用于单臂和多臂机械臂的轨迹优化算法，直接在系数空间进行优化，使用正交基函数参数化轨迹，通过高斯-牛顿近似和自适应约束更新解决非线性约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹优化方法在解决单臂和多臂机械臂的约束轨迹规划问题时，在解的质量和可行性方面存在不足，特别是在复杂约束场景下需要更有效的优化算法。

Method: 使用正交基函数线性组合参数化轨迹表示，直接在系数空间进行优化。采用高斯-牛顿近似配合指数移动平均处理非线性，使用系数空间映射处理轨迹范围约束，在活动约束的零空间中使用Levenberg-Marquardt算法进行自适应约束更新。

Result: 与优化型规划器（CHOMP、TrajOpt、GPMP2）和采样型规划器（RRT-Connect、RRT*、PRM）相比，FACTO在解的质量和可行性方面表现更优，特别是在约束单臂和多臂场景中。在Franka机器人上的实验验证了部署可行性。

Conclusion: FACTO是一种有效的轨迹优化算法，能够处理单臂和多臂机械臂的复杂约束轨迹规划问题，在解的质量和可行性方面优于现有方法，具有实际部署的可行性。

Abstract: This paper introduces Function-space Adaptive Constrained Trajectory Optimization (FACTO), a new trajectory optimization algorithm for both single- and multi-arm manipulators. Trajectory representations are parameterized as linear combinations of orthogonal basis functions, and optimization is performed directly in the coefficient space. The constrained problem formulation consists of both an objective functional and a finite-dimensional objective defined over truncated coefficients. To address nonlinearity, FACTO uses a Gauss-Newton approximation with exponential moving averaging, yielding a smoothed quadratic subproblem. Trajectory-wide constraints are addressed using coefficient-space mappings, and an adaptive constrained update using the Levenberg-Marquardt algorithm is performed in the null space of active constraints. Comparisons with optimization-based planners (CHOMP, TrajOpt, GPMP2) and sampling-based planners (RRT-Connect, RRT*, PRM) show the improved solution quality and feasibility, especially in constrained single- and multi-arm scenarios. The experimental evaluation of FACTO on Franka robots verifies the feasibility of deployment.

</details>


### [7] [UniLACT: Depth-Aware RGB Latent Action Learning for Vision-Language-Action Models](https://arxiv.org/abs/2602.20231)
*Manish Kumar Govind,Dominick Reilly,Pu Wang,Srijan Das*

Main category: cs.RO

TL;DR: UniLACT：通过深度感知潜在预训练将几何结构融入视觉-语言-动作模型，提升接触式操作性能


<details>
  <summary>Details</summary>
Motivation: 现有从无标签视频学习的潜在动作表示主要编码外观驱动的动态，缺乏明确的3D几何结构，这对于精确和接触丰富的操作至关重要

Method: 提出UniLACT（基于Transformer的VLA模型）和UniLARN（统一潜在动作学习框架），通过逆动力学和正动力学目标学习RGB和深度的共享嵌入空间，显式建模跨模态交互，为UniLACT提供深度感知预训练

Result: 在仿真和真实世界实验中，UniLACT在域内和域外预训练机制下，以及在已见和未见操作任务上，均优于基于RGB的潜在动作基线

Conclusion: 深度感知的统一潜在动作表示能有效提升视觉-语言-动作模型的性能，特别是在需要精确空间感知的操作任务中

Abstract: Latent action representations learned from unlabeled videos have recently emerged as a promising paradigm for pretraining vision-language-action (VLA) models without explicit robot action supervision. However, latent actions derived solely from RGB observations primarily encode appearance-driven dynamics and lack explicit 3D geometric structure, which is essential for precise and contact-rich manipulation. To address this limitation, we introduce UniLACT, a transformer-based VLA model that incorporates geometric structure through depth-aware latent pretraining, enabling downstream policies to inherit stronger spatial priors. To facilitate this process, we propose UniLARN, a unified latent action learning framework based on inverse and forward dynamics objectives that learns a shared embedding space for RGB and depth while explicitly modeling their cross-modal interactions. This formulation produces modality-specific and unified latent action representations that serve as pseudo-labels for the depth-aware pretraining of UniLACT. Extensive experiments in both simulation and real-world settings demonstrate the effectiveness of depth-aware unified latent action representations. UniLACT consistently outperforms RGB-based latent action baselines under in-domain and out-of-domain pretraining regimes, as well as on both seen and unseen manipulation tasks.

</details>


### [8] [Smoothly Differentiable and Efficiently Vectorizable Contact Manifold Generation](https://arxiv.org/abs/2602.20304)
*Onur Beker,Andreas René Geist,Anselm Paulus,Nico Gürtler,Ji Shi,Sylvain Calinon,Georg Martius*

Main category: cs.RO

TL;DR: 提出了一种用于刚体动力学接触模拟的快速、可向量化、平滑可微的框架，解决了现有可微模拟框架中接触流形生成的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模拟器的接触检测例程在设计时未充分考虑向量化和可微性，导致在可微模拟中成为性能瓶颈。需要一种既能保持高效性又能实现平滑可微的接触处理方法。

Method: 提出了一种新的框架，结合了两种方法的优点：1）使用平滑解析符号距离基元实现顶点-面碰撞；2）提出新颖的可微边-边碰撞例程，能够提供符号距离和符号接触法线。

Result: 通过教学实验进行评估，并与成熟的Mujoco XLA框架的碰撞检测例程进行基准测试，观察到显著的加速效果。

Conclusion: 该框架在保持可微性的同时实现了高效性，为机器人学中的刚体动力学接触模拟提供了一种快速、可向量化、平滑可微的解决方案。

Abstract: Simulating rigid-body dynamics with contact in a fast, massively vectorizable, and smoothly differentiable manner is highly desirable in robotics. An important bottleneck faced by existing differentiable simulation frameworks is contact manifold generation: representing the volume of intersection between two colliding geometries via a discrete set of properly distributed contact points. A major factor contributing to this bottleneck is that the related routines of commonly used robotics simulators were not designed with vectorization and differentiability as a primary concern, and thus rely on logic and control flow that hinder these goals. We instead propose a framework designed from the ground up with these goals in mind, by trying to strike a middle ground between: i) convex primitive based approaches used by common robotics simulators (efficient but not differentiable), and ii) mollified vertex-face and edge-edge unsigned distance-based approaches used by barrier methods (differentiable but inefficient). Concretely, we propose: i) a representative set of smooth analytical signed distance primitives to implement vertex-face collisions, and ii) a novel differentiable edge-edge collision routine that can provide signed distances and signed contact normals. The proposed framework is evaluated via a set of didactic experiments and benchmarked against the collision detection routine of the well-established Mujoco XLA framework, where we observe a significant speedup. Supplementary videos can be found at https://github.com/bekeronur/contax, where a reference implementation in JAX will also be made available at the conclusion of the review process.

</details>


### [9] [Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory](https://arxiv.org/abs/2602.20323)
*Haoyang Li,Yang You,Hao Su,Leonidas Guibas*

Main category: cs.RO

TL;DR: PhysMem是一个让视觉语言模型机器人规划器在测试时通过交互学习物理原理的记忆框架，无需更新模型参数，通过验证假设而非直接应用经验来适应变化的物理条件。


<details>
  <summary>Details</summary>
Motivation: 可靠的物体操作需要理解随物体和环境变化的物理属性。现有的视觉语言模型规划器虽然能在一般意义上推理摩擦和稳定性，但无法预测特定物体在具体表面上的行为，或判断哪个石头能提供稳定基础，缺乏直接经验。

Method: PhysMem框架记录交互经验，生成候选假设，并通过有针对性的交互验证这些假设，然后将验证后的知识提升为指导未来决策。核心设计是"先验证后应用"：系统用新观察测试假设，而不是直接应用检索到的经验，减少物理条件变化时对先前经验的僵化依赖。

Result: 在三个真实世界操作任务和四个VLM骨干的模拟基准测试中评估PhysMem。在受控的砖块插入任务中，原则性抽象达到76%成功率，而直接经验检索只有23%。真实世界实验显示在30分钟部署会话中持续改进。

Conclusion: PhysMem框架使VLM机器人规划器能够在测试时通过交互学习物理原理，通过验证假设而非直接应用经验的方法，显著提高了在变化物理条件下的操作成功率。

Abstract: Reliable object manipulation requires understanding physical properties that vary across objects and environments. Vision-language model (VLM) planners can reason about friction and stability in general terms; however, they often cannot predict how a specific ball will roll on a particular surface or which stone will provide a stable foundation without direct experience. We present PhysMem, a memory framework that enables VLM robot planners to learn physical principles from interaction at test time, without updating model parameters. The system records experiences, generates candidate hypotheses, and verifies them through targeted interaction before promoting validated knowledge to guide future decisions. A central design choice is verification before application: the system tests hypotheses against new observations rather than applying retrieved experience directly, reducing rigid reliance on prior experience when physical conditions change. We evaluate PhysMem on three real-world manipulation tasks and simulation benchmarks across four VLM backbones. On a controlled brick insertion task, principled abstraction achieves 76% success compared to 23% for direct experience retrieval, and real-world experiments show consistent improvement over 30-minute deployment sessions.

</details>


### [10] [Energy-Based Injury Protection Database: Including Shearing Contact Thresholds for Hand and Finger Using Porcine Surrogates](https://arxiv.org/abs/2602.20362)
*Robin Jeanne Kirschner,Anna Huber,Carina M. Micheler,Dirk Müller,Nader Rajaei,Rainer Burgkart,Sami Haddadin*

Main category: cs.RO

TL;DR: 该研究扩展了机器人碰撞安全数据集，首次建立了基于能量的伤害保护数据库，特别关注剪切接触场景，发现碰撞角度显著影响伤害结果。


<details>
  <summary>Details</summary>
Motivation: 当前机器人安全验证主要依赖EN ISO 10218-2:2025的钝器碰撞数据，缺乏针对边缘或尖锐碰撞的可扩展临床数据集，限制了安全验证的有效性。

Method: 扩展先前数据集，纳入无约束碰撞中的剪切接触场景，重新评估所有先前的猪替代物数据，建立跨几何形状和接触类型的能量阈值。

Result: 发现碰撞角度显著影响伤害结果，无约束剪切接触比垂直碰撞造成更少伤害，建立了首个基于能量的伤害保护数据库。

Conclusion: 该数据库支持开发有意义的能量限制控制器，确保在各种现实碰撞事件中的安全性，为机器人安全设计提供了更全面的数据基础。

Abstract: While robotics research continues to propose strategies for collision avoidance in human-robot interaction, the reality of constrained environments and future humanoid systems makes contact inevitable. To mitigate injury risks, energy-constraining control approaches are commonly used, often relying on safety thresholds derived from blunt impact data in EN ISO 10218-2:2025. However, this dataset does not extend to edged or pointed collisions. Without scalable, clinically grounded datasets covering diverse contact scenarios, safety validation remains limited. Previous studies have laid the groundwork by assessing surrogate-based velocity and mass limits across various geometries, focusing on perpendicular impacts. This study expands those datasets by including shearing contact scenarios in unconstrained collisions, revealing that collision angle significantly affects injury outcomes. Notably, unconstrained shearing contacts result in fewer injuries than perpendicular ones. By reevaluating all prior porcine surrogate data, we establish energy thresholds across geometries and contact types, forming the first energy-based Injury Protection Database. This enables the development of meaningful energy-limiting controllers that ensure safety across a wide range of realistic collision events.

</details>


### [11] [Generalizing from References using a Multi-Task Reference and Goal-Driven RL Framework](https://arxiv.org/abs/2602.20375)
*Jiashun Wang,M. Eva Mungai,He Li,Jean Pierre Sleiman,Jessica Hodgins,Farbod Farshidian*

Main category: cs.RO

TL;DR: 提出统一的多任务强化学习框架，通过将参考运动作为行为塑造的先验而非部署时约束，实现自然运动质量与任务适应性的平衡


<details>
  <summary>Details</summary>
Motivation: 现有方法存在权衡：参考跟踪策略在演示数据集外往往脆弱，而纯任务驱动的强化学习虽然适应性强但运动质量差。需要一种既能学习自然协调运动又能适应新目标和条件的统一方法

Method: 提出多任务强化学习框架，训练单一目标条件策略同时优化两个任务：1)参考引导的模仿任务，使用参考轨迹定义密集模仿奖励但不作为策略输入；2)目标条件泛化任务，独立采样目标且奖励仅反映任务成功。通过共享观察和动作空间的联合优化，学习结构化的人类运动技能

Result: 在基于箱子的跑酷场景中评估，控制器能够超越参考分布进行泛化，同时保持运动自然性。通过组合多个学习技能展示了长时程行为生成能力

Conclusion: 该方法通过统一的多任务强化学习框架，实现了从人类运动中学习敏捷人形行为，在保持运动质量的同时获得对新目标和条件的适应性，无需对抗目标、显式轨迹跟踪、相位变量或参考依赖推理

Abstract: Learning agile humanoid behaviors from human motion offers a powerful route to natural, coordinated control, but existing approaches face a persistent trade-off: reference-tracking policies are often brittle outside the demonstration dataset, while purely task-driven Reinforcement Learning (RL) can achieve adaptability at the cost of motion quality. We introduce a unified multi-task RL framework that bridges this gap by treating reference motion as a prior for behavioral shaping rather than a deployment-time constraint. A single goal-conditioned policy is trained jointly on two tasks that share the same observation and action spaces, but differ in their initialization schemes, command spaces, and reward structures: (i) a reference-guided imitation task in which reference trajectories define dense imitation rewards but are not provided as policy inputs, and (ii) a goal-conditioned generalization task in which goals are sampled independently of any reference and where rewards reflect only task success. By co-optimizing these objectives within a shared formulation, the policy acquires structured, human-like motor skills from dense reference supervision while learning to adapt these skills to novel goals and initial conditions. This is achieved without adversarial objectives, explicit trajectory tracking, phase variables, or reference-dependent inference. We evaluate the method on a challenging box-based parkour playground that demands diverse athletic behaviors (e.g., jumping and climbing), and show that the learned controller transfers beyond the reference distribution while preserving motion naturalness. Finally, we demonstrate long-horizon behavior generation by composing multiple learned skills, illustrating the flexibility of the learned polices in complex scenarios.

</details>


### [12] [Grasp to Act: Dexterous Grasping for Tool Use in Dynamic Settings](https://arxiv.org/abs/2602.20466)
*Harsh Gupta,Mohammad Amin Mirzaee,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 提出Grasp-to-Act混合系统，结合物理抓取优化和强化学习适应，实现动态工具使用任务中的稳定抓握


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对静态几何稳定性优化抓握，在真实世界工具使用中遇到冲击、扭矩和持续阻力等动态力时容易失效

Method: 结合基于物理的抓取优化和基于强化学习的抓取适应，通过人类演示信息合成鲁棒抓取配置，并使用自适应控制器发出关节修正来防止手内滑动

Result: 在五种动态工具使用任务（锤击、锯切、切割、搅拌、舀取）中实现零样本仿真到真实转移，减少平移和旋转滑动，获得最高任务完成率

Conclusion: Grasp-to-Act系统能够在动态、接触丰富的条件下实现稳定的功能性抓握，优于现有基线方法

Abstract: Achieving robust grasping with dexterous hands remains challenging, especially when manipulation involves dynamic forces such as impacts, torques, and continuous resistance--situations common in real-world tool use. Existing methods largely optimize grasps for static geometric stability and often fail once external forces arise during manipulation. We present Grasp-to-Act, a hybrid system that combines physics-based grasp optimization with reinforcement-learning-based grasp adaptation to maintain stable grasps throughout functional manipulation tasks. Our method synthesizes robust grasp configurations informed by human demonstrations and employs an adaptive controller that residually issues joint corrections to prevent in-hand slip while tracking the object trajectory. Grasp-to-Act enables robust zero-shot sim-to-real transfer across five dynamic tool-use tasks--hammering, sawing, cutting, stirring, and scooping--consistently outperforming baselines. Across simulation and real-world hardware trials with a 16-DoF dexterous hand, our method reduces translational and rotational in-hand slip and achieves the highest task completion rates, demonstrating stable functional grasps under dynamic, contact-rich conditions.

</details>


### [13] [Strategy-Supervised Autonomous Laparoscopic Camera Control via Event-Driven Graph Mining](https://arxiv.org/abs/2602.20500)
*Keyu Zhou,Peisen Xu,Yahao Wu,Jiming Chen,Gaofeng Li,Shunlei Li*

Main category: cs.RO

TL;DR: 提出基于策略的自主腹腔镜相机控制框架，结合高层视觉语言推理与低层闭环控制，通过事件图挖掘可重用策略原语，在离体实验中优于初级外科医生


<details>
  <summary>Details</summary>
Motivation: 自主腹腔镜相机控制需要在快速器械-组织交互中保持稳定安全的手术视野，同时保持对外科医生的可解释性。现有方法难以同时满足稳定性、安全性和可解释性要求。

Method: 提出策略基础框架：离线阶段将原始手术视频解析为相机相关时间事件（交互、工作距离偏差、视野质量退化等），构建属性事件图，挖掘可重用相机操作策略原语；在线阶段使用微调视觉语言模型处理实时腹腔镜视图预测主导策略和离散图像运动指令，由IBVS-RCM控制器在严格安全约束下执行，支持语音输入实现人机协同。

Result: 事件解析实现可靠时间定位（F1分数0.86），挖掘策略与专家解释语义对齐强（聚类纯度0.81）。在硅胶模型和猪组织离体实验中，系统在标准化相机操作评估中优于初级外科医生，视野中心误差减少35.26%，图像抖动减少62.33%，同时保持平滑运动和稳定工作距离调节。

Conclusion: 提出的策略基础框架成功实现了稳定、安全且可解释的自主腹腔镜相机控制，通过结合高层语义推理和低层闭环控制，在离体实验中展现出优于人类操作者的性能，为手术机器人自主化提供了有前景的解决方案。

Abstract: Autonomous laparoscopic camera control must maintain a stable and safe surgical view under rapid tool-tissue interactions while remaining interpretable to surgeons. We present a strategy-grounded framework that couples high-level vision-language inference with low-level closed-loop control. Offline, raw surgical videos are parsed into camera-relevant temporal events (e.g., interaction, working-distance deviation, and view-quality degradation) and structured as attributed event graphs. Mining these graphs yields a compact set of reusable camera-handling strategy primitives, which provide structured supervision for learning. Online, a fine-tuned Vision-Language Model (VLM) processes the live laparoscopic view to predict the dominant strategy and discrete image-based motion commands, executed by an IBVS-RCM controller under strict safety constraints; optional speech input enables intuitive human-in-the-loop conditioning. On a surgeon-annotated dataset, event parsing achieves reliable temporal localization (F1-score 0.86), and the mined strategies show strong semantic alignment with expert interpretation (cluster purity 0.81). Extensive ex vivo experiments on silicone phantoms and porcine tissues demonstrate that the proposed system outperforms junior surgeons in standardized camera-handling evaluations, reducing field-of-view centering error by 35.26% and image shaking by 62.33%, while preserving smooth motion and stable working-distance regulation.

</details>


### [14] [BFA++: Hierarchical Best-Feature-Aware Token Prune for Multi-View Vision Language Action Model](https://arxiv.org/abs/2602.20566)
*Haosheng Li,Weixin Mao,Zihan Lan,Hongwei Xiong,Hongan Wang,Chenyang Si,Ziwei Liu,Xiaoming Deng,Hua Chen*

Main category: cs.RO

TL;DR: BFA++是一个专门为视觉-语言-动作模型设计的动态令牌剪枝框架，通过分层剪枝策略提高计算效率，在保持操作成功率的同时实现1.5-1.8倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在处理多视角视觉输入时面临大量视觉令牌带来的实时性挑战，而现有的令牌剪枝技术在直接应用于VLA模型时会导致性能下降，因为它们忽略了不同视角之间的关系以及机器人操作的动态和任务特定特性。

Method: 提出BFA++动态令牌剪枝框架，采用分层剪枝策略，包含两个级别的重要性预测器：1）视图内预测器突出显示每张图像中与任务相关的区域以抑制空间噪声；2）视图间预测器识别不同操作阶段的关键相机视角以减少跨视角冗余。

Result: 在RoboTwin基准测试和真实世界机器人任务中，BFA++始终优于现有方法。在π0和RDT模型上，成功率提高约10%，分别实现1.8倍和1.5倍的加速。

Conclusion: 上下文敏感和任务感知的令牌剪枝比完整的视觉处理更有效，能够在真实世界机器人系统中实现更快的推理速度和更高的操作精度。

Abstract: Vision-Language-Action (VLA) models have achieved significant breakthroughs by leveraging Large Vision Language Models (VLMs) to jointly interpret instructions and visual inputs. However, the substantial increase in visual tokens, particularly from multi-view inputs, poses serious challenges to real-time robotic manipulation. Existing acceleration techniques for VLMs, such as token pruning, often result in degraded performance when directly applied to VLA models, as they overlook the relationships between different views and fail to account for the dynamic and task-specific characteristics of robotic operation. To address this, we propose BFA++, a dynamic token pruning framework designed specifically for VLA models. BFA++ introduces a hierarchical pruning strategy guided by two-level importance predictors: an intra-view predictor highlights task-relevant regions within each image to suppress spatial noise, while an inter-view predictor identifies critical camera views throughout different manipulation phases to reduce cross-view redundancy. This design enables efficient token selection while preserving essential visual cues, resulting in improved computational efficiency and higher manipulation success rates. Evaluations on the RoboTwin benchmark and real-world robotic tasks demonstrate that BFA++ consistently outperforms existing methods. BFA++ improves the success rate by about 10% on both the π0 and RDT models, achieving speedup of 1.8X and 1.5X, respectively. Our results highlight that context-sensitive and task-aware token pruning serves as a more effective strategy than full visual processing, enabling faster inference and improved manipulation accuracy in real-world robotic systems.

</details>


### [15] [Acoustic Feedback for Closed-Loop Force Control in Robotic Grinding](https://arxiv.org/abs/2602.20596)
*Zongyuan Zhang,Christopher Lehnert,Will N. Browne,Jonathan M. Roberts*

Main category: cs.RO

TL;DR: 本文提出了一种低成本声学反馈机器人磨削系统(AFRG)，使用接触式麦克风采集音频信号，实时估计磨削力，实现闭环力控制，相比传统力传感器方法成本降低200倍，在不同磨削盘条件下一致性提高4倍。


<details>
  <summary>Details</summary>
Motivation: 人类在磨削任务中依赖声学反馈判断工具与工件接触状态，而机器人磨削系统主要依赖昂贵的力传感器，难以适应不同磨削工具。音频传感器成本低且可安装在任何传导磨削声音的介质上，因此需要开发基于声学反馈的低成本解决方案。

Method: 提出AFRG系统：使用接触式麦克风采集音频信号，从音频中实时估计磨削力，实现磨削过程的闭环力控制。系统仅依赖低成本麦克风作为传感方式。

Result: 相比传统力传感方法，AFRG在不同磨削盘条件下一致性提高了4倍。系统使用的麦克风成本约为传统力传感器的1/200，提供了易于部署、经济高效的机器人磨削解决方案。

Conclusion: AFRG系统通过低成本声学反馈实现了有效的机器人磨削力控制，克服了传统力传感器成本高、适应性差的缺点，为机器人磨削提供了经济高效的替代方案。

Abstract: Acoustic feedback is a critical indicator for assessing the contact condition between the tool and the workpiece when humans perform grinding tasks with rotary tools. In contrast, robotic grinding systems typically rely on force sensing, with acoustic information largely ignored. This reliance on force sensors is costly and difficult to adapt to different grinding tools, whereas audio sensors (microphones) are low-cost and can be mounted on any medium that conducts grinding sound.
  This paper introduces a low-cost Acoustic Feedback Robotic Grinding System (AFRG) that captures audio signals with a contact microphone, estimates grinding force from the audio in real time, and enables closed-loop force control of the grinding process. Compared with conventional force-sensing approaches, AFRG achieves a 4-fold improvement in consistency across different grinding disc conditions. AFRG relies solely on a low-cost microphone, which is approximately 200-fold cheaper than conventional force sensors, as the sensing modality, providing an easily deployable, cost-effective robotic grinding solution.

</details>


### [16] [Robot Local Planner: A Periodic Sampling-Based Motion Planner with Minimal Waypoints for Home Environments](https://arxiv.org/abs/2602.20645)
*Keisuke Takeshita,Takahiro Yamazaki,Tomohiro Ono,Takashi Yamamoto*

Main category: cs.RO

TL;DR: 提出了一种名为"机器人局部规划器(RLP)"的周期性采样全身轨迹规划方法，用于家庭环境中的快速安全操作任务。


<details>
  <summary>Details</summary>
Motivation: 为了在家庭环境中实现快速安全的操作任务，需要开发能够识别周围环境、识别目标物体并在运动中规划执行动作的系统。

Method: 采用周期性采样全身轨迹规划方法(RLP)，利用家庭环境的独特特征提高计算效率、运动最优性和鲁棒性，同时确保安全性。通过最小化路径点规划、生成安全轨迹、周期性执行轨迹规划选择更优运动，并采用对基座位置误差鲁棒的逆运动学。

Result: 评估实验表明RLP在运动规划时间、运动持续时间和鲁棒性方面优于现有方法。应用实验在整理任务中实现了高成功率和短操作时间。

Conclusion: RLP方法在家庭环境中有效且实用，能够实现快速安全的操作任务，具有实际可行性。

Abstract: The objective of this study is to enable fast and safe manipulation tasks in home environments. Specifically, we aim to develop a system that can recognize its surroundings and identify target objects while in motion, enabling it to plan and execute actions accordingly. We propose a periodic sampling-based whole-body trajectory planning method, called the "Robot Local Planner (RLP)." This method leverages unique features of home environments to enhance computational efficiency, motion optimality, and robustness against recognition and control errors, all while ensuring safety. The RLP minimizes computation time by planning with minimal waypoints and generating safe trajectories. Furthermore, overall motion optimality is improved by periodically executing trajectory planning to select more optimal motions. This approach incorporates inverse kinematics that are robust to base position errors, further enhancing robustness. Evaluation experiments demonstrated that the RLP outperformed existing methods in terms of motion planning time, motion duration, and robustness, confirming its effectiveness in home environments. Moreover, application experiments using a tidy-up task achieved high success rates and short operation times, thereby underscoring its practical feasibility.

</details>


### [17] [IG-RFT: An Interaction-Guided RL Framework for VLA Models in Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2602.20715)
*Zhian Su,Weijie Kong,Haonan Dong,Huixu Dong*

Main category: cs.RO

TL;DR: IG-RFT是一个用于视觉-语言-动作模型的交互引导强化微调系统，通过IG-AWR算法和混合密集奖励函数，在真实世界长视野任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: VLA模型在真实世界复杂任务中泛化能力有限，面临分布偏移和高质量演示稀缺的问题。强化学习虽然能改进策略，但在真实世界VLA微调中存在探索效率、训练稳定性和样本成本等挑战

Method: 提出IG-RFT系统：1) IG-AWR算法根据机器人交互状态动态调节探索强度；2) 设计混合密集奖励函数，结合轨迹级和子任务级奖励；3) 构建三阶段RL系统（SFT、离线RL、人在环RL）微调VLA模型

Result: 在四个挑战性长视野任务上的真实世界实验显示，IG-RFT平均成功率85.0%，显著优于SFT（18.8%）和标准离线RL基线（40.0%）。消融研究证实了IG-AWR和混合奖励塑形的关键贡献

Conclusion: 该工作建立并验证了一个新颖的VLA模型强化微调系统，为真实世界机器人操作任务提供了有效的解决方案

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential for generalist robotic policies; however, they struggle to generalize to long-horizon complex tasks in novel real-world domains due to distribution shifts and the scarcity of high-quality demonstrations. Although reinforcement learning (RL) offers a promising avenue for policy improvement, applying it to real-world VLA fine-tuning faces challenges regarding exploration efficiency, training stability, and sample cost. To address these issues, we propose IG-RFT, a novel Interaction-Guided Reinforced Fine-Tuning system designed for flow-based VLA models. Firstly, to facilitate effective policy optimization, we introduce Interaction-Guided Advantage Weighted Regression (IG-AWR), an RL algorithm that dynamically modulates exploration intensity based on the robot's interaction status. Furthermore, to address the limitations of sparse or task-specific rewards, we design a novel hybrid dense reward function that integrates the trajectory-level reward and the subtask-level reward. Finally, we construct a three-stage RL system comprising SFT, Offline RL, and Human-in-the-Loop RL for fine-tuning VLA models. Extensive real-world experiments on four challenging long-horizon tasks demonstrate that IG-RFT achieves an average success rate of 85.0%, significantly outperforming SFT (18.8%) and standard Offline RL baselines (40.0%). Ablation studies confirm the critical contributions of IG-AWR and hybrid reward shaping. In summary, our work establishes and validates a novel reinforced fine-tuning system for VLA models in real-world robotic manipulation.

</details>


### [18] [Visual Cooperative Drone Tracking for Open-Path Gas Measurements](https://arxiv.org/abs/2602.20768)
*Marius Schaab,Alisha Kiefer,Thomas Wiedemann,Patrick Hinsen,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 本文提出了一种用于开放路径激光吸收光谱测量的机器人系统，通过地面云台单元和携带反射器的无人机协同工作，实现了远距离气体浓度的自主测量。


<details>
  <summary>Details</summary>
Motivation: 开放路径可调谐二极管激光吸收光谱技术能够有效测量气体浓度，但传统方法需要专用反射表面，使得空间采样过程自动化困难。本文旨在解决这一挑战。

Method: 开发了一个机器人系统，包括地面云台单元（搭载传感器和变焦相机）和小型无人机（携带反射器和红色LED标记）。通过视觉跟踪无人机上的LED标记，结合GNSS位置信息，使激光束与反射器对齐。

Result: 室外实验验证了系统性能，成功实现了60米距离内的自主跟踪和有效的CO2测量。系统能够测量CO2羽流而不受无人机推进系统干扰，优于飞行原位传感器。

Conclusion: 该系统成功解决了开放路径激光吸收光谱测量的自动化挑战，为大规模户外环境的气体浓度监测提供了一种高效、非侵入性的解决方案。

Abstract: Open-path Tunable Diode Laser Absorption Spectroscopy offers an effective method for measuring, mapping, and monitoring gas concentrations, such as leaking CO2 or methane. Compared to spatial sampling of gas distributions using in-situ sensors, open-path sensors in combination with gas tomography algorithms can cover large outdoor environments faster in a non-invasive way. However, the requirement of a dedicated reflection surface for the open-path laser makes automating the spatial sampling process challenging. This publication presents a robotic system for collecting open-path measurements, making use of a sensor mounted on a ground-based pan-tilt unit and a small drone carrying a reflector. By means of a zoom camera, the ground unit visually tracks red LED markers mounted on the drone and aligns the sensor's laser beam with the reflector. Incorporating GNSS position information provided by the drone's flight controller further improves the tracking approach. Outdoor experiments validated the system's performance, demonstrating successful autonomous tracking and valid CO2 measurements at distances up to 60 meters. Furthermore, the system successfully measured a CO2 plume without interference from the drone's propulsion system, demonstrating its superiority compared to flying in-situ sensors.

</details>


### [19] [KCFRC: Kinematic Collision-Aware Foothold Reachability Criteria for Legged Locomotion](https://arxiv.org/abs/2602.20850)
*Lei Ye,Haibo Gao,Huaiguang Yang,Peng Xu,Haoyu Wang,Tie Liu,Junqi Shan,Zongquan Deng,Liang Ding*

Main category: cs.RO

TL;DR: KCFRC算法为足式机器人提供高效的落脚点可达性分析，能在2毫秒内验证900个潜在落脚点，显著提升机器人在复杂环境中的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 足式机器人在复杂环境中导航面临重大挑战，需要精确的实时决策来选择落脚点和规划接触。现有方法主要基于地形几何或运动学选择落脚点，但缺乏高效验证无碰撞摆动轨迹存在性的方法。

Method: 提出KCFRC算法：首先正式定义落脚点可达性问题并建立落脚点可达性的充分条件，基于此条件开发KCFRC算法，使机器人能够实时验证落脚点可达性。

Result: KCFRC在时间效率上表现卓越，单腿对900个潜在落脚点的可达性检查平均仅需2毫秒。该算法能加速轨迹优化，特别有利于受限空间中的接触规划。

Conclusion: KCFRC填补了足式机器人落脚点可达性分析的关键空白，显著提升了机器人在挑战性环境中的适应性和鲁棒性，为实时决策提供了有效解决方案。

Abstract: Legged robots face significant challenges in navigating complex environments, as they require precise real-time decisions for foothold selection and contact planning. While existing research has explored methods to select footholds based on terrain geometry or kinematics, a critical gap remains: few existing methods efficiently validate the existence of a non-collision swing trajectory. This paper addresses this gap by introducing KCFRC, a novel approach for efficient foothold reachability analysis. We first formally define the foothold reachability problem and establish a sufficient condition for foothold reachability. Based on this condition, we develop the KCFRC algorithm, which enables robots to validate foothold reachability in real time. Our experimental results demonstrate that KCFRC achieves remarkable time efficiency, completing foothold reachability checks for a single leg across 900 potential footholds in an average of 2 ms. Furthermore, we show that KCFRC can accelerate trajectory optimization and is particularly beneficial for contact planning in confined spaces, enhancing the adaptability and robustness of legged robots in challenging environments.

</details>


### [20] [GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer](https://arxiv.org/abs/2602.20871)
*Wenbo Yu,Wenke Xia,Weitao Zhang,Di Hu*

Main category: cs.RO

TL;DR: GeCo-SRT提出了一种几何感知的持续适应方法，通过积累跨任务的知识来桥接仿真到现实的差距，实现高效低成本的跨任务迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的仿真到现实迁移方法将每次迁移视为孤立任务，需要重复昂贵的调优，浪费了之前的迁移经验。需要超越这种孤立模式，建立持续跨任务的迁移范式。

Method: GeCo-SRT方法包含两个核心模块：1）几何感知的专家混合模块，动态激活专家来专门处理不同的几何知识；2）几何专家引导的优先经验回放模块，优先从未充分利用的专家中采样，防止知识遗忘。

Result: 该方法相比基线平均性能提升52%，并且在新任务适应中表现出显著的数据效率，仅需1/6的数据量。

Conclusion: GeCo-SRT通过积累迭代迁移中的知识，实现了高效低成本的跨任务仿真到现实迁移，为相关研究提供了新思路。

Abstract: Bridging the sim-to-real gap is important for applying low-cost simulation data to real-world robotic systems. However, previous methods are severely limited by treating each transfer as an isolated endeavor, demanding repeated, costly tuning and wasting prior transfer experience.To move beyond isolated sim-to-real, we build a continual cross-task sim-to-real transfer paradigm centered on knowledge accumulation across iterative transfers, thereby enabling effective and efficient adaptation to novel tasks. Thus, we propose GeCo-SRT, a geometry-aware continual adaptation method. It utilizes domain-invariant and task-invariant knowledge from local geometric features as a transferable foundation to accelerate adaptation during subsequent sim-to-real transfers. This method starts with a geometry-aware mixture-of-experts module, which dynamically activates experts to specialize in distinct geometric knowledge to bridge observation sim-to-real gap. Further, the geometry-expert-guided prioritized experience replay module preferentially samples from underutilized experts, refreshing specialized knowledge to combat forgetting and maintain robust cross-task performance. Leveraging knowledge accumulated during iterative transfer, GeCo-SRT method not only achieves 52% average performance improvement over the baseline, but also demonstrates significant data efficiency for new task adaptation with only 1/6 data.We hope this work inspires approaches for efficient, low-cost cross-task sim-to-real transfer.

</details>


### [21] [Task-oriented grasping for dexterous robots using postural synergies and reinforcement learning](https://arxiv.org/abs/2602.20915)
*Dimitrios Dimou,José Santos-Victor,Plinio Moreno*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的人形机器人任务导向抓取方法，结合人类抓取偏好数据和VAE手部协同模型，实现考虑下游任务约束的多物体抓取


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏端到端的解决方案，无法在抓取多个物体时考虑下游任务的约束，需要开发能够符合人类社交规范和任务特定目标的人形机器人抓取方法

Method: 1. 从ContactPose数据集中提取人类抓取偏好；2. 基于变分自编码器(VAE)训练手部协同模型来模仿人类抓取动作；3. 使用强化学习训练能够考虑任务特定后抓取意图的智能体

Result: 开发出能够抓取多个物体并考虑不同任务特定后抓取意图的智能体，结合人类抓取行为的数据驱动洞察和强化学习的探索学习能力

Conclusion: 通过结合人类抓取行为数据和强化学习，可以开发出具有情境感知操作能力的人形机器人，促进在以人为本环境中的协作

Abstract: In this paper, we address the problem of task-oriented grasping for humanoid robots, emphasizing the need to align with human social norms and task-specific objectives. Existing methods, employ a variety of open-loop and closed-loop approaches but lack an end-to-end solution that can grasp several objects while taking into account the downstream task's constraints. Our proposed approach employs reinforcement learning to enhance task-oriented grasping, prioritizing the post-grasp intention of the agent. We extract human grasp preferences from the ContactPose dataset, and train a hand synergy model based on the Variational Autoencoder (VAE) to imitate the participant's grasping actions. Based on this data, we train an agent able to grasp multiple objects while taking into account distinct post-grasp intentions that are task-specific. By combining data-driven insights from human grasping behavior with learning by exploration provided by reinforcement learning, we can develop humanoid robots capable of context-aware manipulation actions, facilitating collaboration in human-centered environments.

</details>


### [22] [Computer-Aided Design of Rational Motions for 4R and 6R Spatial Mechanism Synthesis](https://arxiv.org/abs/2602.20920)
*Daniel Huczala,Severinas Zube,Martin Pfurner,Johannes Siegele,Frank C. Park*

Main category: cs.RO

TL;DR: 本文提出基于三次四元数贝塞尔曲线的七点插值方法，用于生成有理运动并合成空间六杆机构


<details>
  <summary>Details</summary>
Motivation: 为单回路有理连杆机构设计提供几何方法，使机构能够执行规定的空间任务，支持工程实践中的运动生成和机构合成

Method: 基于现有有理运动合成方法，引入基于三次四元数贝塞尔曲线的七点3D插值方案，实现运动分解和空间六杆机构合成

Result: 开发了开源CAD工具，实现运动生成和机构合成的快速可视化评估，支持工程实践应用

Conclusion: 提出的几何方法能够有效生成有理运动并合成空间六杆机构，为单回路有理连杆机构设计提供了实用的工程工具

Abstract: This paper focuses on geometric methods for generating rational motions used in the design of single-loop rational linkages, 1-degree-of-freedom mechanisms that can execute prescribed spatial tasks. Building on established rational motion synthesis methods, we introduce a new interpolation scheme for seven 3D points based on cubic quaternionic Bezier curves. The resulting motion admits factorization, i.e. the synthesis of a spatial six-bar mechanism whose tool frame passes the specified seven points. To support engineering practice, we provide open-source CAD tools that implement also the other methods and provide fast visual evaluation of motion generation and mechanism synthesis.

</details>


### [23] [ParkDiffusion++: Ego Intention Conditioned Joint Multi-Agent Trajectory Prediction for Automated Parking using Diffusion Models](https://arxiv.org/abs/2602.20923)
*Jiarong Wei,Anna Rehr,Christian Feist,Abhinav Valada*

Main category: cs.RO

TL;DR: ParkDiffusion++：一种用于自动泊车的联合多模态意图预测和多智能体轨迹预测方法，通过意图标记化、条件预测、安全引导去噪和反事实知识蒸馏提升性能。


<details>
  <summary>Details</summary>
Motivation: 自动泊车是高级驾驶辅助系统的挑战性领域，需要强大的场景理解和交互推理。现有方法通常将相互依赖的意图预测和轨迹预测问题孤立处理，无法有效支持"what-if"决策制定。

Method: 1. 引入自我意图标记器预测离散终点意图；2. 执行自我意图条件联合预测；3. 使用轻量级安全引导去噪器优化联合场景；4. 提出反事实知识蒸馏，通过EMA教师模型提供伪目标。

Result: 在Dragon Lake Parking (DLP)数据集和Intersections Drone (inD)数据集上达到最先进性能。定性可视化显示其他智能体对不同自我意图做出适当反应。

Conclusion: ParkDiffusion++通过联合学习多模态自我意图预测和自我条件多智能体联合轨迹预测，有效解决了自动泊车中的场景理解和交互推理挑战，支持更好的what-if决策制定。

Abstract: Automated parking is a challenging operational domain for advanced driver assistance systems, requiring robust scene understanding and interaction reasoning. The key challenge is twofold: (i) predict multiple plausible ego intentions according to context and (ii) for each intention, predict the joint responses of surrounding agents, enabling effective what-if decision-making. However, existing methods often fall short, typically treating these interdependent problems in isolation. We propose ParkDiffusion++, which jointly learns a multi-modal ego intention predictor and an ego-conditioned multi-agent joint trajectory predictor for automated parking. Our approach makes several key contributions. First, we introduce an ego intention tokenizer that predicts a small set of discrete endpoint intentions from agent histories and vectorized map polylines. Second, we perform ego-intention-conditioned joint prediction, yielding socially consistent predictions of the surrounding agents for each possible ego intention. Third, we employ a lightweight safety-guided denoiser with different constraints to refine joint scenes during training, thus improving accuracy and safety. Fourth, we propose counterfactual knowledge distillation, where an EMA teacher refined by a frozen safety-guided denoiser provides pseudo-targets that capture how agents react to alternative ego intentions. Extensive evaluations demonstrate that ParkDiffusion++ achieves state-of-the-art performance on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Importantly, qualitative what-if visualizations show that other agents react appropriately to different ego intentions.

</details>


### [24] [LST-SLAM: A Stereo Thermal SLAM System for Kilometer-Scale Dynamic Environments](https://arxiv.org/abs/2602.20925)
*Zeyu Jiang,Kuan Xu,Changhao Chen*

Main category: cs.RO

TL;DR: LST-SLAM是一种用于大规模动态户外环境的新型立体热成像SLAM系统，通过自监督特征学习、双级运动跟踪和几何姿态优化，在复杂场景中实现鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 热成像相机在恶劣光照和天气条件下具有感知优势，但热成像SLAM面临特征提取不可靠、运动跟踪不稳定、全局姿态和地图构建不一致等挑战，特别是在动态大规模户外环境中。

Method: 结合自监督热成像特征学习、立体双级运动跟踪和几何姿态优化；引入语义-几何混合约束抑制缺乏帧间几何一致性的动态特征；开发在线增量词袋模型进行回环检测，配合全局姿态优化减少累积漂移。

Result: 在千米级动态热成像数据集上的广泛实验表明，LST-SLAM在鲁棒性和准确性方面显著优于最近的代表性SLAM系统，包括AirSLAM和DROID-SLAM。

Conclusion: LST-SLAM系统成功解决了热成像SLAM在复杂动态环境中的关键挑战，通过创新的特征学习、运动跟踪和优化方法，实现了大规模户外场景下的鲁棒性能。

Abstract: Thermal cameras offer strong potential for robot perception under challenging illumination and weather conditions. However, thermal Simultaneous Localization and Mapping (SLAM) remains difficult due to unreliable feature extraction, unstable motion tracking, and inconsistent global pose and map construction, particularly in dynamic large-scale outdoor environments. To address these challenges, we propose LST-SLAM, a novel large-scale stereo thermal SLAM system that achieves robust performance in complex, dynamic scenes. Our approach combines self-supervised thermal feature learning, stereo dual-level motion tracking, and geometric pose optimization. We also introduce a semantic-geometric hybrid constraint that suppresses potentially dynamic features lacking strong inter-frame geometric consistency. Furthermore, we develop an online incremental bag-of-words model for loop closure detection, coupled with global pose optimization to mitigate accumulated drift. Extensive experiments on kilometer-scale dynamic thermal datasets show that LST-SLAM significantly outperforms recent representative SLAM systems, including AirSLAM and DROID-SLAM, in both robustness and accuracy.

</details>


### [25] [EKF-Based Depth Camera and Deep Learning Fusion for UAV-Person Distance Estimation and Following in SAR Operations](https://arxiv.org/abs/2602.20958)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 该论文提出了一种用于无人机搜救任务的距离估计系统，通过融合深度相机数据和单目相机的人体距离估计，使用YOLO-pose和扩展卡尔曼滤波实现实时距离测量，以保持无人机与目标之间的安全距离。


<details>
  <summary>Details</summary>
Motivation: 搜救任务需要快速响应，无人机配备视觉系统可以辅助搜救任务。关键的安全要求是在真实条件下准确估计相机与目标物体之间的距离，这需要融合多种图像模态来实现。

Method: 提出了一种融合深度相机测量和单目相机到人体距离估计的系统。使用YOLO-pose进行深度相机数据的深度学习滤波和单目相机距离估计，通过扩展卡尔曼滤波算法实时融合深度信息。

Result: 系统在室内实时测试中，在三种测试场景下将距离估计的平均误差、均方根误差和标准差降低了15.3%。系统提供了准确的估计距离，并通过运动捕捉地面真实数据进行了验证。

Conclusion: 提出的子系统能够准确估计深度相机与人体关键点之间的距离，为无人机搜救任务中的安全跟踪和跟随提供了有效的距离估计解决方案。

Abstract: Search and rescue (SAR) operations require rapid responses to save lives or property. Unmanned Aerial Vehicles (UAVs) equipped with vision-based systems support these missions through prior terrain investigation or real-time assistance during the mission itself. Vision-based UAV frameworks aid human search tasks by detecting and recognizing specific individuals, then tracking and following them while maintaining a safe distance. A key safety requirement for UAV following is the accurate estimation of the distance between camera and target object under real-world conditions, achieved by fusing multiple image modalities. UAVs with deep learning-based vision systems offer a new approach to the planning and execution of SAR operations. As part of the system for automatic people detection and face recognition using deep learning, in this paper we present the fusion of depth camera measurements and monocular camera-to-body distance estimation for robust tracking and following. Deep learning-based filtering of depth camera data and estimation of camera-to-body distance from a monocular camera are achieved with YOLO-pose, enabling real-time fusion of depth information using the Extended Kalman Filter (EKF) algorithm. The proposed subsystem, designed for use in drones, estimates and measures the distance between the depth camera and the human body keypoints, to maintain the safe distance between the drone and the human target. Our system provides an accurate estimated distance, which has been validated against motion capture ground truth data. The system has been tested in real time indoors, where it reduces the average errors, root mean square error (RMSE) and standard deviations of distance estimation up to 15,3\% in three tested scenarios.

</details>


### [26] [A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators](https://arxiv.org/abs/2602.20963)
*Ang,Li,Alexander Yin,Alexander White,Sahib Sandhu,Matthew Francoeur,Victor Jimenez-Santiago,Van Remenar,Codrin Tugui,Mihai Duduta*

Main category: cs.RO

TL;DR: 本文提出了一种用于优化线性介电弹性体致动器（DEA）寿命的自驾实验室方法，通过新型测试机器人扫描多参数空间，将DEA寿命提升100%，并成功应用于模块化四足机器人。


<details>
  <summary>Details</summary>
Motivation: 线性介电弹性体致动器在高电场下的短寿命限制了其在机器人领域的广泛应用。传统方法难以系统扫描高维参数空间，因为每个样本测试耗时且参数众多影响性能。

Method: 提出了一种由新型测试机器人支持的优化流程，该机器人集成了机电性能测量、可编程电压输入和多通道测试能力。使用该机器人扫描了基于Elastosil的线性致动器在不同参数（包括输入电压幅值、频率、电极材料浓度和电连接填料）下的寿命。

Result: 最优参数组合在边界操作条件下将运行寿命提高了100%。随后将优化结果放大，实现了更高的力和位移输出。最终产品在模块化可扩展的四足行走机器人上展示了良好的性能，承载能力超过其无绳体重的100%，以及超过致动器组合重量的700%。

Conclusion: 这项工作是首次将自驾实验室方法引入机器人致动器设计，为DEA性能优化提供了系统化的解决方案，显著提升了致动器寿命和机器人性能。

Abstract: Short lifetime under high electrical fields hinders the widespread robotic application of linear dielectric elastomer actuators (DEAs). Systematic scanning is difficult due to time-consuming per-sample testing and the high-dimensional parameter space affecting performance. To address this, we propose an optimization pipeline enabled by a novel testing robot capable of scanning DEA lifetime. The robot integrates electro-mechanical property measurement, programmable voltage input, and multi-channel testing capacity. Using it, we scanned the lifetime of Elastosil-based linear actuators across parameters including input voltage magnitude, frequency, electrode material concentration, and electrical connection filler. The optimal parameter combinations improved operational lifetime under boundary operating conditions by up to 100% and were subsequently scaled up to achieve higher force and displacement output. The final product demonstrated resilience on a modular, scalable quadruped walking robot with payload carrying capacity (>100% of its untethered body weight, and >700% of combined actuator weight). This work is the first to introduce a self-driving lab approach into robotic actuator design.

</details>


### [27] [Surface-based Manipulation Using Tunable Compliant Porous-Elastic Soft Sensing](https://arxiv.org/abs/2602.21028)
*Gayatri Indukumar,Muhammad Awais,Diana Cafiso,Matteo Lo Preti,Lucia Beccai*

Main category: cs.RO

TL;DR: COPESS系统通过可调晶格层同时调控机械柔顺性和传感性能，实现自适应物体操作和局部传感


<details>
  <summary>Details</summary>
Motivation: 现有表面操作系统缺乏处理各种物体所需的柔顺性和触觉反馈，需要开发能够进行轻柔、精确操作的软机器人平台

Method: 引入COPESS系统，集成感应传感器，采用可调晶格层设计，通过调整晶格几何形状同时调制机械柔顺性和传感性能

Result: 实验表明，通过简单调整晶格密度（从7%到20%），可以显著改变灵敏度和操作力范围（分别约-23倍和9倍）

Conclusion: 该方法为创建自适应传感表面提供了蓝图，实现了机械和感官特性的协同优化，支持被动但可编程的精细操作

Abstract: There is a growing need for soft robotic platforms that perform gentle, precise handling of a wide variety of objects. Existing surface-based manipulation systems, however, lack the compliance and tactile feedback needed for delicate handling. This work introduces the COmpliant Porous-Elastic Soft Sensing (COPESS) integrated with inductive sensors for adaptive object manipulation and localised sensing. The design features a tunable lattice layer that simultaneously modulates mechanical compliance and sensing performance. By adjusting lattice geometry, both stiffness and sensor response can be tailored to handle objects with varying mechanical properties. Experiments demonstrate that by easily adjusting one parameter, the lattice density, from 7 % to 20 %, it is possible to significantly alter the sensitivity and operational force range (about -23x and 9x, respectively). This approach establishes a blueprint for creating adaptive, sensorized surfaces where mechanical and sensory properties are co-optimized, enabling passive, yet programmable, delicate manipulation.

</details>


### [28] [Cooperative-Competitive Team Play of Real-World Craft Robots](https://arxiv.org/abs/2602.21119)
*Rui Zhao,Xihui Li,Yizheng Zhang,Yuzhen Liu,Zhong Zhang,Yufeng Zhang,Cheng Zhou,Zhengyou Zhang,Lei Han*

Main category: cs.RO

TL;DR: 该研究开发了一个完整的机器人系统平台，并提出OODSI方法来解决多智能体强化学习从仿真到现实的迁移问题，在真实机器人实验中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体深度强化学习在游戏智能体开发方面取得了显著进展，但如何高效训练集体机器人并将学习到的策略迁移到现实应用中仍然是开放的研究问题。

Method: 首先开发了包含仿真、分布式学习框架和物理机器人组件的综合机器人系统；然后提出并评估了专门为此平台设计的强化学习技术；针对多智能体仿真到现实迁移的挑战，引入了OODSI（分布外状态初始化）方法来减少仿真与现实之间的差距影响。

Result: OODSI方法将Sim2Real性能提升了20%；通过多机器人汽车竞争游戏和真实环境中的协作任务实验，证明了该方法的有效性。

Conclusion: 该研究提出的综合机器人系统和OODSI方法有效解决了多智能体强化学习从仿真到现实的迁移问题，为集体机器人的高效训练提供了可行的解决方案。

Abstract: Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement learning techniques designed for efficient training of cooperative and competitive policies on this platform. To address the challenges of multi-agent sim-to-real transfer, we introduce Out of Distribution State Initialization (OODSI) to mitigate the impact of the sim-to-real gap. In the experiments, OODSI improves the Sim2Real performance by 20%. We demonstrate the effectiveness of our approach through experiments with a multi-robot car competitive game and a cooperative task in real-world settings.

</details>


### [29] [A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms](https://arxiv.org/abs/2602.21148)
*Davis S. Catherman,Carlo Pinciroli*

Main category: cs.RO

TL;DR: 本文提出了相遇驱动信息扩散（EDID）问题，研究机器人在只能相遇时交换信息且无法安排会面的场景，建立了基于微观和宏观模型的信息扩散理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究在机器人只能通过相遇交换信息且无法预测会面时间、地点和对象的情况下，如何设计有效的信息存储和路由算法，这是分布式机器人系统中的重要挑战。

Method: 提出双层模型：微观模型基于"平均自由程"概念的推广，描述个体相遇概率；宏观模型捕捉信息扩散的全局动态。通过大量机器人仿真验证模型，考虑群体规模、通信范围、环境大小和不同随机运动机制。

Result: 建立了能够准确捕捉EDID基本动态的信息扩散模型，并通过仿真验证了模型的有效性，为设计支持信息扩散的算法提供了理论基础。

Conclusion: 该模型为EDID问题中的存储和路由算法设计提供了重要依据，揭示了不同参数对信息扩散效率的影响，为分布式机器人系统的信息传播策略提供了理论指导。

Abstract: In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.

</details>


### [30] [HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.21157)
*Quanxin Shou,Fangqi Zhu,Shawn Chen,Puxin Yan,Zhengyang Yan,Yikun Miao,Xiaoyi Pang,Zicong Hong,Ruikai Shi,Hao Huang,Jie Zhang,Song Guo*

Main category: cs.RO

TL;DR: HALO模型通过多模态思维链推理，在机器人操作任务中实现了更好的长视野和分布外泛化能力，相比基线策略提升34.1%


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在长视野或分布外场景中表现不佳，缺乏明确的多模态推理和动作影响预测机制。虽然已有工作引入文本思维链或视觉子目标预测，但仍缺乏统一的人类式推理框架来整合文本推理、视觉预见和动作预测。

Method: 提出HALO模型，通过具身多模态思维链(EM-CoT)推理实现文本任务推理、视觉子目标预测和动作预测的统一框架。采用混合Transformer架构，将语义推理、视觉预见和动作预测解耦为专家模块，同时支持跨专家协作。开发了自动化的EM-CoT训练数据合成流水线和精心设计的训练方案。

Result: 在模拟和真实世界环境中均取得优越性能，在RoboTwin基准上超越基线策略34.1%。所有提出的训练方案和EM-CoT设计组件都有助于提高任务成功率。在激进的未见环境随机化下展现出强大的泛化能力。

Conclusion: HALO通过统一的具身多模态思维链推理框架，显著提升了VLA模型在机器人操作任务中的性能、鲁棒性和泛化能力，为解决长视野和分布外场景挑战提供了有效方案。

Abstract: Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, and action prediction. To this end, we propose HALO, a unified VLA model that enables embodied multimodal chain-of-thought (EM-CoT) reasoning through a sequential process of textual task reasoning, visual subgoal prediction for fine-grained guidance, and EM-CoT-augmented action prediction. We instantiate HALO with a Mixture-of-Transformers (MoT) architecture that decouples semantic reasoning, visual foresight, and action prediction into specialized experts while allowing seamless cross-expert collaboration. To enable HALO learning at scale, we introduce an automated pipeline to synthesize EM-CoT training data along with a carefully crafted training recipe. Extensive experiments demonstrate that: (1) HALO achieves superior performance in both simulated and real-world environments, surpassing baseline policy pi_0 by 34.1% on RoboTwin benchmark; (2) all proposed components of the training recipe and EM-CoT design help improve task success rate; and (3) HALO exhibits strong generalization capabilities under aggressive unseen environmental randomization with our proposed EM-CoT reasoning.

</details>


### [31] [ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking](https://arxiv.org/abs/2602.21161)
*Guangming Wang,Qizhen Ying,Yixiong Jing,Olaf Wysocki,Brian Sheil*

Main category: cs.RO

TL;DR: 论文提出ActionReasoning框架，利用LLM进行显式动作推理，生成符合物理规律的动作决策，用于机器人砖块堆叠任务。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统依赖定制规划器，缺乏泛化能力；现有VLA方法受限于语言token对连续动作空间的表示能力，需要物理推理来弥补这一差距。

Method: 提出ActionReasoning框架，利用LLM中已有的物理先验和现实世界知识，构建多智能体架构，将环境状态序列化后输入LLM生成物理感知的动作计划。

Result: 实验表明该多智能体LLM框架能够实现稳定的砖块放置，将工作重心从底层编码转移到高层工具调用和提示工程，展现出泛化潜力。

Conclusion: 该工作通过将物理推理与LLM结合，为机器人操作中的感知与执行提供了有前景的桥梁方法。

Abstract: Classical robotic systems typically rely on custom planners designed for constrained environments. While effective in restricted settings, these systems lack generalization capabilities, limiting the scalability of embodied AI and general-purpose robots. Recent data-driven Vision-Language-Action (VLA) approaches aim to learn policies from large-scale simulation and real-world data. However, the continuous action space of the physical world significantly exceeds the representational capacity of linguistic tokens, making it unclear if scaling data alone can yield general robotic intelligence. To address this gap, we propose ActionReasoning, an LLM-driven framework that performs explicit action reasoning to produce physics-consistent, prior-guided decisions for robotic manipulation. ActionReasoning leverages the physical priors and real-world knowledge already encoded in Large Language Models (LLMs) and structures them within a multi-agent architecture. We instantiate this framework on a tractable case study of brick stacking, where the environment states are assumed to be already accurately measured. The environmental states are then serialized and passed to a multi-agent LLM framework that generates physics-aware action plans. The experiments demonstrate that the proposed multi-agent LLM framework enables stable brick placement while shifting effort from low-level domain-specific coding to high-level tool invocation and prompting, highlighting its potential for broader generalization. This work introduces a promising approach to bridging perception and execution in robotic manipulation by integrating physical reasoning with LLMs.

</details>


### [32] [Efficient Hierarchical Any-Angle Path Planning on Multi-Resolution 3D Grids](https://arxiv.org/abs/2602.21174)
*Victor Reijgwart,Cesar Cadena,Roland Siegwart,Lionel Ott*

Main category: cs.RO

TL;DR: 提出一种利用多分辨率体素地图的任意角度路径规划方法，结合了任意角度规划的最优性和完备性，同时通过多分辨率表示解决了搜索方法的计算可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的路径规划方法存在局限性：采样和轨迹优化方法不利用地图的显式连通性信息，而基于搜索的方法（如A*）在大规模高分辨率地图中存在可扩展性问题。需要一种既能利用多分辨率地图连通性信息，又能保持计算效率的路径规划方法。

Method: 提出一种任意角度规划方法，通过连接障碍物角落的直线段来寻找最优路径。该方法利用多分辨率体素地图表示，结合了任意角度规划的最优性和完备性，同时通过多分辨率表示克服了搜索方法的计算可扩展性问题。

Result: 在真实和合成环境中的大量实验表明，该方法在解质量和速度方面表现出色，甚至优于基于采样的方法。该方法具有最优性和完备性，同时保持了计算效率。

Conclusion: 提出的方法成功地将任意角度规划的最优性和完备性与多分辨率表示的计算效率相结合，为大规模复杂环境中的路径规划提供了一个高效且最优的解决方案。该框架已开源，供机器人学和规划社区使用。

Abstract: Hierarchical, multi-resolution volumetric mapping approaches are widely used to represent large and complex environments as they can efficiently capture their occupancy and connectivity information. Yet widely used path planning methods such as sampling and trajectory optimization do not exploit this explicit connectivity information, and search-based methods such as A* suffer from scalability issues in large-scale high-resolution maps. In many applications, Euclidean shortest paths form the underpinning of the navigation system. For such applications, any-angle planning methods, which find optimal paths by connecting corners of obstacles with straight-line segments, provide a simple and efficient solution. In this paper, we present a method that has the optimality and completeness properties of any-angle planners while overcoming computational tractability issues common to search-based methods by exploiting multi-resolution representations. Extensive experiments on real and synthetic environments demonstrate the proposed approach's solution quality and speed, outperforming even sampling-based methods. The framework is open-sourced to allow the robotics and planning community to build on our research.

</details>


### [33] [Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics](https://arxiv.org/abs/2602.21203)
*Abdulaziz Almuzairee,Henrik I. Christensen*

Main category: cs.RO

TL;DR: Squint是一种视觉软演员-评论家方法，通过并行仿真、分布评论家、分辨率压缩等技术，在单GPU上15分钟内完成训练，比现有视觉离策略和同策略方法训练更快。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习在机器人应用中很有前景但成本高昂：离策略方法样本效率高但训练慢；同策略方法可并行化但浪费样本。现有工作表明离策略方法在状态控制中比同策略方法训练更快，但扩展到视觉领域仍面临高维图像输入带来的训练动态复杂、存储和编码开销大的挑战。

Method: Squint方法包含：1) 并行仿真；2) 分布评论家；3) 分辨率压缩（降低图像分辨率）；4) 层归一化；5) 优化的更新-数据比率；6) 优化的实现。在SO-101任务集（ManiSkill3中的8个操作任务）上进行评估，采用重度域随机化。

Result: 在单RTX 3090 GPU上15分钟内完成训练，大多数任务在6分钟内收敛。实现了从仿真到真实SO-101机器人的迁移，比现有视觉离策略和同策略方法训练更快。

Conclusion: Squint通过多种优化技术解决了视觉强化学习的训练效率问题，实现了快速训练和仿真到真实的迁移，为机器人视觉控制提供了高效的解决方案。

Abstract: Visual reinforcement learning is appealing for robotics but expensive -- off-policy methods are sample-efficient yet slow; on-policy methods parallelize well but waste samples. Recent work has shown that off-policy methods can train faster than on-policy methods in wall-clock time for state-based control. Extending this to vision remains challenging, where high-dimensional input images complicate training dynamics and introduce substantial storage and encoding overhead. To address these challenges, we introduce Squint, a visual Soft Actor Critic method that achieves faster wall-clock training than prior visual off-policy and on-policy methods. Squint achieves this via parallel simulation, a distributional critic, resolution squinting, layer normalization, a tuned update-to-data ratio, and an optimized implementation. We evaluate on the SO-101 Task Set, a new suite of eight manipulation tasks in ManiSkill3 with heavy domain randomization, and demonstrate sim-to-real transfer to a real SO-101 robot. We train policies for 15 minutes on a single RTX 3090 GPU, with most tasks converging in under 6 minutes.

</details>
