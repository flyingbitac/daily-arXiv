<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding](https://arxiv.org/abs/2512.04231)
*Zhou Chen,Joe Lin,Carson Bulgin,Sathyanarayanan N. Aakur*

Main category: cs.RO

TL;DR: CRAFT-E是一个模块化神经符号框架，通过组合结构化知识图谱、视觉语言对齐和基于能量的抓取推理，实现可解释的物体选择，用于辅助机器人的功能检索任务。


<details>
  <summary>Details</summary>
Motivation: 辅助机器人在非结构化环境中需要理解物体的功能用途，现有方法依赖黑盒模型或固定功能标签，缺乏透明度、可控性和可靠性，限制了在人机交互应用中的实用性。

Method: 提出CRAFT-E框架：1)构建结构化动词-属性-对象知识图谱；2)视觉语言对齐；3)基于能量的抓取推理。系统生成可解释的接地路径，将抓取可行性作为功能推理的组成部分。

Result: 在静态场景、基于ImageNet的功能检索和涉及20个动词和39个物体的真实世界实验中取得竞争性性能。框架在感知噪声下保持鲁棒性，提供透明的组件级诊断。

Conclusion: CRAFT-E通过符号推理与具身感知的结合，为功能接地的物体选择提供了可解释且可定制的端到端模型替代方案，支持辅助机器人系统中的可信决策。

Abstract: Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.

</details>


### [2] [Sliding Mode Control and Subspace Stabilization Methodology for the Orbital Stabilization of Periodic Trajectories](https://arxiv.org/abs/2512.04249)
*Maksim Surov,Leonid Freidovich*

Main category: cs.RO

TL;DR: 提出了一种结合滑模控制和子空间稳定的方法，用于欠驱动机械系统中周期轨迹的轨道稳定，避免计算密集型周期LQR问题，提高了抗干扰鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对欠驱动机械系统（具有一个欠驱动自由度）中周期轨迹的轨道稳定问题，传统方法如周期LQR计算量大，需要更高效、鲁棒的控制方法。

Method: 采用部分反馈线性化和稳定化，计算沿参考轨道的横向线性化得到周期线性时变系统及其稳定子空间，通过滑模控制驱动轨迹趋向该子空间。

Result: 该方法避免了计算密集型周期LQR问题，提高了对匹配干扰的鲁棒性，并在蝴蝶机器人上进行了实验验证。

Conclusion: 提出的滑模控制与子空间稳定相结合的方法为欠驱动机械系统的周期轨迹轨道稳定提供了一种计算高效且鲁棒的解决方案。

Abstract: This paper presents a combined sliding-mode control and subspace stabilization methodology for orbital stabilization of periodic trajectories in underactuated mechanical systems with one degree of underactuation. The approach starts with partial feedback linearization and stabilization. Then, transverse linearization along the reference orbit is computed, resulting in a periodic linear time-varying system with a stable subspace. Sliding-mode control drives trajectories toward this subspace. The proposed design avoids solving computationally intensive periodic LQR problems and improves robustness to matched disturbances. The methodology is validated through experiments on the Butterfly robot.

</details>


### [3] [Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies](https://arxiv.org/abs/2512.04279)
*Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: 提出奖励特权世界模型蒸馏框架，通过教师模型学习密集奖励来训练动态模型，学生模型仅使用稀疏任务奖励但继承教师动态模型，在自动驾驶任务中实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶仿真中，密集奖励（如车道几何、碰撞时间等）能加速强化学习训练，但直接使用这些奖励训练的策略容易过拟合，与部署时的稀疏目标（如路线完成、无碰撞超车）不匹配。需要一种方法既能利用密集奖励的优势，又能确保策略针对稀疏目标进行优化。

Method: 提出两阶段框架：1）教师DreamerV3智能体使用密集特权奖励训练；2）仅将教师的潜在动态模型蒸馏到学生模型中，学生仅使用稀疏任务奖励训练。师生共享相同的观测空间（语义鸟瞰图），特权信息仅通过教师奖励输入，学生不模仿教师动作或价值估计，而是通过匹配教师潜在动态来正则化自身世界模型。

Result: 在CARLA车道跟随和超车基准测试中，稀疏奖励学生模型优于密集奖励教师模型和从头训练的稀疏奖励基线。在未见过的车道跟随路线上，成功率比密集教师提高约23%，同时保持相当或更好的安全性。在超车任务中，学生在训练路线上保持近乎完美的性能，在未见路线上成功率提高高达27倍，车道保持能力也得到改善。

Conclusion: 密集奖励可用于学习更丰富的动态模型，同时确保部署策略严格针对稀疏、与部署目标对齐的目标进行优化。奖励特权蒸馏框架能有效利用密集奖励的稳定化优势，同时避免其与部署指标的不匹配问题。

Abstract: We study how to exploit dense simulator-defined rewards in vision-based autonomous driving without inheriting their misalignment with deployment metrics. In realistic simulators such as CARLA, privileged state (e.g., lane geometry, infractions, time-to-collision) can be converted into dense rewards that stabilize and accelerate model-based reinforcement learning, but policies trained directly on these signals often overfit and fail to generalize when evaluated on sparse objectives such as route completion and collision-free overtaking. We propose reward-privileged world model distillation, a two-stage framework in which a teacher DreamerV3-style agent is first trained with a dense privileged reward, and only its latent dynamics are distilled into a student trained solely on sparse task rewards. Teacher and student share the same observation space (semantic bird's-eye-view images); privileged information enters only through the teacher's reward, and the student does not imitate the teacher's actions or value estimates. Instead, the student's world model is regularized to match the teacher's latent dynamics while its policy is learned from scratch on sparse success/failure signals. In CARLA lane-following and overtaking benchmarks, sparse-reward students outperform both dense-reward teachers and sparse-from-scratch baselines. On unseen lane-following routes, reward-privileged distillation improves success by about 23 percent relative to the dense teacher while maintaining comparable or better safety. On overtaking, students retain near-perfect performance on training routes and achieve up to a 27x improvement in success on unseen routes, with improved lane keeping. These results show that dense rewards can be leveraged to learn richer dynamics models while keeping the deployed policy optimized strictly for sparse, deployment-aligned objectives.

</details>


### [4] [Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates](https://arxiv.org/abs/2512.04373)
*Hann Woei Ho,Ye Zhou*

Main category: cs.RO

TL;DR: 提出一种基于局部光流发散估计的非线性控制策略，用于小型航天器在斜坡地形上的自主着陆，通过调节两个局部光流发散估计值来控制推力和姿态，实现稳定着陆和地形对齐。


<details>
  <summary>Details</summary>
Motivation: 小型轻量级航天器（如旋翼机和着陆器）处理能力和有效载荷有限，难以使用先进的深度学习方法或重型传感器。受蜜蜂等飞行昆虫利用光流实现卓越着陆的启发，需要开发一种低资源消耗的自主着陆策略，解决斜坡地形着陆中的两个关键挑战：全局光流发散估计会掩盖地形倾斜，以及基于发散的非线性控制在使用传统控制器时可能导致不稳定。

Method: 提出一种非线性控制策略，利用两个不同的局部光流发散估计来调节垂直着陆期间的推力和姿态。控制律基于增量非线性动态反演（INDI）来处理非线性光流发散。推力控制通过保持局部光流发散估计值的恒定平均值来确保平滑垂直下降，而姿态控制则利用它们的差异来在触地时使飞行器与倾斜表面对齐。使用简化的2D航天器模型在不同坡度和发散设定点下进行数值模拟评估。

Result: 数值模拟结果显示，调节平均发散能够实现速度和高度指数衰减的稳定着陆，而利用发散差异能够有效与倾斜地形对齐。该方法为小型航天器提供了一种稳健、低资源的着陆策略。

Conclusion: 该方法通过生物启发的光流发散调节策略，解决了小型航天器在斜坡地形上自主着陆的挑战，提高了小型航天器自主行星任务的可行性。非线性控制策略能够处理光流发散的非线性特性，同时实现稳定的垂直下降和地形对齐。

Abstract: Autonomous landing on sloped terrain poses significant challenges for small, lightweight spacecraft, such as rotorcraft and landers. These vehicles have limited processing capability and payload capacity, which makes advanced deep learning methods and heavy sensors impractical. Flying insects, such as bees, achieve remarkable landings with minimal neural and sensory resources, relying heavily on optical flow. By regulating flow divergence, a measure of vertical velocity divided by height, they perform smooth landings in which velocity and height decay exponentially together. However, adapting this bio-inspired strategy for spacecraft landings on sloped terrain presents two key challenges: global flow-divergence estimates obscure terrain inclination, and the nonlinear nature of divergence-based control can lead to instability when using conventional controllers. This paper proposes a nonlinear control strategy that leverages two distinct local flow divergence estimates to regulate both thrust and attitude during vertical landings. The control law is formulated based on Incremental Nonlinear Dynamic Inversion to handle the nonlinear flow divergence. The thrust control ensures a smooth vertical descent by keeping a constant average of the local flow divergence estimates, while the attitude control aligns the vehicle with the inclined surface at touchdown by exploiting their difference. The approach is evaluated in numerical simulations using a simplified 2D spacecraft model across varying slopes and divergence setpoints. Results show that regulating the average divergence yields stable landings with exponential decay of velocity and height, and using the divergence difference enables effective alignment with inclined terrain. Overall, the method offers a robust, low-resource landing strategy that enhances the feasibility of autonomous planetary missions with small spacecraft.

</details>


### [5] [FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination](https://arxiv.org/abs/2512.04381)
*Chengyang He,Ge Sun,Yue Bai,Junkai Lu,Jiadong Zhao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: FALCON框架通过视觉语言基础模型协调解耦的移动和操作模块化扩散策略，解决异构观测融合问题，提升移动操作任务的性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 移动操作任务中，单一策略需要融合移动和操作这两种异构且可能不匹配的观测数据，导致性能下降。需要一种既能保持子系统专业化，又能实现有效协调的方法。

Method: 1) 将移动和操作解耦为两个专门的视觉运动策略；2) 使用视觉语言基础模型作为协调器，编码全局观测和语言指令为共享潜在嵌入；3) 引入阶段进度头，通过任务阶段文本描述推断离散阶段和连续进度；4) 采用协调感知对比损失，显式编码臂和底座动作的跨子系统兼容性。

Result: 在两个需要导航、精确末端执行器放置和紧密底座-臂协调的移动操作任务上，FALCON超越了集中式和分散式基线方法，表现出更好的鲁棒性和对分布外场景的泛化能力。

Conclusion: FALCON框架通过视觉语言基础模型协调解耦的移动和操作策略，有效解决了异构观测融合问题，为复杂移动操作任务提供了一种性能优越、鲁棒性强且泛化能力好的解决方案。

Abstract: We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision-language foundation model as the coordinator. Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation. Our key innovation lies in restoring coordination between these two independent policies through a vision-language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels. To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.

</details>


### [6] [Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation](https://arxiv.org/abs/2512.04399)
*Haoqi Han,Yi Yang,Yifei Yu,Yixuan Zhou,Xiaohan Zhu,Hesheng Wang*

Main category: cs.RO

TL;DR: 提出一种新型15自由度仿生机械手，采用创新的肌腱驱动机制，仅用15个电机实现人类手部尺寸和自由度的仿生设计，系统重量仅1.4kg


<details>
  <summary>Details</summary>
Motivation: 在机械手研究中，如何在保持人类手部尺寸和自由度的同时最小化执行器数量是一个基本挑战。传统肌腱驱动系统需要大量电机，结构复杂且性能有限。

Method: 借鉴人类手部运动学配置和肌肉分布策略，提出新型肌腱驱动机制。在前臂安装5个电机提供强力抓握，在手掌安装10个小电机支持精细操作，开发相应的关节传感和电机驱动电气系统。

Result: 系统总重仅1.4kg，结合轻量化和高性能特点。实验表明该仿生手展现出卓越的灵巧性和强大的抓取能力，显著减少了传统肌腱驱动系统所需的电机数量。

Conclusion: 该15自由度仿生机械手设计在减少电机数量的同时保持了人类手部尺寸和自由度，展现出优异的运动性能和抓取能力，在机器人操作任务中具有重要应用潜力。

Abstract: In robotic hand research, minimizing the number of actuators while maintaining human-hand-consistent dimensions and degrees of freedom constitutes a fundamental challenge. Drawing bio-inspiration from human hand kinematic configurations and muscle distribution strategies, this work proposes a novel 15-DoF dexterous robotic hand, with detailed analysis of its mechanical architecture, electrical system, and control system. The bionic hand employs a new tendon-driven mechanism, significantly reducing the number of motors required by traditional tendon-driven systems while enhancing motion performance and simplifying the mechanical structure. This design integrates five motors in the forearm to provide strong gripping force, while ten small motors are installed in the palm to support fine manipulation tasks. Additionally, a corresponding joint sensing and motor driving electrical system was developed to ensure efficient control and feedback. The entire system weighs only 1.4kg, combining lightweight and high-performance features. Through experiments, the bionic hand exhibited exceptional dexterity and robust grasping capabilities, demonstrating significant potential for robotic manipulation tasks.

</details>


### [7] [RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation](https://arxiv.org/abs/2512.04415)
*Zhoufeng Wang,Hang Zhao,Juzhan Xu,Shishun Zhang,Zeyu Xiong,Ruizhen Hu,Chenyang Zhu,Kai Xu*

Main category: cs.RO

TL;DR: RoboBPP是一个用于机器人在线装箱的基准测试系统，包含物理仿真器、真实工业数据集和综合评估指标，旨在解决该领域缺乏标准化基准的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D装箱领域存在以下问题：1) 问题设置、测试数据集和评估指标不一致阻碍了领域进展；2) 缺乏全面的基准测试系统；3) 真实硬件测试成本高，构建真实仿真环境困难；4) 现有研究依赖与真实工业数据分布不同的合成数据集。

Method: 1) 开发RoboBPP基准测试系统，集成基于物理的仿真器评估物理可行性；2) 在仿真环境中引入真实尺度的机械臂和箱子，模拟真实工业包装流程；3) 从真实工业工作流程收集三个数据集（装配线生产、物流包装、家具制造）；4) 设计三种测试设置，扩展现有评估指标，新增结构稳定性和操作安全性指标；5) 设计评分系统并提供可视化工具和在线排行榜。

Result: 开发了完全开源的RoboBPP基准测试系统，包含物理仿真器、真实工业数据集、综合评估指标和可视化工具，为未来研究和工业应用提供了可复现和可扩展的基础。

Conclusion: RoboBPP解决了3D装箱领域缺乏标准化基准的问题，通过物理仿真、真实工业数据集和综合评估指标，确保评估的算法在实际工业应用中可部署，为领域研究提供了重要基础设施。

Abstract: Physical feasibility in 3D bin packing is a key requirement in modern industrial logistics and robotic automation. With the growing adoption of industrial automation, online bin packing has gained increasing attention. However, inconsistencies in problem settings, test datasets, and evaluation metrics have hindered progress in the field, and there is a lack of a comprehensive benchmarking system. Direct testing on real hardware is costly, and building a realistic simulation environment is also challenging. To address these limitations, we introduce RoboBPP, a benchmarking system designed for robotic online bin packing. RoboBPP integrates a physics-based simulator to assess physical feasibility. In our simulation environment, we introduce a robotic arm and boxes at real-world scales to replicate real industrial packing workflows. By simulating conditions that arise in real industrial applications, we ensure that evaluated algorithms are practically deployable. In addition, prior studies often rely on synthetic datasets whose distributions differ from real-world industrial data. To address this issue, we collect three datasets from real industrial workflows, including assembly-line production, logistics packing, and furniture manufacturing. The benchmark comprises three carefully designed test settings and extends existing evaluation metrics with new metrics for structural stability and operational safety. We design a scoring system and derive a range of insights from the evaluation results. RoboBPP is fully open-source and is equipped with visualization tools and an online leaderboard, providing a reproducible and extensible foundation for future research and industrial applications (https://robot-bin-packing-benchmark.github.io).

</details>


### [8] [Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops](https://arxiv.org/abs/2512.04446)
*Chang Liu,Sibo Tian,Sara Behdad,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 该研究探索了将视觉-语言-动作模型应用于废旧台式机关键部件（RAM和CPU）的自动化拆卸，发现纯VLA模型能完成部分步骤但无法处理关键子任务，而结合规则控制器的混合策略能成功完成整个拆卸操作。


<details>
  <summary>Details</summary>
Motivation: 废旧台式机关键部件（如RAM、CPU和硬盘）的自动化拆卸面临挑战，因为产品存在变异性、不确定性，且需要精确的顺序操作。当前机器人拆卸流程需要分阶段显式建模，限制了泛化能力。虽然VLA模型在简单任务上表现良好，但将其应用于复杂拆卸任务的可行性尚未充分探索。

Method: 收集了机器人拆卸RAM和CPU的定制数据集，用于微调两种成熟的VLA方法（OpenVLA和OpenVLA-OFT）。将整个拆卸任务分解为多个小步骤，并测试了纯VLA模型和结合规则控制器的混合策略的性能。

Result: 微调后的VLA模型能够忠实完成多个早期步骤，但在某些关键子任务上表现不佳，导致任务失败。然而，简单的混合策略（VLA结合规则控制器）能够成功执行整个拆卸操作。

Conclusion: VLA模型在处理机器人废旧产品拆卸所需的灵巧性和精确性方面存在局限性。混合策略展示了解决当前挑战的可行路径，为未来端到端机器人自动化拆卸研究提供了重要见解。

Abstract: Automating disassembly of critical components from end-of-life (EoL) desktops, such as high-value items like RAM modules and CPUs, as well as sensitive parts like hard disk drives, remains challenging due to the inherent variability and uncertainty of these products. Moreover, their disassembly requires sequential, precise, and dexterous operations, further increasing the complexity of automation. Current robotic disassembly processes are typically divided into several stages: perception, sequence planning, task planning, motion planning, and manipulation. Each stage requires explicit modeling, which limits generalization to unfamiliar scenarios. Recent development of vision-language-action (VLA) models has presented an end-to-end approach for general robotic manipulation tasks. Although VLAs have demonstrated promising performance on simple tasks, the feasibility of applying such models to complex disassembly remains largely unexplored. In this paper, we collected a customized dataset for robotic RAM and CPU disassembly and used it to fine-tune two well-established VLA approaches, OpenVLA and OpenVLA-OFT, as a case study. We divided the whole disassembly task into several small steps, and our preliminary experimental results indicate that the fine-tuned VLA models can faithfully complete multiple early steps but struggle with certain critical subtasks, leading to task failure. However, we observed that a simple hybrid strategy that combines VLA with a rule-based controller can successfully perform the entire disassembly operation. These findings highlight the current limitations of VLA models in handling the dexterity and precision required for robotic EoL product disassembly. By offering a detailed analysis of the observed results, this study provides insights that may inform future research to address current challenges and advance end-to-end robotic automated disassembly.

</details>


### [9] [Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration](https://arxiv.org/abs/2512.04453)
*Debasmita Ghose,Oz Gitelson,Marynel Vazquez,Brian Scassellati*

Main category: cs.RO

TL;DR: BALI方法通过整合自然语言偏好和观察到的动作来预测人类目标，在协作烹饪任务中比基线方法表现更好


<details>
  <summary>Details</summary>
Motivation: 机器人需要推断人类目标，但这些目标常常模糊、难以表达或不来自固定集合。现有方法要么限制在预定义目标集，要么仅依赖观察动作，要么完全依赖明确指令，在真实世界交互中表现脆弱。

Method: 提出BALI（双向动作-语言推断）方法，在后退水平规划树中整合自然语言偏好和观察到的动作。结合人类语言和动作线索，仅在预期信息增益超过中断成本时提问澄清问题，并选择与推断目标一致的支持性动作。

Result: 在协作烹饪任务中评估，目标对机器人可能是新颖且无界的。与基线相比，BALI产生更稳定的目标预测和显著更少的错误。

Conclusion: BALI方法通过整合语言和动作线索，在不确定环境中有效推断人类目标，提高了机器人协作能力。

Abstract: To collaborate with humans, robots must infer goals that are often ambiguous, difficult to articulate, or not drawn from a fixed set. Prior approaches restrict inference to a predefined goal set, rely only on observed actions, or depend exclusively on explicit instructions, making them brittle in real-world interactions. We present BALI (Bidirectional Action-Language Inference) for goal prediction, a method that integrates natural language preferences with observed human actions in a receding-horizon planning tree. BALI combines language and action cues from the human, asks clarifying questions only when the expected information gain from the answer outweighs the cost of interruption, and selects supportive actions that align with inferred goals. We evaluate the approach in collaborative cooking tasks, where goals may be novel to the robot and unbounded. Compared to baselines, BALI yields more stable goal predictions and significantly fewer mistakes.

</details>


### [10] [One Ring to Rule Them All: Constrained Distributional Control for Massive-Scale Heterogeneous Robotic Ensemble Systems](https://arxiv.org/abs/2512.04502)
*Andres Arias,Wei Zhang,Haoyu Qian,Jr-Shin Li,Chuangchuang Sun*

Main category: cs.RO

TL;DR: 提出了一种用于参数化异构机器人系统的约束集成控制框架，通过矩核变换将参数化集成动力学映射到核空间中的矩系统，实现群体级行为表征，并利用信号时序逻辑规范编码复杂的访问-避障任务。


<details>
  <summary>Details</summary>
Motivation: 集成控制旨在使用共享控制输入来引导动态系统群体，但现有方法在处理参数化、异构机器人系统在状态和环境约束（如避障）下的操作方面存在不足，需要开发能够处理大规模约束的集成控制框架。

Method: 开发了矩核变换，将参数化集成动力学映射到核空间中的矩系统；将状态空间约束（如多面体航点和障碍物）转换到矩空间；采用表达性信号时序逻辑规范编码复杂任务；通过约束集成控制公式合成单一共享控制器。

Result: 仿真和硬件实验表明，所提出的方法能够在约束环境中安全高效地控制机器人集成系统，实现了复杂访问-避障任务的自动化控制。

Conclusion: 该约束集成控制框架为参数化异构机器人系统在约束环境中的操作提供了统一公式，通过矩核变换和信号时序逻辑规范实现了安全、大规模集成控制，具有实际应用价值。

Abstract: Ensemble control aims to steer a population of dynamical systems using a shared control input. This paper introduces a constrained ensemble control framework for parameterized, heterogeneous robotic systems operating under state and environmental constraints, such as obstacle avoidance. We develop a moment kernel transform that maps the parameterized ensemble dynamics to the moment system in a kernel space, enabling the characterization of population-level behavior. The state-space constraints, such as polyhedral waypoints to be visited and obstacles to be avoided, are also transformed into the moment space, leading to a unified formulation for safe, large-scale ensemble control. Expressive signal temporal logic specifications are employed to encode complex visit-avoid tasks, which are achieved through a single shared controller synthesized from our constrained ensemble control formulation. Simulation and hardware experiments demonstrate the effectiveness of the proposed approach in safely and efficiently controlling robotic ensembles within constrained environments.

</details>


### [11] [Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting](https://arxiv.org/abs/2512.04731)
*Jian Tang,Pu Pang,Haowen Sun,Chengzhong Ma,Xingyu Chen,Hua Huang,Xuguang Lan*

Main category: cs.RO

TL;DR: 提出S2GS方法，通过提取物体中心、领域不变的空间特征来桥接机器人操作中的仿真-现实领域鸿沟，显著提升策略的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中的仿真到现实迁移存在显著领域鸿沟，现有方法如领域随机化、适应和仿真-现实校准需要大量调优或难以泛化到未见场景。

Method: 提出语义2D高斯泼溅（S2GS）表示方法，构建多视图2D语义场并通过特征级高斯泼溅投影到统一3D空间，使用语义过滤机制去除无关背景内容。

Result: 在ManiSkill仿真环境中采用Diffusion Policy作为下游学习算法，实验表明S2GS显著提升仿真到现实的迁移能力，在现实场景中保持高且稳定的任务性能。

Conclusion: S2GS通过提取领域不变特征有效桥接仿真-现实鸿沟，为机器人操作的跨域迁移提供了有前景的解决方案。

Abstract: Cross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.

</details>


### [12] [Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges](https://arxiv.org/abs/2512.04770)
*Yuxing Wang,Zhiyu Chen,Tiantian Zhang,Qiyue Yin,Yongzhe Chang,Zhiheng Li,Liang Wang,Xueqian Wang*

Main category: cs.RO

TL;DR: 该论文系统综述了具身协同设计(ECD)领域的最新进展，这是一种受生物脑体协同进化启发的智能体设计范式，通过联合优化形态和控制器来创造从虚拟生物到物理机器人的智能体。


<details>
  <summary>Details</summary>
Motivation: 受生物脑体协同进化的启发，传统方法将控制与形态设计分离存在局限性。具身协同设计作为一种变革性范式，通过联合优化智能体的形态和控制器，能够实现更丰富的环境交互和更鲁棒的任务性能。

Method: 论文首先形式化ECD概念并定位其在相关领域中的位置，然后提出一个分层分类法：下层将智能体设计分解为三个基本组件（控制大脑、身体形态、任务环境），上层将这些组件整合为四种主要ECD框架（双层、单层、生成式和开放式）。基于此分类法，系统分析了100多项最新研究。

Result: 论文系统综述了ECD领域的研究进展，包括显著基准、数据集以及在仿真和现实场景中的应用。通过分层分类法整合了该领域的核心见解，为研究人员提供了清晰的框架。

Conclusion: 具身协同设计是一个快速发展的研究领域，具有重要的理论和应用价值。论文识别了该领域面临的重大挑战，并提出了有前景的未来研究方向。同时创建了相关的开源项目以促进该领域的发展。

Abstract: Brain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at https://github.com/Yuxing-Wang-THU/SurveyBrainBody.

</details>


### [13] [TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards](https://arxiv.org/abs/2512.04772)
*Mauro Martini,Marco Ambrosio,Judith Vilella-Cantos,Alessandro Navone,Marcello Chiaberge*

Main category: cs.RO

TL;DR: TEMPO-VINE是一个专为葡萄园环境设计的大规模多模态数据集，包含多种传感器数据和真实场景下的基准轨迹，旨在促进农业自动化中的传感器融合、SLAM和地点识别技术发展。


<details>
  <summary>Details</summary>
Motivation: 当前农业机器人研究多依赖受控模拟或孤立田间试验，缺乏真实复杂农业条件下的通用基准。葡萄园因其动态特性对自主系统提出重大挑战，需要更真实的数据集来推动稳健自动化系统的发展。

Method: 创建了TEMPO-VINE数据集，这是首个在真实葡萄园环境中收集的多模态公开数据集，整合了不同价格级别的异构LiDAR、AHRS、RTK-GPS和相机数据，覆盖不同季节、植被生长阶段、地形和天气条件。

Result: 提供了包含超过100米长多行葡萄园的大规模数据收集，包含多次运行和重访的序列路径，为传感器融合、定位、建图和地点识别解决方案的开发提供了基础。

Conclusion: TEMPO-VINE填补了农业数据集领域的空白，为研究人员提供了在真实复杂农业条件下评估和开发自主系统的宝贵资源，将促进农业自动化技术的进步。

Abstract: In recent years, precision agriculture has been introducing groundbreaking innovations in the field, with a strong focus on automation. However, research studies in robotics and autonomous navigation often rely on controlled simulations or isolated field trials. The absence of a realistic common benchmark represents a significant limitation for the diffusion of robust autonomous systems under real complex agricultural conditions. Vineyards pose significant challenges due to their dynamic nature, and they are increasingly drawing attention from both academic and industrial stakeholders interested in automation. In this context, we introduce the TEMPO-VINE dataset, a large-scale multi-temporal dataset specifically designed for evaluating sensor fusion, simultaneous localization and mapping (SLAM), and place recognition techniques within operational vineyard environments. TEMPO-VINE is the first multi-modal public dataset that brings together data from heterogeneous LiDARs of different price levels, AHRS, RTK-GPS, and cameras in real trellis and pergola vineyards, with multiple rows exceeding 100 m in length. In this work, we address a critical gap in the landscape of agricultural datasets by providing researchers with a comprehensive data collection and ground truth trajectories in different seasons, vegetation growth stages, terrain and weather conditions. The sequence paths with multiple runs and revisits will foster the development of sensor fusion, localization, mapping and place recognition solutions for agricultural fields. The dataset, the processing tools and the benchmarking results will be available at the dedicated webpage upon acceptance.

</details>


### [14] [Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions](https://arxiv.org/abs/2512.04773)
*Giorgos Polychronis,Foivos Pournaropoulos,Christos D. Antonopoulos,Spyros Lalis*

Main category: cs.RO

TL;DR: 无人机在数据驱动任务中面临"等待处理数据"与"提前移动"的权衡，本文提出基于分支预测和强化学习的机器学习方法，显著优化任务时间


<details>
  <summary>Details</summary>
Motivation: 无人机在数据采集任务中面临关键决策困境：如果原地等待数据处理结果，可能浪费时间；如果提前移动到下一个兴趣点，当需要返回执行后续操作时又会增加飞行时间。现有方法无法有效平衡这一权衡。

Method: 提出基于分支预测和强化学习的机器学习方法，用于决策无人机在采集数据后是应该原地等待处理结果，还是立即移动到下一个兴趣点。这些方法考虑了事件发生概率随时间变化的各种场景。

Result: 提出的方法在广泛场景下显著优于文献中基于回归的方法，最坏情况任务时间最多改善4.1倍。中位任务时间与具有完美事件概率知识的方法相比仅高出最多2.7%。

Conclusion: 基于分支预测和强化学习的机器学习方法能够有效解决无人机在数据驱动任务中的决策问题，显著优化任务执行时间，接近理想情况下的性能表现。

Abstract: Drones are becoming indispensable in many application domains. In data-driven missions, besides sensing, the drone must process the collected data at runtime to decide whether additional action must be taken on the spot, before moving to the next point of interest. If processing does not reveal an event or situation that requires such an action, the drone has waited in vain instead of moving to the next point. If, however, the drone starts moving to the next point and it turns out that a follow-up action is needed at the previous point, it must spend time to fly-back. To take this decision, we propose different machine-learning methods based on branch prediction and reinforcement learning. We evaluate these methods for a wide range of scenarios where the probability of event occurrence changes with time. Our results show that the proposed methods consistently outperform the regression-based method proposed in the literature and can significantly improve the worst-case mission time by up to 4.1x. Also, the achieved median mission time is very close, merely up to 2.7% higher, to that of a method with perfect knowledge of the current underlying event probability at each point of interest.

</details>


### [15] [MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.04813)
*Huanqian Wang,Chi Bene Chen,Yang Yue,Danhua Tao,Tong Guo,Shaoxuan Xie,Denghang Huang,Shiji Song,Guocai Yao,Gao Huang*

Main category: cs.RO

TL;DR: MOVE提出了一种通过动态演示增强空间信息的数据收集范式，通过在演示过程中移动环境中的可移动物体，从单条轨迹中生成密集多样的空间配置，显著提升模仿学习的空间泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人操作中前景广阔，但实际部署受到数据稀缺的根本限制。现有大规模数据集仍存在显著的空间泛化差距，主要问题是单个轨迹通常从环境的单一静态空间配置收集，包括固定的物体和目标位置以及不变的相机视角，这严重限制了可用于学习的空间信息多样性。

Method: 提出MOVE（MOtion-Based Variability Enhancement）数据收集范式，核心贡献是一种增强策略：在每个演示过程中为环境中的任何可移动物体注入运动。这一过程隐式地在单个轨迹内生成密集多样的空间配置，从而从动态演示中获取更丰富的空间信息。

Result: 在仿真和真实环境中的广泛实验验证了该方法。在需要强空间泛化的仿真任务中，MOVE平均成功率达到39.1%，相比静态数据收集范式（22.2%）有76.1%的相对提升，在某些任务上实现了2-5倍的数据效率增益。

Conclusion: MOVE通过简单的动态演示增强策略，有效解决了模仿学习中空间信息多样性的关键瓶颈，显著提升了空间泛化能力和数据效率，为机器人操作的实际部署提供了更实用的数据收集方法。

Abstract: Imitation learning method has shown immense promise for robotic manipulation, yet its practical deployment is fundamentally constrained by the data scarcity. Despite prior work on collecting large-scale datasets, there still remains a significant gap to robust spatial generalization. We identify a key limitation: individual trajectories, regardless of their length, are typically collected from a \emph{single, static spatial configuration} of the environment. This includes fixed object and target spatial positions as well as unchanging camera viewpoints, which significantly restricts the diversity of spatial information available for learning. To address this critical bottleneck in data efficiency, we propose \textbf{MOtion-Based Variability Enhancement} (\emph{MOVE}), a simple yet effective data collection paradigm that enables the acquisition of richer spatial information from dynamic demonstrations. Our core contribution is an augmentation strategy that injects motion into any movable objects within the environment for each demonstration. This process implicitly generates a dense and diverse set of spatial configurations within a single trajectory. We conduct extensive experiments in both simulation and real-world environments to validate our approach. For example, in simulation tasks requiring strong spatial generalization, \emph{MOVE} achieves an average success rate of 39.1\%, a 76.1\% relative improvement over the static data collection paradigm (22.2\%), and yields up to 2--5$\times$ gains in data efficiency on certain tasks. Our code is available at https://github.com/lucywang720/MOVE.

</details>


### [16] [Hoi! - A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation](https://arxiv.org/abs/2512.04884)
*Tim Engelbracht,René Zurbrügg,Matteo Wohlrapp,Martin Büchner,Abhinav Valada,Marc Pollefeys,Hermann Blum,Zuria Bauer*

Main category: cs.RO

TL;DR: 研究人员创建了一个包含3048个序列的数据集，涵盖381个铰接物体在38个环境中的操作，包含四种操作方式（人手、带摄像头的人手、手持UMI夹爪、Hoi!夹爪），提供同步的末端执行器力和触觉感知数据。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够将视觉观察、操作动作和力感知相结合的数据集，特别是在跨视角（人类与机器人）的铰接物体操作场景中。需要为交互理解提供更全面的多模态数据支持。

Method: 构建了一个大规模数据集，包含3048个操作序列，涉及381个铰接物体在38个不同环境中。采用四种操作方式收集数据：人手操作、带手腕摄像头的人手操作、手持UMI夹爪操作、以及定制的Hoi!夹爪操作。所有工具都提供同步的末端执行器力和触觉感知数据。

Result: 创建了一个全面的力感知、跨视角铰接操作数据集，为交互理解研究提供了多模态数据基础。数据集支持从视频中理解交互，并能够评估方法在人类和机器人视角之间的迁移能力。

Conclusion: 该数据集为交互理解研究提供了重要的资源，特别支持跨视角迁移学习和力感知等未充分探索的模态研究，推动了机器人操作和人类-机器人交互领域的发展。

Abstract: We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.

</details>


### [17] [On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator](https://arxiv.org/abs/2512.04917)
*Matteo Masoni,Vincenzo Palermo,Marco Gabiccini,Martino Gulisano,Giorgio Previati,Massimiliano Gobbi,Francesco Comolli,Gianpiero Mastinu,Massimo Guiggiani*

Main category: cs.RO

TL;DR: 研究比较了三种扰动感知的鲁棒参考轨迹与无参考基准在驾驶模拟器中的表现，发现摩擦极限鲁棒轨迹(FLC)能在小幅增加圈速的情况下显著降低转向负荷，达到接近帕累托最优的平衡。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索扰动感知、鲁棒性嵌入的参考轨迹如何影响专业驾驶员在动态模拟器中的驾驶表现，特别是圈速与转向负荷之间的权衡关系。

Method: 比较三种参考轨迹：名义时间最优轨迹(NOM)、轨道极限鲁棒轨迹(TLC)和摩擦极限鲁棒轨迹(FLC)，以及无参考基准(NOREF)。所有轨迹基于作者先前提出的扰动感知最小圈速框架，通过传播最坏情况扰动增长来收紧轮胎摩擦和轨道极限约束。由两名专业驾驶员在虚拟赛道上使用高性能车辆进行评估。

Result: 结果显示帕累托式的圈速-转向负荷权衡：NOM获得最短圈速但转向负荷最高；TLC最小化转向负荷但圈速较长；FLC接近效率前沿，相对于NOM显著降低转向负荷而仅小幅增加圈速。无参考轨迹时圈速和转向负荷均增加。

Conclusion: 参考轨迹特别是扰动感知规划能有效提升驾驶表现，FLC轨迹在保持快速的同时提供稳定控制，是训练和实现快速稳定轨迹的有效工具。

Abstract: This work investigates how disturbance-aware, robustness-embedded reference trajectories translate into driving performance when executed by professional drivers in a dynamic simulator. Three planned reference trajectories are compared against a free-driving baseline (NOREF) to assess trade-offs between lap time (LT) and steering effort (SE): NOM, the nominal time-optimal trajectory; TLC, a track-limit-robust trajectory obtained by tightening margins to the track edges; and FLC, a friction-limit-robust trajectory obtained by tightening against axle and tire saturation. All trajectories share the same minimum lap-time objective with a small steering-smoothness regularizer and are evaluated by two professional drivers using a high-performance car on a virtual track. The trajectories derive from a disturbance-aware minimum-lap-time framework recently proposed by the authors, where worst-case disturbance growth is propagated over a finite horizon and used to tighten tire-friction and track-limit constraints, preserving performance while providing probabilistic safety margins. LT and SE are used as performance indicators, while RMS lateral deviation, speed error, and drift angle characterize driving style. Results show a Pareto-like LT-SE trade-off: NOM yields the shortest LT but highest SE; TLC minimizes SE at the cost of longer LT; FLC lies near the efficient frontier, substantially reducing SE relative to NOM with only a small LT increase. Removing trajectory guidance (NOREF) increases both LT and SE, confirming that reference trajectories improve pace and control efficiency. Overall, the findings highlight reference-based and disturbance-aware planning, especially FLC, as effective tools for training and for achieving fast yet stable trajectories.

</details>


### [18] [Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies](https://arxiv.org/abs/2512.04960)
*Jonne Van Haastregt,Bastian Orthmann,Michael C. Welle,Yuchong Zhang,Danica Kragic*

Main category: cs.RO

TL;DR: 提出Hybrid-Diffusion模型，结合开环例程和视觉运动扩散策略，通过Teleoperation Augmentation Primitives在演示中无缝执行预定义例程，并在真实世界任务中验证效果。


<details>
  <summary>Details</summary>
Motivation: 尽管基于模仿学习的视觉运动策略在复杂操作任务中表现良好，但通常难以达到传统控制方法的精度和速度。需要结合两者的优势来提升性能。

Method: 提出Hybrid-Diffusion模型，结合开环例程和视觉运动扩散策略。开发Teleoperation Augmentation Primitives（TAPs），允许操作者在演示过程中无缝执行预定义例程。模型在推理过程中学习触发这些TAPs。

Result: 在具有挑战性的真实世界任务中验证了方法：Vial Aspiration、Open-Container Liquid Transfer和容器拧开。实验视频可在项目网站上查看。

Conclusion: Hybrid-Diffusion方法成功结合了开环例程和视觉运动策略的优势，在真实世界操作任务中表现出色，为机器人操作提供了新的解决方案。

Abstract: Despite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project's website: https://hybriddiffusion.github.io/

</details>


### [19] [Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist](https://arxiv.org/abs/2512.04973)
*Giuseppe Milazzo,Manuel G. Catalano,Antonio Bicchi,Giorgio Grioli*

Main category: cs.RO

TL;DR: 本文提出了一种采用冗余弹性驱动的3自由度并联手腕，通过仅使用4个电机实现紧凑轻量化的变刚度设计，适用于假肢或人形机器人应用。


<details>
  <summary>Details</summary>
Motivation: 变刚度执行器在非结构化环境中对机器人应用很有价值，但传统设计往往导致结构更大更重。需要开发紧凑轻量的变刚度解决方案，特别是用于假肢和人形机器人等领域。

Method: 提出了一种3自由度并联手腕，采用冗余弹性驱动实现变刚度。利用并联架构仅使用4个电机，使设备紧凑轻量化。建立了设备理论模型，并提出独立调节关节位置和刚度的先进控制策略。

Result: 通过仿真验证了所提出的控制器，系统动力学综合分析显示设备能够在刚性配置下实现高精度和干扰抑制，同时在顺应行为下最小化交互力。

Conclusion: 该3自由度并联手腕通过冗余弹性驱动成功实现了紧凑轻量化的变刚度设计，验证的控制策略使其在刚性配置下具有高精度，在顺应行为下能最小化交互力，特别适合假肢和人形机器人应用。

Abstract: Variable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.

</details>


### [20] [Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness](https://arxiv.org/abs/2512.04998)
*Giuseppe Milazzo,Giorgio Grioli,Antonio Bicchi,Manuel G. Catalano*

Main category: cs.RO

TL;DR: 开发了一种带有可变刚度执行器的经肱骨假肢，通过模块化设计和弹性元件模拟生物关节的可控顺应性，提升假肢的自然运动和交互能力。


<details>
  <summary>Details</summary>
Motivation: 当前上肢假肢虽然增强了用户日常活动的独立性，但无法复制人类手臂的自然运动和交互能力。人类肢体利用内在顺应性和主动调节关节刚度，能够适应不同任务、吸收冲击并在动态动作中实现高效能量传递。

Method: 开发了带有可变刚度执行器（VSAs）的经肱骨假肢，采用模块化设计以适应不同残肢形状，并整合弹性元件被动支持自然运动、促进安全环境交互和适应多样化任务需求。

Result: 该假肢平台能够复制生物关节的可控顺应性，通过模块化设计实现个性化适配，弹性元件支持更自然的运动模式，并能够适应从用户生物信号中提取的各种独立控制信号。

Conclusion: 提出的可变刚度执行器假肢平台在假肢领域具有广阔应用前景，能够更好地模拟人类肢体的适应性特征，提升假肢使用者的生活质量和功能表现。

Abstract: Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users' biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.

</details>


### [21] [Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain](https://arxiv.org/abs/2512.05008)
*Haroon Hublikar*

Main category: cs.RO

TL;DR: 该论文提出了一个统一的建模与仿真框架，用于分析COBRA蛇形机器人在刚性、柔性和颗粒地形上的侧向蜿蜒和翻滚运动，结合了接触隐式建模、连续介质土壤模型和离散元方法，建立了分层仿真流程。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够分析蛇形机器人在多种复杂地形（刚性、柔性、颗粒状）上运动的统一仿真框架，以解决现有模型在软性和动态环境中运动预测不准确的问题，提升机器人在非结构化环境中的地形感知和鲁棒运动能力。

Method: 1. 使用接触隐式公式化建模侧向蜿蜒运动中的分布式摩擦相互作用；2. 通过MATLAB Simscape仿真和物理实验在刚性地面和松散沙地上验证；3. 集成Project Chrono的土壤接触模型(SCM)来捕捉地形变形效应；4. 使用Chrono DEM引擎模拟陡坡上高能翻滚运动的颗粒级相互作用；5. 建立分层仿真流程，涵盖实时控制导向仿真和高保真颗粒物理。

Result: 刚性地面模型能准确预测短期运动，但在软性和高度动态环境中，连续介质和基于颗粒的地形建模变得必要。SCM模型能预测滑移、下沉和载荷重新分布，降低步态效率；DEM模拟揭示了土壤失效、间歇性离地和能量耗散机制，这些是刚性模型无法捕捉的。

Conclusion: 该工作建立了一个分层仿真流程，推进了机器人在挑战性非结构化环境中鲁棒、地形感知的运动能力。框架能够根据地形特性选择合适的建模精度，为复杂环境中的机器人运动分析提供了系统化的解决方案。

Abstract: This thesis presents a unified modeling and simulation framework for analyzing sidewinding and tumbling locomotion of the COBRA snake robot across rigid, compliant, and granular terrains. A contact-implicit formulation is used to model distributed frictional interactions during sidewinding, and validated through MATLAB Simscape simulations and physical experiments on rigid ground and loose sand. To capture terrain deformation effects, Project Chrono's Soil Contact Model (SCM) is integrated with the articulated multibody dynamics, enabling prediction of slip, sinkage, and load redistribution that reduce stride efficiency on deformable substrates. For high-energy rolling locomotion on steep slopes, the Chrono DEM Engine is used to simulate particle-resolved granular interactions, revealing soil failure, intermittent lift-off, and energy dissipation mechanisms not captured by rigid models. Together, these methods span real-time control-oriented simulation and high-fidelity granular physics. Results demonstrate that rigid-ground models provide accurate short-horizon motion prediction, while continuum and particle-based terrain modeling becomes necessary for reliable mobility analysis in soft and highly dynamic environments. This work establishes a hierarchical simulation pipeline that advances robust, terrain-aware locomotion for robots operating in challenging unstructured settings.

</details>


### [22] [From Generated Human Videos to Physically Plausible Robot Trajectories](https://arxiv.org/abs/2512.05094)
*James Ni,Zekai Wang,Wei Lin,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik,Roei Herzig*

Main category: cs.RO

TL;DR: 提出GenMimic框架，通过两阶段流程让类人机器人零样本模仿生成视频中的人类动作，解决生成视频噪声和形态差异问题。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在合成人类动作方面进步迅速，有潜力作为机器人控制的高级规划器。但生成视频通常包含噪声和形态扭曲，使得类人机器人难以直接模仿真实视频中的动作。

Method: 1) 两阶段流程：先将视频像素提升为4D人体表示，然后重定向到类人机器人形态；2) 提出GenMimic策略：基于物理感知的强化学习策略，以3D关键点为条件，使用对称正则化和关键点加权跟踪奖励进行训练。

Result: 创建了GenMimicBench合成人体运动数据集，包含多种动作和场景。实验显示在模拟环境中优于强基线，并在Unitree G1类人机器人上实现了连贯、物理稳定的运动跟踪，无需微调。

Conclusion: 该工作为实现视频生成模型作为机器人控制高级策略的潜力提供了一条有前景的路径，能够零样本模仿生成视频中的人类动作。

Abstract: Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.

</details>


### [23] [STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](https://arxiv.org/abs/2512.05107)
*Feng Xu,Guangyao Zhai,Xin Kong,Tingzhong Fu,Daniel F. N. Gordon,Xueli An,Benjamin Busam*

Main category: cs.RO

TL;DR: 提出STARE模块，将长时程动作轨迹分解为语义阶段，提供密集、可解释的阶段对齐强化信号，结合TPO和PPO形成STA-TPO和STA-PPO，通过IPI微调流程提升VLA模型动作精度。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将长时程动作视为语言序列，采用轨迹级优化方法（如TPO、PPO），导致信用分配粗糙和训练不稳定。与语言不同，动作轨迹通过因果链阶段推进，各阶段学习难度不同，需要渐进式阶段优化。

Method: 提出STARE模块，将长时程动作轨迹分解为语义阶段，提供密集、可解释的阶段对齐强化信号。结合TPO形成STA-TPO用于离线阶段偏好优化，结合PPO形成STA-PPO用于在线阶段内交互。提出IPI（模仿->偏好->交互）串行微调流程。

Result: 在SimplerEnv和ManiSkill3实验中取得显著提升，达到最先进成功率：SimplerEnv上98.0%，ManiSkill3任务上96.4%。

Conclusion: STARE模块通过阶段分解和阶段对齐强化信号解决了长时程动作轨迹优化中的信用分配问题，STA-TPO和STA-PPO结合IPI微调流程显著提升了VLA模型的行动精度和训练稳定性。

Abstract: Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.

</details>
