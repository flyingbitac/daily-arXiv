<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 38]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 提出基于冲突的两阶段自动驾驶场景测试框架，先搜索冲突场景再突变产生碰撞，相比现有方法发现更多碰撞类型且效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统测试方法主要评估接近碰撞的场景，忽略了其他危险情况。需要更全面、高效的安全评估方法来发现更多潜在危险场景。

Method: 引入冲突作为中间搜索目标，提出两阶段测试框架：第一阶段搜索冲突场景，第二阶段通过突变冲突场景来诱导实际碰撞。

Result: 在百度Apollo上评估，单次运行发现12种不同碰撞类型，是现有基线方法发现多样性的两倍，同时通过冲突导向的突变减少了模拟次数。

Conclusion: 使用冲突作为中间目标能够扩大搜索范围，显著提高自动驾驶安全评估的效率和效果。

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [2] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 该论文对2015-2025年间XR（扩展现实）在社交机器人交互研究中的应用进行了系统性综述，发现该领域仍处于实验室模拟阶段，存在硬件软件报告不全、机器人互动性差、样本同质化等问题，并提出了五阶段发展路线图。


<details>
  <summary>Details</summary>
Motivation: 尽管XR技术在过去十年中作为人机交互研究工具受到关注，但在社交机器人实证研究中的应用仍未被充分探索。研究者希望通过系统性综述来描绘该领域现状，识别当前局限，并为建立可靠的社交XR-HRI研究媒介提供指导。

Method: 对2015-2025年间的6,527篇同行评审文章进行系统性综述，最终筛选出33篇符合严格纳入标准的研究。分析内容包括：(1) XR和虚拟社交机器人的使用方式和应用场景；(2) 数据收集和分析方法；(3) 研究者和参与者的人口统计学特征；(4) 研究挑战和未来议程。

Result: 研究发现：社交XR-HRI研究仍以实验室模拟为主，关键硬件、软件和机器人规格常未报告；机器人通常作为被动、低互动的视觉刺激；现代头戴式显示器的丰富生物信号和日志功能未被充分利用；研究团队和样本主要为技术中心、西方、年轻、男性群体，人口统计学报告存在空白；主要局限包括硬件延迟、样本小且同质、研究周期短且浅。

Conclusion: 提出了五阶段路线图来建立可靠的社交XR-HRI研究媒介：促进方法创新；通过应用场景增强生态效度；提高机器人交互质量；促进样本多样性；发展社交XR-HRI分类学。这些方向的发展对于XR从实验室原型转变为社交机器人研究的生态有效工具至关重要。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [3] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: ReasonNavi是一个受人类启发的导航框架，通过结合多模态大语言模型和确定性规划器，实现"先推理后行动"的范式，在无需微调的情况下显著提升零样本导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体主要依赖局部自我中心观察，缺乏全局预见性，导致探索效率低下。相比之下，人类使用地图进行规划：先全局推理，再局部行动。

Method: 将俯视图转换为离散推理空间（房间分割和候选目标节点采样），通过多阶段查询MLLM识别与指令最一致的候选目标，利用确定性动作规划器将选定路径点转换为可执行轨迹，同时使用预训练的目标检测器和分割器确保目标识别鲁棒性。

Result: 在三个导航任务中，ReasonNavi始终优于需要大量训练或复杂场景建模的先前方法，提供了可扩展、可解释且全局基础的解决方案。

Conclusion: ReasonNavi提供了一个统一的零样本导航框架，无需MLLM微调，避免了基于强化学习策略的脆弱性，并能随着基础模型的改进自然扩展，为具身导航提供了可扩展、可解释的解决方案。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page: https://reasonnavi.github.io/

</details>


### [4] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: MARVL通过微调视觉语言模型实现空间语义一致性，将任务分解为多阶段子任务，显著提升了机器人强化学习的样本效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前密集奖励函数主要依赖人工设计，这限制了强化学习的可扩展性和自动化。虽然视觉语言模型为奖励设计提供了有前景的路径，但原始的VLM奖励往往与任务进展不匹配，在空间定位和任务语义理解方面存在局限。

Method: MARVL通过微调VLM实现空间和语义一致性，将任务分解为多阶段子任务，并采用任务方向投影实现轨迹敏感性。

Result: 在Meta-World基准测试中，MARVL显著优于现有的VLM奖励方法，在稀疏奖励操作任务上表现出卓越的样本效率和鲁棒性。

Conclusion: MARVL通过改进VLM奖励设计，解决了传统VLM奖励在空间定位和任务语义理解方面的不足，为机器人强化学习的自动化奖励设计提供了有效解决方案。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [5] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种针对触觉-视觉-语言（TVL）模型在测试时分布偏移下的可靠性感知自适应框架，通过估计各模态可靠性来过滤不可靠样本、自适应融合特征并指导优化，显著提升了模型在模态异步偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中TVL模型部署时面临不可避免的测试时分布偏移，现有测试时自适应方法在单模态设置下提供过滤，但缺乏对异步跨模态偏移下模态可靠性的显式处理，当某些模态变得不可靠时表现脆弱。

Method: 提出可靠性感知框架：1）基于预测不确定性和基于扰动的响应估计各模态可靠性；2）使用共享可靠性信号：过滤不可靠测试样本、自适应融合触觉/视觉/语言特征、通过可靠性引导目标正则化测试时优化。

Result: 在TAG-C基准和额外TVL场景中，该方法持续优于强基线，在严重模态损坏下实现高达49.9%的准确率提升，证明了显式模态可靠性建模对鲁棒测试时自适应的重要性。

Conclusion: 显式建模模态可靠性对于TVL模型在异步跨模态偏移下的鲁棒测试时自适应至关重要，提出的可靠性感知框架能有效处理模态不可靠情况，显著提升模型性能。

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [6] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: Fly0框架通过解耦语义推理与几何规划来解决视觉语言导航中的语义理解与控制精度权衡问题，使用三阶段流程提升导航性能


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言导航方法面临语义理解与控制精度之间的权衡，多模态大语言模型作为低级控制器存在高延迟、轨迹振荡和几何基础薄弱导致的泛化能力差等问题

Method: 提出Fly0框架，采用三阶段流程：1) MLLM驱动模块将自然语言指令转换为2D像素坐标；2) 几何投影模块利用深度数据将目标定位到3D空间；3) 几何规划器生成无碰撞轨迹

Result: 在仿真和真实环境中的广泛实验表明，Fly0优于现有基准方法，在非结构化环境中将成功率提高20%以上，导航误差降低约50%，同时减少计算开销并提高系统稳定性

Conclusion: Fly0通过解耦语义推理与几何规划，解决了VLN中的关键挑战，实现了更高效、稳定的导航性能，即使在视觉接触丢失的情况下也能保持鲁棒性

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at https://github.com/xuzhenxing1/Fly0.

</details>


### [7] [FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution](https://arxiv.org/abs/2602.15882)
*Jingjing Fan,Yushan Liu,Shoujie Li,Botao Ren,Siyuan Li,Xiao-Ping Zhang,Wenbo Ding,Zhidong Deng*

Main category: cs.RO

TL;DR: FUTURE-VLA是一个统一架构，将长时程控制和未来预测重构为单一序列生成任务，通过双端效率范式实现实时预测，在保持单帧基线推理延迟的同时扩展16倍时空窗口。


<details>
  <summary>Details</summary>
Motivation: 当前通用视觉语言模型虽然支持长视频流的时空推理，但在机器人部署中受到长时程历史处理和高维未来预测的高延迟限制，需要解决实时性瓶颈。

Method: 采用双端效率范式：1）时间自适应压缩策略最大化时空信息密度，支持多视角历史输入；2）潜在空间自回归对齐可操作动态与可预览视觉前瞻；3）预测引导的人机交互机制通过交互执行门控实现动态验证。

Result: 在LIBERO上达到99.2%成功率，RoboTwin上75.4%，真实世界Piper平台78.0%，所有实验在保持单帧基线推理延迟的同时实现16倍时空窗口扩展。

Conclusion: FUTURE-VLA通过统一序列生成框架和双端效率设计，成功解决了机器人长时程控制与未来预测的实时性挑战，建立了新的最先进性能。

Abstract: General vision-language models increasingly support unified spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained by the prohibitive latency of processing long-horizon histories and generating high-dimensional future predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon control and future forecasting as a monolithic sequence-generation task. Adopting a dual-sided efficiency paradigm, FUTURE-VLA leverages a temporally adaptive compression strategy to maximize spatiotemporal information density, enabling the ingestion of extensive multi-view histories while maintaining constant inference latency. Simultaneously, it performs latent-space autoregression to align actionable dynamics with reviewable visual look-aheads in a single forward pass. These real-time predictive capabilities further enable a prediction-guided Human-In-the-Loop mechanism via interactive execution gating, allowing operators to dynamically validate behaviors based on interpretable future previews. Extensive evaluations demonstrate that FUTURE-VLA establishes new state-of-the-art performance, attaining success rates of 99.2% on LIBERO, 75.4% on RoboTwin, and 78.0% on a real-world Piper platform, all with a $16\times$ extended spatiotemporal window while maintaining the inference latency of a single-frame baseline.

</details>


### [8] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: 论文批评SLAM社区过度追求基准分数而忽视不确定性估计，导致系统几何准确但概率不一致且脆弱，呼吁将不确定性计算作为主要成功指标


<details>
  <summary>Details</summary>
Motivation: SLAM社区陷入"置信度陷阱"，过度关注基准测试分数而忽视了原则性的不确定性估计，导致系统虽然几何上准确，但在概率上不一致且脆弱

Method: 提出范式转变，将一致、实时的不确定性计算作为主要成功指标，而非仅仅追求几何精度

Result: 指出当前SLAM系统存在的问题：几何准确但概率不一致、脆弱，需要重新定义评估标准

Conclusion: SLAM社区需要进行范式转变，将不确定性估计提升到与几何精度同等重要的地位，建立更稳健可靠的系统

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [9] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种用于腹腔镜手术训练与评估的新型紧凑型四自由度运动跟踪设备（IMTD），该设备具有低成本、集成化设计，能够提供客观实时反馈，改善手术技能并缩短学习曲线。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术训练需要客观的性能评估工具，现有系统往往成本高、复杂，难以在训练环境中普及。需要开发一种能够准确跟踪手术器械运动、提供实时反馈且易于集成到标准训练设备中的低成本解决方案。

Method: 开发了IMTD设备，包括运动学设计、机械结构、仪器配置和原型制作。该系统专门针对腹腔镜训练环境设计，支持围绕固定运动中心的移动，并能无缝集成到标准箱式训练器中。通过将IMTD与运动捕捉系统（MoCap）进行比较，评估其跟踪手术器械角度和平移运动的准确性和可靠性。

Result: IMTD系统在跟踪手术手势方面表现出有效性，能够准确捕捉关键性能参数，包括精度、流畅性、速度和整体运动效率。系统具有低成本优势，集成化设计使其易于在训练室中部署和实施。

Conclusion: IMTD系统为腹腔镜手术训练提供了一种实用且易于获取的解决方案，通过提供客观的实时反馈，能够显著改善手术技能并缩短新手学习曲线。该系统还为未来手势评分算法和标准化训练协议的开发奠定了基础。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [10] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 提出一种用于脊柱手术钻孔的新型机械架构，基于改进的R-CUBE全平移机构，实现手术钻所需的3T2R运动


<details>
  <summary>Details</summary>
Motivation: 脊柱手术中需要在椎骨上钻孔以植入椎弓根螺钉，需要一种能够精确控制手术钻的机械系统

Method: 基于改进的全平移R-CUBE机构，增加旋转运动能力，构建三阶段机构（平移、传动、旋转），分别推导各阶段运动学和速度模型并组合，根据真实患者钻孔轨迹优化机构性能

Result: 设计出具有3T2R运动能力的机械架构，能够满足手术钻操作需求，并通过优化获得最佳运动学性能

Conclusion: 提出的新型机械架构适用于脊柱手术钻孔应用，通过改进R-CUBE机构实现所需的多自由度运动，优化后具有良好性能

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [11] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: NOMAD使用自博弈多智能体强化学习，仅需目标城市地图和元信息即可将自动驾驶策略适应到新城市，无需人工演示数据


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在新城市部署成本高、速度慢，主要瓶颈是需要收集大量人工演示轨迹来适应新城市的不同道路几何、交通规则和交互模式

Method: 提出NOMAD方法，基于自博弈多智能体强化学习，在目标城市地图构建的模拟器中进行策略适应，使用简单的奖励函数

Result: NOMAD显著提高了目标城市的任务成功率和轨迹真实性，展示了比数据密集型城市迁移方法更有效和可扩展的替代方案

Conclusion: 自博弈多智能体强化学习能够仅使用地图和元信息将驾驶策略适应到显著不同的目标城市，无需该城市的人工演示数据

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page: https://nomaddrive.github.io/

</details>


### [12] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 本文针对无人机在灾后废墟中定位幸存者时遇到的非视距传播问题，提出了AsymmetricHuberEKF方法，通过引入非负物理先验和不对称损失函数，解决了传统对称滤波器在非对称误差下的统计几何退化问题。


<details>
  <summary>Details</summary>
Motivation: 灾后废墟中无人机定位幸存者面临非视距传播的物理挑战，信号反射产生的非负测距偏差与现有基于对称损失函数的鲁棒估计器存在理论不匹配，导致统计几何退化现象，而数据驱动方法又受限于训练数据稀缺和仿真到现实的差距。

Method: 提出AsymmetricHuberEKF方法，通过推导的不对称损失函数显式地纳入非视距偏差的非负物理先验，并设计协同的主动感知策略获取必要的双边信息，在2D天底视角扫描场景中进行验证。

Result: 与对称基线方法相比，该方法显著加速了收敛速度，为数据稀缺和几何受限的搜索操作提供了有弹性的构建模块。

Conclusion: 解决统计几何退化问题不仅需要鲁棒滤波器，还需要特定的双边信息，通过物理基础的不对称损失函数和主动感知策略，可以有效应对灾后废墟中非对称误差的定位挑战。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [13] [VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation](https://arxiv.org/abs/2602.15899)
*Anna Gelencsér-Horváth,Gergely Dinya,Dorka Boglárka Erős,Péter Halász,Islam Muhammad Muqsit,Kristóf Karacs*

Main category: cs.RO

TL;DR: SceneVGGT是一个结合SLAM与语义映射的时空3D场景理解框架，用于自主和辅助导航。它通过滑动窗口管道扩展到长视频流，使用相机位姿变换对齐局部子地图，实现内存和速度高效的地图构建，同时保持几何一致性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理长视频流、内存高效且能保持几何一致性的3D场景理解框架，以支持自主和辅助导航应用，特别是为视障人士提供交互式辅助导航。

Method: 基于VGGT构建，采用滑动窗口管道处理长视频流；通过相机位姿变换对齐局部子地图；使用VGGT跟踪头将2D实例掩码提升到3D对象，保持时间一致的身份用于变化检测；将对象位置投影到估计的地板平面上进行辅助导航。

Result: GPU内存使用保持在17GB以下，不受输入序列长度影响；在ScanNet++基准测试中达到有竞争力的点云性能；能够支持带有音频反馈的交互式辅助导航。

Conclusion: SceneVGGT提供了一个稳健的语义识别框架，速度快到足以支持交互式辅助导航，为视障人士等应用场景提供了实用的解决方案。

Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

</details>


### [14] [Adaptive Illumination Control for Robot Perception](https://arxiv.org/abs/2602.15900)
*Yash Turkar,Shekoufeh Sadeghi,Karthik Dantu*

Main category: cs.RO

TL;DR: Lightning是一个用于视觉SLAM的闭环光照控制框架，通过重新照明、离线优化和模仿学习来优化机器人感知


<details>
  <summary>Details</summary>
Motivation: 在低光照或高动态范围条件下，机器人感知通常通过下游方法改进，但这些方法都受限于捕获的图像质量。可编程机载光源可以改善图像，但难以预测其对图像形成的影响

Method: 采用三阶段方法：1) 训练CLID重新照明模型分解环境光和光源贡献；2) 离线优化光照强度调度；3) 通过行为克隆将优化方案蒸馏为实时控制器

Result: Lightning显著提高了SLAM轨迹的鲁棒性，同时减少了不必要的照明功耗

Conclusion: 该框架通过智能光照控制有效改善了机器人视觉SLAM在挑战性光照条件下的性能

Abstract: Robot perception under low light or high dynamic range is usually improved downstream - via more robust feature extraction, image enhancement, or closed-loop exposure control. However, all of these approaches are limited by the image captured these conditions. An alternate approach is to utilize a programmable onboard light that adds to ambient illumination and improves captured images. However, it is not straightforward to predict its impact on image formation. Illumination interacts nonlinearly with depth, surface reflectance, and scene geometry. It can both reveal structure and induce failure modes such as specular highlights and saturation. We introduce Lightning, a closed-loop illumination-control framework for visual SLAM that combines relighting, offline optimization, and imitation learning. This is performed in three stages. First, we train a Co-Located Illumination Decomposition (CLID) relighting model that decomposes a robot observation into an ambient component and a light-contribution field. CLID enables physically consistent synthesis of the same scene under alternative light intensities and thereby creates dense multi-intensity training data without requiring us to repeatedly re-run trajectories. Second, using these synthesized candidates, we formulate an offline Optimal Intensity Schedule (OIS) problem that selects illumination levels over a sequence trading off SLAM-relevant image utility against power consumption and temporal smoothness. Third, we distill this ideal solution into a real-time controller through behavior cloning, producing an Illumination Control Policy (ILC) that generalizes beyond the initial training distribution and runs online on a mobile robot to command discrete light-intensity levels. Across our evaluation, Lightning substantially improves SLAM trajectory robustness while reducing unnecessary illumination power.

</details>


### [15] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 本文提出了一种面向自主帆船时空覆盖路径规划的框架，结合空间拓扑约束和时间预测规划，在非均匀时变海洋环境中实现高效可行的覆盖路径。


<details>
  <summary>Details</summary>
Motivation: 自主帆船适合长期海洋观测，但其性能具有高度各向异性，且受非均匀时变风场和流场影响，传统覆盖方法（如往复扫描）效果有限，现有规划方法在这些环境和机动约束下研究不足。

Method: 提出时空覆盖路径规划框架：1) 空间域采用基于拓扑的形态约束，促进紧凑连续覆盖；2) 时间域采用预测感知的前瞻规划，预测环境演变并实现有远见的决策。

Result: 在随机非均匀时变海洋环境（包括部分方向可达场景）的仿真中，该方法能生成高效可行的覆盖路径，而传统策略往往失败。

Conclusion: 该研究首次为自主帆船在非均匀时变海洋环境中的覆盖路径规划问题提供了专门解决方案，为未来多帆船协同覆盖奠定了基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [16] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: DreamZero是一个基于预训练视频扩散模型的世界动作模型，通过联合建模视频和动作学习物理动态，在未见任务和环境上比现有VLA模型有2倍以上的泛化提升，并能实现实时闭环控制和跨具身迁移。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉-语言-动作模型在语义泛化方面表现良好，但在新环境中面对未见物理运动时泛化能力不足。需要一种能够学习物理动态并实现更好泛化的模型。

Method: 基于预训练视频扩散主干构建世界动作模型，通过联合建模视频和动作来预测未来世界状态和动作，使用视频作为世界演化的密集表示。从异构机器人数据中学习多样化技能，无需重复演示。

Result: 在真实机器人实验中，相比最先进的VLA模型，在新任务和环境上的泛化能力提升超过2倍。通过模型和系统优化，使140亿参数的自回归视频扩散模型能够以7Hz频率进行实时闭环控制。跨具身迁移方面：仅使用其他机器人或人类的视频演示，在未见任务上获得超过42%的相对提升；仅需30分钟的玩耍数据即可适应新具身，同时保持零样本泛化能力。

Conclusion: DreamZero通过世界动作模型框架，在物理动态学习、任务泛化、实时控制和跨具身迁移方面取得了显著进展，为机器人学习提供了新的有效范式。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [17] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 本文针对机器人学中人类意图理解研究缺乏统一定义的问题，从心理学角度提出意图的多维度分类框架，并通过协作搜索和物体运输案例展示其重要性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人研究中人类意图理解缺乏统一定义，现有工作常将意图简单等同于任务相关目标，需要从心理学角度建立更全面的意图理解框架。

Method: 借鉴心理学和传播学理论，将意图分类为不同类型，建立可理解的框架；通过分析协作搜索和物体运输两个具体用例，展示如何将机器人研究对齐到这些意图类别。

Result: 提出了基于心理学的人类意图分类框架，为机器人研究从纯技术改进转向以人为中心的视角提供指导，展示了不同机器人研究如何与这些意图类别对应。

Conclusion: 考虑人类意图的多维度特性对机器人研究至关重要，提出的分类框架有助于建立更全面的人类意图理解，促进人机协作的发展。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [18] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: ODYN是一个新型的全位移原始-对偶非内点二次规划求解器，能高效处理稠密和稀疏QP问题，具有强大的热启动性能，适用于机器人、AI和控制应用。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够鲁棒处理病态和退化二次规划问题的求解器，无需约束线性独立性，特别适合机器人、AI和控制应用中常见的序列和实时设置。

Method: 结合全位移非线性互补问题函数和近端乘子法，采用非内点方法处理QP问题，避免了对约束线性独立性的要求。

Result: 在Maros-Mészáros测试集上展示了最先进的收敛性能，在小到大规模问题上表现优异，热启动能力突出，已成功应用于预测控制框架、深度学习优化层和接触动力学仿真。

Conclusion: ODYN是一个高效、鲁棒的QP求解器，特别适合需要热启动和实时性能的应用场景，在机器人、AI和控制领域具有重要实用价值。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [19] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 该研究分析了感知不确定性传播和校准对自动驾驶运动规划的影响，通过在nuPlan基准上比较两种不确定性传播方法，发现包含不确定性传播的方法在复杂闭环场景中表现更好。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要处理传感器数据中的不确定性，并将其纳入决策过程。虽然已有不确定性感知规划器，但它们对预测不确定性校准误差的敏感性尚未得到充分研究。

Method: 在nuPlan规划基准上比较两种具有不同不确定性传播水平的新型预测-规划流水线，使用闭环评估研究上游不确定性校准的影响。

Result: 包含上游不确定性传播的方法在复杂的闭环场景中表现出更好的泛化能力。

Conclusion: 感知不确定性传播对自动驾驶运动规划至关重要，包含不确定性传播的方法在真实世界复杂场景中具有更好的性能。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [20] [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073)
*Kevin Kai-Chun Chang,Ekin Beyazit,Alberto Sangiovanni-Vincentelli,Tichakorn Wongpiromsarn,Sanjit A. Seshia*

Main category: cs.RO

TL;DR: 提出了ScenicRules基准，用于在随机环境中评估自动驾驶系统，包含多目标优先级规范和形式化环境建模


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶评估基准缺乏多目标优先级规则与形式化环境模型的结合，而复杂交通环境中多个目标（如避撞、遵守规则、高效行驶）常存在优先级关系且需要上下文

Method: 1) 形式化多样化目标作为量化评估指标；2) 设计可解释、可适应的层次化规则书框架编码多目标及其优先级关系；3) 在Scenic语言中构建紧凑而具代表性的场景集合，涵盖多样化驾驶上下文和近事故情况

Result: 实验结果表明，形式化目标和层次化规则书与人类驾驶判断一致，且基准能有效暴露智能体在优先级目标方面的失败

Conclusion: ScenicRules基准填补了现有评估方法的空白，为自动驾驶系统在复杂交通环境中的多目标优先级规范评估提供了有效工具

Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.

</details>


### [21] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 提出了一种结合学习和模型的方法，通过调整内部抓取力来阻止多指机器人夹爪上的滑动，利用多模态触觉传感实现快速响应


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人抓取过程中物体滑动的问题，需要一种能够快速检测滑动并实时调整抓取力的方法，以实现稳定可靠的抓取

Method: 采用混合学习和模型方法，结合压电传感器快速检测滑动信号和压阻阵列进行接触定位，在线构建抓取矩阵，通过二次规划在抓取零空间中更新内部力

Result: 实现了35-40毫秒的理论传感到命令延迟，在受控试验中20毫秒检测到滑动起始，展示了在外部扰动下多指抓取的闭环稳定能力

Conclusion: 将高效的分析力控制与学习的触觉线索相结合，既实现了鲁棒性又获得了快速反应能力，为亚50毫秒闭环稳定提供了清晰的技术路径

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [22] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 提出基于广角摄像头的图像测量方法，用于测量托盘在相机坐标系中的俯仰倾斜角度，并简化相机坐标系与叉车坐标系之间的标定，实现AGF自动叉取托盘


<details>
  <summary>Details</summary>
Motivation: 为了实现AGF（自动导引叉车）自动将叉子插入托盘孔中，需要精确控制叉子的高度位置、伸出位置和倾斜角度，使其与托盘孔的位置和方向匹配。传统方法需要复杂的标定和控制，因此需要开发一种简化的图像测量方法。

Method: 提出两种图像测量方法：1）使用广角摄像头从图像中测量托盘在相机坐标系中的俯仰倾斜角度；2）简化相机坐标系与叉车坐标系之间的标定信息获取。实验中将广角摄像头固定在伸缩式叉车的靠背上，处理前方放置托盘的广角图像。

Result: 通过改变托盘的俯仰倾斜角度、托盘与叉子的相对高度以及托盘是否装载等条件，将图像测量值与手动测量值进行比较评估误差。结果确认误差在安全插入叉子的允许范围内。

Conclusion: 提出的图像测量方法能够有效测量托盘姿态并简化标定过程，误差控制在安全操作范围内，为实现AGF自动叉取托盘提供了可行的技术方案。

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [23] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出SIT-LMPC算法，结合信息论模型预测控制与归一化流学习，用于迭代任务中的安全高效控制


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂不确定环境中执行迭代任务时，需要平衡鲁棒性、安全性和高性能的控制策略。现有方法在处理非线性随机系统的约束优化问题时存在局限性。

Method: 基于信息论模型预测控制框架，设计自适应惩罚方法确保安全性；利用先前迭代轨迹通过归一化流学习价值函数，实现更丰富的非高斯不确定性建模；支持GPU并行执行实现实时优化。

Result: 基准仿真和硬件实验表明，SIT-LMPC能够迭代提升系统性能，同时鲁棒地满足系统约束条件。

Conclusion: SIT-LMPC为非线性随机系统的迭代控制任务提供了一种安全、高效的信息论学习模型预测控制解决方案。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [24] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出了一种用于非平面地形上自动驾驶车辆的非平面模型预测控制框架，通过几何感知建模学习残差高斯过程来近似复杂车辆动力学，使用递归稀疏GP实现实时适应，在自定义Isaac Sim环境中验证了在挑战性3D表面上保持高跟踪精度的能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在非平面地形上运行时，传统平面模型无法准确描述复杂车辆动力学，需要开发能够适应变化地形几何的实时控制框架。

Method: 提出非平面MPC框架，采用几何感知建模方法学习残差高斯过程来近似复杂车辆动力学，利用递归稀疏GP实现实时适应，结合模型预测路径积分控制器进行参考跟踪。

Result: 在自定义Isaac Sim环境中验证了框架的有效性，证明其能够在挑战性3D表面上保持高跟踪精度，实现了对变化地形几何的实时适应。

Conclusion: 该非平面MPC框架通过几何感知建模和递归稀疏GP学习，成功解决了自动驾驶车辆在非平面地形上的控制问题，实现了高精度的参考跟踪性能。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [25] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 提出基于深度学习6D姿态估计的无标记多机器人SLAM系统，解决传统基于标记方法在光照变化、视角差异下的局限性


<details>
  <summary>Details</summary>
Motivation: 传统多机器人SLAM系统在数据关联方面面临挑战：不同机器人间的回环检测容易受感知混淆和视角差异影响；直接相互观测通常依赖校准的基准标记阵列（如AprilTag），但这种方法观测范围有限，在强光照条件下（如反射或过曝）容易失效

Method: 利用深度学习6D姿态估计的最新进展，提出无标记姿态估计方法，并将其集成到去中心化多机器人SLAM系统中，通过深度学习实现机器人间的相对姿态估计

Result: 实验验证表明，该方法能提高机器人团队间的相对定位精度，在行星类似环境的测试场活动中进行了数据验证

Conclusion: 基于深度学习的无标记6D姿态估计为多机器人SLAM系统提供了有效的解决方案，克服了传统标记方法的局限性，提高了系统在复杂光照条件下的鲁棒性

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [26] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 提出一种基于安全强化学习的双四足机器人协同运输方法，通过约束马尔可夫博弈建模，采用成本优势分解和约束分配机制，在狭窄环境中实现安全高效的多机器人协作运输。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同运输在狭窄环境中面临挑战，因为可行区域极其有限，难以同时保证安全性和高性能的机器人间协作。现有方法在狭窄环境下难以平衡安全约束与任务性能。

Method: 1. 将任务建模为完全合作的约束马尔可夫博弈，将碰撞避免作为约束条件；2. 提出成本优势分解方法，确保团队约束总和低于上限，在强化学习框架内保证任务安全性；3. 设计约束分配方法，将共享约束分配给个体机器人以最大化整体任务奖励，促进机器人间的自主任务分配。

Result: 仿真和实时实验结果表明，相比现有方法，所提方法在双四足机器人协同运输任务中实现了更优的性能和更高的成功率。

Conclusion: 提出的安全强化学习方法有效解决了狭窄环境中多机器人协同运输的安全与性能平衡问题，通过约束分配机制促进了机器人间的自主协作，为复杂环境下的多机器人系统提供了可行的解决方案。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [27] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: MoMa-SG是一个构建语义-运动学3D场景图的新框架，能够从RGB-D序列中推断物体运动并估计铰接模型，支持机器人对日常环境中铰接物体的鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实环境中操作时面临关键限制：无法预测物体如何运动。长时程移动操作需要在语义、几何和运动学之间建立联系。

Method: 提出MoMa-SG框架：1）从包含多个物体铰接的RGB-D序列中，通过时间分割和遮挡鲁棒的点跟踪推断物体运动；2）将点轨迹提升到3D，使用统一的扭转估计公式同时估计旋转和棱柱关节参数；3）将物体与估计的铰接关联，并通过在识别的开启状态下推理父子关系检测包含的物体。

Result: 在两个数据集上广泛评估了MoMa-SG的性能，并消融了关键设计选择。真实世界实验表明，语义-运动学场景图能够在日常家庭环境中实现对铰接物体的鲁棒操作。

Conclusion: MoMa-SG通过构建语义-运动学3D场景图，成功将语义、几何和运动学联系起来，使机器人能够理解和操作日常环境中的铰接物体。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.

</details>


### [28] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 提出贝叶斯系统辨识框架，联合估计机器人状态轨迹和物理参数，通过硬约束、能量回归器和高效算法实现高精度辨识


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统辨识方法在联合估计状态轨迹和物理参数时精度不足，特别是在处理非线性摩擦效应、接触约束和动态一致性方面存在局限

Method: 1. 嵌入物理一致的反向动力学、接触和闭环约束作为硬等式约束；2. 使用能量回归器增强参数可观测性；3. 支持惯性参数和驱动参数的不等式先验；4. 强制动态一致的扰动投影；5. 结合本体感觉测量和能量观测；6. 开发参数化等式约束Riccati递归算法保持带状结构，实现线性时间复杂度

Result: 在代表性机器人系统仿真和Unitree B1+Z1机械臂硬件实验中，相比前向动力学和解耦辨识基线方法，收敛更快，惯性和摩擦估计误差更低，接触一致性更好；在模型预测控制中部署时，在挑战性环境下的运动跟踪性能有明显提升

Conclusion: 提出的贝叶斯系统辨识框架通过硬约束、能量回归器和高效算法，能够高精度联合估计机器人状态和物理参数，显著提升模型质量和控制性能

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [29] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 开发并部署了90米水深的水下驻留基础设施系统，使用带对接站的迷你级ROV，实现自主导航、对接和检查任务，验证了可靠的无缆深水操作可行性。


<details>
  <summary>Details</summary>
Motivation: 当前海洋观测方法受限于高昂成本和后勤困难，主要依赖稀疏的广域调查或固定位置的长期测量。需要能够在不依赖持续水面支持的情况下实现持久自主操作的监测系统。

Method: 开发并部署了90米水深的驻留基础设施系统，包括对接站和迷你级ROV。ROV配备增强的机载处理和感知能力，能够通过USBL信号自主导航，通过ArUco标记视觉定位（通过扩展卡尔曼滤波器融合）进行对接，并执行本地检查任务。

Result: 系统实现了90%的自主对接成功率，在四分钟内完成完整的检查任务，验证了在实际环境中声学和视觉导航的集成。结果表明可靠的、无缆的深水操作是可行的。

Conclusion: 驻留ROV系统展示了可扩展、经济高效的水下监测潜力，通过集成声学和视觉导航技术，实现了可靠的自主深水操作，为克服当前海洋观测限制提供了有效解决方案。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [30] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: SLOT是一种肌腱驱动的软四足机器人，使用3D打印TPU腿，仅用四个执行器研究顺应性腿式运动的物理建模与控制。


<details>
  <summary>Details</summary>
Motivation: 研究如何将连续体软腿集成到基于模型的运动控制中，开发可扩展、可重复使用的软四足机器人建模与控制方法。

Method: 采用离散Cosserat杆理论建模腿部为可变形连续体，引入模块化全身建模框架，将顺应性腿部动力学表示为施加在刚性躯干上的物理一致反作用力，并嵌入凸模型预测控制框架优化地面反作用力。

Result: 控制器在不同扰动下实现渐近稳定性，在物理原型上验证爬行和行走步态，质心轨迹RMSE小于5毫米，达到高精度。

Conclusion: 该框架展示了将连续体软腿集成到基于模型运动控制的通用方法，推进了软四足机器人可扩展和可重复使用的建模与控制技术。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [31] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 该论文提出了一种结合动态感知与反应式规划的机械臂运动生成方法，通过张量化粒子权重更新方案显式建模障碍物动态特性，并基于此提出障碍物感知的MPPI规划框架，在动态不确定环境中提升安全性和反应能力。


<details>
  <summary>Details</summary>
Motivation: 传统反应式运动生成方法通常基于静态感知和系统动力学，难以可靠地建模动态障碍物并在感知和控制不确定性下优化无碰撞轨迹。本文旨在从模型基础的角度揭示机械臂反应式规划与动态映射之间的紧密联系。

Method: 1) 提出张量化粒子权重更新方案，显式维护障碍物速度和协方差，实现具有表达性动态特性的高效粒子感知；2) 基于此动态表示，提出障碍物感知的MPPI规划框架，联合传播机器人-障碍物动力学，在不确定性下预测和评估未来系统运动。

Result: 模型预测方法显著提高了动态环境中的安全性和反应能力。在模拟和噪声真实环境中的完整框架应用表明，显式建模机器人-障碍物动力学相比现有最先进的MPPI感知规划基线，在避免多个静态和动态障碍物方面持续提升性能。

Conclusion: 通过显式建模机器人-障碍物动力学，结合动态感知与反应式规划的方法能够有效提升机械臂在动态非结构化场景中的运动生成性能，特别是在存在感知和控制不确定性的情况下。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [32] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 提出统一跌倒安全方法，通过特权教师-学生蒸馏框架实现跨复杂地形的零样本跌倒恢复


<details>
  <summary>Details</summary>
Motivation: 人形机器人在复杂环境中需要可靠的跌倒恢复能力，现有方法将跌倒安全分解为独立问题或依赖端到端策略，缺乏统一解决方案且泛化能力有限

Method: 基于两个关键洞察：1) 自然人类跌倒和恢复姿势高度受限且可通过对齐从平坦地形迁移到复杂地形；2) 快速全身反应需要集成感知-运动表征。使用稀疏人类演示训练特权教师模型，然后蒸馏到仅依赖自我中心深度和本体感知的可部署学生模型

Result: 在仿真和真实Unitree G1人形机器人上展示了跨多样非平坦环境的鲁棒、零样本跌倒安全能力，无需真实世界微调

Conclusion: 提出的统一跌倒安全方法通过集成感知-运动表征和特权蒸馏，实现了跨复杂地形的零样本泛化，为人形机器人在杂乱环境中的可靠操作提供了解决方案

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/

</details>


### [33] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的距离辅助定位和编队控制方法，通过块坐标下降进行定位，基于因子图的编队控制，无需全局定位系统或严格协调，在室内外实验中达到分米级精度。


<details>
  <summary>Details</summary>
Motivation: 集中式机器人团队控制方法扩展性差，且依赖全局定位系统可能不可用。需要一种去中心化的解决方案，使机器人仅依靠自身里程计和与其他机器人的距离测量就能实现定位和编队控制。

Method: 1. 使用块坐标下降方法进行距离辅助定位，无需机器人间的严格协调；2. 将编队控制问题建模为因子图上的推理问题，考虑状态估计不确定性；3. 完全去中心化的架构，每个机器人仅使用自身传感器数据和与其他机器人的距离测量。

Result: 方法在多种室内外环境中进行了真实实验验证，实现了分米级的定位和编队控制精度，无需特殊轨迹来维持编队，完全去中心化运行。

Conclusion: 提出的距离辅助去中心化定位和编队控制方法有效解决了机器人团队协调控制问题，不依赖全局定位系统，具有良好扩展性，在实际环境中表现出高精度和鲁棒性。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [34] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 该论文提出了一种通过求解半定规划问题来确定传感器参数（测量频率和噪声协方差）的方法，以实现特定的轨迹估计精度要求。


<details>
  <summary>Details</summary>
Motivation: 移动机器人轨迹估计的精度受传感器参数（测量频率和噪声协方差）影响，但实际应用中成本和资源限制了传感器性能。需要一种方法来计算达到特定估计精度所需的传感器参数。

Method: 将传感器参数估计问题（测量频率/调度和噪声协方差）建模为半定规划问题，可以使用现成的求解器进行求解。

Result: 通过仿真和真实实验验证，使用该方法计算的传感器调度和协方差能够达到期望的轨迹估计精度，并能识别出在给定系统和传感器特性下无法达到特定精度的情况。

Conclusion: 该方法为系统设计者提供了一种工具，可以在成本和资源约束下，确定实现特定轨迹估计精度所需的传感器参数，并识别不可行的精度要求。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [35] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 提出基于模板引导最优旋转的自主肾脏超声成像工作流，通过探索性成像定位肾脏后执行固定点旋转扫描，最小化探头移动，提高成像效率。


<details>
  <summary>Details</summary>
Motivation: 传统手持超声成像存在结果不一致、操作者依赖、缺乏3D定位信息等问题，而现有机器人超声系统缺乏确定最佳成像窗口的能力，导致扫描盲目、探头覆盖范围过大，造成声影和器官覆盖不全。

Method: 提出自主工作流：1）执行探索性成像获取肾脏部分观测数据；2）将数据配准到肾脏模板以估计器官位姿；3）机器人执行固定点旋转扫描，使成像平面与肾脏长轴对齐，最小化探头平移。

Result: 仿真结果表明60%探索比例在肾脏定位精度和扫描效率间达到最佳平衡。在两名男性受试者上的体内评估显示肾脏定位精度达7.36毫米和13.84度。最优旋转方法相比基线缩短探头覆盖范围约75毫米。

Conclusion: 该方法验证了利用解剖模板优化探头对齐进行体积扫描的可行性，通过最小化探头移动实现高效的肾脏成像。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [36] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: HERO：结合大视觉模型泛化能力与仿真训练控制性能的人形机器人物体定位操作新范式，通过残差感知末端执行器跟踪策略实现精确控制


<details>
  <summary>Details</summary>
Motivation: 现有基于真实世界模仿学习的方法由于难以收集大规模训练数据而泛化能力有限，需要一种能结合大视觉模型泛化能力和仿真训练控制性能的新方法

Method: 设计残差感知末端执行器跟踪策略，结合逆运动学、学习型神经前向模型、目标调整和重规划；构建模块化定位操作系统，利用开放词汇大视觉模型实现视觉泛化

Result: 末端执行器跟踪误差降低3.2倍；系统能在办公室、咖啡店等多样化真实环境中可靠操作各种日常物体（杯子、苹果、玩具等），支持43-92cm高度范围表面

Conclusion: HERO范式通过结合大视觉模型泛化能力和仿真训练控制性能，为人形机器人日常物体交互训练开辟了新途径

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [37] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: EgoScale框架利用大规模人类自我中心视频数据训练VLA模型，通过两阶段迁移方法实现灵巧机器人操作，性能提升54%


<details>
  <summary>Details</summary>
Motivation: 人类行为数据是学习物理智能的重要来源，但如何有效利用这些数据进行灵巧操作仍不清楚。现有方法在受限环境中实现了人机迁移，但大规模人类数据能否支持精细、高自由度的灵巧操作尚不明确。

Method: 提出EgoScale框架，基于20,854小时带动作标签的人类自我中心视频训练Vision Language Action模型，引入两阶段迁移方法：大规模人类预训练 + 轻量级人机对齐中训练

Result: 发现人类数据规模与验证损失之间存在对数线性缩放规律，验证损失与下游真实机器人性能强相关。最终策略在22自由度灵巧手上平均成功率提升54%，并能有效迁移到低自由度机器人

Conclusion: 大规模人类运动数据提供了可重用、与具体实现无关的运动先验知识，通过适当的迁移方法可以实现强大的长时程灵巧操作和一次性任务适应

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [38] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 提出了一种参数化规范表示方法，统一了多种灵巧手架构，实现了跨不同手部形态的零样本策略迁移。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧操作策略主要针对固定手部设计，难以泛化到具有不同运动学和结构布局的新手部形态。需要一种能够统一不同灵巧手架构的表示方法。

Method: 引入参数化规范表示，包括统一的参数空间和规范URDF格式。参数空间捕获形态和运动学变化，规范URDF标准化动作空间。训练VAE获得紧凑的潜在嵌入，开发基于规范表示的抓取策略。

Result: 通过抓取策略重放、VAE潜在编码和跨形态零样本迁移实验验证了方法的有效性。在未见过的3指LEAP手上实现了81.9%的零样本成功率，统一了结构多样化手的表示和动作空间。

Conclusion: 该框架为跨手学习提供了可扩展的基础，推动了通用灵巧操作的发展，能够实现从仿真到真实世界的跨形态策略迁移。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>
