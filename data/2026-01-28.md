<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [DeFM: Learning Foundation Representations from Depth for Robotics](https://arxiv.org/abs/2601.18923)
*Manthan Patel,Jonas Frey,Mayank Mittal,Fan Yang,Alexander Hansson,Amir Bar,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: DeFM是一个专门为机器人应用设计的自监督深度图像基础模型，通过60M深度图像训练，在多种深度感知任务上实现SOTA性能，并支持从仿真到真实环境的泛化。


<details>
  <summary>Details</summary>
Motivation: 深度传感器在机器人平台中广泛应用，但深度模态的表征学习相比RGB模态仍未被充分探索。当前RGB领域已有大规模基础模型，而深度模态缺乏类似的基础模型支持机器人应用。

Method: 采用DINO风格的自蒸馏目标，在60M深度图像数据集上训练；引入新颖的输入归一化策略以保持多尺度下的度量感知；将DeFM蒸馏为适合资源受限机器人系统的紧凑模型。

Result: 在深度图像分类、分割、导航、运动控制和操作等基准测试中达到最先进性能；展示了从仿真到真实环境的强大泛化能力；模型无需任务特定微调即可用于深度机器人学习。

Conclusion: DeFM填补了深度模态基础模型的空白，为机器人应用提供了强大的深度表征学习能力，支持开箱即用的深度机器人学习，并发布了所有预训练模型。

Abstract: Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/

</details>


### [2] [Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot](https://arxiv.org/abs/2601.18963)
*Fauna Robotics,:,Diego Aldarondo,Ana Pervan,Daniel Corbalan,Dave Petrillo,Bolun Dai,Aadhithya Iyer,Nina Mortensen,Erik Pearson,Sridhar Pandian Arunachalam,Emma Reznick,David Weis,Jacob Davison,Samuel Patterson,Tess Carella,Michael Suguitan,David Ye,Oswaldo Ferro,Nilesh Suriyarachchi,Spencer Ling,Erik Su,Daniel Giebisch,Peter Traver,Sam Fonseca,Mack Mor,Rohan Singh,Sertac Guven,Kangni Liu,Yaswanth Kumar Orru,Ashiq Rahman Anwar Batcha,Shruthi Ravindranath,Silky Arora,Hugo Ponte,Dez Hernandez,Utsav Chaudhary,Zack Walker,Michael Kelberman,Ivan Veloz,Christina Santa Lucia,Kat Casale,Helen Han,Michael Gromis,Michael Mignatti,Jason Reisman,Kelleher Guerin,Dario Narvaez,Christopher Anderson,Anthony Moschella,Robert Cochran,Josh Merel*

Main category: cs.RO

TL;DR: Sprout是一个专为人类环境安全部署设计的开发者平台，通过轻量级设计、合规控制和软外壳确保安全，集成了全身控制、抓取操作和VR遥操作，并具备社交交互能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人领域缺乏适合在人类环境中安全、长期部署的通用机器人控制器平台，现有的人形机器人要么是封闭的工业系统，要么是难以在人类周围部署和操作的学术原型，这限制了机器人技术的发展。

Method: Sprout采用轻量级外形设计，配备合规控制、有限关节扭矩和软外壳以确保安全；平台集成了全身控制、集成夹持器的操作和基于虚拟现实的遥操作；具备表达性的头部支持社交交互。

Result: Sprout平台通过降低物理和技术部署障碍，扩展了有能力的人形机器人平台的访问范围，为在真实人类环境中开发具身智能提供了实用基础。

Conclusion: Sprout作为一个开发者平台，通过强调安全性、表达性和开发者可访问性，解决了当前人形机器人在人类环境中部署的局限性，为机器人技术在现实世界中的应用提供了新途径。

Abstract: Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.

</details>


### [3] [A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System](https://arxiv.org/abs/2601.18971)
*Ioannis G. Polyzos,Konstantinos J. Kyriakopoulos*

Main category: cs.RO

TL;DR: 提出了一种切换非线性模型预测控制策略，用于水下车辆-机械臂系统的安全碰撞处理，包括避免碰撞或在不可避免时利用机械臂推离障碍物


<details>
  <summary>Details</summary>
Motivation: 水下自主车辆在执行干预任务时可能面临与障碍物碰撞的风险，需要安全处理碰撞情况，特别是在无法避免碰撞时如何最小化损害

Method: 采用切换非线性模型预测控制策略，当检测到碰撞风险时，控制算法利用机械臂推离障碍物以偏转碰撞轨迹

Result: 虚拟实验表明该算法能够成功检测碰撞，并能有效避免碰撞或在必要时利用机械臂适当处理碰撞而不损坏车辆的敏感区域

Conclusion: 提出的切换NMPC策略为水下车辆-机械臂系统提供了一种有效的碰撞处理方案，增强了水下自主干预任务的安全性

Abstract: For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.

</details>


### [4] [Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing](https://arxiv.org/abs/2601.19079)
*Naqash Afzal,Niklas Funk,Erik Helmut,Jan Peters,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出基于神经形态事件触觉传感器的连续盲文识别系统，实现高精度实时识别，模拟人类手指滑动扫描策略


<details>
  <summary>Details</summary>
Motivation: 传统盲文阅读器采用逐字符离散扫描，速度慢且不自然；基于视觉的方法计算量大、延迟高、在真实环境中性能下降。需要一种更自然、高效、鲁棒的盲文识别方案

Method: 使用开源神经形态事件触觉传感器Evetac，结合时空分割和轻量级ResNet分类器处理稀疏事件流，模拟人类手指连续滑动扫描策略

Result: 在标准深度下达到接近完美准确率（≥98%），适应多种盲文板布局，在快速扫描下保持强性能。在实际盲文板上获得超过90%的单词级准确率，对时间压缩效应具有鲁棒性

Conclusion: 神经形态触觉感知为机器人盲文阅读提供了可扩展、低延迟的解决方案，对辅助技术和机器人应用中的触觉感知具有更广泛意义

Abstract: Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.

</details>


### [5] [SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers](https://arxiv.org/abs/2601.19098)
*Kurt Enkera,Josh Pinskier,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: SimTO框架通过从物理模拟器中自动提取接触力载荷，实现针对特征丰富物体的高分辨率拓扑优化软体夹持器设计


<details>
  <summary>Details</summary>
Motivation: 现有软体夹持器难以抓取具有高拓扑变异性的特征丰富物体（如齿轮、珊瑚、西兰花等），这些物体缺乏明确的"最优"接触表面，传统拓扑优化方法需要预先定义载荷工况，而软体夹持器与特征丰富物体交互时会产生数百种不可预测的接触力

Method: 提出SimTO框架，通过从接触式物理模拟器中自动提取载荷工况，消除手动载荷规范的需求，实现高分辨率拓扑优化，为任意特征丰富物体生成高度定制的软体夹持器

Result: 数值结果表明，SimTO设计的夹持器不仅对特征丰富物体具有高度专一性，还能泛化到未见过的物体

Conclusion: SimTO框架通过自动载荷提取解决了传统拓扑优化在软体夹持器设计中的局限性，能够为特征丰富物体生成具有精细形态特征的定制化软体夹持器

Abstract: Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear "optimal" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.

</details>


### [6] [Agree to Disagree: Consensus-Free Flocking under Constraints](https://arxiv.org/abs/2601.19119)
*Peter Travis Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 论文提出了一种改进的群集控制方法，允许智能体协商不同的期望距离参数，无需全局信息或通信，适用于目标部分对齐或冲突的半信任场景。


<details>
  <summary>Details</summary>
Motivation: 传统群集控制假设智能体具有统一的期望距离，但实际应用中智能体类型和配置多样化，且常在没有信任保证或安全通信的环境下运行，需要更灵活的方法处理部分对齐或冲突的目标。

Method: 通过引入一种新的约束集体势函数，允许智能体协商距离参数和约束。该方法仅通过局部观测实现，无需全局信息或智能体间通信，继承了传统群集控制框架的特点。

Result: 通过一系列仿真验证了方法的有效性，表明该方法能够处理相邻智能体追求冲突目标的半信任场景，实现了灵活的群集协调。

Conclusion: 该方法扩展了传统群集控制框架，通过参数协商机制增强了多智能体系统在多样化配置和半信任环境下的适应性和鲁棒性。

Abstract: Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.

</details>


### [7] [Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity](https://arxiv.org/abs/2601.19144)
*Tzvika Geft,William Zhang,Jingjin Yu,Kostas Bekris*

Main category: cs.RO

TL;DR: 提出一个框架，用于在不确定性下提高自动化存储系统的运行效率，通过分析k-有界扰动下的存储布局优化，显著减少货物重新定位次数。


<details>
  <summary>Details</summary>
Motivation: 在物流应用中（如最后一公里配送中心和船厂），自动化存储系统需要在存储和检索序列不同的情况下高效运行。虽然已有研究保证在已知序列下可实现零重新定位，但实际中检索序列可能在存储后发生变化，需要处理这种不确定性。

Method: 研究k-有界扰动模型，其中任意两个货物如果原始位置最多相差k个位置，则可能无序离开。证明Θ(k)网格宽度对于消除最大容量下的重新定位是必要且充分的。提供高效求解器计算对此类扰动鲁棒的存储布局，并为超出k的更高不确定性情况引入最小化重新定位的策略。

Result: 实验表明，当k达到网格宽度一半时，提出的存储-检索框架基本消除重新定位；当k达到完整网格宽度时，重新定位减少50%以上。

Conclusion: 该框架通过分析k-有界扰动下的存储布局优化，显著提高了自动化存储系统在不确定性下的运行效率，为实际物流应用提供了有效的解决方案。

Abstract: This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $Θ(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\%+$.

</details>


### [8] [Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist](https://arxiv.org/abs/2601.19275)
*Tatsuya Kamijo,Mai Nishimura,Cristian C. Beltran-Hernandez,Nodoka Shibasaki,Masashi Hamaya*

Main category: cs.RO

TL;DR: 提出Tactile Memory with Soft Robot (TaMeSo-bot)系统，通过软手腕和触觉检索控制实现安全鲁棒操作，核心是Masked Tactile Trajectory Transformer (MAT³)模型，在真实机器人实验中验证了其在多样化peg-in-hole任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 触觉记忆对于接触丰富的任务（如不确定条件下的钥匙插入）至关重要，需要复制这种能力以实现安全且鲁棒的机器人操作。

Method: 集成软手腕进行安全接触探索，通过触觉记忆重用过去演示，核心是MAT³模型，通过掩码标记预测联合建模机器人动作、分布式触觉反馈、力扭矩测量和本体感觉信号之间的时空交互。

Result: 在真实机器人peg-in-hole任务实验中，MAT³在所有条件下都比基线方法获得更高的成功率，并展现出对未见过的peg和条件的显著适应能力。

Conclusion: TaMeSo-bot系统通过软手腕和触觉检索控制实现了安全鲁棒的操作，MAT³模型能够学习丰富的时空表示并自主提取任务相关特征，在多样化操作任务中表现出优越性能。

Abstract: Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.

</details>


### [9] [Teaching Machine Learning Fundamentals with LEGO Robotics](https://arxiv.org/abs/2601.19376)
*Viacheslav Sydora,Guner Dilsad Er,Michael Muehlebach*

Main category: cs.RO

TL;DR: 基于网页的平台"Machine Learning with Bricks"通过无编程的机器人活动向12-17岁学生教授机器学习概念，结合乐高机器人和可视化交互，显著提升了学生的理解和兴趣。


<details>
  <summary>Details</summary>
Motivation: 让年轻学习者（12-17岁）能够接触和理解机器学习概念，通过无编程、可视化的方式降低学习门槛，同时保持技术深度，激发学生对AI的兴趣。

Method: 开发了开源网页平台，结合乐高机器人和交互式可视化，教授KNN、线性回归和Q-learning三种核心算法。学生通过收集数据、训练模型和与机器人交互来学习，无需编程。

Result: 对14名学生的前后测调查显示：机器学习概念理解显著提升，对AI的认知态度积极转变，平台可用性高，学习动机增强。证明了可视化实物方法对年轻学习者的有效性。

Conclusion: 可视化实物方法能够有效向年轻学习者传授机器学习概念，既保持技术深度又具吸引力。平台开源免费，配有视频教程，为青少年AI教育提供了实用工具。

Abstract: This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.

</details>


### [10] [Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing](https://arxiv.org/abs/2601.19388)
*Yimin Tang,Sven Koenig,Erdem Bıyık*

Main category: cs.RO

TL;DR: Judgelight是一种后优化方法，通过压缩智能体轨迹中的闭合子路径来减少冗余移动，提升多智能体路径规划解决方案的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型MAPF求解器虽然快速且可扩展，但生成的可行轨迹往往包含不必要的或振荡性移动，不适合实际部署。

Method: 提出Judgelight后优化方法，将轨迹优化形式化为MAPF-Collapse问题，证明其NP难性，并通过整数线性规划(ILP)实现精确优化。

Result: 实验结果显示Judgelight能持续降低约20%的解决方案成本，特别是对学习型求解器效果显著，产生更适合实际部署的轨迹。

Conclusion: Judgelight作为一种有效的后优化方法，能够显著提升MAPF解决方案的质量，使其更适合实际应用场景。

Abstract: Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization method that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.

</details>


### [11] [Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.19406)
*Kaipeng Fang,Weiqing Liang,Yuyang Li,Ji Zhang,Pengpeng Zeng,Lianli Gao,Jingkuan Song,Heng Tao Shen*

Main category: cs.RO

TL;DR: SimHum框架通过协同训练，从模拟机器人动作中提取运动学先验，从真实人类观察中提取视觉先验，解决模拟到真实视觉差距和人类到机器人具身差距问题，实现数据高效且可泛化的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 模拟数据和真实人类数据虽然能规避机器人数据收集的高成本，但分别存在模拟到真实的视觉差距和人类到机器人的具身差距，限制了策略在真实场景中的泛化能力。研究发现这两种数据源存在自然互补性：模拟提供机器人动作，人类数据提供真实世界观察。

Method: 提出SimHum协同训练框架，同时从模拟机器人动作中提取运动学先验，从真实人类观察中提取视觉先验。基于这两种互补先验，实现数据高效且可泛化的机器人操作。

Result: 在相同数据收集预算下，SimHum比基线方法性能提升高达40%；仅使用80个真实数据就能达到62.5%的OOD成功率，比仅使用真实数据的基线方法高出7.1倍。

Conclusion: 通过利用模拟数据和人类数据的互补性，SimHum框架能够有效解决机器人学习中的数据效率问题，实现更好的泛化性能，为机器人操作任务提供了一种高效的数据利用方法。

Abstract: Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\mathbf{40\%}$ under the same data collection budget, and achieves a $\mathbf{62.5\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\times$. Videos and additional information can be found at \href{https://kaipengfang.github.io/sim-and-human}{project website}.

</details>


### [12] [Task-Centric Policy Optimization from Misaligned Motion Priors](https://arxiv.org/abs/2601.19411)
*Ziang Zheng,Kai Feng,Yi Nie,Shentao Qin*

Main category: cs.RO

TL;DR: TCMP提出任务优先对抗模仿框架，将模仿作为条件正则化而非平等目标，在保持任务性能的同时获得自然运动风格


<details>
  <summary>Details</summary>
Motivation: 人形机器人控制中，人类演示数据常因具身差异、重定向误差和任务无关变化而次优或不对齐，导致单纯模仿降低任务性能；而仅依赖任务强化学习会产生不自然或不稳定运动

Method: 提出任务中心运动先验(TCMP)，任务优先对抗模仿框架，将模仿作为条件正则化器而非平等目标，仅在模仿信号与任务进展兼容时纳入，产生自适应、几何感知的更新

Result: 通过人形控制实验验证，在噪声演示下实现稳健任务性能并保持一致运动风格，提供梯度冲突和任务优先稳定点的理论分析

Conclusion: TCMP框架解决了对抗模仿学习中线性奖励混合的基本限制，通过任务优先方法在保持任务可行下降的同时抑制有害模仿，实现任务性能与自然运动的平衡

Abstract: Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing naïve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.

</details>


### [13] [Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots](https://arxiv.org/abs/2601.19496)
*Jie Gu,Hongrun Gao,Zhihao Xia,Yirun Sun,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: 提出了一种保证稳定连接的四边形模块化自重构机器人自重构规划算法，通过虚拟图表示构建可行连接/断开动作，并使用依赖反向树组织执行序列。


<details>
  <summary>Details</summary>
Motivation: 对于晶格型模块化自重构机器人，在重构过程中保持稳定连接对于物理可行性和部署能力至关重要。现有方法在保证连接稳定性方面存在不足。

Method: 1. 使用虚拟图表示构建可行的连接/断开动作；2. 通过依赖反向树（DRTree）组织这些动作形成有效的执行序列；3. 证明了对于任意包含7个或更多模块的配置对（不包括线性拓扑），存在满足运动特性的重构序列。

Result: 1. 与改进的BiRRT算法相比，该方法在效率和稳定性方面表现更优；2. 在物理机器人平台上部署验证了其实际可行性；3. 算法能够保证重构过程中的连接稳定性。

Conclusion: 该算法为四边形模块化自重构机器人提供了一种有效的自重构规划方法，能够保证重构过程中的连接稳定性，具有较高的效率和实际应用价值。

Abstract: For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.

</details>


### [14] [Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots](https://arxiv.org/abs/2601.19499)
*Mehdi Heydari Shahna,Seyed Adel Alizadeh Kolagar,Jouni Mattila*

Main category: cs.RO

TL;DR: 该论文提出了一种结合强化学习和李雅普诺夫稳定器的控制框架，为轮式移动机器人在非结构化环境中提供形式化的目标到达保证，将目标到达率从84.6%提升到99.0%。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能有效学习目标到达策略，但缺乏形式化保证目标一定能到达。现有的屏蔽机制虽然能提供安全约束，但容易导致学习过程过于保守，影响探索效率。

Method: 1. 设计实时RL策略，包含15个精心定义的奖励项，鼓励机器人到达静态和动态目标，同时生成平滑的控制信号并满足安全规范；2. 在基准RL框架中集成李雅普诺夫类稳定器作为策略监督器，在保持状态动作空间有意义探索的同时，形式化加强目标到达控制。

Result: 实验结果表明，提出的李雅普诺夫类稳定器持续改进了基准RL策略，将目标到达率从84.6%提升到99.0%，显著减少了失败率，并提高了效率。

Conclusion: 该框架适合在挑战性环境中实时部署，提供了到达预期目标状态的形式化保证，通过基于当前状态生成实时控制信号来补偿不确定性，同时尊重实际运动约束。

Abstract: Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.

</details>


### [15] [A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation](https://arxiv.org/abs/2601.19509)
*Jin Huang,Zichen Liu,Haoda Li,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 该论文针对水下SINS/DVL组合导航系统，提出两种改进方法：1) 包含姿态误差的DVL速度转换模型；2) 基于协方差矩阵的方差传播方法。联合应用可显著抑制长期误差发散。


<details>
  <summary>Details</summary>
Motivation: 传统SINS/DVL松耦合架构使用SINS推导的姿态将DVL速度从机体坐标系转换到导航坐标系，但累积的姿态估计误差会在速度投影中引入偏差，导致长期导航性能下降。

Method: 1) 建立包含姿态误差项的车辆姿态误差感知DVL速度转换模型，减少投影引起的速度偏差；2) 开发基于协方差矩阵的方差传播方法，通过期望姿态误差补偿项实现统计一致的噪声建模。

Result: 仿真和现场实验表明：两种改进分别提升导航精度；累积姿态误差同时影响投影速度测量及其不确定性；联合应用有效抑制长期误差发散。现场实验显示，相比基线IMU+DVL方法，3D位置RMSE提升78.3%，最大分量位置误差减少71.8%。

Conclusion: 提出的方法通过姿态误差感知的速度转换和统计一致的噪声建模，显著改善长期SINS/DVL导航性能，为水下导航系统提供了鲁棒的解决方案。

Abstract: In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.

</details>


### [16] [PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment](https://arxiv.org/abs/2601.19514)
*Ruiyu Wang,Zheyu Zhuang,Danica Kragic,Florian T. Pokorny*

Main category: cs.RO

TL;DR: PALM通过利用局部动作分布在OOD和演示域之间的不变性，同时处理工作空间偏移、视角变化和跨具身转移等OOD问题，无需额外输入模态、模型修改或数据收集。


<details>
  <summary>Details</summary>
Motivation: 基于图像的行为克隆在训练域外的泛化能力仍然具有挑战性。现有方法通常单独处理各个泛化轴（工作空间偏移、视角变化、跨具身转移），且依赖复杂流程，缺乏统一解决方案。

Method: PALM将操作策略模块化为粗粒度全局组件和细粒度局部策略。通过强制局部视觉聚焦和一致的本体感知表示，减少域内和OOD输入在局部策略层面的差异，使策略能在OOD条件下检索不变的局部动作。

Result: 实验显示PALM将OOD性能下降限制在模拟环境中8%、现实世界中24%，而基线方法分别为45%和77%。

Conclusion: PALM通过利用局部动作分布的不变性，有效解决了多种OOD偏移问题，显著提升了基于图像的行为克隆在训练域外的泛化能力。

Abstract: Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.

</details>


### [17] [Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion](https://arxiv.org/abs/2601.19529)
*Jie Gu,Yirui Sun,Zhihao Xia,Tin Lun Lam,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: Rhombot是一种新型可变形平面晶格模块化自重构机器人，采用菱形模块设计，通过单个中央执行器实现沿对角线折叠/展开，旨在以最小控制复杂度实现变形、对接和运动等核心功能。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在不同环境中可靠形成各种配置的模块化自重构机器人系统，通过简化设计降低控制复杂度，实现连续稳定的重构过程，且不受周围介质影响。

Method: 设计菱形模块，采用平行四边形骨架和单个中央执行器实现沿对角线折叠；提出morphpivoting运动原语用于重构，并设计连续执行策略；通过物理实验验证系统性能。

Result: 物理实验验证了模块的稳定重构能力、位置精度和对接精度，系统能够可靠地在不同环境中形成各种配置。

Conclusion: Rhombot通过简化设计和创新运动原语，实现了以最小控制复杂度完成模块化自重构机器人的核心功能，为在不同环境中可靠运行提供了有效解决方案。

Abstract: In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.

</details>


### [18] [Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation](https://arxiv.org/abs/2601.19536)
*Hongji Liu,Linwei Zheng,Yongjian Li,Mingkai Tang,Xiaoyang Yan,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 提出低成本统一框架，利用增强逆透视映射进行矢量化道路制图，通过优化IPM矩阵和车辆位姿，实现近厘米级精度的自动高精度地图生成。


<details>
  <summary>Details</summary>
Motivation: 传统逆透视映射(IPM)在矢量化道路制图中存在映射误差、共面性假设限制等问题，需要低成本且能处理各种地面标记的统一解决方案。

Method: 使用Catmull-Rom样条表征车道线，多边形统一描绘其他地面标记；通过实例分割结果优化样条控制点和多边形角点的三维位置；同时优化IPM单应矩阵和车辆位姿。

Result: 框架显著减少IPM映射误差，提高IPM单应矩阵和车辆位姿预测精度；在两种实际场景中测试，能自动生成近厘米级精度的高精度地图；优化后的IPM矩阵达到人工校准精度水平。

Conclusion: 增强IPM框架为矢量化道路制图提供了低成本、高精度的解决方案，突破了传统IPM的共面性限制，能统一处理所有常见地面标记和车道线。

Abstract: In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.

</details>


### [19] [AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation](https://arxiv.org/abs/2601.19634)
*Wenda Yu,Tianshi Wang,Fengling Li,Jingjing Li,Lei Zhu*

Main category: cs.RO

TL;DR: AC²-VLA：一种基于动作上下文的自适应计算框架，通过认知重用、token剪枝和选择性执行来减少VLA模型在机器人操作中的计算开销，实现1.79倍加速和70.6%的FLOPs减少。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在机器人操作中表现出色，但闭环部署时存在高延迟和高计算成本问题。现有效率方法忽略了动作上下文的重要性，而VLA推理在时间、空间和深度维度上存在结构化冗余。

Method: 提出AC²-VLA框架，基于当前视觉观察、语言指令和先前动作状态来条件化计算。通过统一的机制自适应执行：1）跨时间步的认知重用；2）token剪枝；3）模型组件的选择性执行。采用动作引导的自蒸馏训练方案来保持密集VLA策略的行为。

Result: 在机器人操作基准测试中，AC²-VLA实现了高达1.79倍的加速，FLOPs减少到密集基线的29.4%，同时保持可比较的任务成功率。

Conclusion: AC²-VLA通过动作上下文感知的自适应计算，有效解决了VLA模型在机器人操作中的计算效率问题，实现了显著的加速和计算资源节省，为VLA模型的实时部署提供了可行方案。

Abstract: Vision-Language-Action (VLA) models have demonstrated strong performance in robotic manipulation, yet their closed-loop deployment is hindered by the high latency and compute cost of repeatedly running large vision-language backbones at every timestep. We observe that VLA inference exhibits structured redundancies across temporal, spatial, and depth dimensions, and that most existing efficiency methods ignore action context, despite its central role in embodied tasks. To address this gap, we propose Action-Context-aware Adaptive Computation for VLA models (AC^2-VLA), a unified framework that conditions computation on current visual observations, language instructions, and previous action states. Based on this action-centric context, AC^2-VLA adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components within a unified mechanism. To train the adaptive policy, we introduce an action-guided self-distillation scheme that preserves the behavior of the dense VLA policy while enabling structured sparsification that transfers across tasks and settings. Extensive experiments on robotic manipulation benchmarks show that AC^2-VLA achieves up to a 1.79\times speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success.

</details>


### [20] [Enhancing Worker Safety in Harbors Using Quadruped Robots](https://arxiv.org/abs/2601.19643)
*Zoe Betta,Davide Corongiu,Carmine Tommaso Recchiuto,Antonio Sgorbissa*

Main category: cs.RO

TL;DR: 该研究提出使用四足机器人进行港口基础设施检查的初步方案，包括识别关键区域和初步分析


<details>
  <summary>Details</summary>
Motivation: 基础设施检查对确保工人安全至关重要，港口环境复杂，日常操作存在挑战，需要机器人解决方案

Method: 1. 识别港口环境中的关键区域；2. 分析使用四足机器人检查这些关键区域的初步方案

Result: 提出了港口基础设施检查的初步框架，包括关键区域识别和四足机器人应用的可行性分析

Conclusion: 四足机器人在港口基础设施检查中具有应用潜力，为复杂环境下的机器人检查方案提供了初步探索

Abstract: Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.

</details>


### [21] [SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects](https://arxiv.org/abs/2601.19742)
*Ali Jnadi,Hadi Salloum,Yaroslav Kholodov,Alexander Gasnikov,Karam Almaghout*

Main category: cs.RO

TL;DR: SCOPE是一个快速高效的框架，用于建模和操作可变形线性物体，采用凸近似方法在保持物理合理性的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于能量的方法计算成本高，需要一种能够在保持物理合理性的同时实现实时或近实时响应的可变形线性物体建模方法。

Method: 采用凸近似方法替代传统的能量基方法，在速度和精度之间取得平衡，显著降低计算成本。

Result: 通过综合仿真实验验证了框架的有效性，能够生成满足几何和长度约束的平滑形状轨迹。

Conclusion: SCOPE框架在速度和精度之间取得了良好平衡，特别适用于需要实时或近实时响应的应用场景。

Abstract: We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.

</details>


### [22] [Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications](https://arxiv.org/abs/2601.19761)
*Jin Huang,Fethiye Irmak Doğan,Hatice Gunes*

Main category: cs.RO

TL;DR: 该论文提出将推荐系统技术整合到社交机器人中，以解决现有个性化方法的局限性，通过模块化组件增强用户偏好建模和个性化交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人个性化方法（如大语言模型和强化学习）无法全面捕捉用户偏好（包括长期、短期和细粒度方面），也不能有效利用这些偏好进行动作排序选择、主动个性化交互和确保伦理负责任的适应。

Method: 通过三个步骤整合推荐系统技术：(1) 对齐社交机器人与推荐系统的基本范式；(2) 识别能增强社交机器人个性化的关键技术；(3) 将这些技术设计为模块化、即插即用的组件。

Result: 建立了一个将推荐系统技术整合到社交机器人的框架，为推荐系统与人机交互社区之间的深度合作开辟了途径，加速两个领域的创新。

Conclusion: 推荐系统技术能够有效解决社交机器人个性化中的关键挑战，通过模块化整合方法为社交机器人提供更全面的用户偏好建模和个性化能力，促进跨学科合作与创新。

Abstract: Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.

</details>


### [23] [Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse](https://arxiv.org/abs/2601.19826)
*Fan Yang,Renkai Ma,Yaxin Hu,Lingyao Li*

Main category: cs.RO

TL;DR: 研究探讨机器人拟人化程度和道德基础如何影响人们对机器人虐待的反应，发现拟人化决定是否给予道德关怀，而道德基础影响关怀的推理方式。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，理解人们对机器人虐待的反应具有重要的伦理和设计意义。需要研究拟人化水平和道德基础如何塑造对机器人虐待的反应。

Method: 采用混合方法研究（N=201），参与者观看不同拟人化程度机器人（蜘蛛型、双足型、人形）被物理虐待的视频，完成道德基础、愤怒和社会距离测量，并进行定性分析。

Result: 拟人化程度决定人们是否将道德关怀扩展到机器人，而道德基础塑造他们如何推理这种关怀。低进步主义个体采用基于性格的判断，高进步主义个体进行面向未来的道德审议。

Conclusion: 研究结果为机器人设计和政策沟通提供了启示，表明需要考虑拟人化程度和道德基础在塑造人们对机器人虐待反应中的作用。

Abstract: As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.

</details>


### [24] [Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation](https://arxiv.org/abs/2601.19832)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种单次RGB视频演示生成双臂机器人执行计划的方法，通过信息流分析手部协调策略，生成模块化行为树


<details>
  <summary>Details</summary>
Motivation: 编程示教可以简化非专家的机器人编程过程，但双臂任务的采用因手部协调复杂性而研究不足，这阻碍了数据记录

Method: 应用香农信息论分析场景元素间的信息流，利用场景图属性检测手部协调策略，生成基于不同手臂协调需求的模块化行为树

Result: 通过多个主题视频演示验证了框架有效性，收集并开源了数据集，与现有方法比较显示在生成双臂系统集中执行计划方面有显著改进

Conclusion: 该方法能够从单次RGB视频演示中有效生成双臂机器人执行计划，解决了双臂任务编程示教中手部协调的挑战

Abstract: Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.

</details>


### [25] [HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs](https://arxiv.org/abs/2601.19839)
*Jeanne Malécot,Hamed Rahimi,Jeanne Cattoni,Marie Samson,Mouad Abrini,Mahdi Khoramshahi,Maribel Pino,Mohamed Chetouani*

Main category: cs.RO

TL;DR: HARMONI是一个基于大语言模型的多模态个性化框架，使社交辅助机器人能够在多用户环境中进行长期个性化交互，通过四个核心模块实现感知、世界建模、用户建模和响应生成。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互系统缺乏在多用户环境中持续个性化和动态适应的机制，限制了其在现实世界部署中的有效性，特别是在需要长期个性化交互的社交辅助场景中。

Method: HARMONI框架包含四个关键模块：1）感知模块识别活跃说话者并提取多模态输入；2）世界建模模块维护环境和短期对话上下文表示；3）用户建模模块更新长期说话者特定档案；4）生成模块产生上下文相关且符合伦理的响应。

Result: 通过在四个数据集上的广泛评估和消融研究，以及在养老院环境中的真实场景用户研究，HARMONI在说话者识别、在线记忆更新和伦理对齐个性化方面表现出色，在用户建模准确性、个性化质量和用户满意度方面优于基线LLM驱动方法。

Conclusion: HARMONI框架为社交辅助机器人提供了有效的多用户长期个性化交互能力，通过整合多模态感知、上下文建模和伦理约束，显著提升了人机交互系统的适应性和用户满意度。

Abstract: Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.

</details>


### [26] [Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability](https://arxiv.org/abs/2601.19856)
*Giulio Campagna,Marta Lagomarsino,Marta Lorenzini,Dimitrios Chrysostomou,Matthias Rehm,Arash Ajoudani*

Main category: cs.RO

TL;DR: 该研究提出了一个数据驱动框架，通过行为指标评估人机协作中的信任度，使用基于偏好的优化算法生成增强信任的轨迹，并在化工场景中验证了机器学习模型预测信任度的有效性。


<details>
  <summary>Details</summary>
Motivation: 工业5.0强调以人为中心的人机协作，需要确保安全、舒适和信任。然而，如何客观评估和增强人机协作中的信任水平是一个重要挑战，需要数据驱动的方法来量化信任指标。

Method: 研究提出数据驱动框架：1）使用基于偏好的优化算法根据操作员反馈生成信任增强轨迹；2）将操作员反馈作为真实标签训练机器学习模型；3）通过行为指标预测信任水平；4）在化工行业混合化学品的人机协作场景中进行测试。

Result: 机器学习模型在信任分类任务中达到超过80%的准确率，其中投票分类器获得84.07%的准确率和0.90的AUC-ROC分数，证明了行为指标在预测人机信任动态方面的有效性。

Conclusion: 数据驱动方法在评估人机协作信任方面具有显著效果，行为指标是预测人类信任动态的宝贵工具，为工业5.0环境下的人机协作信任管理提供了实用框架。

Abstract: Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\% accuracy, with the Voting Classifier achieving 84.07\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.

</details>
