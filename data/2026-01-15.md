<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fairness risk and its privacy-enabled solution in AI-driven robotic applications](https://arxiv.org/abs/2601.08953)
*Le Liu,Bangguo Yu,Nynke Vellinga,Ming Cao*

Main category: cs.RO

TL;DR: 论文提出了一种用于机器人决策的效用感知公平性度量方法，并分析了公平性与用户数据隐私之间的联合关系，建立了隐私预算控制公平性指标的框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI驱动的自主决策系统存在公平性隐患，而机器人应用中缺乏既考虑用户效用又考虑数据随机性的可实施公平性定义。同时，法律要求下大多数机器人系统需要保护用户隐私，需要探索隐私与公平性的关系。

Method: 提出效用感知的机器人决策公平性度量方法，分析公平性与用户数据隐私的联合关系，推导隐私预算控制公平性指标的条件，建立统一的形式化框架，并在机器人导航任务中进行测试验证。

Result: 研究发现隐私预算可以联合用于满足公平性目标，隐私保护机制能够同时促进公平性，这为在隐私约束下实现公平决策提供了理论基础。

Conclusion: 通过创造性结合隐私考量来解决公平性问题，是迈向AI伦理使用的重要一步，有助于增强日常环境中部署的自主机器人的信任度。

Abstract: Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.

</details>


### [2] [Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object](https://arxiv.org/abs/2601.09104)
*Ko Yamamoto,Kyosuke Ishibashi,Hiroki Ishikawa,Osamu Azami*

Main category: cs.RO

TL;DR: 开发液压驱动软体机器人抓手，用于抓取10-20公斤重物，相比气动方案能提供更大抓取力


<details>
  <summary>Details</summary>
Motivation: 现有气动软体抓手压力仅几百kPa，无法抓取10-20公斤重物；液压驱动可达几MPa压力，能产生更大功率

Method: 基于数学模型确定设计参数（压力、弯曲角度、物体质量、抓取力关系）；通过有限元分析选择合适材料；实现20公斤物体抓取和弯曲角度闭环控制

Result: 成功开发出液压驱动软体抓手，能够抓取20公斤物体，并实现手指弯曲角度的闭环控制

Conclusion: 液压驱动软体抓手设计方法有效，能够抓取传统气动软体抓手无法处理的大型重物

Abstract: This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle.

</details>


### [3] [CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space](https://arxiv.org/abs/2601.09163)
*Tong Wu,Shoujie Li,Junhao Gong,Changqing Guo,Xingting Li,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: CEI框架通过功能相似性度量和梯度优化实现不同机器人形态间的演示迁移，支持16种仿真和6种真实任务的双向策略转移。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型在大规模操作数据集上训练时，往往因数据集偏差而过度拟合特定视角、机械臂和平行夹爪，限制了跨形态的泛化能力。

Method: 提出Cross-Embodiment Interface (CEI)框架，引入功能相似性概念并使用方向性Chamfer距离量化，通过梯度优化对齐机器人轨迹，为未见过的机械臂和末端执行器合成观测和动作。

Result: 在仿真中将Franka Panda机器人的数据和策略迁移到16种不同形态，在真实世界中实现UR5+AG95与UR5+Xhand之间的6个任务双向迁移，平均迁移率达到82.4%。

Conclusion: CEI框架有效解决了机器人基础模型的形态过拟合问题，实现了跨不同机械臂和末端执行器的演示迁移，并可扩展到空间泛化和多模态运动生成能力。

Abstract: Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \CEI introduces the concept of \textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \CEI transfers data and policies from a Franka Panda robot to \textbf{16} different embodiments across \textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\%. Finally, we demonstrate that \CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/

</details>


### [4] [Vision-Conditioned Variational Bayesian Last Layer Dynamics Models](https://arxiv.org/abs/2601.09178)
*Paul Brunzema,Thomas Lew,Ray Zhang,Takeru Shirasawa,John Subosits,Marcus Greiff*

Main category: cs.RO

TL;DR: 提出了一种基于视觉条件的变分贝叶斯最后一层动力学模型，利用视觉上下文预测环境变化，应用于车辆赛车控制，在积水路面条件下显著优于无视觉条件的基线方法。


<details>
  <summary>Details</summary>
Motivation: 机器人系统的敏捷控制需要预测环境对系统行为的影响，传统建模方法难以捕捉系统行为的突变，而自适应方法本质上是反应式的，可能无法及时适应以确保安全。

Method: 提出视觉条件的变分贝叶斯最后一层动力学模型，先学习名义车辆动力学，然后通过潜在特征的逐特征仿射变换进行微调，实现上下文感知的动力学预测，并将该模型集成到最优控制器中。

Result: 在雷克萨斯LC500赛车通过积水路面的实验中，视觉条件模型在变化条件下完成了所有12次尝试的圈数，而无视觉上下文的基线方法全部失控，证明了在高性能应用中主动动力学适应的重要性。

Conclusion: 视觉条件的变分贝叶斯最后一层动力学模型能够有效预测环境变化，实现主动适应，在动态变化环境下显著提升机器人系统的控制性能和安全保障。

Abstract: Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.

</details>


### [5] [Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces](https://arxiv.org/abs/2601.09231)
*Shuoye Li,Zhiyuan Song,Yulin Li,Zhihai Bi,Jun Ma*

Main category: cs.RO

TL;DR: 提出使用多项式超曲面替代线性超平面进行轨迹优化中的碰撞避免，解决了凸近似在复杂环境中的保守性问题


<details>
  <summary>Details</summary>
Motivation: 现有基于线性超平面的轨迹优化方法需要将机器人和障碍物近似为凸集，这在杂乱狭窄环境中过于保守，限制了实际应用

Method: 1. 推广经典分离超平面定理，证明任意两个不相交的有界闭集都可用多项式超曲面分离；2. 构建非线性规划问题，联合优化机器人轨迹和分离多项式系数；3. 使用标准NLP求解器高效求解

Result: 仿真和真实世界实验表明，该方法在非凸机器人环境中实现了平滑、无碰撞、敏捷的机动，而基于凸近似的基线方法在这些环境中失败

Conclusion: 通过引入多项式超曲面分离，彻底消除了轨迹优化中碰撞避免的凸近似限制，为复杂环境中的几何感知碰撞避免提供了理论基础和实用方法

Abstract: An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail.

</details>


### [6] [Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report](https://arxiv.org/abs/2601.09318)
*Ro'i Lang,Elon Rimon*

Main category: cs.RO

TL;DR: 本文提出了一种用于3D工作空间中球形和圆柱形障碍物运动规划的导航函数构造方法，通过多项式隐函数编码障碍物，确保目标点存在唯一非退化最小值且无局部极小值。


<details>
  <summary>Details</summary>
Motivation: 在3D工作空间中进行运动规划时，需要处理球形和圆柱形障碍物，传统方法可能面临局部极小值问题。本文旨在构建能够保证全局收敛到目标的导航函数，即使在障碍物相互交叉的复杂环境中也能有效工作。

Method: 采用多项式导航函数方法，将工作空间建模为有界球形区域，使用光滑多项式隐函数编码球形和圆柱形障碍物。通过数学分析建立条件，确保导航函数在目标点存在唯一非退化最小值，同时避免局部极小值，包括在障碍物相互交叉的情况下。

Result: 理论分析表明所提出的导航函数在目标点具有唯一非退化最小值，能够避免局部极小值问题。提供了梯度和Hessian分析，并通过数值模拟在障碍物丰富的3D环境中验证了理论结果的有效性。

Conclusion: 本文成功构建了适用于3D工作空间中球形和圆柱形障碍物的多项式导航函数，该方法能够保证运动规划系统全局收敛到目标位置，即使在复杂障碍物配置下也能有效工作，为3D环境中的机器人导航提供了理论保证。

Abstract: This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments.

</details>


### [7] [ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving](https://arxiv.org/abs/2601.09377)
*Xuemei Yao,Xiao Yang,Jianbin Sun,Liuwei Xie,Xuebin Shao,Xiyu Fang,Hang Su,Kewei Yang*

Main category: cs.RO

TL;DR: ReflexDiffusion：一种通过反射调整增强扩散轨迹规划器的推理阶段框架，专门针对高横向加速度场景（如急转弯），通过梯度调整机制在去噪过程中放大关键条件信号，提高自动驾驶车辆在极限工况下的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划器在长尾场景（特别是高横向加速度的急转弯等关键安全场景）中存在系统性失败，主要原因是数据不平衡导致对车辆动力学、道路几何和环境约束的建模不足，当车辆接近物理极限时会产生次优或不安全的轨迹预测。

Method: 提出ReflexDiffusion框架，在扩散模型的迭代去噪过程中引入基于梯度的调整机制：在每次标准轨迹更新后，计算条件噪声预测和无条件噪声预测之间的梯度，显式放大关键条件信号（包括道路曲率和横向车辆动力学），从而在去噪过程中强制遵守物理约束。

Result: 在nuPlan Test14-hard基准测试中，ReflexDiffusion在高横向加速度场景下相比最先进方法实现了14.1%的驾驶分数提升，证明推理时轨迹优化可以有效补偿训练数据稀疏性，在接近操控极限时动态强化安全关键约束。

Conclusion: ReflexDiffusion提供了一种实用的解决方案，通过其架构无关的设计可以直接部署到现有的基于扩散的规划器中，有效提高自动驾驶车辆在挑战性驾驶条件下的安全性，特别是在高横向加速度的极限工况下。

Abstract: Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions.

</details>


### [8] [Data Scaling for Navigation in Unknown Environments](https://arxiv.org/abs/2601.09444)
*Lauri Suomela,Naoki Takahata,Sasanka Kuruppu Arachchige,Harry Edelman,Joni-Kristian Kämäräinen*

Main category: cs.RO

TL;DR: 大规模研究表明，数据多样性比数据量对视觉导航策略的零样本泛化能力更为关键，使用来自35个国家161个地点的4,565小时众包数据训练的策略，在未见过的环境中实现了接近特定环境训练的性能。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习导航策略在训练未见环境中泛化能力不足的问题，通过大规模研究探索数据量和数据多样性对端到端、无地图视觉导航在现实世界中泛化能力的影响。

Method: 收集来自35个国家161个地点的4,565小时众包数据集，训练点目标导航策略，在四个国家的侧道机器人上进行闭环控制性能评估，覆盖125公里自主驾驶，比较不同数据量和数据多样性配置下的性能。

Result: 大规模训练数据使策略能在未知环境中实现零样本导航，性能接近使用环境特定演示训练的策略。数据多样性比数据量更重要：训练集中地理位置数量翻倍可使导航错误减少约15%，而从现有位置添加数据的性能收益在数据量很少时就饱和。在噪声众包数据下，简单回归模型优于生成式和序列架构。

Conclusion: 数据多样性是实现视觉导航策略良好泛化能力的关键因素，大规模多样化数据集能够支持零样本导航，而简单回归模型在噪声众包数据下表现更优，为实际应用提供了实用指导。

Abstract: Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving.
  Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page.

</details>


### [9] [CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion](https://arxiv.org/abs/2601.09512)
*Ralf Römer,Yi Zhang,Angela P. Schoellig*

Main category: cs.RO

TL;DR: CLARE是一个参数高效的免示例持续学习框架，用于视觉-语言-动作模型，通过轻量级模块化适配器和自动编码器路由机制实现新任务学习而不遗忘旧知识。


<details>
  <summary>Details</summary>
Motivation: 现有机器人持续学习方法需要存储先前数据、难以处理长任务序列或依赖任务标识符部署，无法满足机器人在现实世界中长期运行的需求。

Method: CLARE在选定前馈层引入轻量级模块化适配器，基于层间特征相似性自主扩展模型；部署时使用基于自动编码器的路由机制动态激活最相关适配器，无需任务标签。

Result: 在LIBERO基准测试中，CLARE在新任务上实现高性能且不灾难性遗忘早期任务，显著优于基于示例的方法。

Conclusion: CLARE为视觉-语言-动作模型提供了一个通用、参数高效的免示例持续学习框架，解决了机器人长期运行中的知识保留与适应问题。

Abstract: To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.

</details>


### [10] [Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations](https://arxiv.org/abs/2601.09518)
*Wei-Jin Huang,Yue-Yi Zhang,Yi-Lin Wei,Zhi-Wei Xia,Juantao Tan,Yuan-Ming Li,Zhilin Zhao,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: PAIR+D-STAR：基于物理感知交互重定向和时空解耦推理的分层策略，从人类交互数据生成高质量人形机器人交互数据并学习复杂全身协作行为


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要与人类进行物理交互，但高质量的人-人形交互数据稀缺。虽然利用丰富的人-人交互数据是可行方案，但标准重定向方法会破坏关键接触点，而传统模仿学习策略仅模仿轨迹缺乏交互理解

Method: 提出两阶段框架：1) PAIR（物理感知交互重定向）- 基于接触中心的管道，跨形态差异保持接触语义，生成物理一致的人-人形交互数据；2) D-STAR（解耦时空动作推理器）- 分层策略，通过相位注意力（何时行动）和多尺度空间模块（何处行动）解耦时空推理，由扩散头融合生成超越模仿的同步全身行为

Result: 通过广泛严格的仿真验证，相比基线方法获得显著性能提升，展示了从人-人交互数据学习复杂全身交互的完整有效管道

Conclusion: PAIR和D-STAR共同构成了从丰富人-人交互数据学习复杂人-人形交互的有效解决方案，通过解耦时空推理实现了超越简单模仿的响应式同步协作

Abstract: Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.

</details>


### [11] [Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping](https://arxiv.org/abs/2601.09578)
*Jiajun Sun,Yangyi Ou,Haoyuan Zheng,Chao yang,Yue Ma*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的语义增强3D点云地图方法，通过融合可见光和红外图像，将热信息作为语义层添加到3D地图中，实现环境几何与热源语义的双重感知。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，自主机器人导航和环境感知对SLAM技术提出了更高要求。现有SLAM系统通常缺乏对环境的语义理解，特别是在需要识别热源目标（如火灾、设备故障）的应用场景中，传统方法无法提供温度相关的语义信息。

Method: 1. 首先在像素级别融合可见光和红外图像；2. 将实时LiDAR点云投影到融合后的图像流上；3. 在热通道中分割热源特征，实时识别高温目标；4. 将温度信息作为语义层应用到最终的3D地图中。

Result: 该方法生成的地图不仅具有精确的几何结构，还包含对环境的关键语义理解，能够实时识别高温目标并将温度信息整合到3D地图中。

Conclusion: 这种热信息语义增强的3D点云地图方法对于快速灾害评估和工业预防性维护等特定应用具有重要价值，为自主机器人提供了更丰富的环境感知能力。

Abstract: In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.

</details>
