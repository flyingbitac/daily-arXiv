<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Bridging Planning and Execution: Multi-Agent Path Finding Under Real-World Deadlines](https://arxiv.org/abs/2511.21886)
*Jingtian Yan,Shuai Zhou,Stephen F. Smith,Jiaoyang Li*

Main category: cs.RO

TL;DR: REMAP是一个执行感知的多智能体路径规划框架，通过ExecTimeNet准确估计执行时间，解决规划与执行之间的差距，在MAPF-RD问题上比基线方法提升20%的解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 传统的多智能体路径规划(MAPF)假设简化的机器人模型，忽略了执行时的动力学约束、通信延迟和控制器变异性等因素，导致规划与执行之间存在差距，这对时间敏感应用尤其成问题。

Method: 提出REMAP执行感知MAPF规划框架，结合ExecTimeNet准确估计执行时间，可轻松集成到主流搜索式MAPF规划器中。框架用于解决具有实时截止时间的MAPF-RD问题。

Result: 将REMAP与MAPF-LNS和CBS两种流行MAPF方法集成，在最多300个智能体的基准地图上，比基线方法（如恒定执行速度估计器）的解决方案质量提升高达20%。

Conclusion: REMAP框架有效弥合了MAPF规划与执行之间的差距，通过准确执行时间估计提高了时间敏感应用的解决方案质量，为实际部署提供了更可靠的规划方案。

Abstract: The Multi-Agent Path Finding (MAPF) problem aims to find collision-free paths for multiple agents while optimizing objectives such as the sum of costs or makespan. MAPF has wide applications in domains like automated warehouses, manufacturing systems, and airport logistics. However, most MAPF formulations assume a simplified robot model for planning, which overlooks execution-time factors such as kinodynamic constraints, communication latency, and controller variability. This gap between planning and execution is problematic for time-sensitive applications. To bridge this gap, we propose REMAP, an execution-informed MAPF planning framework that can be combined with leading search-based MAPF planners with minor changes. Our framework integrates the proposed ExecTimeNet to accurately estimate execution time based on planned paths. We demonstrate our method for solving MAPF with Real-world Deadlines (MAPF-RD) problem, where agents must reach their goals before a predefined wall-clock time. We integrate our framework with two popular MAPF methods, MAPF-LNS and CBS. Experiments show that REMAP achieves up to 20% improvement in solution quality over baseline methods (e.g., constant execution speed estimators) on benchmark maps with up to 300 agents.

</details>


### [2] [RSPECT: Robust and Scalable Planner for Energy-Aware Coordination of UAV-UGV Teams in Aerial Monitoring](https://arxiv.org/abs/2511.21957)
*Cahit Ikbal Er,Amin Kashiri,Yasin Yazicioglu*

Main category: cs.RO

TL;DR: 论文提出RSPECT算法，用于规划无人机和地面充电车的协同路径，在不确定性环境下实现鲁棒的长时程空中监测任务


<details>
  <summary>Details</summary>
Motivation: 无人机执行长时程监测任务时面临能量限制，需要地面充电车协同支持。同时，实际环境中存在未知障碍、地形、风力等不确定性因素，需要鲁棒的规划方案

Method: 将问题形式化为混合整数规划（MIP），提出RSPECT启发式算法。该算法具有可扩展性和高效性，能够处理NP-hard的复杂规划问题

Result: 提供了算法的复杂度理论分析，证明了生成计划的可行性和鲁棒性。通过仿真和实验验证了方法的性能表现

Conclusion: RSPECT算法能够有效解决无人机-地面车协同的鲁棒路径规划问题，在不确定性环境下实现最小时间完成任务，具有实际应用价值

Abstract: We consider the robust planning of energy-constrained unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), which act as mobile charging stations, to perform long-horizon aerial monitoring missions. More specifically, given a set of points to be visited by the UAVs and desired final positions of the UAV-UGV teams, the objective is to find a robust plan (the vehicle trajectories) that can be realized without a major revision in the face of uncertainty (e.g., unknown obstacles/terrain, wind) to complete this mission in minimum time. We provide a formal description of this problem as a mixed-integer program (MIP), which is NP-hard. Since exact solution methods are computationally intractable for such problems, we propose RSPECT, a scalable and efficient heuristic. We provide theoretical results on the complexity of our algorithm and the feasibility and robustness of resulting plans. We also demonstrate the performance of our method via simulations and experiments.

</details>


### [3] [Constant-Volume Deformation Manufacturing for Material-Efficient Shaping](https://arxiv.org/abs/2511.22042)
*Lei Li,Jiale Gong,Ziyang Li,Hong Wang*

Main category: cs.RO

TL;DR: 提出了一种体积保持的数字模具范式，通过实时体积一致性建模、几何信息变形预测和误差补偿策略，实现塑料材料的高度可预测成形，达到98%以上的材料利用率。


<details>
  <summary>Details</summary>
Motivation: 增材和减材制造虽然能实现复杂几何形状，但依赖于离散堆叠或局部去除，限制了连续可控变形，导致体积损失和形状偏差。需要一种能保持体积一致性的可持续、零浪费的成形方法。

Method: 提出体积保持的数字模具范式，集成实时体积一致性建模、几何信息变形预测和误差补偿策略。通过分析成形后点云的变形模式和误差趋势，校正弹性回弹和累积误差，保持体积一致性和表面连续性。

Result: 在五种代表性几何形状上的实验表明，该系统能够高保真地再现目标形状，同时实现超过98%的材料利用率。

Conclusion: 该方法为可持续、零浪费的用户自定义设计成形建立了数字化驱动、可重复的途径，连接了数字建模、实时传感和自适应成形，推动了下一代可持续和可定制制造的发展。

Abstract: Additive and subtractive manufacturing enable complex geometries but rely on discrete stacking or local removal, limiting continuous and controllable deformation and causing volume loss and shape deviations. We present a volumepreserving digital-mold paradigm that integrates real-time volume-consistency modeling with geometry-informed deformation prediction and an error-compensation strategy to achieve highly predictable shaping of plastic materials. By analyzing deformation patterns and error trends from post-formed point clouds, our method corrects elastic rebound and accumulation errors, maintaining volume consistency and surface continuity. Experiments on five representative geometries demonstrate that the system reproduces target shapes with high fidelity while achieving over 98% material utilization. This approach establishes a digitally driven, reproducible pathway for sustainable, zero-waste shaping of user-defined designs, bridging digital modeling, real-time sensing, and adaptive forming, and advancing next-generation sustainable and customizable manufacturing.

</details>


### [4] [SwordRiding: A Unified Navigation Framework for Quadrotors in Unknown Complex Environments via Online Guiding Vector Fields](https://arxiv.org/abs/2511.22043)
*Xuchen Liu,Ruocheng Li,Bin Xin,Weijia Yao,Qigeng Duan,Jinqiang Cui,Ben M. Chen,Jie Chen*

Main category: cs.RO

TL;DR: 提出基于引导向量场的四旋翼无人机实时导航框架，通过在线构建GVF实现未知复杂环境中的闭环导航，显著提升抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 现有四旋翼导航框架大多采用开环方式运行，难以应对环境不确定性（如风扰、外部扰动），在未知复杂环境中实时适应性不足。

Method: 基于机载感知构建ESDF环境表示，使用全局规划器生成离散无碰撞路径点，通过均匀B样条参数化生成平滑参考轨迹，然后从ESDF和优化B样条轨迹合成自适应引导向量场，实现闭环导航。

Result: 大量仿真和真实实验表明，该方法相比传统GVF方法能直接适应离散化路径，与标准规划算法兼容，在外部扰动下具有更强鲁棒性和优越的实时性能。

Conclusion: 该统一实时导航框架通过在线构建引导向量场，实现了四旋翼在未知复杂环境中的闭环导航，显著提升了系统在外部扰动下的鲁棒性和实时适应性。

Abstract: Although quadrotor navigation has achieved high performance in trajectory planning and control, real-time adaptability in unknown complex environments remains a core challenge. This difficulty mainly arises because most existing planning frameworks operate in an open-loop manner, making it hard to cope with environmental uncertainties such as wind disturbances or external perturbations. This paper presents a unified real-time navigation framework for quadrotors in unknown complex environments, based on the online construction of guiding vector fields (GVFs) from discrete reference path points. In the framework, onboard perception modules build a Euclidean Signed Distance Field (ESDF) representation of the environment, which enables obstacle awareness and path distance evaluation. The system first generates discrete, collision-free path points using a global planner, and then parameterizes them via uniform B-splines to produce a smooth and physically feasible reference trajectory. An adaptive GVF is then synthesized from the ESDF and the optimized B-spline trajectory. Unlike conventional approaches, the method adopts a closed-loop navigation paradigm, which significantly enhances robustness under external disturbances. Compared with conventional GVF methods, the proposed approach directly accommodates discretized paths and maintains compatibility with standard planning algorithms. Extensive simulations and real-world experiments demonstrate improved robustness against external disturbances and superior real-time performance.

</details>


### [5] [Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation](https://arxiv.org/abs/2511.22100)
*Zelong Zhou,Wenrui Chen,Zeyun Hu,Qiang Diao,Qixin Gao,Yaonan Wang*

Main category: cs.RO

TL;DR: 提出一种由2个驱动器驱动4自由度的仿人手指拓扑结构，并基于此开发自适应模块化灵巧手，平衡驱动复杂性与灵巧性


<details>
  <summary>Details</summary>
Motivation: 生物协同作用已成为灵巧手设计的广泛采用范式，但过度耦合会降低手的灵巧性。本文旨在解决驱动复杂性与灵巧性之间的权衡问题。

Method: 提出4自由度2驱动的仿人手指拓扑结构；探索手部协同作用的生物学基础和人类手势分析；将关节级协调和结构属性转化为模块化手指架构；基于这些仿生映射设计五指模块化手并建立其运动学模型

Result: 构建了物理原型并进行初步实验，验证了所提设计和分析的有效性

Conclusion: 通过仿人手指拓扑和模块化设计，成功平衡了驱动复杂性与灵巧性，实现了自适应抓取和手内操作

Abstract: Biological synergies have emerged as a widely adopted paradigm for dexterous hand design, enabling human-like manipulation with a small number of actuators. Nonetheless, excessive coupling tends to diminish the dexterity of hands. This paper tackles the trade-off between actuation complexity and dexterity by proposing an anthropomorphic finger topology with 4 DoFs driven by 2 actuators, and by developing an adaptive, modular dexterous hand based on this finger topology. We explore the biological basis of hand synergies and human gesture analysis, translating joint-level coordination and structural attributes into a modular finger architecture. Leveraging these biomimetic mappings, we design a five-finger modular hand and establish its kinematic model to analyze adaptive grasping and in-hand manipulation. Finally, we construct a physical prototype and conduct preliminary experiments, which validate the effectiveness of the proposed design and analysis.

</details>


### [6] [Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates](https://arxiv.org/abs/2511.22225)
*Gabriel Aguirre,Simay Atasoy Bingöl,Heiko Hamann,Jonas Kuckling*

Main category: cs.RO

TL;DR: 提出一种去中心化贝叶斯框架，使简单机器人群体能够在两个具有未知危险事件率的区域中识别更安全的区域，通过泊松过程建模危险事件，实现样本高效的安全决策。


<details>
  <summary>Details</summary>
Motivation: 在危险环境中，群体机器人需要平衡探索、通信和个体不确定性估计，特别是在直接测量受限或成本高昂的情况下，需要开发能够识别安全区域的集体决策方法。

Method: 采用去中心化贝叶斯框架，机器人使用共轭先验逐步预测危险事件之间的时间间隔，并推导置信度估计来调整行为，基于泊松过程对危险事件进行建模。

Result: 模拟结果显示，机器人群体能够一致选择正确区域，同时通过样本高效性减少暴露于危险事件的风险。相比基线启发式方法，该方法在安全性和收敛速度方面表现更优。

Conclusion: 该场景有潜力扩展集体决策的基准测试集，所提方法在危险动态环境中的自适应风险感知采样和探索方面具有应用价值。

Abstract: Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments.

</details>


### [7] [MLATC: Fast Hierarchical Topological Mapping from 3D LiDAR Point Clouds Based on Adaptive Resonance Theory](https://arxiv.org/abs/2511.22238)
*Ryosuke Ofuchi,Yuichiro Toda,Naoki Masuyama,Takayuki Matsuno*

Main category: cs.RO

TL;DR: 本文提出了一种多层自适应共振理论拓扑聚类（MLATC）方法，用于从3D激光雷达点云构建全局拓扑地图，通过分层结构显著提高了原始ATC-DT算法的计算效率，实现了大规模环境中的实时地图构建。


<details>
  <summary>Details</summary>
Motivation: 原始ATC-DT算法虽然能够构建全局拓扑地图并缓解灾难性遗忘问题，但其基于穷举最近邻搜索的获胜节点选择机制导致随着地图规模增大，计算效率急剧下降，限制了在大规模环境中的实时应用。

Method: 提出了多层自适应共振理论拓扑聚类（MLATC）方法，通过将节点组织成层次结构，使最近邻搜索能够从粗到细分辨率进行，大幅减少了每次查询的距离计算次数。该方法采用自适应层增加机制，当较低层饱和时自动加深层次结构，无需预先固定层数。

Result: 在合成大规模环境中的仿真实验表明，MLATC相比原始ATC-DT显著加速了拓扑地图构建，搜索时间与节点数量呈亚线性（近似对数）关系。在校园规模的真实世界LiDAR数据集实验中，MLATC保持了毫秒级的每帧运行时间，实现了大规模环境中的实时全局拓扑地图构建。

Conclusion: MLATC通过分层组织结构有效解决了ATC-DT算法的可扩展性限制，在大规模动态未知环境中实现了高效的实时全局拓扑地图构建，显著提升了计算效率，为自主移动机器人的大规模环境导航提供了实用解决方案。

Abstract: This paper addresses the problem of building global topological maps from 3D LiDAR point clouds for autonomous mobile robots operating in large-scale, dynamic, and unknown environments. Adaptive Resonance Theory-based Topological Clustering with Different Topologies (ATC-DT) builds global topological maps represented as graphs while mitigating catastrophic forgetting during sequential processing. However, its winner selection mechanism relies on an exhaustive nearest-neighbor search over all existing nodes, leading to scalability limitations as the map grows. To address this challenge, we propose a hierarchical extension called Multi-Layer ATC (MLATC). MLATC organizes nodes into a hierarchy, enabling the nearest-neighbor search to proceed from coarse to fine resolutions, thereby drastically reducing the number of distance evaluations per query. The number of layers is not fixed in advance. MLATC employs an adaptive layer addition mechanism that automatically deepens the hierarchy when lower layers become saturated, keeping the number of user-defined hyperparameters low. Simulation experiments on synthetic large-scale environments show that MLATC accelerates topological map building compared to the original ATC-DT and exhibits a sublinear, approximately logarithmic scaling of search time with respect to the number of nodes. Experiments on campus-scale real-world LiDAR datasets confirm that MLATC maintains a millisecond-level per-frame runtime and enables real-time global topological map building in large-scale environments, significantly outperforming the original ATC-DT in terms of computational efficiency.

</details>


### [8] [Soft Fluidic Sheet Transistor for Soft Robotic System Enabling Fluid Logic Operations](https://arxiv.org/abs/2511.22318)
*Yuki Origane,Koya Cho,Hideyuki Tsukagoshi*

Main category: cs.RO

TL;DR: 提出一种柔性聚氨酯片状阀门，通过气动信号实现逻辑运算，类似电子晶体管，可构建流体机器人系统


<details>
  <summary>Details</summary>
Motivation: 为了实现软体机器人系统的高功能性和灵活性，需要开发能够仅使用气动信号执行逻辑运算的柔性阀门系统

Method: 设计软聚氨酯片状阀门，当控制腔加压时，主通道沿中心轴压缩、屈曲并被压紧，实现阻断。这种阀门类似晶体管，可组合实现各种逻辑运算。基本类型作为NOT逻辑元件，称为流体片晶体管(FST)。通过集成多个FST，可在单张片上实现正逻辑、NAND和NOR等逻辑运算

Result: 成功开发了FST，描述了其工作原理、制造方法和特性，并展示了逻辑运算配置方法。使用FST构建了锁存电路(自保持逻辑电路)，结合触觉管作为流体检测器和流体执行器，构建了流体机器人系统原型

Conclusion: 该研究证明了仅使用单管气压就能实现当碰到障碍物时主动改变姿态的行为，验证了所提方法的有效性，为软体机器人系统提供了新的气动逻辑控制方案

Abstract: Aiming to achieve both high functionality and flexibility in soft robot system, this paper presents a soft urethane sheet-like valve with an amplifier that can perform logical operations using only pneumatic signals. When the control chamber in the valve is pressurized, the main path is compressed along its central axis, buckling and being pressed,resulting in blockage. This allows control by a pressure signal smaller than that within the main channel. Furthermore, similar to transistors in electrical circuits, when combined, the proposed valve can perform a variety of logical operations. The basic type operates as a NOT logic element, which is named the fluidic sheet transistor (FST). By integrating multiple FSTs, logical operations such as positive logic, NAND, and NOR can be performed on a single sheet. This paper describes the operating principle, fabrication method, and characteristics of the FST,followed by a method for configuring logical operations.Moreover, we demonstrate the construction of a latch circuit(self-holding logic circuit) using FST, introducing a prototype of a fluid robot system that combines a tactile tube as a fluidic detector and fluid actuators. This demonstrates that it is possible to generate behavior that actively changes posture when hitting an obstacle using only air pressure from a single pipe, which verifies the effectiveness of the proposed methods.

</details>


### [9] [Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning](https://arxiv.org/abs/2511.22338)
*Denghan Xiong,Yanzhe Zhao,Yutong Chen,Zichun Wang*

Main category: cs.RO

TL;DR: 该研究针对阿克曼转向车辆在狭窄死胡同中的非完整约束导航问题，提出了一种基于深度强化学习的解决方案，相比传统规划器在解决成功率、机动次数等方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 非完整约束限制了阿克曼转向车辆的可行速度，使其无法执行原地旋转，在狭窄死胡同中需要复杂的进退机动序列。传统规划器将全局搜索与局部转向解耦，在狭窄通道中采样效率低且对间隙敏感，难以有效解决这类问题。

Method: 研究包含三个核心组件：1)构建生成器，采样与阿克曼运动学兼容的多阶段进退轨迹，并膨胀其包络以合成保证至少存在一个可行逃逸路径的狭窄死胡同家族；2)构建强制执行运动学约束的训练环境，使用软演员-评论家算法训练策略；3)与结合全局搜索和非完整转向的代表性传统规划器进行对比评估。

Result: 在参数化的死胡同家族中，学习到的策略解决了更大比例的实例，减少了机动次数，在相同感知和控制限制下保持了可比较的路径长度和规划时间。

Conclusion: 基于深度强化学习的方法在阿克曼车辆的非完整狭窄死胡同逃逸问题上优于传统规划器，为解决具有挑战性的非完整约束导航问题提供了有效方案，相关代码已开源。

Abstract: Nonholonomic constraints restrict feasible velocities without reducing configuration-space dimension, which makes collision-free geometric paths generally non-executable for car-like robots. Ackermann steering further imposes curvature bounds and forbids in-place rotation, so escaping from narrow dead ends typically requires tightly sequenced forward and reverse maneuvers. Classical planners that decouple global search and local steering struggle in these settings because narrow passages occupy low-measure regions and nonholonomic reachability shrinks the set of valid connections, which degrades sampling efficiency and increases sensitivity to clearances. We study nonholonomic narrow dead-end escape for Ackermann vehicles and contribute three components. First, we construct a generator that samples multi-phase forward-reverse trajectories compatible with Ackermann kinematics and inflates their envelopes to synthesize families of narrow dead ends that are guaranteed to admit at least one feasible escape. Second, we construct a training environment that enforces kinematic constraints and train a policy using the soft actor-critic algorithm. Third, we evaluate against representative classical planners that combine global search with nonholonomic steering. Across parameterized dead-end families, the learned policy solves a larger fraction of instances, reduces maneuver count, and maintains comparable path length and planning time while under the same sensing and control limits. We provide our project as open source at https://github.com/gitagitty/cisDRL-RobotNav.git

</details>


### [10] [LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning](https://arxiv.org/abs/2511.22354)
*Suraj Borate,Bhavish Rai B,Vipul Pardeshi,Madhu Vadali*

Main category: cs.RO

TL;DR: CoMuRoS是一个可泛化的分层架构，用于异构机器人团队，结合了集中式规划和分布式执行，支持事件驱动的重新规划，通过LLM实现自然语言任务解释、任务分配和代码生成，在硬件和仿真中展示了自主恢复、协调运输和人类-机器人协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM机器人系统通常缺乏运行时的事件驱动重新规划能力，特别是在物理机器人上的实现有限。需要一种能够处理动态环境变化、任务失败和人类意图变化的系统，实现鲁棒的多机器人和人机协作。

Method: 采用分层架构：顶层任务管理器LLM解释自然语言目标、分类任务并使用静态规则加动态上下文分配子任务；每个机器人运行本地LLM，从原始技能（ROS2节点、策略）组合可执行的Python代码；机载感知（VLM/图像处理）持续监控事件并分类为相关或无关；任务失败或用户意图变化触发重新规划。

Result: 硬件研究展示了自主恢复干扰事件、过滤无关干扰、紧密协调运输和涌现的人机协作（多机器人协作物体恢复成功率：9/10，协调运输：8/8，人类辅助恢复：5/5）。仿真研究显示意图感知的重新规划。在22个场景的基准测试中，任务分配、分类、IoU、可执行性和正确性得分高（正确性最高达0.91），单独的重新规划集（5个场景）达到1.0正确性。

Conclusion: CoMuRoS相比之前的LLM系统，独特地展示了在物理机器人上的运行时事件驱动重新规划能力，提供了鲁棒、灵活的多机器人和人机协作解决方案，能够处理动态环境变化和任务失败，支持自主恢复和人类协助。

Abstract: This paper introduces CoMuRoS (Collaborative Multi-Robot System), a generalizable hierarchical architecture for heterogeneous robot teams that unifies centralized deliberation with decentralized execution, and supports event-driven replanning. A Task Manager LLM interprets natural-language goals, classifies tasks, and allocates subtasks using static rules plus dynamic contexts (task, history, robot and task status, and events).Each robot runs a local LLM that composes executable Python code from primitive skills (ROS2 nodes, policies), while onboard perception (VLMs/image processing) continuously monitors events and classifies them into relevant or irrelevant to the task. Task failures or user intent changes trigger replanning, allowing robots to assist teammates, resume tasks, or request human help. Hardware studies demonstrate autonomous recovery from disruptive events, filtering of irrelevant distractions, and tightly coordinated transport with emergent human-robot cooperation (e.g., multirobot collaborative object recovery success rate: 9/10, coordinated transport: 8/8, human-assisted recovery: 5/5).Simulation studies show intention-aware replanning. A curated textual benchmark spanning 22 scenarios (3 tasks each, around 20 robots) evaluates task allocation, classification, IoU, executability, and correctness, with high average scores (e.g., correctness up to 0.91) across multiple LLMs, a separate replanning set (5 scenarios) achieves 1.0 correctness. Compared with prior LLM-based systems, CoMuRoS uniquely demonstrates runtime, event-driven replanning on physical robots, delivering robust, flexible multi-robot and human-robot collaboration.

</details>


### [11] [BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands](https://arxiv.org/abs/2511.22364)
*Seongwon Cho,Daechul Ahn,Donghyun Shin,Hyeonbeom Choi,San Kim,Jonghyun Choi*

Main category: cs.RO

TL;DR: BINDER是一个双过程框架，通过解耦战略规划和连续环境监控来解决开放词汇移动操作中的动态环境适应问题，显著提升了成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇移动操作方法只在离散更新点（如导航目标、路径点或动作结束时）更新世界表示，导致机器人在更新之间处于"盲区"，造成级联失败：遗漏对象、错误检测延迟和重规划滞后。

Method: 提出BINDER框架，包含两个互补模块：Deliberative Response Module（多模态LLM用于任务规划）和Instant Response Module（VideoLLM用于连续监控）。DRM进行战略规划并指导IRM关注点，IRM分析视频流更新记忆、纠正正在进行的动作并在必要时触发重规划。

Result: 在三个真实世界动态物体放置环境中评估，BINDER相比最先进的基线方法实现了显著更高的成功率和效率。

Conclusion: BINDER通过双向协调解决了保持环境感知与避免昂贵更新之间的权衡问题，能够在动态条件下实现鲁棒适应，展示了在真实世界部署中的有效性。

Abstract: Open-vocabulary mobile manipulation (OVMM) requires robots to follow language instructions, navigate, and manipulate while updating their world representation under dynamic environmental changes. However, most prior approaches update their world representation only at discrete update points such as navigation targets, waypoints, or the end of an action step, leaving robots blind between updates and causing cascading failures: overlooked objects, late error detection, and delayed replanning. To address this limitation, we propose BINDER (Bridging INstant and DEliberative Reasoning), a dual process framework that decouples strategic planning from continuous environment monitoring. Specifically, BINDER integrates a Deliberative Response Module (DRM, a multimodal LLM for task planning) with an Instant Response Module (IRM, a VideoLLM for continuous monitoring). The two modules play complementary roles: the DRM performs strategic planning with structured 3D scene updates and guides what the IRM attends to, while the IRM analyzes video streams to update memory, correct ongoing actions, and trigger replanning when necessary. Through this bidirectional coordination, the modules address the trade off between maintaining awareness and avoiding costly updates, enabling robust adaptation under dynamic conditions. Evaluated in three real world environments with dynamic object placement, BINDER achieves substantially higher success and efficiency than SoTA baselines, demonstrating its effectiveness for real world deployment.

</details>


### [12] [Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion](https://arxiv.org/abs/2511.22445)
*Yikai Tang,Haoran Geng,Sheng Zang,Pieter Abbeel,Jitendra Malik*

Main category: cs.RO

TL;DR: VGDP是一种多模态模仿学习框架，通过互补感知融合模块平衡使用RGB和点云信息，在视觉和空间随机化下表现出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法在空间和视觉随机化条件下容易过拟合，难以泛化。需要设计更有效的观察编码器来提升策略的泛化能力。

Method: 提出视觉几何扩散策略(VGDP)，采用互补感知融合模块，通过模态级dropout强制平衡使用RGB和点云线索，交叉注意力仅作为轻量级交互层。

Result: 在18个模拟任务和4个真实世界任务中，VGDP平均性能提升39.1%，在视觉扰动下平均提升41.5%，在空间设置下平均提升15.2%，显著优于7个基线策略。

Conclusion: VGDP通过强制模态互补性而非依赖交叉注意力作为主要鲁棒性来源，在多模态模仿学习中实现了更好的泛化性能和鲁棒性。

Abstract: Imitation learning has emerged as a crucial ap proach for acquiring visuomotor skills from demonstrations, where designing effective observation encoders is essential for policy generalization. However, existing methods often struggle to generalize under spatial and visual randomizations, instead tending to overfit. To address this challenge, we propose Visual Geometry Diffusion Policy (VGDP), a multimodal imitation learning framework built around a Complementarity-Aware Fusion Module where modality-wise dropout enforces balanced use of RGB and point-cloud cues, with cross-attention serving only as a lightweight interaction layer. Our experiments show that the expressiveness of the fused latent space is largely induced by the enforced complementarity from modality-wise dropout, with cross-attention serving primarily as a lightweight interaction mechanism rather than the main source of robustness. Across a benchmark of 18 simulated tasks and 4 real-world tasks, VGDP outperforms seven baseline policies with an average performance improvement of 39.1%. More importantly, VGDP demonstrates strong robustness under visual and spatial per turbations, surpassing baselines with an average improvement of 41.5% in different visual conditions and 15.2% in different spatial settings.

</details>


### [13] [RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion](https://arxiv.org/abs/2511.22505)
*Xiujian Liang,Jiacheng Liu,Mingyang Sun,Qichen He,Cewu Lu,Jianhua Sun*

Main category: cs.RO

TL;DR: 提出RealD²iff框架，通过从干净到噪声的扩散模型学习合成真实噪声深度，解决机器人操作中的视觉sim2real差距问题，实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人操作受限于视觉sim2real差距，模拟中的深度观测无法反映真实传感器的复杂噪声模式，需要一种纯模拟驱动的解决方案。

Method: 提出RealD²iff分层扩散框架，将深度噪声分解为全局结构失真和局部扰动；采用频率引导监督(FGS)进行全局建模和差异引导优化(DGO)进行局部细化；构建六阶段模仿学习流程。

Result: RealD²iff能够生成真实世界般的深度数据构建干净-噪声配对数据集，无需手动传感器数据收集；实现零样本sim2real机器人操作，显著提升真实世界性能而无需额外微调。

Conclusion: 通过干净到噪声的范式，利用扩散模型的去噪能力反向学习合成噪声深度，成功桥接视觉sim2real差距，为纯模拟驱动的机器人学习提供了有效解决方案。

Abstract: Robot manipulation in the real world is fundamentally constrained by the visual sim2real gap, where depth observations collected in simulation fail to reflect the complex noise patterns inherent to real sensors. In this work, inspired by the denoising capability of diffusion models, we invert the conventional perspective and propose a clean-to-noisy paradigm that learns to synthesize noisy depth, thereby bridging the visual sim2real gap through purely simulation-driven robotic learning. Building on this idea, we introduce RealD$^2$iff, a hierarchical coarse-to-fine diffusion framework that decomposes depth noise into global structural distortions and fine-grained local perturbations. To enable progressive learning of these components, we further develop two complementary strategies: Frequency-Guided Supervision (FGS) for global structure modeling and Discrepancy-Guided Optimization (DGO) for localized refinement. To integrate RealD$^2$iff seamlessly into imitation learning, we construct a pipeline that spans six stages. We provide comprehensive empirical and experimental validation demonstrating the effectiveness of this paradigm. RealD$^2$iff enables two key applications: (1) generating real-world-like depth to construct clean-noisy paired datasets without manual sensor data collection. (2) Achieving zero-shot sim2real robot manipulation, substantially improving real-world performance without additional fine-tuning.

</details>


### [14] [BUDD-e: an autonomous robotic guide for visually impaired users](https://arxiv.org/abs/2511.22541)
*Jinyang Li,Marcello Farina,Luca Mozzarelli,Luca Cattaneo,Panita Rattamasanaprapai,Eleonora A. Tagarelli,Matteo Corno,Paolo Perego,Giuseppe Andreoni,Emanuele Lettieri*

Main category: cs.RO

TL;DR: 本文介绍了一款为视障用户设计的新型导盲机器人BUDD-e的原型设计与实现，并在米兰Niguarda医院通过视障志愿者进行了真实场景测试，展示了出色的性能和用户接受度。


<details>
  <summary>Details</summary>
Motivation: 为视障用户开发实用的导盲机器人，帮助他们在复杂环境中独立导航，提高生活质量和自主性。

Method: 设计并实现了BUDD-e导盲机器人原型，在米兰Niguarda医院的实际场景中与视障志愿者合作进行测试。

Result: 实验结果显示机器人表现出色，获得了良好的用户接受度，验证了其在实际应用中的有效性。

Conclusion: BUDD-e导盲机器人原型在真实场景测试中证明了其可行性和实用性，为视障用户的辅助导航提供了有前景的技术解决方案。

Abstract: This paper describes the design and the realization of a prototype of the novel guide robot BUDD-e for visually impaired users. The robot has been tested in a real scenario with the help of visually disabled volunteers at ASST Grande Ospedale Metropolitano Niguarda, in Milan. The results of the experimental campaign are throughly described in the paper, displaying its remarkable performance and user-acceptance.

</details>


### [15] [Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation](https://arxiv.org/abs/2511.22685)
*Haoyi Wang,Licheng Luo,Yiannis Kantaros,Bruno Sinopoli,Mingyu Cai*

Main category: cs.RO

TL;DR: 本文提出了一种混合框架，将基于强化学习的反应式导航与按需多智能体路径规划相结合，以解决密集多机器人导航中的死锁问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人在杂乱环境中的导航面临基本挑战：需要在反应式避碰与长期目标达成之间取得平衡。在狭窄通道或受限空间中，死锁问题频繁出现，特别是当强化学习控制策略遇到超出学习分布的新配置时。现有的基于强化学习的方法在未见环境中泛化能力有限。

Method: 提出混合框架，无缝集成基于强化学习的反应式导航与按需多智能体路径规划。包含安全层监控智能体进度以检测死锁，触发时启动受影响智能体的协调控制器。框架通过多智能体路径规划构建全局可行轨迹，并调节航点进度以减少导航过程中的智能体间冲突。

Result: 在密集多智能体基准测试中的广泛评估表明，该方法将任务完成率从边缘提升到接近普遍成功，显著减少了死锁和碰撞。与分层任务规划集成时，能够实现异构机器人的协调导航。

Conclusion: 将反应式强化学习导航与选择性多智能体路径规划干预相结合，能够实现鲁棒的零样本性能，为解决多机器人导航中的死锁问题提供了有效方案。

Abstract: Multi-robot navigation in cluttered environments presents fundamental challenges in balancing reactive collision avoidance with long-range goal achievement. When navigating through narrow passages
  or confined spaces, deadlocks frequently emerge that prevent agents from reaching their destinations, particularly when Reinforcement Learning (RL) control policies encounter novel configurations out of learning distribution. Existing RL-based approaches suffer from limited generalization capability in unseen environments. We propose a hybrid framework that seamlessly integrates RL-based reactive navigation with on-demand Multi-Agent Path Finding (MAPF) to explicitly resolve topological deadlocks. Our approach integrates a safety layer that monitors agent progress to detect deadlocks and, when detected, triggers a coordination controller for affected agents. The framework constructs globally feasible trajectories via MAPF and regulates waypoint progression to reduce inter-agent conflicts during navigation.
  Extensive evaluation on dense multi-agent benchmarks shows that our method boosts task completion from marginal to near-universal success, markedly reducing deadlocks and collisions. When integrated with hierarchical task planning, it enables coordinated navigation for heterogeneous robots, demonstrating that coupling reactive RL navigation with selective MAPF intervention yields a robust, zero-shot performance.

</details>


### [16] [Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations](https://arxiv.org/abs/2511.22697)
*Chancharik Mitra,Yusen Luo,Raj Saravanan,Dantong Niu,Anirudh Pai,Jesse Thomason,Trevor Darrell,Abrar Anwar,Deva Ramanan,Roei Herzig*

Main category: cs.RO

TL;DR: Robotic Steering：一种基于机制可解释性的VLA微调方法，通过少样本演示识别并选择性微调与机器人任务物理、视觉和语言需求对齐的特定注意力头，相比LoRA在任务变化下表现更优、计算成本更低、可解释性更强。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型微调方法缺乏特异性，无论任务的视觉、语言和物理特性如何都调整相同的参数集。受神经科学中功能特异性的启发，作者认为针对特定任务微调稀疏模型表示更有效。

Method: 提出Robotic Steering方法，基于机制可解释性，利用少样本演示识别并选择性微调与机器人任务物理、视觉和语言需求对齐的任务特定注意力头。

Result: 在Franka Emika机器人臂上的全面评估表明，Robotic Steering在任务变化下比LoRA表现更优，具有更强的鲁棒性、更低的计算成本和更好的可解释性。

Conclusion: Robotic Steering通过选择性微调任务特定注意力头，为适应多样化机器人任务提供了一种高效、鲁棒且可解释的VLA微调方法。

Abstract: Vision-Language Action (VLAs) models promise to extend the remarkable success of vision-language models (VLMs) to robotics. Yet, unlike VLMs in the vision-language domain, VLAs for robotics require finetuning to contend with varying physical factors like robot embodiment, environment characteristics, and spatial relationships of each task. Existing fine-tuning methods lack specificity, adapting the same set of parameters regardless of a task's visual, linguistic, and physical characteristics. Inspired by functional specificity in neuroscience, we hypothesize that it is more effective to finetune sparse model representations specific to a given task. In this work, we introduce Robotic Steering, a finetuning approach grounded in mechanistic interpretability that leverages few-shot demonstrations to identify and selectively finetune task-specific attention heads aligned with the physical, visual, and linguistic requirements of robotic tasks. Through comprehensive on-robot evaluations with a Franka Emika robot arm, we demonstrate that Robotic Steering outperforms LoRA while achieving superior robustness under task variation, reduced computational cost, and enhanced interpretability for adapting VLAs to diverse robotic tasks.

</details>


### [17] [A Two Degrees-of-Freedom Floor-Based Robot for Transfer and Rehabilitation Applications](https://arxiv.org/abs/2511.22705)
*Ian Lalonde,Jeff Denis,Mathieu Lamy,Camille Martin,Karina Lebel,Alexandre Girard*

Main category: cs.RO

TL;DR: 开发了一种坐立训练设备，能够通过调节阻抗和垂直/前向力来适应不同活动能力水平，同时保持商业升降辅助设备的转移功能。


<details>
  <summary>Details</summary>
Motivation: 现有升降辅助设备和部分体重支撑设备无法根据不同的活动能力水平调整坐立训练，需要一种能够适应多种训练需求的设备。

Method: 开发了一种坐立训练设备，允许配置不同的阻抗和垂直/前向力，以适应用户的训练需求，同时保持商业升降辅助设备的转移能力。

Result: 对健康成年人的实验表明：1）设备对自然坐立运动学影响小；2）能在患者质心提供精确的减重支持；3）能在坐立动作开始时增加虚拟前向弹簧辅助体重转移到脚部。

Conclusion: 该设备能够适应不同训练需求，有效辅助坐立动作，具有临床应用潜力。

Abstract: The ability to accomplish a sit-to-stand (STS) motion is key to increase functional mobility and reduce rehospitalization risks. While raising aid (transfer) devices and partial bodyweight support (rehabilitation) devices exist, both are unable to adjust the STS training to different mobility levels. Therefore, We have developed an STS training device that allows various configurations of impedance and vertical/forward forces to adapt to many training needs while maintaining commercial raising aid transfer capabilities. Experiments with healthy adults (both men and women) of various heights and weights show that the device 1) has a low impact on the natural STS kinematics, 2) can provide precise weight unloading at the patient's center of mass and 3) can add a forward virtual spring to assist the transfer of the bodyweight to the feet for seat-off, at the start of the STS motion.

</details>


### [18] [Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion](https://arxiv.org/abs/2511.22744)
*Rémy Rahem,Wael Suleiman*

Main category: cs.RO

TL;DR: 多视角深度感知框架结合机器人本体视角和外部视角，通过师生蒸馏方法学习融合双深度流，提升四足机器人在动态运动中的鲁棒性和敏捷性


<details>
  <summary>Details</summary>
Motivation: 现有腿式机器人运动方法主要依赖本体视角感知，当机器人视角被遮挡时性能受限。需要增强环境感知能力，通过多视角互补信息提升运动性能

Method: 提出多视角深度感知运动框架，结合本体视角和外部视角观测。采用师生蒸馏方法，学生策略学习融合本体感知和双深度流，并引入广泛域随机化（包括随机远程相机丢失和3D位置扰动）来模拟空地协同感知

Result: 模拟实验显示多视角策略在跨越间隙、台阶下降等动态动作上优于单视角基线，当外部相机部分或完全不可用时仍能保持稳定性。中等程度的视角错位在训练中被良好容忍

Conclusion: 异构视觉反馈显著提升了四足机器人运动的鲁棒性和敏捷性。该研究为多视角感知在动态机器人运动中的应用提供了有效框架，相关实现已公开以支持可复现性

Abstract: Recent progress in legged locomotion has allowed highly dynamic and parkour-like behaviors for robots, similar to their biological counterparts. Yet, these methods mostly rely on egocentric (first-person) perception, limiting their performance, especially when the viewpoint of the robot is occluded. A promising solution would be to enhance the robot's environmental awareness by using complementary viewpoints, such as multiple actors exchanging perceptual information. Inspired by this idea, this work proposes a multi-view depth-based locomotion framework that combines egocentric and exocentric observations to provide richer environmental context during agile locomotion. Using a teacher-student distillation approach, the student policy learns to fuse proprioception with dual depth streams while remaining robust to real-world sensing imperfections. To further improve robustness, we introduce extensive domain randomization, including stochastic remote-camera dropouts and 3D positional perturbations that emulate aerial-ground cooperative sensing. Simulation results show that multi-viewpoints policies outperform single-viewpoint baseline in gap crossing, step descent, and other dynamic maneuvers, while maintaining stability when the exocentric camera is partially or completely unavailable. Additional experiments show that moderate viewpoint misalignment is well tolerated when incorporated during training. This study demonstrates that heterogeneous visual feedback improves robustness and agility in quadrupedal locomotion. Furthermore, to support reproducibility, the implementation accompanying this work is publicly available at https://anonymous.4open.science/r/multiview-parkour-6FB8

</details>


### [19] [CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance](https://arxiv.org/abs/2511.22773)
*Rui Heng Yang,Xuan Zhao,Leo Maxime Brunswic,Montgomery Alban,Mateo Clemente,Tongtong Cao,Jun Jin,Amir Rasouli*

Main category: cs.RO

TL;DR: CAPE提出了一种上下文感知的扩散策略，通过近端模式扩展来解决模仿学习中数据稀缺问题，特别针对避障等挑战性任务，在未见环境中实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人模仿学习中能捕捉多模态轨迹，但需要大规模数据集，这在避障等挑战性任务中成本高昂。测试时需要泛化到多种障碍物类型和空间配置，纯数据驱动方法不切实际。

Method: 提出CAPE框架，通过上下文感知先验和引导扩展轨迹分布模式。采用先验种子迭代引导精炼过程：生成初始轨迹计划，执行短前缀轨迹，将剩余轨迹扰动到中间噪声水平形成上下文感知先验，然后通过上下文感知引导去噪迭代扩展模式支持。

Result: 在杂乱未见模拟和真实世界设置中评估CAPE，相比SOTA方法分别实现高达26%和80%的成功率提升，在未见环境中表现出更好的泛化能力，能采样无碰撞轨迹同时保持目标一致性。

Conclusion: CAPE通过上下文感知先验和引导扩展轨迹分布模式，有效解决了模仿学习中数据稀缺问题，在避障等挑战性任务中实现了更好的泛化性能，为机器人操作任务提供了更鲁棒的解决方案。

Abstract: In robotics, diffusion models can capture multi-modal trajectories from demonstrations, making them a transformative approach in imitation learning. However, achieving optimal performance following this regiment requires a large-scale dataset, which is costly to obtain, especially for challenging tasks, such as collision avoidance. In those tasks, generalization at test time demands coverage of many obstacles types and their spatial configurations, which are impractical to acquire purely via data. To remedy this problem, we propose Context-Aware diffusion policy via Proximal mode Expansion (CAPE), a framework that expands trajectory distribution modes with context-aware prior and guidance at inference via a novel prior-seeded iterative guided refinement procedure. The framework generates an initial trajectory plan and executes a short prefix trajectory, and then the remaining trajectory segment is perturbed to an intermediate noise level, forming a trajectory prior. Such a prior is context-aware and preserves task intent. Repeating the process with context-aware guided denoising iteratively expands mode support to allow finding smoother, less collision-prone trajectories. For collision avoidance, CAPE expands trajectory distribution modes with collision-aware context, enabling the sampling of collision-free trajectories in previously unseen environments while maintaining goal consistency. We evaluate CAPE on diverse manipulation tasks in cluttered unseen simulated and real-world settings and show up to 26% and 80% higher success rates respectively compared to SOTA methods, demonstrating better generalization to unseen environments.

</details>


### [20] [Improving Robotic Manipulation Robustness via NICE Scene Surgery](https://arxiv.org/abs/2511.22777)
*Sajjad Pakdamansavoji,Mozhgan Pourkeshavarz,Adam Sigal,Zhiyuan Li,Rui Heng Yang,Amir Rasouli*

Main category: cs.RO

TL;DR: NICE框架通过自然图像修复增强视觉多样性，减少模仿学习中的分布外差距，无需额外数据收集或模型训练


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉干扰物会显著降低机器人操作策略的性能和安全性，需要一种有效且可扩展的方法来增强视觉鲁棒性

Method: 利用图像生成框架和大语言模型对现有演示数据进行三种编辑操作：对象替换、重新风格化和移除干扰物，保持空间关系和动作标签一致性

Result: 在高度杂乱场景中，空间可及性预测准确率提升超过20%；在含干扰物的环境中，操作成功率平均提高11%；目标混淆率降低6%，碰撞率减少7%

Conclusion: NICE框架通过增强视觉多样性有效减少模仿学习的分布外差距，提高机器人操作的鲁棒性和安全性，且无需额外数据收集或模型训练

Abstract: Learning robust visuomotor policies for robotic manipulation remains a challenge in real-world settings, where visual distractors can significantly degrade performance and safety. In this work, we propose an effective and scalable framework, Naturalistic Inpainting for Context Enhancement (NICE). Our method minimizes out-of-distribution (OOD) gap in imitation learning by increasing visual diversity through construction of new experiences using existing demonstrations. By utilizing image generative frameworks and large language models, NICE performs three editing operations, object replacement, restyling, and removal of distracting (non-target) objects. These changes preserve spatial relationships without obstructing target objects and maintain action-label consistency. Unlike previous approaches, NICE requires no additional robot data collection, simulator access, or custom model training, making it readily applicable to existing robotic datasets.
  Using real-world scenes, we showcase the capability of our framework in producing photo-realistic scene enhancement. For downstream tasks, we use NICE data to finetune a vision-language model (VLM) for spatial affordance prediction and a vision-language-action (VLA) policy for object manipulation. Our evaluations show that NICE successfully minimizes OOD gaps, resulting in over 20% improvement in accuracy for affordance prediction in highly cluttered scenes. For manipulation tasks, success rate increases on average by 11% when testing in environments populated with distractors in different quantities. Furthermore, we show that our method improves visual robustness, lowering target confusion by 6%, and enhances safety by reducing collision rate by 7%.

</details>


### [21] [Distracted Robot: How Visual Clutter Undermine Robotic Manipulation](https://arxiv.org/abs/2511.22780)
*Amir Rasouli,Montgomery Alban,Sajjad Pakdamansavoji,Zhiyuan Li,Zhanguang Zhang,Aaron Wu,Xuan Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一个从心理物理学角度评估机器人操作策略在杂乱场景中性能的协议，使用统一的杂乱度量标准，并在仿真和现实世界中进行了广泛实验，发现场景杂乱会显著降低VLA模型性能达34%，不同策略有独特弱点，且微调不能完全解决杂乱带来的负面影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏从心理物理学角度评估机器人操作策略在杂乱场景中性能的系统方法，需要统一的杂乱度量标准来综合考虑环境因素、干扰物数量、特征和排列方式，以更全面地评估策略的鲁棒性。

Method: 提出基于心理物理学的评估协议，使用统一的杂乱度量标准，在超现实仿真和真实世界中系统构建评估场景，对视觉-语言-动作(VLA)模型进行广泛实验，分析杂乱度量与性能下降的关系以及干扰物的数量和遮挡影响。

Result: 场景杂乱显著降低策略性能达34%；不同VLA策略虽然平均性能相似，但各有独特弱点且成功场景一致性较低；杂乱度量能有效指示性能下降；干扰物数量和遮挡影响显著；基于增强数据的微调虽然有效，但不能平等解决所有杂乱带来的负面影响。

Conclusion: 需要更系统的方法来评估机器人操作策略在杂乱场景中的鲁棒性，统一的杂乱度量标准能有效预测性能下降，不同策略有独特脆弱性，仅靠数据增强微调不足以完全解决杂乱挑战，未来研究需要更针对性的改进方法。

Abstract: In this work, we propose an evaluation protocol for examining the performance of robotic manipulation policies in cluttered scenes. Contrary to prior works, we approach evaluation from a psychophysical perspective, therefore we use a unified measure of clutter that accounts for environmental factors as well as the distractors quantity, characteristics, and arrangement. Using this measure, we systematically construct evaluation scenarios in both hyper-realistic simulation and real-world and conduct extensive experimentation on manipulation policies, in particular vision-language-action (VLA) models. Our experiments highlight the significant impact of scene clutter, lowering the performance of the policies, by as much as 34% and show that despite achieving similar average performance across the tasks, different VLA policies have unique vulnerabilities and a relatively low agreement on success scenarios. We further show that our clutter measure is an effective indicator of performance degradation and analyze the impact of distractors in terms of their quantity and occluding influence. At the end, we show that finetuning on enhanced data, although effective, does not equally remedy all negative impacts of clutter on performance.

</details>


### [22] [Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation](https://arxiv.org/abs/2511.22829)
*Zhen Tian,Zhihao Lin*

Main category: cs.RO

TL;DR: 提出了一种用于自动驾驶车道变换等复杂场景的新型轨迹规划框架，通过将风险感知规划与保证碰撞避免集成到统一优化框架中，实现了安全、高效、舒适的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹规划方法在复杂动态交通场景中难以同时保证安全性、效率和舒适性，特别是在车道变换等交互场景中需要平衡风险规避与轨迹平滑性。

Method: 首先构建动态风险场(DRF)捕捉静态和动态碰撞风险，然后生成时变凸可行空间确保运动学可行性和安全性，最后将轨迹规划问题建模为有限时域最优控制问题，使用约束迭代线性二次调节器(iLQR)算法联合优化轨迹平滑性、控制努力和风险暴露。

Result: 在密集环岛环境中，该方法相比APF、MPC和RRT基准方法表现出更强的鲁棒适应性，产生更大的安全裕度、更低的急动度和更优的曲率平滑性，车道变换距离(28.59 m)和时间(2.84 s)更短。

Conclusion: 集成的DRF与凸可行空间以及约束iLQR求解器为动态交互交通场景提供了安全、高效、舒适的平衡解决方案，在复杂驾驶场景中优于传统方法。

Abstract: This paper presents a novel trajectory planning pipeline for complex driving scenarios like autonomous lane changing, by integrating risk-aware planning with guaranteed collision avoidance into a unified optimization framework. We first construct a dynamic risk fields (DRF) that captures both the static and dynamic collision risks from surrounding vehicles. Then, we develop a rigorous strategy for generating time-varying convex feasible spaces that ensure kinematic feasibility and safety requirements. The trajectory planning problem is formulated as a finite-horizon optimal control problem and solved using a constrained iterative Linear Quadratic Regulator (iLQR) algorithm that jointly optimizes trajectory smoothness, control effort, and risk exposure while maintaining strict feasibility. Extensive simulations demonstrate that our method outperforms traditional approaches in terms of safety and efficiency, achieving collision-free trajectories with shorter lane-changing distances (28.59 m) and times (2.84 s) while maintaining smooth and comfortable acceleration patterns. In dense roundabout environments the planner further demonstrates robust adaptability, producing larger safety margins, lower jerk, and superior curvature smoothness compared with APF, MPC, and RRT based baselines. These results confirm that the integrated DRF with convex feasible space and constrained iLQR solver provides a balanced solution for safe, efficient, and comfortable trajectory generation in dynamic and interactive traffic scenarios.

</details>


### [23] [Threat-Aware UAV Dodging of Human-Thrown Projectiles with an RGB-D Camera](https://arxiv.org/abs/2511.22847)
*Yuying Zhang,Na Fan,Haowen Zheng,Junning Liang,Zongliang Pan,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 该论文提出了一种基于RGB-D相机和人体姿态估计的无人机实时躲避系统，用于防御人类投掷的突然性高速抛射物攻击。


<details>
  <summary>Details</summary>
Motivation: 执行运输、航拍等任务的无人机容易受到人类故意投掷抛射物的攻击。躲避这种突然且高速的抛射物对无人机提出了巨大挑战，需要超低延迟响应和敏捷机动能力。

Method: 受棒球运动中通过分析投手身体动作预测球轨迹的启发，提出了一种集成人体姿态估计和深度信息的系统。通过RGB-D相机预测攻击者的运动轨迹和抛射物轨迹，并引入不确定性感知的躲避策略。

Result: 感知系统实现了高预测精度，在有效距离和延迟方面优于基线方法。躲避策略能够处理时间和空间不确定性以确保无人机安全。大量真实世界实验证明了该框架在突然攻击下的可靠躲避能力和跨场景的出色鲁棒性。

Conclusion: 该研究成功开发了一种能够实时躲避人类抛射物攻击的无人机系统，通过结合人体姿态分析和不确定性感知策略，为无人机在对抗性环境中的安全运行提供了有效解决方案。

Abstract: Uncrewed aerial vehicles (UAVs) performing tasks such as transportation and aerial photography are vulnerable to intentional projectile attacks from humans. Dodging such a sudden and fast projectile poses a significant challenge for UAVs, requiring ultra-low latency responses and agile maneuvers. Drawing inspiration from baseball, in which pitchers' body movements are analyzed to predict the ball's trajectory, we propose a novel real-time dodging system that leverages an RGB-D camera. Our approach integrates human pose estimation with depth information to predict the attacker's motion trajectory and the subsequent projectile trajectory. Additionally, we introduce an uncertainty-aware dodging strategy to enable the UAV to dodge incoming projectiles efficiently. Our perception system achieves high prediction accuracy and outperforms the baseline in effective distance and latency. The dodging strategy addresses temporal and spatial uncertainties to ensure UAV safety. Extensive real-world experiments demonstrate the framework's reliable dodging capabilities against sudden attacks and its outstanding robustness across diverse scenarios.

</details>


### [24] [MARVO: Marine-Adaptive Radiance-aware Visual Odometry](https://arxiv.org/abs/2511.22860)
*Sacchin Sundar,Atman Kikani,Aaliya Alam,Sumukh Shrote,A. Nayeemulla Khan,A. Shahina*

Main category: cs.RO

TL;DR: MARVO是一个融合水下物理模型、可微分匹配和强化学习优化的视觉-惯性-气压里程计框架，用于解决水下视觉定位的挑战。


<details>
  <summary>Details</summary>
Motivation: 水下视觉定位面临波长相关衰减、纹理差和非高斯传感器噪声等挑战，传统方法难以应对这些复杂的水下环境条件。

Method: 1. 前端：基于Transformer的特征匹配器，加入物理感知辐射适配器补偿颜色通道衰减和对比度损失；2. 后端：基于因子图的视觉-惯性-气压估计器，使用GTSAM库；3. 全局优化：强化学习姿态图优化器，学习SE(2)上的最优回缩动作。

Result: 框架能够在水下浑浊条件下产生几何一致的特征对应关系，实现实时全状态最大后验估计，并能超越经典最小二乘求解器的局部最小值优化全局轨迹。

Conclusion: MARVO通过融合物理建模、可微分匹配和强化学习优化，为水下视觉定位提供了一个鲁棒且准确的解决方案，能够有效应对水下环境的特殊挑战。

Abstract: Underwater visual localization remains challenging due to wavelength-dependent attenuation, poor texture, and non-Gaussian sensor noise. We introduce MARVO, a physics-aware, learning-integrated odometry framework that fuses underwater image formation modeling, differentiable matching, and reinforcement-learning optimization. At the front-end, we extend transformer-based feature matcher with a Physics Aware Radiance Adapter that compensates for color channel attenuation and contrast loss, yielding geometrically consistent feature correspondences under turbidity. These semi dense matches are combined with inertial and pressure measurements inside a factor-graph backend, where we formulate a keyframe-based visual-inertial-barometric estimator using GTSAM library. Each keyframe introduces (i) Pre-integrated IMU motion factors, (ii) MARVO-derived visual pose factors, and (iii) barometric depth priors, giving a full-state MAP estimate in real time. Lastly, we introduce a Reinforcement-Learningbased Pose-Graph Optimizer that refines global trajectories beyond local minima of classical least-squares solvers by learning optimal retraction actions on SE(2).

</details>


### [25] [SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving](https://arxiv.org/abs/2511.22865)
*Wonjeong Ryu,Seungjun Yu,Seokha Moon,Hojun Choi,Junsung Park,Jinkyu Kim,Hyunjung Shim*

Main category: cs.RO

TL;DR: 提出一种相机端到端自动驾驶框架，在BEV空间直接估计偶然不确定性并融入规划，生成密集的像素级不确定性感知可行驶地图，结合车道跟随正则化实现鲁棒轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统存在根本性缺陷：假设感知输出完全可靠，即使在模糊或观测不良的场景中也不考虑不确定性，导致规划器缺乏明确的不确定性度量。

Method: 1. 在BEV空间直接估计偶然不确定性；2. 生成密集的像素级不确定性感知可行驶地图，同时捕获语义结构和几何布局；3. 引入车道跟随正则化，编码车道结构和交通规范。

Result: 在NAVSIM基准测试中达到最先进性能，在具有挑战性的NAVHARD和NAVSAFE子集上取得显著提升，证明了不确定性建模与驾驶先验结合能显著提高安全性。

Conclusion: 通过原则性的偶然不确定性建模结合驾驶先验，显著提升了纯相机端到端自动驾驶的安全性和可靠性，实现了在挑战性不确定性条件下的鲁棒和可解释轨迹规划。

Abstract: End-to-End (E2E) planning has become a powerful paradigm for autonomous driving, yet current systems remain fundamentally uncertainty-blind. They assume perception outputs are fully reliable, even in ambiguous or poorly observed scenes, leaving the planner without an explicit measure of uncertainty. To address this limitation, we propose a camera-only E2E framework that estimates aleatoric uncertainty directly in BEV space and incorporates it into planning. Our method produces a dense, uncertainty-aware drivability map that captures both semantic structure and geometric layout at pixel-level resolution. To further promote safe and rule-compliant behavior, we introduce a lane-following regularization that encodes lane structure and traffic norms. This prior stabilizes trajectory planning under normal conditions while preserving the flexibility needed for maneuvers such as overtaking or lane changes. Together, these components enable robust and interpretable trajectory planning, even under challenging uncertainty conditions. Evaluated on the NAVSIM benchmark, our method achieves state-of-the-art performance, delivering substantial gains on both the challenging NAVHARD and NAVSAFE subsets. These results demonstrate that our principled aleatoric uncertainty modeling combined with driving priors significantly advances the safety and reliability of camera-only E2E autonomous driving.

</details>


### [26] [Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models](https://arxiv.org/abs/2511.22928)
*Jiaxin Liu,Xiangyu Yan,Liang Peng,Lei Yang,Lingjun Zhang,Yuechen Luo,Yueming Tao,Ashton Yu Xuan Tan,Mu Li,Lei Zhang,Ziqi Zhan,Sai Guo,Hong Wang,Jun Li*

Main category: cs.RO

TL;DR: 提出了PotentialRiskQA数据集和PR-Reasoner框架，用于自动驾驶系统在风险可观测前进行潜在风险推理


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统缺乏对潜在风险（风险尚未可观测但可从细微前兆推断）的识别能力，现有数据集缺乏此类罕见复杂场景和因果推理链标注

Method: 引入PotentialRiskQA视觉语言数据集，包含结构化场景描述、语义前兆和推断风险结果标注；提出PR-Reasoner视觉语言模型框架进行车载潜在风险推理

Result: 在PotentialRiskQA上微调的PR-Reasoner在潜在风险推理任务上显著优于基线视觉语言模型

Conclusion: 该数据集和模型为开发具有更好预见性和主动安全能力的自动驾驶系统奠定了基础，推动更智能、更具韧性的自动驾驶发展

Abstract: Ensuring safety remains a key challenge for autonomous vehicles (AVs), especially in rare and complex scenarios. One critical but understudied aspect is the \textbf{potential risk} situations, where the risk is \textbf{not yet observable} but can be inferred from subtle precursors, such as anomalous behaviors or commonsense violations. Recognizing these precursors requires strong semantic understanding and reasoning capabilities, which are often absent in current AV systems due to the scarcity of such cases in existing driving or risk-centric datasets. Moreover, current autonomous driving accident datasets often lack annotations of the causal reasoning chains behind incidents, which are essential for identifying potential risks before they become observable. To address these gaps, we introduce PotentialRiskQA, a novel vision-language dataset designed for reasoning about potential risks prior to observation. Each sample is annotated with structured scene descriptions, semantic precursors, and inferred risk outcomes. Based on this dataset, we further propose PR-Reasoner, a vision-language-model-based framework tailored for onboard potential risk reasoning. Experimental results show that fine-tuning on PotentialRiskQA enables PR-Reasoner to significantly enhance its performance on the potential risk reasoning task compared to baseline VLMs. Together, our dataset and model provide a foundation for developing autonomous systems with improved foresight and proactive safety capabilities, moving toward more intelligent and resilient AVs.

</details>


### [27] [Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary](https://arxiv.org/abs/2511.22963)
*Zhirui Liu,Kaiyang Ji,Ke Yang,Jingyi Yu,Ye Shi,Jingya Wang*

Main category: cs.RO

TL;DR: Humanoid-LLA：一种大型语言动作模型，可将自由形式语言指令映射为类人机器人的全身动作，实现语言泛化与物理可行性的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前类人机器人虽然低级运动控制有所进步，但语言条件全身控制仍面临挑战，现有方法要么指令简单，要么牺牲运动多样性或物理合理性，需要解决语言指令与物理可行动作之间的映射问题。

Method: 提出Humanoid-LLA模型，包含三个核心组件：1）统一运动词汇表，将人类和类人机器人运动基元对齐到共享离散空间；2）从特权策略蒸馏的词汇导向控制器，确保物理可行性；3）使用强化学习和动力学感知奖励的物理感知微调阶段，增强鲁棒性和稳定性。

Result: 在仿真和真实Unitree G1类人机器人上的广泛评估表明，Humanoid-LLA在保持高物理保真度的同时实现了强大的语言泛化能力，在运动自然性、稳定性和执行成功率方面优于现有语言条件控制器。

Conclusion: Humanoid-LLA成功解决了类人机器人语言条件全身控制的挑战，通过统一运动表示、物理可行控制器和物理感知微调，实现了自由形式语言指令到物理可执行动作的有效映射，为人机交互和通用具身智能提供了有前景的解决方案。

Abstract: Enabling humanoid robots to follow free-form language commands is critical for seamless human-robot interaction, collaborative task execution, and general-purpose embodied intelligence. While recent advances have improved low-level humanoid locomotion and robot manipulation, language-conditioned whole-body control remains a significant challenge. Existing methods are often limited to simple instructions and sacrifice either motion diversity or physical plausibility. To address this, we introduce Humanoid-LLA, a Large Language Action Model that maps expressive language commands to physically executable whole-body actions for humanoid robots. Our approach integrates three core components: a unified motion vocabulary that aligns human and humanoid motion primitives into a shared discrete space; a vocabulary-directed controller distilled from a privileged policy to ensure physical feasibility; and a physics-informed fine-tuning stage using reinforcement learning with dynamics-aware rewards to enhance robustness and stability. Extensive evaluations in simulation and on a real-world Unitree G1 humanoid show that Humanoid-LLA delivers strong language generalization while maintaining high physical fidelity, outperforming existing language-conditioned controllers in motion naturalness, stability, and execution success rate.

</details>


### [28] [Analytical Inverse Kinematic Solution for "Moz1" NonSRS 7-DOF Robot arm with novel arm angle](https://arxiv.org/abs/2511.22996)
*Ke Chen*

Main category: cs.RO

TL;DR: 本文为带有腕部偏移的7自由度Moz1机械臂提出了逆运动学问题的解析解，使用新颖的臂角概念提供闭式解，解决了工作空间内的算法奇异性问题


<details>
  <summary>Details</summary>
Motivation: 解决7自由度机械臂逆运动学问题，特别是处理腕部偏移的情况，传统SEW角在某些情况下无法定义，需要新的方法来处理冗余度和奇异性

Method: 提出基于新颖臂角概念的闭式解析解方法，通过新的臂角表示解决冗余度问题，处理传统SEW角无法定义的情况，并有效处理奇异性

Result: 实现了简单、快速且精确的逆运动学解，能够为每个位姿提供完整的解空间（所有16个解），解决了工作空间内的算法奇异性问题

Conclusion: 该方法为7自由度带偏移腕部机械臂提供了有效的逆运动学解决方案，解决了传统方法中的定义问题和奇异性问题，实现了完全的自运动控制

Abstract: This paper presents an analytical solution to the inverse kinematic problem(IKP) for the seven degree-of-freedom (7-DOF) Moz1 Robot Arm with offsets on wrist. We provide closed-form solutions with the novel arm angle . it allow fully self-motion and solve the problem of algorithmic singularities within the workspace. It also provides information on how the redundancy is resolved in a new arm angle representation where traditional SEW angle faied to be defined and how singularities are handled. The solution is simple, fast and exact, providing full solution space (i.e. all 16 solutions) per pose.

</details>


### [29] [Adaptive Factor Graph-Based Tightly Coupled GNSS/IMU Fusion for Robust Positionin](https://arxiv.org/abs/2511.23017)
*Elham Ahmadi,Alireza Olama,Petri Välisuo,Heidi Kuusniemi*

Main category: cs.RO

TL;DR: 提出一种基于因子图的鲁棒自适应GNSS/IMU融合框架，采用Barron损失函数处理非高斯噪声和异常值，在GNSS信号受限的城市场景中显著提升定位精度。


<details>
  <summary>Details</summary>
Motivation: GNSS信号受限环境下的可靠定位是导航系统的关键挑战。传统的紧耦合GNSS/IMU融合虽然提高了鲁棒性，但仍容易受到非高斯噪声和异常值的影响，需要更强大的鲁棒性解决方案。

Method: 提出基于因子图的鲁棒自适应融合框架，直接集成GNSS伪距测量和IMU预积分因子，并引入Barron损失函数（一种通过单个可调参数统一多个M估计器的通用鲁棒损失函数），自适应降低不可靠GNSS测量的权重。

Result: 在UrbanNav数据集上评估，相比标准因子图优化（FGO）定位误差减少高达41%，在都市峡谷环境中相比扩展卡尔曼滤波器（EKF）基线有更大改进。

Conclusion: Barron损失函数能显著增强GNSS/IMU导航在城市场景和信号受限环境中的鲁棒性，为GNSS挑战环境提供了有效的定位解决方案。

Abstract: Reliable positioning in GNSS-challenged environments remains a critical challenge for navigation systems. Tightly coupled GNSS/IMU fusion improves robustness but remains vulnerable to non-Gaussian noise and outliers. We present a robust and adaptive factor graph-based fusion framework that directly integrates GNSS pseudorange measurements with IMU preintegration factors and incorporates the Barron loss, a general robust loss function that unifies several m-estimators through a single tunable parameter. By adaptively down weighting unreliable GNSS measurements, our approach improves resilience positioning. The method is implemented in an extended GTSAM framework and evaluated on the UrbanNav dataset. The proposed solution reduces positioning errors by up to 41% relative to standard FGO, and achieves even larger improvements over extended Kalman filter (EKF) baselines in urban canyon environments. These results highlight the benefits of Barron loss in enhancing the resilience of GNSS/IMU-based navigation in urban and signal-compromised environments.

</details>


### [30] [DiskChunGS: Large-Scale 3D Gaussian SLAM Through Chunk-Based Memory Management](https://arxiv.org/abs/2511.23030)
*Casimir Feldmann,Maximum Wilder-Smith,Vaishakh Patil,Michael Oechsle,Michael Niemeyer,Keisuke Tateno,Marco Hutter*

Main category: cs.RO

TL;DR: DiskChunGS是一个可扩展的3D高斯泼溅SLAM系统，通过外存方法将场景分割成空间块，仅将活动区域保留在GPU内存中，解决了3DGS与SLAM集成时的内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在新视角合成方面表现出色且具有实时渲染能力，但与SLAM系统集成时面临根本性的可扩展性限制：受GPU内存容量约束，只能重建小规模环境。

Method: 采用外存方法，将场景分割成空间块，仅将活动区域保留在GPU内存中，非活动区域存储在磁盘上。该架构与现有的SLAM框架无缝集成，用于姿态估计和闭环检测。

Result: 在室内场景（Replica、TUM-RGBD）、城市驾驶场景（KITTI）和资源受限的Nvidia Jetson平台上进行了验证。该方法独特地完成了所有11个KITTI序列而没有内存故障，同时实现了更优的视觉质量。

Conclusion: DiskChunGS通过算法创新克服了先前3DGS SLAM方法的内存限制，证明了可以在大规模环境中实现全局一致的重建。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated impressive results for novel view synthesis with real-time rendering capabilities. However, integrating 3DGS with SLAM systems faces a fundamental scalability limitation: methods are constrained by GPU memory capacity, restricting reconstruction to small-scale environments. We present DiskChunGS, a scalable 3DGS SLAM system that overcomes this bottleneck through an out-of-core approach that partitions scenes into spatial chunks and maintains only active regions in GPU memory while storing inactive areas on disk. Our architecture integrates seamlessly with existing SLAM frameworks for pose estimation and loop closure, enabling globally consistent reconstruction at scale. We validate DiskChunGS on indoor scenes (Replica, TUM-RGBD), urban driving scenarios (KITTI), and resource-constrained Nvidia Jetson platforms. Our method uniquely completes all 11 KITTI sequences without memory failures while achieving superior visual quality, demonstrating that algorithmic innovation can overcome the memory constraints that have limited previous 3DGS SLAM methods.

</details>


### [31] [LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models](https://arxiv.org/abs/2511.23034)
*Zuolei Li,Xingyu Gao,Xiaofan Wang,Jianlong Fu*

Main category: cs.RO

TL;DR: 提出通用潜在动作学习框架，通过多帧输入和任务指令，结合未来帧重建和动作序列预测，学习可转移的潜在动作表示，在仿真和真实机器人任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉重建目标而忽略物理先验，导致学习通用表示的性能不佳。需要从大规模物体操作视频中学习可转移的潜在动作，以增强下游机器人任务的泛化能力。

Method: 提出通用潜在动作学习框架，输入任务指令和多帧图像，同时优化未来帧重建和动作序列预测。将潜在动作分解为可学习的运动和场景token，区分机器人主动运动和环境变化。将学习到的潜在动作蒸馏到最新的VLA模型中。

Result: 在仿真环境（SIMPLER和LIBERO）和真实机器人设置中均取得优异性能。在Franka机器人上，每个任务仅需10条真实轨迹，就能成功完成所有五个挑战性任务，展示了强大的少样本迁移能力。

Conclusion: 通过结合视觉重建和动作预测，能够学习包含丰富物理先验的通用潜在动作表示，实现从大规模视频到下游机器人任务的无缝迁移，显著提升机器人操作的泛化能力。

Abstract: Learning transferable latent actions from large-scale object manipulation videos can significantly enhance generalization in downstream robotics tasks, as such representations are agnostic to different robot embodiments. Existing approaches primarily rely on visual reconstruction objectives while neglecting physical priors, leading to sub-optimal performance in learning universal representations. To address these challenges, we propose a Universal Latent Action Learning framework that takes task instructions and multiple frames as inputs, and optimizes both future frame reconstruction and action sequence prediction. Unlike prior works, incorporating action predictions (e.g., gripper or hand trajectories and orientations) allows the model to capture richer physical priors such as real-world distances and orientations, thereby enabling seamless transferability to downstream tasks. We further decompose the latent actions into learnable motion and scene tokens to distinguish the robot's active movements from environmental changes, thus filtering out irrelevant dynamics. By distilling the learned latent actions into the latest VLA models, we achieve strong performance across both simulated (SIMPLER and LIBERO) and real-world robot settings. Notably, with only 10 real-world trajectories per task collected on a Franka robot, our approach successfully completes all five challenging tasks, demonstrating strong few-shot transferability in robotic manipulation.

</details>


### [32] [Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications](https://arxiv.org/abs/2511.23143)
*Enrico Saccon,Davide De Martini,Matteo Saveriano,Edoardo Lamon,Luigi Palopoli,Marco Roveri*

Main category: cs.RO

TL;DR: 提出结合大语言模型、自动规划和形式验证的新框架，用于简化马尔可夫决策过程的创建和使用，在机器人交互场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统MDP创建需要大量手动工作，限制了在机器人等领域的可扩展性和可访问性。需要一种方法来自动化MDP构建过程，减少人工干预。

Method: 1) 使用LLM从自然语言描述中提取结构化知识，构建Prolog知识库；2) 通过可达性分析自动构建MDP；3) 使用Storm模型检查器合成最优策略；4) 将策略导出为状态-动作表供执行。

Result: 在三个人机交互场景中验证了框架的有效性，能够以最小的人工努力生成可执行策略，证明了结合语言模型和形式化方法的可行性。

Conclusion: 该工作展示了语言模型与形式化方法结合在机器人概率规划中的潜力，为实现更易访问和可扩展的规划系统提供了新途径。

Abstract: We present a novel framework that integrates Large Language Models (LLMs) with automated planning and formal verification to streamline the creation and use of Markov Decision Processes (MDP). Our system leverages LLMs to extract structured knowledge in the form of a Prolog knowledge base from natural language (NL) descriptions. It then automatically constructs an MDP through reachability analysis, and synthesises optimal policies using the Storm model checker. The resulting policy is exported as a state-action table for execution. We validate the framework in three human-robot interaction scenarios, demonstrating its ability to produce executable policies with minimal manual effort. This work highlights the potential of combining language models with formal methods to enable more accessible and scalable probabilistic planning in robotics.

</details>


### [33] [Obstruction reasoning for robotic grasping](https://arxiv.org/abs/2511.23186)
*Runyu Jiao,Matteo Bortolon,Francesco Giuliari,Alice Fasoli,Sergio Povoli,Guofeng Mei,Yiming Wang,Fabio Poiesi*

Main category: cs.RO

TL;DR: UNOGrasp是一个基于学习的视觉语言模型，专门用于机器人抓取中的障碍物推理和可及性规划，通过多步推理和视觉线索提升在杂乱环境中的抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言具身推理模型在空间理解方面有所进展，但在障碍物推理和可及性规划方面仍存在局限，需要专门的方法来解决在杂乱环境中机器人抓取时的障碍物清除问题。

Method: 提出UNOGrasp模型，采用基于目标物体障碍路径的多步推理过程，结合障碍感知视觉线索，通过监督学习和强化学习的可验证推理奖励进行微调，并构建了包含10万+障碍路径标注的UNOBench数据集。

Result: 实验表明UNOGrasp在合成和真实环境中显著提升了障碍物推理能力和抓取成功率，优于通用模型和专有替代方案。

Conclusion: UNOGrasp通过专门的障碍物推理机制有效解决了杂乱环境中机器人抓取的挑战，为具身智能在复杂环境中的操作提供了新的解决方案。

Abstract: Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning. To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to unobstruct the path and grasp the target object. We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability. UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards. Moreover, we construct UNOBench, a large-scale dataset for both training and benchmarking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. Project website: https://tev-fbk.github.io/UnoGrasp/.

</details>


### [34] [Field-programmable dynamics in a soft magnetic actuator enabling true random number generation and reservoir computing](https://arxiv.org/abs/2511.23215)
*Eduardo Sergio Oliveros-Mata,Oleksandr V. Pylypovskyi,Eleonora Raimondo,Rico Illing,Yevhen Zabila,Lin Guo,Guannan Mu,Mónica Navarro López,Xu Wang,Georgios Tzortzinis,Angelos Filippatos,Gilbert Santiago Cañón Bermúdez,Francesca Garescì,Giovanni Finocchio,Denys Makarov*

Main category: cs.RO

TL;DR: 软机器人中利用复杂动力学实现新功能：设计出可调动态磁软执行器，用于真随机数生成、随机计算和时间序列预测


<details>
  <summary>Details</summary>
Motivation: 传统机电系统通常避免复杂和混沌动力学，担心磨损和可控性问题。但研究表明复杂动力学在软机器人中可能特别有利，能够提供传统驱动方法难以实现的新功能

Method: 设计并实现了具有可调动态机制的弹性磁软执行器，能够在数万次循环中运行而不疲劳。通过实验验证了这些执行器在真随机数生成、随机计算和时间序列预测中的应用

Result: 成功展示了软机器人作为物理储层能够执行Mackey-Glass时间序列预测。执行器表现出稳定的复杂动力学行为，可用于多种应用场景

Conclusion: 探索软机器人中的复杂动力学能够扩展其在软计算、人机交互和协作机器人中的应用场景，如仿生眨眼和随机语音调制等演示所示

Abstract: Complex and even chaotic dynamics, though prevalent in many natural and engineered systems, has been largely avoided in the design of electromechanical systems due to concerns about wear and controlability. Here, we demonstrate that complex dynamics might be particularly advantageous in soft robotics, offering new functionalities beyond motion not easily achievable with traditional actuation methods. We designed and realized resilient magnetic soft actuators capable of operating in a tunable dynamic regime for tens of thousands cycles without fatigue. We experimentally demonstrated the application of these actuators for true random number generation and stochastic computing. {W}e validate soft robots as physical reservoirs capable of performing Mackey--Glass time series prediction. These findings show that exploring the complex dynamics in soft robotics would extend the application scenarios in soft computing, human-robot interaction and collaborative robots as we demonstrate with biomimetic blinking and randomized voice modulation.

</details>


### [35] [SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot](https://arxiv.org/abs/2511.23300)
*Yara Mahmoud,Jeffrin Sam,Nguyen Khang,Marcelino Fernando,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Haris Khan,Artem Lykov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SafeHumanoid：基于视觉语言模型和检索增强生成的仿人机器人阻抗控制框架，通过场景语义理解自适应调整刚度和速度参数，提升人机交互安全性


<details>
  <summary>Details</summary>
Motivation: 安全可信的人机交互需要机器人不仅能完成任务，还要根据场景上下文和人类接近程度调节阻抗和速度参数。现有方法缺乏对场景语义的理解和自适应调节能力。

Method: 提出SafeHumanoid系统：1）使用以自我为中心的视觉管道处理场景；2）通过结构化视觉语言模型提示分析场景；3）利用检索增强生成技术匹配已验证场景数据库；4）通过逆运动学将语义信息映射到关节级阻抗命令。

Result: 在桌面操作任务（擦拭、物体交接、液体倾倒）中测试，系统能够根据上下文自适应调整刚度、阻尼和速度参数，在保持任务成功率的同时提高安全性。当前推理延迟达1.4秒，限制在高度动态环境中的响应性。

Conclusion: 语义基础的阻抗控制是实现更安全、符合标准的仿人机器人协作的可行路径。虽然当前延迟限制了动态环境应用，但证明了语义理解在安全人机交互中的价值。

Abstract: Safe and trustworthy Human Robot Interaction (HRI) requires robots not only to complete tasks but also to regulate impedance and speed according to scene context and human proximity. We present SafeHumanoid, an egocentric vision pipeline that links Vision Language Models (VLMs) with Retrieval-Augmented Generation (RAG) to schedule impedance and velocity parameters for a humanoid robot. Egocentric frames are processed by a structured VLM prompt, embedded and matched against a curated database of validated scenarios, and mapped to joint-level impedance commands via inverse kinematics. We evaluate the system on tabletop manipulation tasks with and without human presence, including wiping, object handovers, and liquid pouring. The results show that the pipeline adapts stiffness, damping, and speed profiles in a context-aware manner, maintaining task success while improving safety. Although current inference latency (up to 1.4 s) limits responsiveness in highly dynamic settings, SafeHumanoid demonstrates that semantic grounding of impedance control is a viable path toward safer, standard-compliant humanoid collaboration.

</details>


### [36] [From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products](https://arxiv.org/abs/2511.23407)
*Jan Baumgärtner,Malte Hansjosten,David Hald,Adrian Hauptmannl,Alexander Puchta,Jürgen Fleischer*

Main category: cs.RO

TL;DR: 提出将拆卸任务建模为部分可观测马尔可夫决策过程（POMDP），开发基于CAD数据、机器人能力和检测结果的概率规划框架，通过强化学习和贝叶斯滤波处理EOL产品的不确定性。


<details>
  <summary>Details</summary>
Motivation: 支持循环经济需要机器人系统能够拆卸报废产品，但现有方法假设确定性且完全可观测的产品模型，而实际EOL产品常因磨损、腐蚀或未记录的维修而偏离原始设计，存在不确定性。

Method: 1. 将拆卸任务数学建模为POMDP，隐藏变量表示不确定的结构或物理属性；2. 提出任务与运动规划框架，从CAD数据、机器人能力和检测结果自动推导POMDP模型；3. 采用强化学习方法近似求解，结合检测先验的随机动作结果；4. 使用贝叶斯滤波器在执行过程中持续维护对潜在EOL状态的信念。

Result: 在两种机器人系统上的三个产品测试表明，该概率规划框架在平均拆卸时间和方差方面优于确定性基线方法，能够跨不同机器人设置泛化，并成功适应CAD模型的偏差（如缺失或卡住零件）。

Conclusion: 将拆卸任务建模为POMDP并采用概率规划框架能够有效处理EOL产品的不确定性，提高机器人拆卸系统的鲁棒性和适应性，为循环经济中的自动化拆卸提供了更实用的解决方案。

Abstract: To support the circular economy, robotic systems must not only assemble new products but also disassemble end-of-life (EOL) ones for reuse, recycling, or safe disposal. Existing approaches to disassembly sequence planning often assume deterministic and fully observable product models, yet real EOL products frequently deviate from their initial designs due to wear, corrosion, or undocumented repairs. We argue that disassembly should therefore be formulated as a Partially Observable Markov Decision Process (POMDP), which naturally captures uncertainty about the product's internal state. We present a mathematical formulation of disassembly as a POMDP, in which hidden variables represent uncertain structural or physical properties. Building on this formulation, we propose a task and motion planning framework that automatically derives specific POMDP models from CAD data, robot capabilities, and inspection results. To obtain tractable policies, we approximate this formulation with a reinforcement-learning approach that operates on stochastic action outcomes informed by inspection priors, while a Bayesian filter continuously maintains beliefs over latent EOL conditions during execution. Using three products on two robotic systems, we demonstrate that this probabilistic planning framework outperforms deterministic baselines in terms of average disassembly time and variance, generalizes across different robot setups, and successfully adapts to deviations from the CAD model, such as missing or stuck parts.

</details>
