<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 提出基于自动机的强化学习框架，在MDP和POMDP中合成满足MITL时序逻辑约束的策略，通过时间限制确定性广义Büchi自动机和奖励结构确保时间正确性。


<details>
  <summary>Details</summary>
Motivation: 动态不确定环境中的机器人系统需要满足复杂时序约束的规划器，但将MITL时序逻辑与强化学习结合面临随机动态和部分可观测性的挑战。

Method: 将MITL公式转换为时间限制确定性广义Büchi自动机，与底层决策过程同步构建产品时间模型，设计简单但表达力强的奖励结构，使用Q-learning学习策略。

Result: 在三个仿真研究中验证：5×5网格世界MDP、10×10网格世界POMDP和办公室服务机器人场景，框架能学习满足严格时间约束的策略，可扩展到更大状态空间，在部分可观测环境中有效。

Conclusion: 该框架为时间关键和不确定环境中的可靠机器人规划提供了潜力，能够一致地学习满足严格时间约束的策略，并在部分可观测环境中保持有效性。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [2] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: CDGS通过将搜索嵌入扩散去噪过程，解决了组合生成模型中的模式平均问题，在机器人操作、全景图像和长视频生成中实现全局一致性规划。


<details>
  <summary>Details</summary>
Motivation: 组合生成模型在建模长时程任务分布方面具有优势，但当局部分布是多模态时，现有组合方法会平均不兼容的模式，导致规划既不可行也不连贯。

Method: CDGS将搜索直接嵌入扩散去噪过程，通过基于种群的采样探索局部模式组合，使用基于似然的过滤剪枝不可行候选，并通过重叠段间的迭代重采样强制全局一致性。

Result: 在7个机器人操作任务上达到oracle性能，优于缺乏组合性或需要长时程训练数据的基线方法，并能跨领域泛化到文本引导的全景图像和长视频生成。

Conclusion: CDGS有效解决了组合生成模型中的模式平均问题，通过局部到全局的消息传递实现了连贯的长时程规划，在多个领域展示了优越性能。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [3] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: SLAP系统为无人机在垂直树干上实现轻柔栖息和故障恢复，通过视觉检测、IMU故障检测、姿态控制、近距离光学检测和弹性抓取器，在1.2kg四旋翼上实现75%栖息成功率和100%故障恢复。


<details>
  <summary>Details</summary>
Motivation: 现有垂直表面栖息方案主要关注轻量化机械设计，缺乏系统级集成，且通常需要高速、激进的着陆操作，对搭载敏感电子设备的无人机存在危险。需要一种适合较大型无人机、能轻柔栖息并能从栖息失败中恢复的系统。

Method: 开发SLAP系统，包含：1) 基于视觉的栖息点检测器；2) IMU基础的栖息故障检测器；3) 用于轻柔栖息的姿态控制器；4) 光学近距离检测系统；5) 基于市售slapbands的快速主动弹性抓取器（带微刺）。在1.2kg商用四旋翼无人机上进行改装和验证。

Result: 室内自主飞行实验中，在真实橡树段上进行20次飞行测试，达到75%的栖息成功率。在2次诱导故障的飞行中，实现了100%的栖息故障恢复率。

Conclusion: SLAP系统为较大型无人机提供了一种能在垂直树干上轻柔栖息并能从栖息失败中恢复的有效方案，通过系统级集成解决了现有方案在安全性和可靠性方面的不足。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [4] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: 本文提出了一种分层优化方法，用于自动化车辆喷漆过程中多机械臂的路径规划，解决了传统手工设计耗时且难以应用现有机器人路径规划技术的问题。


<details>
  <summary>Details</summary>
Motivation: 在车辆生产工厂中，喷漆过程需要多个机械臂同时对传送带上的车身进行喷漆。目前喷漆路径设计仍是工程师耗时的手动任务，需要自动化和缩短设计时间。喷漆过程的独特约束阻碍了传统机器人路径规划技术（如焊接中使用的技术）的直接应用。

Method: 将喷漆路径设计建模为分层优化问题：上层子问题类似于车辆路径问题（VRP），负责分配车身区域给机械臂；下层子问题涉及详细的路径规划。该方法允许在每层使用不同的优化算法，并通过设计变量表示、约束、修复算子和初始化过程，灵活处理车辆喷漆过程特有的约束。

Result: 在三种商用车辆模型上的实验表明，所提出的方法能够自动设计出满足所有车辆喷漆约束的路径，其质量与工程师手动创建的路径相当。

Conclusion: 该分层优化方法成功解决了车辆喷漆路径设计的自动化问题，能够生成满足所有工艺约束的高质量路径，显著减少了设计时间，为车辆生产工厂的喷漆过程自动化提供了有效解决方案。

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [5] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: WiCHINS：一种结合轮载和车体惯性传感器的轮式底盘惯性导航系统，用于在GNSS受限或光照条件差的环境下实现精确的纯惯性导航。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号受限或光照条件恶劣的实际场景中，自主车辆和轮式机器人的导航解决方案可能只能依赖惯性传感器，而惯性测量误差会导致随时间漂移的问题。

Method: 提出WiCHINS系统，将轮载惯性传感器与车体惯性传感器结合，采用三阶段框架，每个阶段使用专用的扩展卡尔曼滤波器，充分利用轮子和车身位置的优势进行估计。

Result: 使用5个惯性测量单元、总记录时间228.6分钟的数据集进行评估，与4个其他惯性基线方法比较，平均位置误差为11.4米，占平均行驶距离的2.4%（使用两个轮子和一个车体惯性测量单元）。

Conclusion: 该方法能够在具有挑战性的环境中实现鲁棒导航，有助于缩小纯惯性导航的性能差距。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [6] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出可更换夹爪头的抓取系统，用于处理杂乱食品包装中的重量控制问题，针对鲑鱼子和意大利面两种柔性食品设计了专用夹爪头，实现了80%和95%以上的重量控制精度。


<details>
  <summary>Details</summary>
Motivation: 食品包装行业面临快速变化的食品种类和重量处理需求，特别是从单件食品到柔性、长条状、杂乱堆积的食品。传统抓取系统难以处理这类杂乱食品的重量控制问题。

Method: 设计可更换夹爪头的抓取系统，包括专用食品夹爪头（bits）和皮带更换系统。针对鲑鱼子（粘性颗粒食品）和意大利面（长条状粘性杂乱食品）两种代表性食品设计了专用夹爪头，实现特定重量的抓取和投放。

Result: 抓取系统成功抓取了意大利面和鲑鱼子，重量控制投放精度分别超过80%和95%。系统还展示了快速更换不同夹爪头的能力，能够处理多种食品类型。

Conclusion: 可更换夹爪头的抓取系统能够有效处理杂乱食品包装中的重量控制问题，针对不同食品特性设计专用夹爪头可实现高精度重量控制，系统具有快速切换能力，适合食品包装行业的多样化需求。

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [7] [LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration](https://arxiv.org/abs/2601.00555)
*Abu Hanif Muhammad Syarubany,Farhan Zaki Rahmani,Trio Widianto*

Main category: cs.RO

TL;DR: 提出基于LLM的端到端机器人探索系统，用于室内购物任务，在Gazebo仿真和真实走廊环境中评估，通过语义地图构建和模块化运动控制实现多店铺导航和物品抓取。


<details>
  <summary>Details</summary>
Motivation: 解决室内购物场景中机器人自主探索、语义理解和任务执行的问题，通过LLM实现自然语言指令到机器人动作的转换，同时保持系统的模块化和可调试性。

Method: 1) 增量构建轻量级语义地图，检测路口标识牌并存储方向-POI关系；2) 使用AprilTags作为可重复的锚点进行定位和对齐；3) LLM根据自然语言购物请求在每个路口生成约束离散动作；4) ROS有限状态主控制器通过门控模块化运动基元执行决策。

Result: 集成系统能够从用户指令到多店铺导航和物品抓取执行端到端任务，同时通过基于文本的地图和记录决策历史保持模块化和可调试性，在仿真和真实环境中均得到验证。

Conclusion: 提出的LLM-based agentic exploration系统成功实现了室内购物任务的端到端执行，展示了LLM在机器人语义理解和决策中的有效性，同时保持了系统的模块化架构和可调试性。

Abstract: This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.

</details>


### [8] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: 本文提出优先级感知的多机器人覆盖路径规划（PA-MCPP）问题，通过两阶段框架优化优先级区域的加权延迟和总完成时间。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设所有区域重要性相同，但在实际应用中某些区域需要优先覆盖，现有方法无法有效处理这种优先级需求。

Method: 提出可扩展的两阶段框架：1）贪心区域分配结合局部搜索和基于生成树的路径规划；2）斯坦纳树引导的剩余覆盖。

Result: 实验表明，该方法相比标准MCPP基线显著降低了优先级加权延迟，同时保持了有竞争力的总完成时间，且能有效通过调整优先级权重控制区域覆盖行为。

Conclusion: PA-MCPP框架能够有效处理优先级区域覆盖问题，在减少优先级加权延迟的同时保持系统效率，为实际应用中的多机器人覆盖任务提供了更灵活的解决方案。

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [9] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出一个用于大型机器人的安全目标到达控制框架，通过模块化设计结合强化学习规划、深度学习建模和鲁棒自适应控制，确保在易滑地形上的稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中需要大量探索状态-动作空间，期间行为可能不安全，这限制了其在复杂地形上运行的大型机器人中的应用。需要设计一个安全的目标到达控制框架来解决这一问题。

Method: 将系统分解为紧密耦合的功能模块：1)实时视觉姿态估计提供准确机器人状态；2)强化学习运动规划器生成平滑运动指令；3)监督深度学习模型捕获机器人复杂动力学；4)基于模型的鲁棒自适应控制器确保轮子跟踪运动指令；5)数学安全监督器监控机器人安全。

Result: 该框架保证了驱动系统的均匀指数稳定性和整个操作的安全性。在6000公斤机器人上的不同场景实验证实了该框架的有效性。

Conclusion: 提出的模块化框架成功解决了大型机器人在不稳定地形上安全应用强化学习的问题，通过结合多种技术确保了系统的稳定性和安全性。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [10] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 提出了一种三维地形跟随的区域覆盖路径规划算法，能够生成多条相邻路径，在保持机械工作宽度间距的同时，在特定工作高度上跟随地形起伏。


<details>
  <summary>Details</summary>
Motivation: 在农业等实际应用中，需要在复杂三维地形上进行高效的区域覆盖作业，而传统的二维路径规划无法适应地形起伏，需要开发能够跟随地形的三维路径规划算法。

Method: 使用逆距离加权方法生成均匀间距的高程数据，结合局部搜索算法，生成多条相邻路径，这些路径在保持机械工作宽度间距的同时，在特定工作高度上跟随地形起伏。

Result: 算法在实际农业场景的三维数据上进行了验证，成功生成了适应地形起伏的区域覆盖路径，展示了算法的可行性和有效性。

Conclusion: 该三维地形跟随区域覆盖路径规划算法能够有效处理复杂地形，相比二维算法具有更好的适应性，在农业等实际应用中具有重要价值。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [11] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 该研究提出了RoboReward数据集和基准，用于评估视觉语言模型在机器人任务中的奖励建模能力，并训练了4B/8B参数的奖励模型，在真实机器人强化学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，获取有效的奖励函数通常需要大量人工标注或手工设计的目标函数，这既耗时又脆弱。视觉语言模型有潜力作为自动奖励模型，但它们在真实机器人任务中的有效性尚未得到充分验证。

Method: 1) 构建RoboReward数据集和基准，基于Open X-Embodiment和RoboArena的大规模真实机器人数据；2) 提出负样本数据增强流程，通过反事实重标注和时间裁剪生成校准的负样本和接近成功样本；3) 训练4B和8B参数的视觉语言奖励模型。

Result: 1) 评估显示现有视觉语言模型在所有任务中表现不均，有较大改进空间；2) 训练的4B/8B参数模型在短视界机器人任务中优于更大的视觉语言模型；3) 8B参数奖励模型在真实机器人强化学习中大幅优于Gemini Robotics-ER 1.5，显著缩小了与人工提供奖励的差距。

Conclusion: 该工作证明了视觉语言模型作为机器人奖励函数的有效性，提出的RoboReward数据集和基准为未来研究提供了重要基础，训练的小型模型在真实机器人强化学习中表现出色，为自动奖励建模提供了有前景的方向。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [12] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: DefVINS是一个视觉惯性里程计框架，通过将刚性IMU锚定状态与非刚性变形图分离，解决可变形场景中的VIO问题，利用可观测性分析指导变形激活策略，提高非刚性环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 可变形场景违反了传统视觉惯性里程计的刚性假设，导致容易过拟合局部非刚性运动或在变形主导视觉视差时产生严重漂移，需要新的方法来处理非刚性环境下的状态估计问题。

Method: 提出DefVINS框架，将刚性IMU锚定状态与非刚性变形图表示的变形分离。系统先用标准VIO程序初始化，固定重力、速度和IMU偏差，然后根据估计条件逐步激活非刚性自由度。包含可观测性分析来表征惯性测量如何约束刚性运动，并指导基于条件的激活策略以防止在激励不足时的病态更新。

Result: 消融研究表明，将惯性约束与可观测性感知的变形激活相结合，在非刚性环境下提高了鲁棒性。可观测性分析显示惯性测量使原本不可观测的模式在存在变形时变得可识别。

Conclusion: DefVINS通过显式分离刚性状态和非刚性变形，结合惯性约束和可观测性指导的激活策略，有效解决了可变形场景中的视觉惯性里程计问题，提高了在非刚性环境下的估计鲁棒性。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [13] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 研究探索儿童对机器人重复错误的反应，发现儿童与成人既有相似调整行为，也有更多脱离互动行为，但错误不影响儿童对机器人的感知。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探讨成人对连续机器人错误的反应，但儿童对此的反应尚不明确。本研究旨在探索儿童对机器人社交错误和性能错误的反应，特别是重复对话错误。

Method: 研究复制了Liu等人的连续机器人失败范式，招募59名8-10岁儿童参与。儿童与机器人互动，机器人连续三次无法理解他们的提示。通过视频记录和分析儿童的行为反应。

Result: 儿童反应与成人既有相似也有差异：相似之处包括调整提示、改变语气、情绪化非语言反应增加；差异在于儿童表现出更多脱离行为（如暂时忽略机器人或寻求成人帮助）。错误不影响儿童对机器人的感知。

Conclusion: 儿童对机器人错误表现出更灵活的对话期望，这些发现有助于为年轻用户设计更有效、更适合发展阶段的机器人交互系统。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>
