<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Wake Vectoring for Efficient Morphing Flight](https://arxiv.org/abs/2512.05211)
*Ioannis Mandralis,Severin Schumacher,Morteza Gharib*

Main category: cs.RO

TL;DR: ATMO机器人通过被动尾流转向机制，在变形过程中恢复垂直推力，解决了变形飞行机器人因推进器倾斜导致的推力损失问题。


<details>
  <summary>Details</summary>
Motivation: 变形飞行机器人具有在复杂环境中导航、栖息以及空中与地面运动无缝转换的潜力，但飞行中变形面临关键气动挑战：倾斜推进器实现形状变化会减少垂直推力，影响稳定性和控制能力。

Method: 提出被动尾流转向机制，集成到新型机器人系统ATMO中。内部偏转器拦截并重新引导转子尾流向下，被动地引导原本会被浪费的气流动量。这是一种无需电子元件的解决方案。

Result: 在原本不会产生有用推力的配置中，实现了高达40%的垂直推力恢复，显著扩展了变形过程中的悬停和机动能力。

Conclusion: 研究为变形飞行机器人设计指出了新方向：受火箭和飞机推力转向启发的被动气动结构，能够实现高效、敏捷的飞行，而无需增加机械复杂性。

Abstract: Morphing aerial robots have the potential to transform autonomous flight, enabling navigation through cluttered environments, perching, and seamless transitions between aerial and terrestrial locomotion. Yet mid-flight reconfiguration presents a critical aerodynamic challenge: tilting propulsors to achieve shape change reduces vertical thrust, undermining stability and control authority. Here, we introduce a passive wake vectoring mechanism that recovers lost thrust during morphing. Integrated into a novel robotic system, Aerially Transforming Morphobot (ATMO), internal deflectors intercept and redirect rotor wake downward, passively steering airflow momentum that would otherwise be wasted. This electronics-free solution achieves up to a 40% recovery of vertical thrust in configurations where no useful thrust would otherwise be produced, substantially extending hover and maneuvering capabilities during transformation. Our findings highlight a new direction for morphing aerial robot design, where passive aerodynamic structures, inspired by thrust vectoring in rockets and aircraft, enable efficient, agile flight without added mechanical complexity.

</details>


### [2] [Search at Scale: Improving Numerical Conditioning of Ergodic Coverage Optimization for Multi-Scale Domains](https://arxiv.org/abs/2512.05229)
*Yanis Lahrach,Christian Hughes,Ian Abraham*

Main category: cs.RO

TL;DR: 提出了一种基于最大均值差异度量的尺度无关自适应遍历覆盖优化方法，解决现有遍历覆盖规划方法对问题空间数值缩放敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有遍历覆盖规划方法虽然能适应多种几何覆盖问题，但对问题空间的数值缩放高度敏感，优化公式在尺度变化时变得脆弱且数值不稳定，特别是在非线性约束条件下。

Method: 基于最大均值差异度量开发尺度无关自适应遍历覆盖优化方法，允许优化器求解微分约束的尺度，同时退火超参数以适应问题域并确保物理一致性；还推导了对数空间中的遍历度量变体以改善数值条件。

Result: 与现有覆盖规划方法进行比较，并在多种覆盖问题上展示了该方法的实用性。

Conclusion: 提出的方法解决了遍历覆盖规划中的尺度敏感性问题，通过自适应优化和数值条件改进，能够在不同尺度下保持稳定性能。

Abstract: Recent methods in ergodic coverage planning have shown promise as tools that can adapt to a wide range of geometric coverage problems with general constraints, but are highly sensitive to the numerical scaling of the problem space. The underlying challenge is that the optimization formulation becomes brittle and numerically unstable with changing scales, especially under potentially nonlinear constraints that impose dynamic restrictions, due to the kernel-based formulation. This paper proposes to address this problem via the development of a scale-agnostic and adaptive ergodic coverage optimization method based on the maximum mean discrepancy metric (MMD). Our approach allows the optimizer to solve for the scale of differential constraints while annealing the hyperparameters to best suit the problem domain and ensure physical consistency. We also derive a variation of the ergodic metric in the log space, providing additional numerical conditioning without loss of performance. We compare our approach with existing coverage planning methods and demonstrate the utility of our approach on a wide range of coverage problems.

</details>


### [3] [Invariance Co-training for Robot Visual Generalization](https://arxiv.org/abs/2512.05230)
*Jonathan Yang,Chelsea Finn,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 该论文提出通过辅助任务（状态相似性和观测扰动不变性）结合机器人演示数据和合成视觉数据，提升机器人策略对相机视角、光照和干扰物变化的泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前大规模机器人策略对观测变化（如相机视角、光照、干扰物）的泛化能力有限，主要原因是需要大量多样性数据来覆盖这些准静态变化轴，而现有机器人数据集在这些方面的变化不够丰富

Method: 引入两个辅助任务：状态相似性和观测扰动不变性，应用于演示数据和静态视觉数据；结合昂贵的机器人演示数据和廉价的合成视觉数据（来自非物理模拟如Unreal Engine）进行协同训练

Result: 该方法显著提升了对未见过的相机视角、光照配置和干扰物条件的泛化能力，性能比现有生成式增强方法提高了18%

Conclusion: 通过辅助任务结合机器人演示数据和合成视觉数据的协同训练，可以有效提升机器人策略对观测变化的鲁棒性和泛化能力

Abstract: Reasoning from diverse observations is a fundamental capability for generalist robot policies to operate in a wide range of environments. Despite recent advancements, many large-scale robotic policies still remain sensitive to key sources of observational variation such as changes in camera perspective, lighting, and the presence of distractor objects. We posit that the limited generalizability of these models arises from the substantial diversity required to robustly cover these quasistatic axes, coupled with the current scarcity of large-scale robotic datasets that exhibit rich variation across them. In this work, we propose to systematically examine what robots need to generalize across these challenging axes by introducing two key auxiliary tasks, state similarity and invariance to observational perturbations, applied to both demonstration data and static visual data. We then show that via these auxiliary tasks, leveraging both more-expensive robotic demonstration data and less-expensive, visually rich synthetic images generated from non-physics-based simulation (for example, Unreal Engine) can lead to substantial increases in generalization to unseen camera viewpoints, lighting configurations, and distractor conditions. Our results demonstrate that co-training on this diverse data improves performance by 18 percent over existing generative augmentation methods. For more information and videos, please visit https://invariance-cotraining.github.io

</details>


### [4] [XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots](https://arxiv.org/abs/2512.05270)
*Tianyi Wang,Jiseop Byeon,Ahmad Yehia,Huihai Wang,Yiming Xu,Tianyi Zeng,Ziran Wang,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: XR-DT框架：扩展现实增强的数字孪生系统，通过虚拟、增强和混合现实层融合实时传感器数据、模拟环境和人类反馈，实现人机双向理解，提升移动机器人在共享工作空间中的安全、高效和可解释交互。


<details>
  <summary>Details</summary>
Motivation: 随着移动机器人在共享工作空间中与人类协作的增加，确保安全、高效和可解释的人机交互成为迫切需求。现有研究主要关注人类行为预测，但人类如何感知、解释和信任机器人的推理能力研究不足，阻碍了在安全关键和社会嵌入环境中的部署。

Method: 提出XR-DT（扩展现实增强数字孪生）框架，包含虚拟现实、增强现实和混合现实分层架构，融合实时传感器数据、Unity游戏引擎模拟环境和可穿戴AR设备捕获的人类反馈。系统采用统一扩散策略进行上下文感知任务适应，设计思维链提示机制让多模态大语言模型推理人类指令和环境上下文，并利用基于AutoGen的多智能体协调层增强动态任务中的鲁棒性和协作能力。

Result: 初步实验结果显示，系统能够准确预测人类和机器人的轨迹，验证了XR-DT框架在人机交互任务中的有效性。

Conclusion: 通过将人类意图、环境动态和机器人认知嵌入XR-DT框架，该系统实现了可解释、可信赖和自适应的人机交互，为安全关键和社会嵌入环境中的机器人部署提供了有效解决方案。

Abstract: As mobile robots increasingly operate alongside humans in shared workspaces, ensuring safe, efficient, and interpretable Human-Robot Interaction (HRI) has become a pressing challenge. While substantial progress has been devoted to human behavior prediction, limited attention has been paid to how humans perceive, interpret, and trust robots' inferences, impeding deployment in safety-critical and socially embedded environments. This paper presents XR-DT, an eXtended Reality-enhanced Digital Twin framework for agentic mobile robots, that bridges physical and virtual spaces to enable bi-directional understanding between humans and robots. Our hierarchical XR-DT architecture integrates virtual-, augmented-, and mixed-reality layers, fusing real-time sensor data, simulated environments in the Unity game engine, and human feedback captured through wearable AR devices. Within this framework, we design an agentic mobile robot system with a unified diffusion policy for context-aware task adaptation. We further propose a chain-of-thought prompting mechanism that allows multimodal large language models to reason over human instructions and environmental context, while leveraging an AutoGen-based multi-agent coordination layer to enhance robustness and collaboration in dynamic tasks. Initial experimental results demonstrate accurate human and robot trajectory prediction, validating the XR-DT framework's effectiveness in HRI tasks. By embedding human intention, environmental dynamics, and robot cognition into the XR-DT framework, our system enables interpretable, trustworthy, and adaptive HRI.

</details>


### [5] [Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture](https://arxiv.org/abs/2512.05292)
*Fan Zhang,Jinfeng Chen,Joseph J. B. Mvogo Ahanda,Hanz Richter,Ge Lv,Bin Hu,Qin Lin*

Main category: cs.RO

TL;DR: 提出了一种用于工业机械臂的外环控制层附加模块，结合扰动抑制控制和鲁棒控制屏障函数，在存在内环控制器不完善、不可修改、不确定以及动态模型显著不确定的情况下，实现高性能跟踪和安全控制。


<details>
  <summary>Details</summary>
Motivation: 商业机器人系统中，内环扭矩控制器通常不可修改，而外环控制器对用户开放。当内环控制器不完善、不可修改且不确定，同时动态模型存在显著不确定性时，需要一种易于集成、能同时保证高性能跟踪和安全控制的外环解决方案。

Method: 在外环控制层开发了一个附加模块，结合了扰动抑制控制和鲁棒控制屏障函数。该方法能够处理内环控制器的不确定性和动态模型的不确定性，同时保证系统的稳定性和安全性。

Result: 通过稳定性分析、形式化安全保证证明和PUMA工业机械臂硬件实验验证，该方法在实现简单性、鲁棒性、跟踪精度和安全性方面优于现有技术。

Conclusion: 提出的外环控制层附加模块为工业机械臂提供了一种易于集成、高性能且安全的控制解决方案，特别适用于内环控制器不可修改且动态模型不确定的商用机器人系统。

Abstract: In commercial robotic systems, it is common to encounter a closed inner-loop torque controller that is not user-modifiable. However, the outer-loop controller, which sends kinematic commands such as position or velocity for the inner-loop controller to track, is typically exposed to users. In this work, we focus on the development of an easily integrated add-on at the outer-loop layer by combining disturbance rejection control and robust control barrier function for high-performance tracking and safe control of the whole dynamic system of an industrial manipulator. This is particularly beneficial when 1) the inner-loop controller is imperfect, unmodifiable, and uncertain; and 2) the dynamic model exhibits significant uncertainty. Stability analysis, formal safety guarantee proof, and hardware experiments with a PUMA robotic manipulator are presented. Our solution demonstrates superior performance in terms of simplicity of implementation, robustness, tracking precision, and safety compared to the state of the art. Video: https://youtu.be/zw1tanvrV8Q

</details>


### [6] [Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite](https://arxiv.org/abs/2512.05303)
*Christian Westerdahl,Jonas Poulsen,Daniel Holmelund,Peter Nicholas Hansen,Fletcher Thompson,Roberto Galeazzi*

Main category: cs.RO

TL;DR: 提出了一种不依赖GNSS的统一海底到天空测绘系统，融合LiDAR-IMU和正交安装的双前视声纳，通过改进的LIO-SAM框架实现实时3D地图构建。


<details>
  <summary>Details</summary>
Motivation: 现有海底到天空测绘系统要么依赖易受干扰的GNSS，要么使用昂贵的测深声纳。需要一种不依赖GNSS、成本效益高的统一测绘系统来增强海上基础设施的态势感知能力。

Method: 1. 使用正交安装的双前视声纳(FLS)进行声学数据采集；2. 扩展正交宽孔径融合技术处理任意声纳间平移；3. 从每个FLS提取前沿形成线扫描；4. 改进LIO-SAM框架，融合立体声纳3D点和前沿线扫描数据；5. 通过运动插值位姿实现稀疏声学更新的连续因子图构建。

Result: 在哥本哈根Belvederekanalen的真实数据验证中，系统实现实时运行：约2.65Hz地图更新频率和约2.85Hz里程计频率，生成了跨越空气-水领域的统一3D模型。

Conclusion: 该系统成功实现了不依赖GNSS的海底到天空统一测绘，通过融合LiDAR-IMU和正交声纳数据，在真实环境中展示了实时运行能力，为海上基础设施监测提供了可靠解决方案。

Abstract: Critical maritime infrastructure increasingly demands situational awareness both above and below the surface, yet existing ''seabed-to-sky'' mapping pipelines either rely on GNSS (vulnerable to shadowing/spoofing) or expensive bathymetric sonars. We present a unified, GNSS-independent mapping system that fuses LiDAR-IMU with a dual, orthogonally mounted Forward Looking Sonars (FLS) to generate consistent seabed-to-sky maps from an Autonomous Surface Vehicle. On the acoustic side, we extend orthogonal wide-aperture fusion to handle arbitrary inter-sonar translations (enabling heterogeneous, non-co-located models) and extract a leading edge from each FLS to form line-scans. On the mapping side, we modify LIO-SAM to ingest both stereo-derived 3D sonar points and leading-edge line-scans at and between keyframes via motion-interpolated poses, allowing sparse acoustic updates to contribute continuously to a single factor-graph map. We validate the system on real-world data from Belvederekanalen (Copenhagen), demonstrating real-time operation with approx. 2.65 Hz map updates and approx. 2.85 Hz odometry while producing a unified 3D model that spans air-water domains.

</details>


### [7] [State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning](https://arxiv.org/abs/2512.05335)
*Yuxiang Liu,Shengfan Cao*

Main category: cs.RO

TL;DR: 论文研究视觉域迁移在端到端模仿学习中的应用，针对目标域数据严格离策略、无专家指导且稀缺的挑战性场景。理论分析表明目标域模仿损失可被源域损失加状态条件潜在KL散度上界约束，据此提出状态条件对抗学习框架，通过判别器估计条件KL项对齐潜在分布。在基于BARC-CARLA模拟器的视觉多样化自动驾驶环境中验证了方法的鲁棒迁移和高效样本利用能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决端到端模仿学习中的视觉域迁移问题，特别是在目标域数据严格离策略、无专家指导且稀缺的现实挑战性场景下。传统方法难以在这种数据受限条件下实现有效的跨域知识迁移。

Method: 提出状态条件对抗学习框架：首先理论分析证明目标域模仿损失可被源域损失加状态条件潜在KL散度上界约束；然后设计基于判别器的条件KL项估计器，在系统状态条件下对齐源域和目标域的潜在分布；采用离策略对抗学习框架实现视觉域间的鲁棒迁移。

Result: 在基于BARC-CARLA模拟器构建的视觉多样化自动驾驶环境中进行实验，结果表明SCAL方法实现了鲁棒的域迁移和强大的样本效率，在目标域数据稀缺条件下仍能有效学习。

Conclusion: 通过理论分析和实验验证，状态条件对抗学习框架成功解决了视觉域迁移在端到端模仿学习中的挑战，特别是在目标域数据离策略、无专家指导且稀缺的困难条件下，为实现现实世界中的视觉域自适应提供了有效解决方案。

Abstract: We study visual domain transfer for end-to-end imitation learning in a realistic and challenging setting where target-domain data are strictly off-policy, expert-free, and scarce. We first provide a theoretical analysis showing that the target-domain imitation loss can be upper bounded by the source-domain loss plus a state-conditional latent KL divergence between source and target observation models. Guided by this result, we propose State- Conditional Adversarial Learning, an off-policy adversarial framework that aligns latent distributions conditioned on system state using a discriminator-based estimator of the conditional KL term. Experiments on visually diverse autonomous driving environments built on the BARC-CARLA simulator demonstrate that SCAL achieves robust transfer and strong sample efficiency.

</details>


### [8] [Spatiotemporal Tubes for Differential Drive Robots with Model Uncertainty](https://arxiv.org/abs/2512.05495)
*Ratnangshu Das,Ahan Basu,Christos Verginis,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出基于时空管道的控制框架，用于具有动态不确定性和外部扰动的差动驱动移动机器人，保证满足时间可达-避障-停留规范。


<details>
  <summary>Details</summary>
Motivation: 为差动驱动移动机器人在动态不确定性和外部扰动下，提供能够满足复杂时空规范（T-RAS）的鲁棒控制框架，解决现有方法在计算效率、鲁棒性和准确性方面的不足。

Method: 1. 使用圆形时空管道定义动态安全走廊；2. 开发基于采样的合成算法构建满足时序和安全约束的可行管道；3. 设计解析的闭式无近似控制律确保机器人保持在管道内。

Result: 提出的控制器计算高效、对扰动和模型不确定性鲁棒、无需模型近似或在线优化。仿真验证表明在鲁棒性、准确性和计算效率方面优于现有方法。

Conclusion: 该框架为差动驱动移动机器人提供了一种能够满足复杂时空规范的有效控制方案，具有理论保证和实际应用价值。

Abstract: This paper presents a Spatiotemporal Tube (STT)-based control framework for differential-drive mobile robots with dynamic uncertainties and external disturbances, guaranteeing the satisfaction of Temporal Reach-Avoid-Stay (T-RAS) specifications. The approach employs circular STT, characterized by smoothly time-varying center and radius, to define dynamic safe corridors that guide the robot from the start region to the goal while avoiding obstacles. In particular, we first develop a sampling-based synthesis algorithm to construct a feasible STT that satisfies the prescribed timing and safety constraints with formal guarantees. To ensure that the robot remains confined within this tube, we then design analytically a closed-form, approximation-free control law. The resulting controller is computationally efficient, robust to disturbances and {model uncertainties}, and requires no model approximations or online optimization. The proposed framework is validated through simulation studies on a differential-drive robot and benchmarked against state-of-the-art methods, demonstrating superior robustness, accuracy, and computational efficiency.

</details>


### [9] [A Comprehensive Framework for Automated Quality Control in the Automotive Industry](https://arxiv.org/abs/2512.05579)
*Panagiota Moraiti,Panagiotis Giannikos,Athanasios Mastrogeorgiou,Panagiotis Mavridis,Linghao Zhou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 基于YOLO11n深度学习模型的机器人视觉检测系统，用于汽车压铸件的表面和螺纹缺陷自动化检测


<details>
  <summary>Details</summary>
Motivation: 为汽车制造业提供自动化质量检测解决方案，满足行业对高效、准确缺陷检测的需求，适应不同生产环境

Method: 集成两台协作机器人，配备高分辨率视觉系统，采用YOLO11n深度学习模型，结合图像切片、集成学习和边界框合并技术，优化镜头和照明配置

Result: 系统实现实时高性能检测，对各种缺陷具有高准确率，同时最小化误检，具有高度可扩展性

Conclusion: 该解决方案前景广阔，能够灵活适应不同生产环境，满足汽车行业不断变化的需求

Abstract: This paper presents a cutting-edge robotic inspection solution designed to automate quality control in automotive manufacturing. The system integrates a pair of collaborative robots, each equipped with a high-resolution camera-based vision system to accurately detect and localize surface and thread defects in aluminum high-pressure die casting (HPDC) automotive components. In addition, specialized lenses and optimized lighting configurations are employed to ensure consistent and high-quality image acquisition. The YOLO11n deep learning model is utilized, incorporating additional enhancements such as image slicing, ensemble learning, and bounding-box merging to significantly improve performance and minimize false detections. Furthermore, image processing techniques are applied to estimate the extent of the detected defects. Experimental results demonstrate real-time performance with high accuracy across a wide variety of defects, while minimizing false detections. The proposed solution is promising and highly scalable, providing the flexibility to adapt to various production environments and meet the evolving demands of the automotive industry.

</details>


### [10] [An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation](https://arxiv.org/abs/2512.05599)
*Panagiotis Giannikos,Lampis Papakostas,Evangelos Katralis,Panagiotis Mavridis,George Chryssinas,Myrto Inglezou,Nikolaos Panagopoulos,Antonis Porichis,Athanasios Mastrogeorgiou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 提出了一种集成X射线双能成像、YOLO/U-Net检测分割和Delta机器人抓取的电池回收系统，通过仿真和实际验证


<details>
  <summary>Details</summary>
Motivation: 电池回收日益重要但存在安全隐患，现有检测系统无法实现跨不同类型电子废料的电池准确识别和分拣

Method: 集成专用X射线双能成像子系统与先进预处理算法实现高对比度图像重建，结合YOLO和U-Net模型进行电池检测分割，采用智能跟踪定位算法引导Delta机器人选择性抓取

Result: 在NVIDIA Isaac Sim仿真环境和实际装置中验证了该方法的有效性

Conclusion: 提出的集成系统能够有效解决电子废料回收中电池的准确检测和分拣问题

Abstract: Battery recycling is becoming increasingly critical due to the rapid growth in battery usage and the limited availability of natural resources. Moreover, as battery energy densities continue to rise, improper handling during recycling poses significant safety hazards, including potential fires at recycling facilities. Numerous systems have been proposed for battery detection and removal from WEEE recycling lines, including X-ray and RGB-based visual inspection methods, typically driven by AI-powered object detection models (e.g., Mask R-CNN, YOLO, ResNets). Despite advances in optimizing detection techniques and model modifications, a fully autonomous solution capable of accurately identifying and sorting batteries across diverse WEEEs types has yet to be realized. In response to these challenges, we present our novel approach which integrates a specialized X-ray transmission dual energy imaging subsystem with advanced pre-processing algorithms, enabling high-contrast image reconstruction for effective differentiation of dense and thin materials in WEEE. Devices move along a conveyor belt through a high-resolution X-ray imaging system, where YOLO and U-Net models precisely detect and segment battery-containing items. An intelligent tracking and position estimation algorithm then guides a Delta robot equipped with a suction gripper to selectively extract and properly discard the targeted devices. The approach is validated in a photorealistic simulation environment developed in NVIDIA Isaac Sim and on the real setup.

</details>


### [11] [Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees](https://arxiv.org/abs/2512.05682)
*Yiming Shu,Jiahui Xu,Linghuan Kong,Fangni Zhang,Guodong Yin,Chen Sun*

Main category: cs.RO

TL;DR: 提出了一种面向自动驾驶轨迹预测的场景感知不确定性量化框架，通过共形校准生成预测区间，结合轨迹可靠性判别器评估预测可靠性，并在nuPlan数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习轨迹预测器缺乏适应异构真实场景的不确定性感知框架，而可靠的轨迹预测不确定性量化对安全关键自动驾驶系统至关重要。

Method: 1) 将预测轨迹和真实轨迹投影到Frenet坐标系的地图参考路径上；2) 使用CopulaCPTS作为共形校准方法为不同场景生成时间预测区间；3) 通过轨迹可靠性判别器(TRD)分析平均误差和校准置信区间建立可靠性模型；4) 风险感知判别器集成纵向和横向预测区间识别关键点，分割轨迹为可靠/不可靠段。

Result: 在真实世界nuPlan数据集上评估，证明该框架在不同驾驶场景中有效实现了场景感知的不确定性量化和可靠性评估。

Conclusion: 提出的框架为轨迹预测提供了预测区间和可靠性评估，能够为下游规划模块提供可操作的可靠性结果，在安全关键自动驾驶系统中具有重要应用价值。

Abstract: Reliable uncertainty quantification in trajectory prediction is crucial for safety-critical autonomous driving systems, yet existing deep learning predictors lack uncertainty-aware frameworks adaptable to heterogeneous real-world scenarios. To bridge this gap, we propose a novel scenario-aware uncertainty quantification framework to provide the predicted trajectories with prediction intervals and reliability assessment. To begin with, predicted trajectories from the trained predictor and their ground truth are projected onto the map-derived reference routes within the Frenet coordinate system. We then employ CopulaCPTS as the conformal calibration method to generate temporal prediction intervals for distinct scenarios as the uncertainty measure. Building upon this, within the proposed trajectory reliability discriminator (TRD), mean error and calibrated confidence intervals are synergistically analyzed to establish reliability models for different scenarios. Subsequently, the risk-aware discriminator leverages a joint risk model that integrates longitudinal and lateral prediction intervals within the Frenet coordinate to identify critical points. This enables segmentation of trajectories into reliable and unreliable segments, holding the advantage of informing downstream planning modules with actionable reliability results. We evaluated our framework using the real-world nuPlan dataset, demonstrating its effectiveness in scenario-aware uncertainty quantification and reliability assessment across diverse driving contexts.

</details>


### [12] [HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies](https://arxiv.org/abs/2512.05693)
*Zhiying Du,Bei Liu,Yaobo Liang,Yichao Shen,Haidong Cao,Xiangyu Zheng,Zhiyuan Feng,Zuxuan Wu,Jiaolong Yang,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: HiMoE-VLA是一个新颖的视觉-语言-动作框架，采用分层混合专家架构处理机器人演示数据的异质性，在模拟和真实机器人平台上表现出优于现有方法的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型开发需要大规模高质量的演示数据，但现有数据集存在严重的异质性（如不同机器人本体、动作空间、传感器配置、控制频率等）。现有方法缺乏处理这种异质性的明确设计，导致集成困难、泛化能力受限，在新场景中性能下降。

Method: 提出HiMoE-VLA框架，其中动作模块采用分层混合专家架构。该架构自适应地处理多个异质性来源，通过分层结构逐步将它们抽象为共享的知识表示，有效整合多样化的机器人数据。

Result: 在模拟基准测试和真实机器人平台上的广泛实验表明，HiMoE-VLA相比现有VLA基线方法实现了性能提升，获得了更高的准确性和更强的泛化能力，能够适应不同的机器人和动作空间。

Conclusion: HiMoE-VLA通过分层混合专家架构有效处理机器人数据的异质性，为构建更强大的具身智能基础模型提供了有前景的解决方案，代码和模型已开源。

Abstract: The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.

</details>


### [13] [Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning](https://arxiv.org/abs/2512.05711)
*Ali Krayani,Seyedeh Fatemeh Sadati,Lucio Marcenaro,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 本文提出了一种用于无人机在对抗性干扰环境下运行的层次化轨迹规划框架，结合贝叶斯主动推理和专家演示，实现干扰预测、干扰源定位和自适应轨迹调整。


<details>
  <summary>Details</summary>
Motivation: 无人机在对抗性干扰环境中运行时面临通信中断和任务失败的风险，传统方法缺乏对干扰源的先验知识，难以实现鲁棒的轨迹规划。

Method: 采用层次化轨迹规划框架，结合贝叶斯主动推理，将专家演示与概率生成模型结合，编码高层符号规划、低层运动策略和无线信号反馈，在线推理干扰并自适应调整轨迹。

Result: 仿真结果表明，该方法达到接近专家水平的性能，显著减少通信干扰和任务成本，相比无模型强化学习基线有更好表现，在动态环境中保持鲁棒泛化能力。

Conclusion: 提出的层次化主动推理框架为无人机在对抗性干扰环境中的轨迹规划提供了一种有效解决方案，无需干扰源先验知识，具有鲁棒性和泛化能力。

Abstract: This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.

</details>


### [14] [Global stability of vehicle-with-driver dynamics via Sum-of-Squares programming](https://arxiv.org/abs/2512.05806)
*Martino Gulisano,Marco Gabiccini*

Main category: cs.RO

TL;DR: 该研究通过优化Lyapunov函数和迭代SOS程序，估计了七状态车辆-驾驶员系统的安全不变子集，能够同时捕获渐近稳定性和轨迹上的状态安全边界约束。


<details>
  <summary>Details</summary>
Motivation: 需要为车辆-驾驶员系统估计安全不变子集，同时考虑渐近稳定性和状态安全边界约束，以支持实时安全评估和主动车辆控制的监督层应用。

Method: 采用原始迭代Sum-of-Squares（SOS）程序优化Lyapunov函数，首先在二状态基准系统验证，然后应用于七状态车辆-驾驶员系统。系统控制动力学通过延迟预览跟踪模型模拟人类驾驶员行为，并推导非线性车辆模型的多项式近似及其操作包络约束。

Result: 方法在二状态基准系统中准确恢复了预设安全区域作为多项式Lyapunov函数的1级集。在车辆-驾驶员系统的不足转向和过度转向场景中，估计的安全集与详尽仿真获得的参考边界进行了比较，结果显示SOS技术能够高效提供Lyapunov定义的安全区域。

Conclusion: SOS技术能够高效计算Lyapunov定义的安全区域，支持其在实时安全评估中的潜在应用，例如作为主动车辆控制的监督层。

Abstract: This work estimates safe invariant subsets of the Region of Attraction (ROA) for a seven-state vehicle-with-driver system, capturing both asymptotic stability and the influence of state-safety bounds along the system trajectory. Safe sets are computed by optimizing Lyapunov functions through an original iterative Sum-of-Squares (SOS) procedure. The method is first demonstrated on a two-state benchmark, where it accurately recovers a prescribed safe region as the 1-level set of a polynomial Lyapunov function. We then describe the distinguishing characteristics of the studied vehicle-with-driver system: the control dynamics mimic human driver behavior through a delayed preview-tracking model that, with suitable parameter choices, can also emulate digital controllers. To enable SOS optimization, a polynomial approximation of the nonlinear vehicle model is derived, together with its operating-envelope constraints. The framework is then applied to understeering and oversteering scenarios, and the estimated safe sets are compared with reference boundaries obtained from exhaustive simulations. The results show that SOS techniques can efficiently deliver Lyapunov-defined safe regions, supporting their potential use for real-time safety assessment, for example as a supervisory layer for active vehicle control.

</details>


### [15] [Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots](https://arxiv.org/abs/2512.05808)
*Sushmita Bhattacharya,Ninad Jadhav,Hammad Izhar,Karen Li,Kevin George,Robert Wood,Stephanie Gil*

Main category: cs.RO

TL;DR: 开发了基于模型强化学习的无人机系统，用于实时追踪和接触抹香鲸，结合声学追踪和鲸鱼潜水模型进行导航决策


<details>
  <summary>Details</summary>
Motivation: 解决海上实时追踪抹香鲸的技术挑战，包括多鲸鱼环境下的声学追踪、分布式机器人通信决策，以及从鱼类追踪器进行机载信号处理和远程检测

Method: 采用基于模型的强化学习方法，结合现场传感器数据和经验鲸鱼潜水模型来指导导航决策；系统包括实时声学追踪、分布式通信决策和机载信号处理

Result: 在多米尼加海域成功与抹香鲸进行了接触实验，同时进行了陆地硬件实验和基于海洋生物学家表面观测数据的鲸鱼轨迹模拟

Conclusion: 该系统能够有效实现海上抹香鲸的实时追踪和接触，为解决海洋生物研究中的追踪难题提供了可行的技术方案

Abstract: We introduce a system for real-time sperm whale rendezvous at sea using an autonomous uncrewed aerial vehicle. Our system employs model-based reinforcement learning that combines in situ sensor data with an empirical whale dive model to guide navigation decisions. Key challenges include (i) real-time acoustic tracking in the presence of multiple whales, (ii) distributed communication and decision-making for robot deployments, and (iii) on-board signal processing and long-range detection from fish-trackers. We evaluate our system by conducting rendezvous with sperm whales at sea in Dominica, performing hardware experiments on land, and running simulations using whale trajectories interpolated from marine biologists' surface observations.

</details>


### [16] [Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation](https://arxiv.org/abs/2512.05812)
*Fabian Konstantinidis,Moritz Sackmann,Ulrich Hofmann,Christoph Stiller*

Main category: cs.RO

TL;DR: 提出一种基于实例中心场景表示的可扩展多智能体驾驶仿真方法，通过局部坐标系建模交通参与者和地图元素，实现高效、视角不变的场景编码，并采用对抗逆强化学习优化行为模型。


<details>
  <summary>Details</summary>
Motivation: 可扩展的多智能体驾驶仿真需要既真实又计算高效的行为模型。现有方法在扩展性和计算效率方面存在挑战，需要优化控制单个交通参与者的行为模型。

Method: 1) 采用实例中心场景表示：每个交通参与者和地图元素在各自的局部坐标系中建模；2) 使用查询中心对称上下文编码器处理局部框架间的相对位置编码；3) 应用对抗逆强化学习训练行为模型；4) 提出自适应奖励变换来平衡训练中的鲁棒性和真实性。

Result: 该方法在令牌数量上高效扩展，显著减少了训练和推理时间，同时在位置准确性和鲁棒性方面优于多个智能体中心基线方法。

Conclusion: 提出的实例中心场景表示和对抗逆强化学习方法为可扩展的多智能体驾驶仿真提供了有效的解决方案，在保持真实性的同时显著提高了计算效率。

Abstract: Scalable multi-agent driving simulation requires behavior models that are both realistic and computationally efficient. We address this by optimizing the behavior model that controls individual traffic participants. To improve efficiency, we adopt an instance-centric scene representation, where each traffic participant and map element is modeled in its own local coordinate frame. This design enables efficient, viewpoint-invariant scene encoding and allows static map tokens to be reused across simulation steps. To model interactions, we employ a query-centric symmetric context encoder with relative positional encodings between local frames. We use Adversarial Inverse Reinforcement Learning to learn the behavior model and propose an adaptive reward transformation that automatically balances robustness and realism during training. Experiments demonstrate that our approach scales efficiently with the number of tokens, significantly reducing training and inference times, while outperforming several agent-centric baselines in terms of positional accuracy and robustness.

</details>


### [17] [Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints](https://arxiv.org/abs/2512.05815)
*Marios-Nektarios Stamatopoulos,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出一个多无人机协同3D打印框架，通过优化任务分配和调度实现无冲突并行作业，同时考虑几何结构依赖、安全约束和资源限制


<details>
  <summary>Details</summary>
Motivation: 解决多无人机同时进行空中3D打印时的协调问题，包括任务冲突、安全约束、资源限制和效率优化

Method: 建立优化问题模型，考虑任务依赖关系、无人机安全约束、材料使用和电池限制；采用重要性优先级加速计算；提出效用最大化公式动态确定最优无人机数量；通过Gazebo仿真验证

Result: 开发了一个有效的协调框架，能够在仿真环境中实现多无人机无冲突并行3D打印，平衡任务完成时间和资源使用效率

Conclusion: 提出的框架成功解决了多无人机协同3D打印的协调问题，通过优化调度和动态资源分配实现了高效、安全的并行作业

Abstract: This article presents a novel coordination and task-planning framework to enable the simultaneous conflict-free collaboration of multiple unmanned aerial vehicles (UAVs) for aerial 3D printing. The proposed framework formulates an optimization problem that takes a construction mission divided into sub-tasks and a team of autonomous UAVs, along with limited volume and battery. It generates an optimal mission plan comprising task assignments and scheduling while accounting for task dependencies arising from the geometric and structural requirements of the 3D design, inter-UAV safety constraints, material usage, and total flight time of each UAV. The potential conflicts occurring during the simultaneous operation of the UAVs are addressed at a segment level by dynamically selecting the starting time and location of each task to guarantee collision-free parallel execution. An importance prioritization is proposed to accelerate the computation by guiding the solution toward more important tasks. Additionally, a utility maximization formulation is proposed to dynamically determine the optimal number of UAVs required for a given mission, balancing the trade-off between minimizing makespan and the deployment of excess agents. The proposed framework's effectiveness is evaluated through a Gazebo-based simulation setup, where agents are coordinated by a mission control module allocating the printing tasks based on the generated optimal scheduling plan while remaining within the material and battery constraints of each UAV.

</details>


### [18] [Physically-Based Simulation of Automotive LiDAR](https://arxiv.org/abs/2512.05932)
*L. Dudzik,M. Roschani,A. Sielemann,K. Trampert,J. Ziehn,J. Beyerer,C. Neumann*

Main category: cs.RO

TL;DR: 提出了一种用于模拟汽车飞行时间激光雷达的分析模型，包含光晕效应、回波脉冲宽度和环境光等效应，并通过光学实验室测量系统性地确定模型参数。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个能够准确模拟汽车激光雷达系统性能的物理模型，该模型应包含实际系统中的关键效应（如光晕、回波脉冲宽度、环境光等），并通过实验测量来系统性地确定模型参数，以支持自动驾驶系统的开发和测试。

Method: 使用基于物理的渲染方法在近红外域进行建模，假设单次反射和逆向反射，通过栅格化渲染图像（着色或光线追踪）实现。模型考虑了传感器发射的光以及其他非相关光源（如阳光）产生的杂散光。光束发射和接收二极管的灵敏度通过灵活的光束转向模式和非零直径进行建模。模型参数通过实验室测量确定，使用测角仪以0.01°分辨率测量不同目标表面的光度亮度。

Result: 该方法成功校准并测试了两个汽车激光雷达系统：Valeo Scala Gen. 2和Blickfeld Cube 1。尽管这两个系统在特性和可用接口上存在显著差异，但相关模型参数均能成功提取。

Conclusion: 提出的分析模型能够准确模拟汽车激光雷达系统，包含关键物理效应，并通过实验测量系统性地确定参数。该方法适用于不同类型的激光雷达系统，为自动驾驶系统的开发和测试提供了可靠的仿真工具。

Abstract: We present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter.
  Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties.
  Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01° resolution, which marks the best available resolution for measuring the beam pattern.
  The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.

</details>


### [19] [Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning](https://arxiv.org/abs/2512.05953)
*Yunhao Cao,Zubin Bhaumik,Jessie Jia,Xingyi He,Kuan Fang*

Main category: cs.RO

TL;DR: COIL是一种用于3D视觉运动控制的对应导向模仿学习框架，通过关键点运动定义任务，支持可变时空粒度的任务规范，使用时空注意力机制融合多模态信息，在真实世界操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设固定数量的关键点或均匀时间间隔，缺乏对用户意图和任务需求的适应性。需要一种能够灵活表示任务、支持可变时空粒度的框架来处理复杂的真实世界操作任务。

Method: 通过场景中物体上选择的关键点的预期运动来定义任务，使用具有时空注意力机制的条件策略融合多模态信息，通过模拟中收集的演示进行自监督训练，并事后自动生成对应标签。

Result: COIL在真实世界操作任务中，无论是稀疏还是密集的任务规范下，都表现出优于先前方法的性能，能够跨任务、物体和运动模式进行泛化。

Conclusion: COIL提供了一个灵活的任务表示框架，通过对应导向的方法和时空注意力机制，在真实世界操作任务中实现了优越的性能和泛化能力。

Abstract: We introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.

</details>


### [20] [SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models](https://arxiv.org/abs/2512.05955)
*Haowen Liu,Shaoxiong Yao,Haonan Chen,Jiawei Gao,Jiayuan Mao,Jia-Bin Huang,Yilun Du*

Main category: cs.RO

TL;DR: SIMPACT框架通过仿真循环为视觉语言模型提供物理推理能力，无需额外训练，在精细物理推理任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然具有常识和语义推理能力，但缺乏对物理动力学的理解，这限制了其在需要物理理解和动作规划的精细机器人操作任务中的应用

Method: 提出SIMPACT框架，在测试时通过仿真循环进行世界建模：从单次RGB-D观测构建物理仿真，使VLM能够提出动作、观察仿真结果并迭代优化推理

Result: 在五个需要精细物理推理的刚体和可变形物体操作任务中实现了最先进的性能，超越了现有的通用机器人操作模型

Conclusion: 通过高效仿真将物理理解嵌入VLM推理，为实现通用具身智能提供了有前景的路径

Abstract: Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

</details>


### [21] [Training-Time Action Conditioning for Efficient Real-Time Chunking](https://arxiv.org/abs/2512.05964)
*Kevin Black,Allen Z. Ren,Michael Equi,Sergey Levine*

Main category: cs.RO

TL;DR: 提出训练时实时分块方法替代推理时修复，通过模拟推理延迟直接条件化动作前缀，消除推理开销，保持性能的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 实时分块技术通过推理时修复实现平滑的机器人轨迹生成，但这种方法引入了计算开销，增加了推理延迟。需要一种更高效的替代方案。

Method: 在训练时模拟推理延迟，直接条件化动作前缀，无需修改模型架构或机器人运行时系统，仅需少量代码修改即可实现。

Result: 在模拟实验中，训练时RTC在高推理延迟下优于推理时RTC；在真实世界实验中（盒子搭建和意式浓缩制作任务），训练时RTC保持任务性能和速度与推理时RTC相当，但计算成本更低。

Conclusion: 训练时动作条件化是推理时修复在实时机器人控制中的实用替代方案，能够在不牺牲性能的情况下降低计算开销。

Abstract: Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.

</details>
